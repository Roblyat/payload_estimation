[2026-01-30 16:44:30] kBestModel^2 started ts=20260130_164430
[2026-01-30 16:44:30] START best_delan (5x10^4_under): /home/robat/.venv/ape_sweep/bin/python3 /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/services/sweep/scripts/run_sweep_delan.py
docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 0 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-e6tk9u_n because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x75f82019e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:44:35.089012: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:44:36.738474: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   2.9s, Loss=8.81e+03, Inv=8.81e+03, For=6.08e+00, Power=7.39e+02
  [eval] val_mse=2.183e+02  (n=7000)
Epoch 00002: Time=   4.5s, Loss=1.35e+03, Inv=1.35e+03, For=5.76e+00, Power=1.91e+02
  [eval] val_mse=1.132e+02  (n=7000)
Epoch 00003: Time=   4.6s, Loss=5.60e+02, Inv=5.60e+02, For=5.61e+00, Power=1.10e+02
  [eval] val_mse=8.204e+01  (n=7000)
Epoch 00004: Time=   4.6s, Loss=3.27e+02, Inv=3.27e+02, For=5.56e+00, Power=7.59e+01
  [eval] val_mse=6.378e+01  (n=7000)
Epoch 00005: Time=   4.6s, Loss=2.23e+02, Inv=2.23e+02, For=5.52e+00, Power=5.48e+01
  [eval] val_mse=5.084e+01  (n=7000)
Epoch 00006: Time=   4.7s, Loss=1.63e+02, Inv=1.63e+02, For=5.46e+00, Power=4.07e+01
  [eval] val_mse=4.155e+01  (n=7000)
Epoch 00007: Time=   4.7s, Loss=1.26e+02, Inv=1.26e+02, For=5.38e+00, Power=3.06e+01
  [eval] val_mse=3.457e+01  (n=7000)
Epoch 00008: Time=   4.7s, Loss=1.01e+02, Inv=1.01e+02, For=5.34e+00, Power=2.39e+01
  [eval] val_mse=2.928e+01  (n=7000)
Epoch 00009: Time=   4.8s, Loss=8.34e+01, Inv=8.34e+01, For=5.34e+00, Power=1.93e+01
  [eval] val_mse=2.501e+01  (n=7000)
Epoch 00010: Time=   4.8s, Loss=6.99e+01, Inv=6.99e+01, For=5.31e+00, Power=1.56e+01
  [eval] val_mse=2.165e+01  (n=7000)
Epoch 00011: Time=   4.8s, Loss=5.97e+01, Inv=5.97e+01, For=5.30e+00, Power=1.30e+01
  [eval] val_mse=1.887e+01  (n=7000)
Epoch 00012: Time=   4.8s, Loss=5.15e+01, Inv=5.15e+01, For=5.28e+00, Power=1.09e+01
  [eval] val_mse=1.658e+01  (n=7000)
Epoch 00013: Time=   4.9s, Loss=4.51e+01, Inv=4.51e+01, For=5.29e+00, Power=9.30e+00
  [eval] val_mse=1.468e+01  (n=7000)
Epoch 00014: Time=   4.9s, Loss=3.98e+01, Inv=3.98e+01, For=5.28e+00, Power=8.01e+00
  [eval] val_mse=1.308e+01  (n=7000)
Epoch 00015: Time=   4.9s, Loss=3.55e+01, Inv=3.55e+01, For=5.31e+00, Power=6.98e+00
  [eval] val_mse=1.173e+01  (n=7000)
Epoch 00016: Time=   5.0s, Loss=3.21e+01, Inv=3.21e+01, For=5.35e+00, Power=6.17e+00
  [eval] val_mse=1.055e+01  (n=7000)
Epoch 00017: Time=   5.0s, Loss=2.90e+01, Inv=2.90e+01, For=5.38e+00, Power=5.44e+00
  [eval] val_mse=9.551e+00  (n=7000)
Epoch 00018: Time=   5.0s, Loss=2.64e+01, Inv=2.64e+01, For=5.42e+00, Power=4.85e+00
  [eval] val_mse=8.694e+00  (n=7000)
Epoch 00019: Time=   5.0s, Loss=2.41e+01, Inv=2.41e+01, For=5.49e+00, Power=4.37e+00
  [eval] val_mse=7.948e+00  (n=7000)
Epoch 00020: Time=   5.1s, Loss=2.22e+01, Inv=2.22e+01, For=5.55e+00, Power=3.97e+00
  [eval] val_mse=7.286e+00  (n=7000)
Epoch 00021: Time=   5.1s, Loss=2.05e+01, Inv=2.05e+01, For=5.62e+00, Power=3.63e+00
  [eval] val_mse=6.720e+00  (n=7000)
Epoch 00022: Time=   5.1s, Loss=1.90e+01, Inv=1.90e+01, For=5.68e+00, Power=3.32e+00
  [eval] val_mse=6.216e+00  (n=7000)
Epoch 00023: Time=   5.2s, Loss=1.77e+01, Inv=1.77e+01, For=5.80e+00, Power=3.05e+00
  [eval] val_mse=5.777e+00  (n=7000)
Epoch 00024: Time=   5.2s, Loss=1.66e+01, Inv=1.66e+01, For=5.92e+00, Power=2.83e+00
  [eval] val_mse=5.382e+00  (n=7000)
Epoch 00025: Time=   5.2s, Loss=1.56e+01, Inv=1.56e+01, For=6.03e+00, Power=2.62e+00
  [eval] val_mse=5.034e+00  (n=7000)
Epoch 00026: Time=   5.2s, Loss=1.47e+01, Inv=1.47e+01, For=6.16e+00, Power=2.44e+00
  [eval] val_mse=4.719e+00  (n=7000)
Epoch 00027: Time=   5.3s, Loss=1.39e+01, Inv=1.39e+01, For=6.31e+00, Power=2.30e+00
  [eval] val_mse=4.448e+00  (n=7000)
Epoch 00028: Time=   5.3s, Loss=1.32e+01, Inv=1.32e+01, For=6.49e+00, Power=2.17e+00
  [eval] val_mse=4.201e+00  (n=7000)
Epoch 00029: Time=   5.3s, Loss=1.26e+01, Inv=1.26e+01, For=6.66e+00, Power=2.05e+00
  [eval] val_mse=3.969e+00  (n=7000)
Epoch 00030: Time=   5.4s, Loss=1.19e+01, Inv=1.19e+01, For=6.84e+00, Power=1.93e+00
  [eval] val_mse=3.764e+00  (n=7000)
Epoch 00031: Time=   5.4s, Loss=1.14e+01, Inv=1.14e+01, For=7.01e+00, Power=1.83e+00
  [eval] val_mse=3.585e+00  (n=7000)
Epoch 00032: Time=   5.4s, Loss=1.09e+01, Inv=1.09e+01, For=7.23e+00, Power=1.74e+00
  [eval] val_mse=3.412e+00  (n=7000)
Epoch 00033: Time=   5.5s, Loss=1.05e+01, Inv=1.05e+01, For=7.46e+00, Power=1.67e+00
  [eval] val_mse=3.257e+00  (n=7000)
Epoch 00034: Time=   5.5s, Loss=1.01e+01, Inv=1.01e+01, For=7.72e+00, Power=1.60e+00
  [eval] val_mse=3.114e+00  (n=7000)
Epoch 00035: Time=   5.5s, Loss=9.71e+00, Inv=9.71e+00, For=7.97e+00, Power=1.54e+00
  [eval] val_mse=2.982e+00  (n=7000)
Epoch 00036: Time=   5.5s, Loss=9.37e+00, Inv=9.37e+00, For=8.21e+00, Power=1.48e+00
  [eval] val_mse=2.862e+00  (n=7000)
Epoch 00037: Time=   5.6s, Loss=9.05e+00, Inv=9.05e+00, For=8.51e+00, Power=1.43e+00
  [eval] val_mse=2.750e+00  (n=7000)
Epoch 00038: Time=   5.6s, Loss=8.78e+00, Inv=8.78e+00, For=8.80e+00, Power=1.38e+00
  [eval] val_mse=2.646e+00  (n=7000)
Epoch 00039: Time=   5.6s, Loss=8.51e+00, Inv=8.51e+00, For=9.10e+00, Power=1.34e+00
  [eval] val_mse=2.551e+00  (n=7000)
Epoch 00040: Time=   5.7s, Loss=8.25e+00, Inv=8.25e+00, For=9.44e+00, Power=1.29e+00
  [eval] val_mse=2.460e+00  (n=7000)
Epoch 00041: Time=   5.7s, Loss=8.01e+00, Inv=8.01e+00, For=9.77e+00, Power=1.26e+00
  [eval] val_mse=2.374e+00  (n=7000)
Epoch 00042: Time=   5.7s, Loss=7.81e+00, Inv=7.81e+00, For=1.01e+01, Power=1.22e+00
  [eval] val_mse=2.297e+00  (n=7000)
Epoch 00043: Time=   5.7s, Loss=7.60e+00, Inv=7.60e+00, For=1.05e+01, Power=1.19e+00
  [eval] val_mse=2.226e+00  (n=7000)
Epoch 00044: Time=   5.8s, Loss=7.43e+00, Inv=7.43e+00, For=1.08e+01, Power=1.16e+00
  [eval] val_mse=2.156e+00  (n=7000)
Epoch 00045: Time=   5.8s, Loss=7.25e+00, Inv=7.25e+00, For=1.12e+01, Power=1.14e+00
  [eval] val_mse=2.092e+00  (n=7000)
Epoch 00046: Time=   5.8s, Loss=7.08e+00, Inv=7.08e+00, For=1.17e+01, Power=1.11e+00
  [eval] val_mse=2.031e+00  (n=7000)
Epoch 00047: Time=   5.9s, Loss=6.91e+00, Inv=6.91e+00, For=1.20e+01, Power=1.09e+00
  [eval] val_mse=1.972e+00  (n=7000)
Epoch 00048: Time=   5.9s, Loss=6.77e+00, Inv=6.77e+00, For=1.25e+01, Power=1.07e+00
  [eval] val_mse=1.918e+00  (n=7000)
Epoch 00049: Time=   5.9s, Loss=6.62e+00, Inv=6.62e+00, For=1.29e+01, Power=1.04e+00
  [eval] val_mse=1.866e+00  (n=7000)
Epoch 00050: Time=   5.9s, Loss=6.51e+00, Inv=6.51e+00, For=1.33e+01, Power=1.03e+00
  [eval] val_mse=1.819e+00  (n=7000)
Epoch 00051: Time=   6.0s, Loss=6.39e+00, Inv=6.39e+00, For=1.38e+01, Power=1.01e+00
  [eval] val_mse=1.774e+00  (n=7000)
Epoch 00052: Time=   6.0s, Loss=6.27e+00, Inv=6.27e+00, For=1.42e+01, Power=9.92e-01
  [eval] val_mse=1.729e+00  (n=7000)
Epoch 00053: Time=   6.0s, Loss=6.16e+00, Inv=6.16e+00, For=1.47e+01, Power=9.83e-01
  [eval] val_mse=1.688e+00  (n=7000)
Epoch 00054: Time=   6.1s, Loss=6.06e+00, Inv=6.06e+00, For=1.53e+01, Power=9.69e-01
  [eval] val_mse=1.649e+00  (n=7000)
Epoch 00055: Time=   6.1s, Loss=5.96e+00, Inv=5.96e+00, For=1.57e+01, Power=9.55e-01
  [eval] val_mse=1.610e+00  (n=7000)
Epoch 00056: Time=   6.1s, Loss=5.86e+00, Inv=5.86e+00, For=1.62e+01, Power=9.43e-01
  [eval] val_mse=1.574e+00  (n=7000)
Epoch 00057: Time=   6.2s, Loss=5.77e+00, Inv=5.77e+00, For=1.67e+01, Power=9.34e-01
  [eval] val_mse=1.540e+00  (n=7000)
Epoch 00058: Time=   6.2s, Loss=5.70e+00, Inv=5.70e+00, For=1.73e+01, Power=9.21e-01
  [eval] val_mse=1.507e+00  (n=7000)
Epoch 00059: Time=   6.2s, Loss=5.61e+00, Inv=5.61e+00, For=1.78e+01, Power=9.07e-01
  [eval] val_mse=1.476e+00  (n=7000)
Epoch 00060: Time=   6.2s, Loss=5.54e+00, Inv=5.54e+00, For=1.84e+01, Power=9.04e-01
  [eval] val_mse=1.448e+00  (n=7000)
Epoch 00061: Time=   6.3s, Loss=5.46e+00, Inv=5.46e+00, For=1.89e+01, Power=8.97e-01
  [eval] val_mse=1.418e+00  (n=7000)
Epoch 00062: Time=   6.3s, Loss=5.39e+00, Inv=5.39e+00, For=1.94e+01, Power=8.87e-01
  [eval] val_mse=1.391e+00  (n=7000)
Epoch 00063: Time=   6.3s, Loss=5.32e+00, Inv=5.32e+00, For=2.00e+01, Power=8.81e-01
  [eval] val_mse=1.365e+00  (n=7000)
Epoch 00064: Time=   6.4s, Loss=5.26e+00, Inv=5.26e+00, For=2.06e+01, Power=8.70e-01
  [eval] val_mse=1.339e+00  (n=7000)
Epoch 00065: Time=   6.4s, Loss=5.19e+00, Inv=5.19e+00, For=2.12e+01, Power=8.66e-01
  [eval] val_mse=1.316e+00  (n=7000)
Epoch 00066: Time=   6.4s, Loss=5.13e+00, Inv=5.13e+00, For=2.18e+01, Power=8.56e-01
  [eval] val_mse=1.293e+00  (n=7000)
Epoch 00067: Time=   6.5s, Loss=5.07e+00, Inv=5.07e+00, For=2.24e+01, Power=8.52e-01
  [eval] val_mse=1.271e+00  (n=7000)
Epoch 00068: Time=   6.5s, Loss=5.01e+00, Inv=5.01e+00, For=2.30e+01, Power=8.46e-01
  [eval] val_mse=1.250e+00  (n=7000)
Epoch 00069: Time=   6.5s, Loss=4.96e+00, Inv=4.96e+00, For=2.36e+01, Power=8.36e-01
  [eval] val_mse=1.229e+00  (n=7000)
Epoch 00070: Time=   6.5s, Loss=4.91e+00, Inv=4.91e+00, For=2.42e+01, Power=8.39e-01
  [eval] val_mse=1.210e+00  (n=7000)
Epoch 00071: Time=   6.6s, Loss=4.86e+00, Inv=4.86e+00, For=2.48e+01, Power=8.30e-01
  [eval] val_mse=1.192e+00  (n=7000)
Epoch 00072: Time=   6.6s, Loss=4.81e+00, Inv=4.81e+00, For=2.55e+01, Power=8.25e-01
  [eval] val_mse=1.173e+00  (n=7000)
Epoch 00073: Time=   6.6s, Loss=4.75e+00, Inv=4.75e+00, For=2.60e+01, Power=8.21e-01
  [eval] val_mse=1.155e+00  (n=7000)
Epoch 00074: Time=   6.7s, Loss=4.71e+00, Inv=4.71e+00, For=2.67e+01, Power=8.17e-01
  [eval] val_mse=1.140e+00  (n=7000)
Epoch 00075: Time=   6.7s, Loss=4.67e+00, Inv=4.67e+00, For=2.74e+01, Power=8.16e-01
  [eval] val_mse=1.124e+00  (n=7000)
Epoch 00076: Time=   6.7s, Loss=4.63e+00, Inv=4.63e+00, For=2.80e+01, Power=8.12e-01
  [eval] val_mse=1.110e+00  (n=7000)
Epoch 00077: Time=   6.7s, Loss=4.58e+00, Inv=4.58e+00, For=2.86e+01, Power=8.04e-01
  [eval] val_mse=1.093e+00  (n=7000)
Epoch 00078: Time=   6.8s, Loss=4.55e+00, Inv=4.55e+00, For=2.93e+01, Power=8.03e-01
  [eval] val_mse=1.079e+00  (n=7000)
Epoch 00079: Time=   6.8s, Loss=4.51e+00, Inv=4.51e+00, For=2.99e+01, Power=7.98e-01
  [eval] val_mse=1.066e+00  (n=7000)
Epoch 00080: Time=   6.8s, Loss=4.47e+00, Inv=4.47e+00, For=3.06e+01, Power=7.97e-01
  [eval] val_mse=1.051e+00  (n=7000)
Epoch 00081: Time=   6.9s, Loss=4.43e+00, Inv=4.43e+00, For=3.14e+01, Power=7.96e-01
  [eval] val_mse=1.039e+00  (n=7000)
Epoch 00082: Time=   6.9s, Loss=4.41e+00, Inv=4.41e+00, For=3.20e+01, Power=7.94e-01
  [eval] val_mse=1.025e+00  (n=7000)
Epoch 00083: Time=   6.9s, Loss=4.38e+00, Inv=4.38e+00, For=3.27e+01, Power=7.93e-01
  [eval] val_mse=1.015e+00  (n=7000)
Epoch 00084: Time=   6.9s, Loss=4.35e+00, Inv=4.35e+00, For=3.34e+01, Power=7.87e-01
  [eval] val_mse=1.003e+00  (n=7000)
Epoch 00085: Time=   7.0s, Loss=4.31e+00, Inv=4.31e+00, For=3.40e+01, Power=7.86e-01
  [eval] val_mse=9.920e-01  (n=7000)
Epoch 00086: Time=   7.0s, Loss=4.28e+00, Inv=4.28e+00, For=3.48e+01, Power=7.84e-01
  [eval] val_mse=9.821e-01  (n=7000)
Epoch 00087: Time=   7.0s, Loss=4.25e+00, Inv=4.25e+00, For=3.55e+01, Power=7.79e-01
  [eval] val_mse=9.704e-01  (n=7000)
Epoch 00088: Time=   7.1s, Loss=4.23e+00, Inv=4.23e+00, For=3.61e+01, Power=7.80e-01
  [eval] val_mse=9.602e-01  (n=7000)
Epoch 00089: Time=   7.1s, Loss=4.20e+00, Inv=4.20e+00, For=3.68e+01, Power=7.80e-01
  [eval] val_mse=9.489e-01  (n=7000)
Epoch 00090: Time=   7.1s, Loss=4.18e+00, Inv=4.18e+00, For=3.76e+01, Power=7.77e-01
  [eval] val_mse=9.400e-01  (n=7000)
Epoch 00091: Time=   7.1s, Loss=4.15e+00, Inv=4.15e+00, For=3.84e+01, Power=7.74e-01
  [eval] val_mse=9.301e-01  (n=7000)
Epoch 00092: Time=   7.2s, Loss=4.13e+00, Inv=4.13e+00, For=3.90e+01, Power=7.73e-01
  [eval] val_mse=9.218e-01  (n=7000)
Epoch 00093: Time=   7.2s, Loss=4.10e+00, Inv=4.10e+00, For=3.95e+01, Power=7.69e-01
  [eval] val_mse=9.129e-01  (n=7000)
Epoch 00094: Time=   7.2s, Loss=4.08e+00, Inv=4.08e+00, For=4.05e+01, Power=7.72e-01
  [eval] val_mse=9.035e-01  (n=7000)
Epoch 00095: Time=   7.3s, Loss=4.06e+00, Inv=4.06e+00, For=4.12e+01, Power=7.64e-01
  [eval] val_mse=8.950e-01  (n=7000)
Epoch 00096: Time=   7.3s, Loss=4.04e+00, Inv=4.04e+00, For=4.20e+01, Power=7.68e-01
  [eval] val_mse=8.864e-01  (n=7000)
Epoch 00097: Time=   7.3s, Loss=4.02e+00, Inv=4.02e+00, For=4.26e+01, Power=7.65e-01
  [eval] val_mse=8.778e-01  (n=7000)
Epoch 00098: Time=   7.4s, Loss=4.00e+00, Inv=4.00e+00, For=4.34e+01, Power=7.67e-01
  [eval] val_mse=8.696e-01  (n=7000)
Epoch 00099: Time=   7.4s, Loss=3.98e+00, Inv=3.98e+00, For=4.43e+01, Power=7.67e-01
  [eval] val_mse=8.615e-01  (n=7000)
Epoch 00100: Time=   7.4s, Loss=3.97e+00, Inv=3.97e+00, For=4.47e+01, Power=7.67e-01
  [eval] val_mse=8.532e-01  (n=7000)
Epoch 00101: Time=   7.4s, Loss=3.95e+00, Inv=3.95e+00, For=4.54e+01, Power=7.63e-01
  [eval] val_mse=8.464e-01  (n=7000)
Epoch 00102: Time=   7.5s, Loss=3.93e+00, Inv=3.93e+00, For=4.61e+01, Power=7.59e-01
  [eval] val_mse=8.379e-01  (n=7000)
Epoch 00103: Time=   7.5s, Loss=3.91e+00, Inv=3.91e+00, For=4.69e+01, Power=7.59e-01
  [eval] val_mse=8.304e-01  (n=7000)
Epoch 00104: Time=   7.5s, Loss=3.90e+00, Inv=3.90e+00, For=4.74e+01, Power=7.60e-01
  [eval] val_mse=8.248e-01  (n=7000)
Epoch 00105: Time=   7.6s, Loss=3.88e+00, Inv=3.88e+00, For=4.82e+01, Power=7.60e-01
  [eval] val_mse=8.160e-01  (n=7000)
Epoch 00106: Time=   7.6s, Loss=3.86e+00, Inv=3.86e+00, For=4.88e+01, Power=7.57e-01
  [eval] val_mse=8.084e-01  (n=7000)
Epoch 00107: Time=   7.6s, Loss=3.85e+00, Inv=3.85e+00, For=4.93e+01, Power=7.56e-01
  [eval] val_mse=8.015e-01  (n=7000)
Epoch 00108: Time=   7.6s, Loss=3.84e+00, Inv=3.84e+00, For=5.02e+01, Power=7.55e-01
  [eval] val_mse=7.946e-01  (n=7000)
Epoch 00109: Time=   7.7s, Loss=3.82e+00, Inv=3.82e+00, For=5.06e+01, Power=7.54e-01
  [eval] val_mse=7.874e-01  (n=7000)
Epoch 00110: Time=   7.7s, Loss=3.80e+00, Inv=3.80e+00, For=5.12e+01, Power=7.50e-01
  [eval] val_mse=7.819e-01  (n=7000)
Epoch 00111: Time=   7.7s, Loss=3.79e+00, Inv=3.79e+00, For=5.23e+01, Power=7.53e-01
  [eval] val_mse=7.753e-01  (n=7000)
Epoch 00112: Time=   7.8s, Loss=3.78e+00, Inv=3.78e+00, For=5.27e+01, Power=7.55e-01
  [eval] val_mse=7.683e-01  (n=7000)
Epoch 00113: Time=   7.8s, Loss=3.77e+00, Inv=3.77e+00, For=5.35e+01, Power=7.55e-01
  [eval] val_mse=7.617e-01  (n=7000)
Epoch 00114: Time=   7.8s, Loss=3.76e+00, Inv=3.76e+00, For=5.39e+01, Power=7.52e-01
  [eval] val_mse=7.552e-01  (n=7000)
Epoch 00115: Time=   7.9s, Loss=3.75e+00, Inv=3.75e+00, For=5.46e+01, Power=7.49e-01
  [eval] val_mse=7.491e-01  (n=7000)
Epoch 00116: Time=   7.9s, Loss=3.74e+00, Inv=3.74e+00, For=5.51e+01, Power=7.48e-01
  [eval] val_mse=7.436e-01  (n=7000)
Epoch 00117: Time=   7.9s, Loss=3.72e+00, Inv=3.72e+00, For=5.53e+01, Power=7.46e-01
  [eval] val_mse=7.353e-01  (n=7000)
Epoch 00118: Time=   8.0s, Loss=3.71e+00, Inv=3.71e+00, For=5.60e+01, Power=7.47e-01
  [eval] val_mse=7.304e-01  (n=7000)
Epoch 00119: Time=   8.0s, Loss=3.70e+00, Inv=3.70e+00, For=5.70e+01, Power=7.47e-01
  [eval] val_mse=7.247e-01  (n=7000)
Epoch 00120: Time=   8.0s, Loss=3.68e+00, Inv=3.68e+00, For=5.71e+01, Power=7.45e-01
  [eval] val_mse=7.187e-01  (n=7000)
Epoch 00121: Time=   8.1s, Loss=3.68e+00, Inv=3.68e+00, For=5.76e+01, Power=7.46e-01
  [eval] val_mse=7.127e-01  (n=7000)
Epoch 00122: Time=   8.1s, Loss=3.67e+00, Inv=3.67e+00, For=5.85e+01, Power=7.46e-01
  [eval] val_mse=7.073e-01  (n=7000)
Epoch 00123: Time=   8.1s, Loss=3.65e+00, Inv=3.65e+00, For=5.86e+01, Power=7.43e-01
  [eval] val_mse=7.012e-01  (n=7000)
Epoch 00124: Time=   8.1s, Loss=3.65e+00, Inv=3.65e+00, For=5.93e+01, Power=7.45e-01
  [eval] val_mse=6.950e-01  (n=7000)
Epoch 00125: Time=   8.2s, Loss=3.64e+00, Inv=3.64e+00, For=5.99e+01, Power=7.42e-01
  [eval] val_mse=6.898e-01  (n=7000)
Epoch 00126: Time=   8.2s, Loss=3.63e+00, Inv=3.63e+00, For=6.01e+01, Power=7.43e-01
  [eval] val_mse=6.844e-01  (n=7000)
Epoch 00127: Time=   8.2s, Loss=3.62e+00, Inv=3.62e+00, For=6.06e+01, Power=7.40e-01
  [eval] val_mse=6.796e-01  (n=7000)
Epoch 00128: Time=   8.3s, Loss=3.61e+00, Inv=3.61e+00, For=6.13e+01, Power=7.39e-01
  [eval] val_mse=6.740e-01  (n=7000)
Epoch 00129: Time=   8.3s, Loss=3.60e+00, Inv=3.60e+00, For=6.14e+01, Power=7.37e-01
  [eval] val_mse=6.684e-01  (n=7000)
Epoch 00130: Time=   8.3s, Loss=3.59e+00, Inv=3.59e+00, For=6.21e+01, Power=7.38e-01
  [eval] val_mse=6.641e-01  (n=7000)
Epoch 00131: Time=   8.4s, Loss=3.58e+00, Inv=3.58e+00, For=6.25e+01, Power=7.39e-01
  [eval] val_mse=6.587e-01  (n=7000)
Epoch 00132: Time=   8.4s, Loss=3.57e+00, Inv=3.57e+00, For=6.24e+01, Power=7.34e-01
  [eval] val_mse=6.526e-01  (n=7000)
Epoch 00133: Time=   8.4s, Loss=3.56e+00, Inv=3.56e+00, For=6.29e+01, Power=7.37e-01
  [eval] val_mse=6.486e-01  (n=7000)
Epoch 00134: Time=   8.4s, Loss=3.55e+00, Inv=3.55e+00, For=6.35e+01, Power=7.37e-01
  [eval] val_mse=6.431e-01  (n=7000)
Epoch 00135: Time=   8.5s, Loss=3.54e+00, Inv=3.54e+00, For=6.32e+01, Power=7.33e-01
  [eval] val_mse=6.374e-01  (n=7000)
Epoch 00136: Time=   8.5s, Loss=3.53e+00, Inv=3.53e+00, For=6.39e+01, Power=7.34e-01
  [eval] val_mse=6.335e-01  (n=7000)
Epoch 00137: Time=   8.5s, Loss=3.53e+00, Inv=3.53e+00, For=6.43e+01, Power=7.33e-01
  [eval] val_mse=6.285e-01  (n=7000)
Epoch 00138: Time=   8.6s, Loss=3.52e+00, Inv=3.52e+00, For=6.47e+01, Power=7.29e-01
  [eval] val_mse=6.231e-01  (n=7000)
Epoch 00139: Time=   8.6s, Loss=3.51e+00, Inv=3.51e+00, For=6.49e+01, Power=7.30e-01
  [eval] val_mse=6.195e-01  (n=7000)
Epoch 00140: Time=   8.6s, Loss=3.50e+00, Inv=3.50e+00, For=6.52e+01, Power=7.30e-01
  [eval] val_mse=6.141e-01  (n=7000)
Epoch 00141: Time=   8.6s, Loss=3.50e+00, Inv=3.50e+00, For=6.55e+01, Power=7.29e-01
  [eval] val_mse=6.089e-01  (n=7000)
Epoch 00142: Time=   8.7s, Loss=3.49e+00, Inv=3.49e+00, For=6.52e+01, Power=7.28e-01
  [eval] val_mse=6.045e-01  (n=7000)
Epoch 00143: Time=   8.7s, Loss=3.48e+00, Inv=3.48e+00, For=6.54e+01, Power=7.26e-01
  [eval] val_mse=6.000e-01  (n=7000)
Epoch 00144: Time=   8.7s, Loss=3.47e+00, Inv=3.47e+00, For=6.57e+01, Power=7.27e-01
  [eval] val_mse=5.956e-01  (n=7000)
Epoch 00145: Time=   8.8s, Loss=3.46e+00, Inv=3.46e+00, For=6.61e+01, Power=7.25e-01
  [eval] val_mse=5.911e-01  (n=7000)
Epoch 00146: Time=   8.8s, Loss=3.46e+00, Inv=3.46e+00, For=6.65e+01, Power=7.25e-01
  [eval] val_mse=5.868e-01  (n=7000)
Epoch 00147: Time=   8.8s, Loss=3.45e+00, Inv=3.45e+00, For=6.62e+01, Power=7.21e-01
  [eval] val_mse=5.826e-01  (n=7000)
Epoch 00148: Time=   8.9s, Loss=3.44e+00, Inv=3.44e+00, For=6.67e+01, Power=7.22e-01
  [eval] val_mse=5.792e-01  (n=7000)
Epoch 00149: Time=   8.9s, Loss=3.44e+00, Inv=3.44e+00, For=6.72e+01, Power=7.23e-01
  [eval] val_mse=5.746e-01  (n=7000)
Epoch 00150: Time=   8.9s, Loss=3.43e+00, Inv=3.43e+00, For=6.70e+01, Power=7.22e-01
  [eval] val_mse=5.711e-01  (n=7000)
Epoch 00151: Time=   9.0s, Loss=3.42e+00, Inv=3.42e+00, For=6.73e+01, Power=7.20e-01
  [eval] val_mse=5.658e-01  (n=7000)
Epoch 00152: Time=   9.0s, Loss=3.41e+00, Inv=3.41e+00, For=6.75e+01, Power=7.17e-01
  [eval] val_mse=5.622e-01  (n=7000)
Epoch 00153: Time=   9.0s, Loss=3.40e+00, Inv=3.40e+00, For=6.75e+01, Power=7.15e-01
  [eval] val_mse=5.582e-01  (n=7000)
Epoch 00154: Time=   9.1s, Loss=3.40e+00, Inv=3.40e+00, For=6.76e+01, Power=7.17e-01
  [eval] val_mse=5.541e-01  (n=7000)
Epoch 00155: Time=   9.1s, Loss=3.39e+00, Inv=3.39e+00, For=6.77e+01, Power=7.15e-01
  [eval] val_mse=5.500e-01  (n=7000)
Epoch 00156: Time=   9.1s, Loss=3.38e+00, Inv=3.38e+00, For=6.76e+01, Power=7.14e-01
  [eval] val_mse=5.477e-01  (n=7000)
Epoch 00157: Time=   9.1s, Loss=3.38e+00, Inv=3.38e+00, For=6.81e+01, Power=7.13e-01
  [eval] val_mse=5.430e-01  (n=7000)
Epoch 00158: Time=   9.2s, Loss=3.38e+00, Inv=3.38e+00, For=6.85e+01, Power=7.16e-01
  [eval] val_mse=5.397e-01  (n=7000)
Epoch 00159: Time=   9.2s, Loss=3.37e+00, Inv=3.37e+00, For=6.84e+01, Power=7.14e-01
  [eval] val_mse=5.355e-01  (n=7000)
Epoch 00160: Time=   9.2s, Loss=3.36e+00, Inv=3.36e+00, For=6.84e+01, Power=7.12e-01
  [eval] val_mse=5.320e-01  (n=7000)
Epoch 00161: Time=   9.3s, Loss=3.35e+00, Inv=3.35e+00, For=6.84e+01, Power=7.11e-01
  [eval] val_mse=5.282e-01  (n=7000)
Epoch 00162: Time=   9.3s, Loss=3.34e+00, Inv=3.34e+00, For=6.86e+01, Power=7.10e-01
  [eval] val_mse=5.260e-01  (n=7000)
Epoch 00163: Time=   9.3s, Loss=3.34e+00, Inv=3.34e+00, For=6.89e+01, Power=7.07e-01
  [eval] val_mse=5.217e-01  (n=7000)
Epoch 00164: Time=   9.4s, Loss=3.34e+00, Inv=3.34e+00, For=6.93e+01, Power=7.09e-01
  [eval] val_mse=5.181e-01  (n=7000)
Epoch 00165: Time=   9.4s, Loss=3.33e+00, Inv=3.33e+00, For=6.95e+01, Power=7.09e-01
  [eval] val_mse=5.151e-01  (n=7000)
Epoch 00166: Time=   9.4s, Loss=3.32e+00, Inv=3.32e+00, For=6.91e+01, Power=7.05e-01
  [eval] val_mse=5.114e-01  (n=7000)
Epoch 00167: Time=   9.5s, Loss=3.31e+00, Inv=3.31e+00, For=6.97e+01, Power=7.08e-01
  [eval] val_mse=5.089e-01  (n=7000)
Epoch 00168: Time=   9.5s, Loss=3.31e+00, Inv=3.31e+00, For=6.95e+01, Power=7.06e-01
  [eval] val_mse=5.048e-01  (n=7000)
Epoch 00169: Time=   9.5s, Loss=3.30e+00, Inv=3.30e+00, For=6.98e+01, Power=7.00e-01
  [eval] val_mse=5.013e-01  (n=7000)
Epoch 00170: Time=   9.6s, Loss=3.30e+00, Inv=3.30e+00, For=6.99e+01, Power=7.02e-01
  [eval] val_mse=4.986e-01  (n=7000)
Epoch 00171: Time=   9.6s, Loss=3.29e+00, Inv=3.29e+00, For=7.03e+01, Power=7.05e-01
  [eval] val_mse=4.953e-01  (n=7000)
Epoch 00172: Time=   9.6s, Loss=3.28e+00, Inv=3.28e+00, For=7.06e+01, Power=7.00e-01
  [eval] val_mse=4.929e-01  (n=7000)
Epoch 00173: Time=   9.6s, Loss=3.28e+00, Inv=3.28e+00, For=7.06e+01, Power=6.98e-01
  [eval] val_mse=4.900e-01  (n=7000)
Epoch 00174: Time=   9.7s, Loss=3.27e+00, Inv=3.27e+00, For=7.12e+01, Power=7.00e-01
  [eval] val_mse=4.871e-01  (n=7000)
Epoch 00175: Time=   9.7s, Loss=3.27e+00, Inv=3.27e+00, For=7.13e+01, Power=7.01e-01
  [eval] val_mse=4.846e-01  (n=7000)
Epoch 00176: Time=   9.7s, Loss=3.26e+00, Inv=3.26e+00, For=7.17e+01, Power=7.02e-01
  [eval] val_mse=4.817e-01  (n=7000)
Epoch 00177: Time=   9.8s, Loss=3.26e+00, Inv=3.26e+00, For=7.20e+01, Power=6.98e-01
  [eval] val_mse=4.784e-01  (n=7000)
Epoch 00178: Time=   9.8s, Loss=3.25e+00, Inv=3.25e+00, For=7.23e+01, Power=6.97e-01
  [eval] val_mse=4.767e-01  (n=7000)
Epoch 00179: Time=   9.8s, Loss=3.25e+00, Inv=3.25e+00, For=7.26e+01, Power=6.97e-01
  [eval] val_mse=4.740e-01  (n=7000)
Epoch 00180: Time=   9.9s, Loss=3.24e+00, Inv=3.24e+00, For=7.32e+01, Power=6.98e-01
  [eval] val_mse=4.711e-01  (n=7000)
Epoch 00181: Time=   9.9s, Loss=3.23e+00, Inv=3.23e+00, For=7.34e+01, Power=6.95e-01
  [eval] val_mse=4.689e-01  (n=7000)
Epoch 00182: Time=   9.9s, Loss=3.23e+00, Inv=3.23e+00, For=7.32e+01, Power=6.97e-01
  [eval] val_mse=4.672e-01  (n=7000)
Epoch 00183: Time=  10.0s, Loss=3.22e+00, Inv=3.22e+00, For=7.45e+01, Power=6.94e-01
  [eval] val_mse=4.642e-01  (n=7000)
Epoch 00184: Time=  10.0s, Loss=3.22e+00, Inv=3.22e+00, For=7.42e+01, Power=6.94e-01
  [eval] val_mse=4.617e-01  (n=7000)
Epoch 00185: Time=  10.0s, Loss=3.22e+00, Inv=3.22e+00, For=7.46e+01, Power=6.92e-01
  [eval] val_mse=4.596e-01  (n=7000)
Epoch 00186: Time=  10.0s, Loss=3.21e+00, Inv=3.21e+00, For=7.56e+01, Power=6.94e-01
  [eval] val_mse=4.577e-01  (n=7000)
Epoch 00187: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=7.59e+01, Power=6.93e-01
  [eval] val_mse=4.556e-01  (n=7000)
Epoch 00188: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=7.61e+01, Power=6.90e-01
  [eval] val_mse=4.533e-01  (n=7000)
Epoch 00189: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=7.68e+01, Power=6.90e-01
  [eval] val_mse=4.512e-01  (n=7000)
Epoch 00190: Time=  10.1s, Loss=3.19e+00, Inv=3.19e+00, For=7.69e+01, Power=6.91e-01
  [eval] val_mse=4.491e-01  (n=7000)
Epoch 00191: Time=  10.2s, Loss=3.19e+00, Inv=3.19e+00, For=7.78e+01, Power=6.92e-01
  [eval] val_mse=4.472e-01  (n=7000)
Epoch 00192: Time=  10.2s, Loss=3.18e+00, Inv=3.18e+00, For=7.82e+01, Power=6.90e-01
  [eval] val_mse=4.455e-01  (n=7000)
Epoch 00193: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=7.84e+01, Power=6.89e-01
  [eval] val_mse=4.441e-01  (n=7000)
Epoch 00194: Time=  10.3s, Loss=3.18e+00, Inv=3.18e+00, For=7.92e+01, Power=6.91e-01
  [eval] val_mse=4.414e-01  (n=7000)
Epoch 00195: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=7.95e+01, Power=6.88e-01
  [eval] val_mse=4.398e-01  (n=7000)
Epoch 00196: Time=  10.3s, Loss=3.16e+00, Inv=3.16e+00, For=8.05e+01, Power=6.89e-01
  [eval] val_mse=4.373e-01  (n=7000)
Epoch 00197: Time=  10.3s, Loss=3.16e+00, Inv=3.16e+00, For=8.07e+01, Power=6.88e-01
  [eval] val_mse=4.370e-01  (n=7000)
Epoch 00198: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=8.18e+01, Power=6.92e-01
  [eval] val_mse=4.343e-01  (n=7000)
Epoch 00199: Time=  10.4s, Loss=3.15e+00, Inv=3.15e+00, For=8.18e+01, Power=6.85e-01
  [eval] val_mse=4.326e-01  (n=7000)
Epoch 00200: Time=  10.4s, Loss=3.15e+00, Inv=3.15e+00, For=8.24e+01, Power=6.90e-01
  [eval] val_mse=4.311e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 2.681e-01
Torque MSE  = 1.301e-01
Torque RMSE = 3.607e-01
Per-joint MSE : 8.625e-02 2.332e-01 5.294e-02 2.385e-02 3.632e-01 2.120e-02
Per-joint RMSE: 2.937e-01 4.829e-01 2.301e-01 1.544e-01 6.027e-01 1.456e-01
Comp Time per Sample = 2.611e-04s / 3829.5Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-orky_lux because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x79098f5ae8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:44:54.861217: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:44:56.499029: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.0s, Loss=4.40e+03, Inv=4.40e+03, For=6.53e+00, Power=1.12e+03
  [eval] val_mse=2.338e+02  (n=7000)
Epoch 00002: Time=   4.6s, Loss=9.59e+02, Inv=9.59e+02, For=6.43e+00, Power=2.28e+02
  [eval] val_mse=8.799e+01  (n=7000)
Epoch 00003: Time=   4.6s, Loss=4.17e+02, Inv=4.17e+02, For=6.20e+00, Power=1.03e+02
  [eval] val_mse=4.892e+01  (n=7000)
Epoch 00004: Time=   4.7s, Loss=2.38e+02, Inv=2.38e+02, For=6.09e+00, Power=5.92e+01
  [eval] val_mse=3.196e+01  (n=7000)
Epoch 00005: Time=   4.7s, Loss=1.54e+02, Inv=1.54e+02, For=6.06e+00, Power=3.85e+01
  [eval] val_mse=2.297e+01  (n=7000)
Epoch 00006: Time=   4.7s, Loss=1.06e+02, Inv=1.06e+02, For=6.00e+00, Power=2.64e+01
  [eval] val_mse=1.740e+01  (n=7000)
Epoch 00007: Time=   4.8s, Loss=7.80e+01, Inv=7.80e+01, For=6.03e+00, Power=1.93e+01
  [eval] val_mse=1.378e+01  (n=7000)
Epoch 00008: Time=   4.8s, Loss=6.02e+01, Inv=6.02e+01, For=6.08e+00, Power=1.46e+01
  [eval] val_mse=1.119e+01  (n=7000)
Epoch 00009: Time=   4.8s, Loss=4.80e+01, Inv=4.80e+01, For=6.20e+00, Power=1.13e+01
  [eval] val_mse=9.368e+00  (n=7000)
Epoch 00010: Time=   4.9s, Loss=3.98e+01, Inv=3.98e+01, For=6.34e+00, Power=9.14e+00
  [eval] val_mse=7.958e+00  (n=7000)
Epoch 00011: Time=   4.9s, Loss=3.35e+01, Inv=3.35e+01, For=6.47e+00, Power=7.49e+00
  [eval] val_mse=6.850e+00  (n=7000)
Epoch 00012: Time=   4.9s, Loss=2.88e+01, Inv=2.88e+01, For=6.63e+00, Power=6.27e+00
  [eval] val_mse=5.978e+00  (n=7000)
Epoch 00013: Time=   4.9s, Loss=2.52e+01, Inv=2.52e+01, For=6.80e+00, Power=5.30e+00
  [eval] val_mse=5.264e+00  (n=7000)
Epoch 00014: Time=   5.0s, Loss=2.23e+01, Inv=2.23e+01, For=6.97e+00, Power=4.58e+00
  [eval] val_mse=4.683e+00  (n=7000)
Epoch 00015: Time=   5.0s, Loss=2.01e+01, Inv=2.01e+01, For=7.18e+00, Power=4.01e+00
  [eval] val_mse=4.189e+00  (n=7000)
Epoch 00016: Time=   5.0s, Loss=1.81e+01, Inv=1.81e+01, For=7.38e+00, Power=3.56e+00
  [eval] val_mse=3.780e+00  (n=7000)
Epoch 00017: Time=   5.1s, Loss=1.65e+01, Inv=1.65e+01, For=7.57e+00, Power=3.17e+00
  [eval] val_mse=3.424e+00  (n=7000)
Epoch 00018: Time=   5.1s, Loss=1.51e+01, Inv=1.51e+01, For=7.79e+00, Power=2.86e+00
  [eval] val_mse=3.127e+00  (n=7000)
Epoch 00019: Time=   5.1s, Loss=1.40e+01, Inv=1.40e+01, For=8.01e+00, Power=2.60e+00
  [eval] val_mse=2.867e+00  (n=7000)
Epoch 00020: Time=   5.1s, Loss=1.30e+01, Inv=1.30e+01, For=8.20e+00, Power=2.38e+00
  [eval] val_mse=2.645e+00  (n=7000)
Epoch 00021: Time=   5.2s, Loss=1.21e+01, Inv=1.21e+01, For=8.43e+00, Power=2.18e+00
  [eval] val_mse=2.450e+00  (n=7000)
Epoch 00022: Time=   5.2s, Loss=1.14e+01, Inv=1.14e+01, For=8.62e+00, Power=2.02e+00
  [eval] val_mse=2.281e+00  (n=7000)
Epoch 00023: Time=   5.2s, Loss=1.07e+01, Inv=1.07e+01, For=8.89e+00, Power=1.90e+00
  [eval] val_mse=2.133e+00  (n=7000)
Epoch 00024: Time=   5.3s, Loss=1.01e+01, Inv=1.01e+01, For=9.14e+00, Power=1.78e+00
  [eval] val_mse=2.005e+00  (n=7000)
Epoch 00025: Time=   5.3s, Loss=9.60e+00, Inv=9.60e+00, For=9.36e+00, Power=1.67e+00
  [eval] val_mse=1.888e+00  (n=7000)
Epoch 00026: Time=   5.3s, Loss=9.13e+00, Inv=9.13e+00, For=9.61e+00, Power=1.57e+00
  [eval] val_mse=1.786e+00  (n=7000)
Epoch 00027: Time=   5.3s, Loss=8.73e+00, Inv=8.73e+00, For=9.88e+00, Power=1.49e+00
  [eval] val_mse=1.699e+00  (n=7000)
Epoch 00028: Time=   5.4s, Loss=8.37e+00, Inv=8.37e+00, For=1.02e+01, Power=1.42e+00
  [eval] val_mse=1.616e+00  (n=7000)
Epoch 00029: Time=   5.4s, Loss=8.05e+00, Inv=8.05e+00, For=1.06e+01, Power=1.36e+00
  [eval] val_mse=1.541e+00  (n=7000)
Epoch 00030: Time=   5.4s, Loss=7.75e+00, Inv=7.75e+00, For=1.09e+01, Power=1.30e+00
  [eval] val_mse=1.474e+00  (n=7000)
Epoch 00031: Time=   5.5s, Loss=7.47e+00, Inv=7.47e+00, For=1.13e+01, Power=1.25e+00
  [eval] val_mse=1.412e+00  (n=7000)
Epoch 00032: Time=   5.5s, Loss=7.22e+00, Inv=7.22e+00, For=1.17e+01, Power=1.21e+00
  [eval] val_mse=1.356e+00  (n=7000)
Epoch 00033: Time=   5.5s, Loss=7.00e+00, Inv=7.00e+00, For=1.21e+01, Power=1.17e+00
  [eval] val_mse=1.304e+00  (n=7000)
Epoch 00034: Time=   5.6s, Loss=6.79e+00, Inv=6.79e+00, For=1.25e+01, Power=1.13e+00
  [eval] val_mse=1.255e+00  (n=7000)
Epoch 00035: Time=   5.6s, Loss=6.62e+00, Inv=6.62e+00, For=1.29e+01, Power=1.10e+00
  [eval] val_mse=1.211e+00  (n=7000)
Epoch 00036: Time=   5.6s, Loss=6.42e+00, Inv=6.42e+00, For=1.33e+01, Power=1.07e+00
  [eval] val_mse=1.171e+00  (n=7000)
Epoch 00037: Time=   5.6s, Loss=6.27e+00, Inv=6.27e+00, For=1.38e+01, Power=1.04e+00
  [eval] val_mse=1.133e+00  (n=7000)
Epoch 00038: Time=   5.7s, Loss=6.12e+00, Inv=6.12e+00, For=1.43e+01, Power=1.02e+00
  [eval] val_mse=1.097e+00  (n=7000)
Epoch 00039: Time=   5.7s, Loss=5.99e+00, Inv=5.99e+00, For=1.49e+01, Power=9.96e-01
  [eval] val_mse=1.063e+00  (n=7000)
Epoch 00040: Time=   5.7s, Loss=5.85e+00, Inv=5.85e+00, For=1.54e+01, Power=9.79e-01
  [eval] val_mse=1.031e+00  (n=7000)
Epoch 00041: Time=   5.8s, Loss=5.74e+00, Inv=5.74e+00, For=1.59e+01, Power=9.63e-01
  [eval] val_mse=1.004e+00  (n=7000)
Epoch 00042: Time=   5.8s, Loss=5.62e+00, Inv=5.62e+00, For=1.65e+01, Power=9.42e-01
  [eval] val_mse=9.747e-01  (n=7000)
Epoch 00043: Time=   5.8s, Loss=5.52e+00, Inv=5.52e+00, For=1.70e+01, Power=9.28e-01
  [eval] val_mse=9.497e-01  (n=7000)
Epoch 00044: Time=   5.8s, Loss=5.42e+00, Inv=5.42e+00, For=1.76e+01, Power=9.09e-01
  [eval] val_mse=9.242e-01  (n=7000)
Epoch 00045: Time=   5.9s, Loss=5.34e+00, Inv=5.34e+00, For=1.82e+01, Power=9.00e-01
  [eval] val_mse=9.024e-01  (n=7000)
Epoch 00046: Time=   5.9s, Loss=5.25e+00, Inv=5.25e+00, For=1.88e+01, Power=8.85e-01
  [eval] val_mse=8.800e-01  (n=7000)
Epoch 00047: Time=   5.9s, Loss=5.17e+00, Inv=5.17e+00, For=1.94e+01, Power=8.75e-01
  [eval] val_mse=8.610e-01  (n=7000)
Epoch 00048: Time=   6.0s, Loss=5.09e+00, Inv=5.09e+00, For=2.00e+01, Power=8.67e-01
  [eval] val_mse=8.399e-01  (n=7000)
Epoch 00049: Time=   6.0s, Loss=5.02e+00, Inv=5.02e+00, For=2.06e+01, Power=8.56e-01
  [eval] val_mse=8.231e-01  (n=7000)
Epoch 00050: Time=   6.0s, Loss=4.95e+00, Inv=4.95e+00, For=2.13e+01, Power=8.47e-01
  [eval] val_mse=8.057e-01  (n=7000)
Epoch 00051: Time=   6.0s, Loss=4.89e+00, Inv=4.89e+00, For=2.20e+01, Power=8.36e-01
  [eval] val_mse=7.890e-01  (n=7000)
Epoch 00052: Time=   6.1s, Loss=4.82e+00, Inv=4.82e+00, For=2.26e+01, Power=8.32e-01
  [eval] val_mse=7.744e-01  (n=7000)
Epoch 00053: Time=   6.1s, Loss=4.77e+00, Inv=4.77e+00, For=2.33e+01, Power=8.23e-01
  [eval] val_mse=7.594e-01  (n=7000)
Epoch 00054: Time=   6.1s, Loss=4.70e+00, Inv=4.70e+00, For=2.39e+01, Power=8.16e-01
  [eval] val_mse=7.455e-01  (n=7000)
Epoch 00055: Time=   6.2s, Loss=4.65e+00, Inv=4.65e+00, For=2.48e+01, Power=8.11e-01
  [eval] val_mse=7.318e-01  (n=7000)
Epoch 00056: Time=   6.2s, Loss=4.60e+00, Inv=4.60e+00, For=2.53e+01, Power=8.02e-01
  [eval] val_mse=7.201e-01  (n=7000)
Epoch 00057: Time=   6.2s, Loss=4.55e+00, Inv=4.55e+00, For=2.61e+01, Power=7.99e-01
  [eval] val_mse=7.072e-01  (n=7000)
Epoch 00058: Time=   6.2s, Loss=4.50e+00, Inv=4.50e+00, For=2.68e+01, Power=7.91e-01
  [eval] val_mse=6.965e-01  (n=7000)
Epoch 00059: Time=   6.3s, Loss=4.45e+00, Inv=4.45e+00, For=2.75e+01, Power=7.86e-01
  [eval] val_mse=6.863e-01  (n=7000)
Epoch 00060: Time=   6.3s, Loss=4.42e+00, Inv=4.42e+00, For=2.83e+01, Power=7.84e-01
  [eval] val_mse=6.760e-01  (n=7000)
Epoch 00061: Time=   6.3s, Loss=4.37e+00, Inv=4.37e+00, For=2.91e+01, Power=7.75e-01
  [eval] val_mse=6.654e-01  (n=7000)
Epoch 00062: Time=   6.4s, Loss=4.33e+00, Inv=4.33e+00, For=2.99e+01, Power=7.73e-01
  [eval] val_mse=6.566e-01  (n=7000)
Epoch 00063: Time=   6.4s, Loss=4.30e+00, Inv=4.30e+00, For=3.06e+01, Power=7.72e-01
  [eval] val_mse=6.471e-01  (n=7000)
Epoch 00064: Time=   6.4s, Loss=4.25e+00, Inv=4.25e+00, For=3.15e+01, Power=7.65e-01
  [eval] val_mse=6.393e-01  (n=7000)
Epoch 00065: Time=   6.5s, Loss=4.22e+00, Inv=4.22e+00, For=3.22e+01, Power=7.64e-01
  [eval] val_mse=6.305e-01  (n=7000)
Epoch 00066: Time=   6.5s, Loss=4.18e+00, Inv=4.18e+00, For=3.31e+01, Power=7.63e-01
  [eval] val_mse=6.230e-01  (n=7000)
Epoch 00067: Time=   6.5s, Loss=4.15e+00, Inv=4.15e+00, For=3.40e+01, Power=7.55e-01
  [eval] val_mse=6.156e-01  (n=7000)
Epoch 00068: Time=   6.6s, Loss=4.12e+00, Inv=4.12e+00, For=3.48e+01, Power=7.55e-01
  [eval] val_mse=6.088e-01  (n=7000)
Epoch 00069: Time=   6.6s, Loss=4.08e+00, Inv=4.08e+00, For=3.58e+01, Power=7.51e-01
  [eval] val_mse=6.021e-01  (n=7000)
Epoch 00070: Time=   6.6s, Loss=4.06e+00, Inv=4.06e+00, For=3.66e+01, Power=7.47e-01
  [eval] val_mse=5.958e-01  (n=7000)
Epoch 00071: Time=   6.7s, Loss=4.03e+00, Inv=4.03e+00, For=3.74e+01, Power=7.48e-01
  [eval] val_mse=5.892e-01  (n=7000)
Epoch 00072: Time=   6.7s, Loss=4.01e+00, Inv=4.01e+00, For=3.85e+01, Power=7.43e-01
  [eval] val_mse=5.826e-01  (n=7000)
Epoch 00073: Time=   6.7s, Loss=3.98e+00, Inv=3.98e+00, For=3.93e+01, Power=7.44e-01
  [eval] val_mse=5.775e-01  (n=7000)
Epoch 00074: Time=   6.8s, Loss=3.96e+00, Inv=3.96e+00, For=4.03e+01, Power=7.39e-01
  [eval] val_mse=5.716e-01  (n=7000)
Epoch 00075: Time=   6.8s, Loss=3.93e+00, Inv=3.93e+00, For=4.10e+01, Power=7.38e-01
  [eval] val_mse=5.665e-01  (n=7000)
Epoch 00076: Time=   6.8s, Loss=3.91e+00, Inv=3.91e+00, For=4.25e+01, Power=7.36e-01
  [eval] val_mse=5.611e-01  (n=7000)
Epoch 00077: Time=   6.8s, Loss=3.88e+00, Inv=3.88e+00, For=4.30e+01, Power=7.32e-01
  [eval] val_mse=5.566e-01  (n=7000)
Epoch 00078: Time=   6.9s, Loss=3.86e+00, Inv=3.86e+00, For=4.41e+01, Power=7.34e-01
  [eval] val_mse=5.506e-01  (n=7000)
Epoch 00079: Time=   6.9s, Loss=3.84e+00, Inv=3.84e+00, For=4.54e+01, Power=7.32e-01
  [eval] val_mse=5.463e-01  (n=7000)
Epoch 00080: Time=   6.9s, Loss=3.82e+00, Inv=3.82e+00, For=4.59e+01, Power=7.32e-01
  [eval] val_mse=5.423e-01  (n=7000)
Epoch 00081: Time=   7.0s, Loss=3.81e+00, Inv=3.81e+00, For=4.71e+01, Power=7.29e-01
  [eval] val_mse=5.375e-01  (n=7000)
Epoch 00082: Time=   7.0s, Loss=3.78e+00, Inv=3.78e+00, For=4.82e+01, Power=7.25e-01
  [eval] val_mse=5.334e-01  (n=7000)
Epoch 00083: Time=   7.0s, Loss=3.76e+00, Inv=3.76e+00, For=4.91e+01, Power=7.22e-01
  [eval] val_mse=5.285e-01  (n=7000)
Epoch 00084: Time=   7.0s, Loss=3.75e+00, Inv=3.75e+00, For=5.04e+01, Power=7.24e-01
  [eval] val_mse=5.250e-01  (n=7000)
Epoch 00085: Time=   7.1s, Loss=3.73e+00, Inv=3.73e+00, For=5.14e+01, Power=7.22e-01
  [eval] val_mse=5.206e-01  (n=7000)
Epoch 00086: Time=   7.1s, Loss=3.72e+00, Inv=3.72e+00, For=5.24e+01, Power=7.21e-01
  [eval] val_mse=5.168e-01  (n=7000)
Epoch 00087: Time=   7.1s, Loss=3.70e+00, Inv=3.70e+00, For=5.32e+01, Power=7.22e-01
  [eval] val_mse=5.132e-01  (n=7000)
Epoch 00088: Time=   7.2s, Loss=3.69e+00, Inv=3.69e+00, For=5.45e+01, Power=7.18e-01
  [eval] val_mse=5.096e-01  (n=7000)
Epoch 00089: Time=   7.2s, Loss=3.67e+00, Inv=3.67e+00, For=5.58e+01, Power=7.19e-01
  [eval] val_mse=5.058e-01  (n=7000)
Epoch 00090: Time=   7.2s, Loss=3.65e+00, Inv=3.65e+00, For=5.65e+01, Power=7.17e-01
  [eval] val_mse=5.021e-01  (n=7000)
Epoch 00091: Time=   7.3s, Loss=3.65e+00, Inv=3.65e+00, For=5.81e+01, Power=7.19e-01
  [eval] val_mse=4.987e-01  (n=7000)
Epoch 00092: Time=   7.3s, Loss=3.63e+00, Inv=3.63e+00, For=5.88e+01, Power=7.15e-01
  [eval] val_mse=4.948e-01  (n=7000)
Epoch 00093: Time=   7.3s, Loss=3.62e+00, Inv=3.62e+00, For=6.01e+01, Power=7.15e-01
  [eval] val_mse=4.920e-01  (n=7000)
Epoch 00094: Time=   7.3s, Loss=3.61e+00, Inv=3.61e+00, For=6.11e+01, Power=7.16e-01
  [eval] val_mse=4.890e-01  (n=7000)
Epoch 00095: Time=   7.4s, Loss=3.60e+00, Inv=3.60e+00, For=6.24e+01, Power=7.13e-01
  [eval] val_mse=4.860e-01  (n=7000)
Epoch 00096: Time=   7.4s, Loss=3.59e+00, Inv=3.59e+00, For=6.35e+01, Power=7.16e-01
  [eval] val_mse=4.817e-01  (n=7000)
Epoch 00097: Time=   7.4s, Loss=3.58e+00, Inv=3.58e+00, For=6.43e+01, Power=7.12e-01
  [eval] val_mse=4.794e-01  (n=7000)
Epoch 00098: Time=   7.5s, Loss=3.56e+00, Inv=3.56e+00, For=6.60e+01, Power=7.12e-01
  [eval] val_mse=4.761e-01  (n=7000)
Epoch 00099: Time=   7.5s, Loss=3.56e+00, Inv=3.56e+00, For=6.65e+01, Power=7.10e-01
  [eval] val_mse=4.735e-01  (n=7000)
Epoch 00100: Time=   7.5s, Loss=3.55e+00, Inv=3.55e+00, For=6.78e+01, Power=7.08e-01
  [eval] val_mse=4.704e-01  (n=7000)
Epoch 00101: Time=   7.6s, Loss=3.53e+00, Inv=3.53e+00, For=6.90e+01, Power=7.09e-01
  [eval] val_mse=4.682e-01  (n=7000)
Epoch 00102: Time=   7.6s, Loss=3.52e+00, Inv=3.52e+00, For=7.05e+01, Power=7.05e-01
  [eval] val_mse=4.653e-01  (n=7000)
Epoch 00103: Time=   7.6s, Loss=3.52e+00, Inv=3.52e+00, For=7.08e+01, Power=7.10e-01
  [eval] val_mse=4.626e-01  (n=7000)
Epoch 00104: Time=   7.7s, Loss=3.51e+00, Inv=3.51e+00, For=7.25e+01, Power=7.10e-01
  [eval] val_mse=4.611e-01  (n=7000)
Epoch 00105: Time=   7.7s, Loss=3.50e+00, Inv=3.50e+00, For=7.41e+01, Power=7.04e-01
  [eval] val_mse=4.575e-01  (n=7000)
Epoch 00106: Time=   7.7s, Loss=3.49e+00, Inv=3.49e+00, For=7.45e+01, Power=7.02e-01
  [eval] val_mse=4.552e-01  (n=7000)
Epoch 00107: Time=   7.8s, Loss=3.49e+00, Inv=3.49e+00, For=7.59e+01, Power=7.06e-01
  [eval] val_mse=4.529e-01  (n=7000)
Epoch 00108: Time=   7.8s, Loss=3.48e+00, Inv=3.48e+00, For=7.72e+01, Power=7.06e-01
  [eval] val_mse=4.500e-01  (n=7000)
Epoch 00109: Time=   7.8s, Loss=3.47e+00, Inv=3.47e+00, For=7.86e+01, Power=7.05e-01
  [eval] val_mse=4.481e-01  (n=7000)
Epoch 00110: Time=   7.8s, Loss=3.46e+00, Inv=3.46e+00, For=7.91e+01, Power=7.04e-01
  [eval] val_mse=4.455e-01  (n=7000)
Epoch 00111: Time=   7.9s, Loss=3.46e+00, Inv=3.46e+00, For=8.12e+01, Power=7.06e-01
  [eval] val_mse=4.436e-01  (n=7000)
Epoch 00112: Time=   7.9s, Loss=3.45e+00, Inv=3.45e+00, For=8.20e+01, Power=7.04e-01
  [eval] val_mse=4.409e-01  (n=7000)
Epoch 00113: Time=   7.9s, Loss=3.44e+00, Inv=3.44e+00, For=8.31e+01, Power=7.03e-01
  [eval] val_mse=4.387e-01  (n=7000)
Epoch 00114: Time=   8.0s, Loss=3.43e+00, Inv=3.43e+00, For=8.40e+01, Power=7.02e-01
  [eval] val_mse=4.367e-01  (n=7000)
Epoch 00115: Time=   8.0s, Loss=3.43e+00, Inv=3.43e+00, For=8.54e+01, Power=7.01e-01
  [eval] val_mse=4.349e-01  (n=7000)
Epoch 00116: Time=   8.0s, Loss=3.42e+00, Inv=3.42e+00, For=8.65e+01, Power=7.02e-01
  [eval] val_mse=4.324e-01  (n=7000)
Epoch 00117: Time=   8.1s, Loss=3.41e+00, Inv=3.41e+00, For=8.82e+01, Power=6.99e-01
  [eval] val_mse=4.306e-01  (n=7000)
Epoch 00118: Time=   8.1s, Loss=3.40e+00, Inv=3.40e+00, For=8.84e+01, Power=6.97e-01
  [eval] val_mse=4.289e-01  (n=7000)
Epoch 00119: Time=   8.1s, Loss=3.40e+00, Inv=3.40e+00, For=9.04e+01, Power=6.98e-01
  [eval] val_mse=4.273e-01  (n=7000)
Epoch 00120: Time=   8.1s, Loss=3.39e+00, Inv=3.39e+00, For=9.16e+01, Power=6.95e-01
  [eval] val_mse=4.248e-01  (n=7000)
Epoch 00121: Time=   8.2s, Loss=3.39e+00, Inv=3.39e+00, For=9.31e+01, Power=6.97e-01
  [eval] val_mse=4.233e-01  (n=7000)
Epoch 00122: Time=   8.2s, Loss=3.38e+00, Inv=3.38e+00, For=9.39e+01, Power=6.99e-01
  [eval] val_mse=4.209e-01  (n=7000)
Epoch 00123: Time=   8.2s, Loss=3.38e+00, Inv=3.38e+00, For=9.51e+01, Power=6.99e-01
  [eval] val_mse=4.204e-01  (n=7000)
Epoch 00124: Time=   8.3s, Loss=3.37e+00, Inv=3.37e+00, For=9.63e+01, Power=6.97e-01
  [eval] val_mse=4.180e-01  (n=7000)
Epoch 00125: Time=   8.3s, Loss=3.37e+00, Inv=3.37e+00, For=9.80e+01, Power=6.98e-01
  [eval] val_mse=4.154e-01  (n=7000)
Epoch 00126: Time=   8.3s, Loss=3.36e+00, Inv=3.36e+00, For=9.85e+01, Power=6.97e-01
  [eval] val_mse=4.143e-01  (n=7000)
Epoch 00127: Time=   8.3s, Loss=3.35e+00, Inv=3.35e+00, For=1.01e+02, Power=6.95e-01
  [eval] val_mse=4.130e-01  (n=7000)
Epoch 00128: Time=   8.4s, Loss=3.35e+00, Inv=3.35e+00, For=1.01e+02, Power=6.94e-01
  [eval] val_mse=4.110e-01  (n=7000)
Epoch 00129: Time=   8.4s, Loss=3.34e+00, Inv=3.34e+00, For=1.03e+02, Power=6.95e-01
  [eval] val_mse=4.086e-01  (n=7000)
Epoch 00130: Time=   8.4s, Loss=3.34e+00, Inv=3.34e+00, For=1.04e+02, Power=6.93e-01
  [eval] val_mse=4.074e-01  (n=7000)
Epoch 00131: Time=   8.5s, Loss=3.33e+00, Inv=3.33e+00, For=1.05e+02, Power=6.95e-01
  [eval] val_mse=4.065e-01  (n=7000)
Epoch 00132: Time=   8.5s, Loss=3.33e+00, Inv=3.33e+00, For=1.07e+02, Power=6.94e-01
  [eval] val_mse=4.046e-01  (n=7000)
Epoch 00133: Time=   8.5s, Loss=3.32e+00, Inv=3.32e+00, For=1.09e+02, Power=6.94e-01
  [eval] val_mse=4.034e-01  (n=7000)
Epoch 00134: Time=   8.5s, Loss=3.32e+00, Inv=3.32e+00, For=1.10e+02, Power=6.92e-01
  [eval] val_mse=4.027e-01  (n=7000)
Epoch 00135: Time=   8.6s, Loss=3.31e+00, Inv=3.31e+00, For=1.11e+02, Power=6.93e-01
  [eval] val_mse=4.010e-01  (n=7000)
Epoch 00136: Time=   8.6s, Loss=3.31e+00, Inv=3.31e+00, For=1.13e+02, Power=6.94e-01
  [eval] val_mse=3.999e-01  (n=7000)
Epoch 00137: Time=   8.6s, Loss=3.30e+00, Inv=3.30e+00, For=1.14e+02, Power=6.92e-01
  [eval] val_mse=3.981e-01  (n=7000)
Epoch 00138: Time=   8.6s, Loss=3.30e+00, Inv=3.30e+00, For=1.16e+02, Power=6.90e-01
  [eval] val_mse=3.965e-01  (n=7000)
Epoch 00139: Time=   8.7s, Loss=3.29e+00, Inv=3.29e+00, For=1.17e+02, Power=6.88e-01
  [eval] val_mse=3.953e-01  (n=7000)
Epoch 00140: Time=   8.7s, Loss=3.29e+00, Inv=3.29e+00, For=1.18e+02, Power=6.91e-01
  [eval] val_mse=3.933e-01  (n=7000)
Epoch 00141: Time=   8.7s, Loss=3.29e+00, Inv=3.29e+00, For=1.20e+02, Power=6.91e-01
  [eval] val_mse=3.934e-01  (n=7000)
Epoch 00142: Time=   8.8s, Loss=3.28e+00, Inv=3.28e+00, For=1.21e+02, Power=6.92e-01
  [eval] val_mse=3.921e-01  (n=7000)
Epoch 00143: Time=   8.8s, Loss=3.28e+00, Inv=3.28e+00, For=1.23e+02, Power=6.92e-01
  [eval] val_mse=3.908e-01  (n=7000)
Epoch 00144: Time=   8.8s, Loss=3.28e+00, Inv=3.28e+00, For=1.25e+02, Power=6.93e-01
  [eval] val_mse=3.891e-01  (n=7000)
Epoch 00145: Time=   8.8s, Loss=3.27e+00, Inv=3.27e+00, For=1.25e+02, Power=6.94e-01
  [eval] val_mse=3.877e-01  (n=7000)
Epoch 00146: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=1.27e+02, Power=6.87e-01
  [eval] val_mse=3.870e-01  (n=7000)
Epoch 00147: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=1.30e+02, Power=6.91e-01
  [eval] val_mse=3.866e-01  (n=7000)
Epoch 00148: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=1.31e+02, Power=6.90e-01
  [eval] val_mse=3.851e-01  (n=7000)
Epoch 00149: Time=   9.0s, Loss=3.25e+00, Inv=3.25e+00, For=1.31e+02, Power=6.88e-01
  [eval] val_mse=3.838e-01  (n=7000)
Epoch 00150: Time=   9.0s, Loss=3.25e+00, Inv=3.25e+00, For=1.35e+02, Power=6.88e-01
  [eval] val_mse=3.830e-01  (n=7000)
Epoch 00151: Time=   9.0s, Loss=3.25e+00, Inv=3.25e+00, For=1.37e+02, Power=6.90e-01
  [eval] val_mse=3.823e-01  (n=7000)
Epoch 00152: Time=   9.1s, Loss=3.24e+00, Inv=3.24e+00, For=1.37e+02, Power=6.88e-01
  [eval] val_mse=3.813e-01  (n=7000)
Epoch 00153: Time=   9.1s, Loss=3.24e+00, Inv=3.24e+00, For=1.38e+02, Power=6.87e-01
  [eval] val_mse=3.803e-01  (n=7000)
Epoch 00154: Time=   9.1s, Loss=3.24e+00, Inv=3.24e+00, For=1.40e+02, Power=6.90e-01
  [eval] val_mse=3.796e-01  (n=7000)
Epoch 00155: Time=   9.2s, Loss=3.23e+00, Inv=3.23e+00, For=1.40e+02, Power=6.88e-01
  [eval] val_mse=3.785e-01  (n=7000)
Epoch 00156: Time=   9.2s, Loss=3.23e+00, Inv=3.23e+00, For=1.44e+02, Power=6.90e-01
  [eval] val_mse=3.776e-01  (n=7000)
Epoch 00157: Time=   9.2s, Loss=3.22e+00, Inv=3.22e+00, For=1.45e+02, Power=6.87e-01
  [eval] val_mse=3.766e-01  (n=7000)
Epoch 00158: Time=   9.3s, Loss=3.22e+00, Inv=3.22e+00, For=1.45e+02, Power=6.86e-01
  [eval] val_mse=3.757e-01  (n=7000)
Epoch 00159: Time=   9.3s, Loss=3.22e+00, Inv=3.22e+00, For=1.51e+02, Power=6.88e-01
  [eval] val_mse=3.757e-01  (n=7000)
Epoch 00160: Time=   9.3s, Loss=3.21e+00, Inv=3.21e+00, For=1.50e+02, Power=6.87e-01
  [eval] val_mse=3.742e-01  (n=7000)
Epoch 00161: Time=   9.3s, Loss=3.21e+00, Inv=3.21e+00, For=1.51e+02, Power=6.87e-01
  [eval] val_mse=3.737e-01  (n=7000)
Epoch 00162: Time=   9.4s, Loss=3.21e+00, Inv=3.21e+00, For=1.55e+02, Power=6.88e-01
  [eval] val_mse=3.726e-01  (n=7000)
Epoch 00163: Time=   9.4s, Loss=3.20e+00, Inv=3.20e+00, For=1.57e+02, Power=6.88e-01
  [eval] val_mse=3.720e-01  (n=7000)
Epoch 00164: Time=   9.4s, Loss=3.20e+00, Inv=3.20e+00, For=1.57e+02, Power=6.86e-01
  [eval] val_mse=3.710e-01  (n=7000)
Epoch 00165: Time=   9.5s, Loss=3.20e+00, Inv=3.20e+00, For=1.58e+02, Power=6.88e-01
  [eval] val_mse=3.707e-01  (n=7000)
Epoch 00166: Time=   9.5s, Loss=3.19e+00, Inv=3.19e+00, For=1.60e+02, Power=6.86e-01
  [eval] val_mse=3.693e-01  (n=7000)
Epoch 00167: Time=   9.5s, Loss=3.19e+00, Inv=3.19e+00, For=1.64e+02, Power=6.88e-01
  [eval] val_mse=3.691e-01  (n=7000)
Epoch 00168: Time=   9.5s, Loss=3.19e+00, Inv=3.19e+00, For=1.64e+02, Power=6.87e-01
  [eval] val_mse=3.683e-01  (n=7000)
Epoch 00169: Time=   9.6s, Loss=3.18e+00, Inv=3.18e+00, For=1.65e+02, Power=6.86e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00170: Time=   9.6s, Loss=3.18e+00, Inv=3.18e+00, For=1.68e+02, Power=6.87e-01
  [eval] val_mse=3.677e-01  (n=7000)
Epoch 00171: Time=   9.6s, Loss=3.18e+00, Inv=3.18e+00, For=1.70e+02, Power=6.88e-01
  [eval] val_mse=3.670e-01  (n=7000)
Epoch 00172: Time=   9.7s, Loss=3.17e+00, Inv=3.17e+00, For=1.71e+02, Power=6.87e-01
  [eval] val_mse=3.659e-01  (n=7000)
Epoch 00173: Time=   9.7s, Loss=3.17e+00, Inv=3.17e+00, For=1.73e+02, Power=6.87e-01
  [eval] val_mse=3.655e-01  (n=7000)
Epoch 00174: Time=   9.7s, Loss=3.17e+00, Inv=3.17e+00, For=1.76e+02, Power=6.87e-01
  [eval] val_mse=3.644e-01  (n=7000)
Epoch 00175: Time=   9.8s, Loss=3.17e+00, Inv=3.17e+00, For=1.78e+02, Power=6.85e-01
  [eval] val_mse=3.634e-01  (n=7000)
Epoch 00176: Time=   9.8s, Loss=3.16e+00, Inv=3.16e+00, For=1.78e+02, Power=6.86e-01
  [eval] val_mse=3.645e-01  (n=7000)
Epoch 00177: Time=   9.8s, Loss=3.16e+00, Inv=3.16e+00, For=1.83e+02, Power=6.84e-01
  [eval] val_mse=3.629e-01  (n=7000)
Epoch 00178: Time=   9.9s, Loss=3.15e+00, Inv=3.15e+00, For=1.81e+02, Power=6.86e-01
  [eval] val_mse=3.622e-01  (n=7000)
Epoch 00179: Time=   9.9s, Loss=3.15e+00, Inv=3.15e+00, For=1.85e+02, Power=6.84e-01
  [eval] val_mse=3.618e-01  (n=7000)
Epoch 00180: Time=   9.9s, Loss=3.15e+00, Inv=3.15e+00, For=1.88e+02, Power=6.82e-01
  [eval] val_mse=3.615e-01  (n=7000)
Epoch 00181: Time=   9.9s, Loss=3.15e+00, Inv=3.15e+00, For=1.89e+02, Power=6.84e-01
  [eval] val_mse=3.608e-01  (n=7000)
Epoch 00182: Time=  10.0s, Loss=3.14e+00, Inv=3.14e+00, For=1.90e+02, Power=6.82e-01
  [eval] val_mse=3.604e-01  (n=7000)
Epoch 00183: Time=  10.0s, Loss=3.14e+00, Inv=3.14e+00, For=1.91e+02, Power=6.80e-01
  [eval] val_mse=3.598e-01  (n=7000)
Epoch 00184: Time=  10.0s, Loss=3.14e+00, Inv=3.14e+00, For=1.95e+02, Power=6.83e-01
  [eval] val_mse=3.599e-01  (n=7000)
Epoch 00185: Time=  10.1s, Loss=3.14e+00, Inv=3.14e+00, For=1.97e+02, Power=6.83e-01
  [eval] val_mse=3.590e-01  (n=7000)
Epoch 00186: Time=  10.1s, Loss=3.14e+00, Inv=3.14e+00, For=2.00e+02, Power=6.87e-01
  [eval] val_mse=3.581e-01  (n=7000)
Epoch 00187: Time=  10.1s, Loss=3.13e+00, Inv=3.13e+00, For=1.99e+02, Power=6.82e-01
  [eval] val_mse=3.577e-01  (n=7000)
Epoch 00188: Time=  10.1s, Loss=3.13e+00, Inv=3.13e+00, For=2.01e+02, Power=6.84e-01
  [eval] val_mse=3.578e-01  (n=7000)
Epoch 00189: Time=  10.2s, Loss=3.12e+00, Inv=3.12e+00, For=2.06e+02, Power=6.83e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00190: Time=  10.2s, Loss=3.13e+00, Inv=3.13e+00, For=2.06e+02, Power=6.86e-01
  [eval] val_mse=3.569e-01  (n=7000)
Epoch 00191: Time=  10.2s, Loss=3.12e+00, Inv=3.12e+00, For=2.08e+02, Power=6.85e-01
  [eval] val_mse=3.555e-01  (n=7000)
Epoch 00192: Time=  10.3s, Loss=3.12e+00, Inv=3.12e+00, For=2.06e+02, Power=6.83e-01
  [eval] val_mse=3.556e-01  (n=7000)
Epoch 00193: Time=  10.3s, Loss=3.12e+00, Inv=3.12e+00, For=2.11e+02, Power=6.83e-01
  [eval] val_mse=3.550e-01  (n=7000)
Epoch 00194: Time=  10.3s, Loss=3.11e+00, Inv=3.11e+00, For=2.13e+02, Power=6.84e-01
  [eval] val_mse=3.544e-01  (n=7000)
Epoch 00195: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=2.14e+02, Power=6.85e-01
  [eval] val_mse=3.540e-01  (n=7000)
Epoch 00196: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=2.15e+02, Power=6.84e-01
  [eval] val_mse=3.544e-01  (n=7000)
Epoch 00197: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=2.18e+02, Power=6.85e-01
  [eval] val_mse=3.536e-01  (n=7000)
Epoch 00198: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=2.18e+02, Power=6.86e-01
  [eval] val_mse=3.532e-01  (n=7000)
Epoch 00199: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=2.21e+02, Power=6.83e-01
  [eval] val_mse=3.524e-01  (n=7000)
Epoch 00200: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=2.24e+02, Power=6.82e-01
  [eval] val_mse=3.523e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 2.423e-01
Torque MSE  = 7.661e-02
Torque RMSE = 2.768e-01
Per-joint MSE : 7.319e-02 1.838e-01 6.356e-02 2.186e-02 9.865e-02 1.859e-02
Per-joint RMSE: 2.705e-01 4.287e-01 2.521e-01 1.478e-01 3.141e-01 1.364e-01
Comp Time per Sample = 2.761e-04s / 3622.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-w5o4wwl1 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x77291671e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:45:14.695758: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:45:16.337555: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.1s, Loss=7.71e+03, Inv=7.71e+03, For=5.82e+00, Power=9.17e+02
  [eval] val_mse=2.828e+02  (n=7000)
Epoch 00002: Time=   4.9s, Loss=1.88e+03, Inv=1.88e+03, For=5.69e+00, Power=2.43e+02
  [eval] val_mse=1.493e+02  (n=7000)
Epoch 00003: Time=   4.9s, Loss=8.79e+02, Inv=8.79e+02, For=5.55e+00, Power=1.21e+02
  [eval] val_mse=1.047e+02  (n=7000)
Epoch 00004: Time=   4.9s, Loss=5.24e+02, Inv=5.24e+02, For=5.50e+00, Power=7.61e+01
  [eval] val_mse=8.267e+01  (n=7000)
Epoch 00005: Time=   5.0s, Loss=3.52e+02, Inv=3.52e+02, For=5.43e+00, Power=5.29e+01
  [eval] val_mse=6.820e+01  (n=7000)
Epoch 00006: Time=   5.0s, Loss=2.55e+02, Inv=2.55e+02, For=5.33e+00, Power=3.87e+01
  [eval] val_mse=5.712e+01  (n=7000)
Epoch 00007: Time=   5.0s, Loss=1.95e+02, Inv=1.95e+02, For=5.27e+00, Power=2.95e+01
  [eval] val_mse=4.812e+01  (n=7000)
Epoch 00008: Time=   5.0s, Loss=1.53e+02, Inv=1.53e+02, For=5.21e+00, Power=2.31e+01
  [eval] val_mse=4.060e+01  (n=7000)
Epoch 00009: Time=   5.1s, Loss=1.23e+02, Inv=1.23e+02, For=5.17e+00, Power=1.84e+01
  [eval] val_mse=3.453e+01  (n=7000)
Epoch 00010: Time=   5.1s, Loss=1.02e+02, Inv=1.02e+02, For=5.16e+00, Power=1.50e+01
  [eval] val_mse=2.951e+01  (n=7000)
Epoch 00011: Time=   5.1s, Loss=8.45e+01, Inv=8.45e+01, For=5.11e+00, Power=1.23e+01
  [eval] val_mse=2.549e+01  (n=7000)
Epoch 00012: Time=   5.2s, Loss=7.17e+01, Inv=7.17e+01, For=5.10e+00, Power=1.03e+01
  [eval] val_mse=2.213e+01  (n=7000)
Epoch 00013: Time=   5.2s, Loss=6.12e+01, Inv=6.12e+01, For=5.09e+00, Power=8.74e+00
  [eval] val_mse=1.934e+01  (n=7000)
Epoch 00014: Time=   5.2s, Loss=5.28e+01, Inv=5.28e+01, For=5.10e+00, Power=7.52e+00
  [eval] val_mse=1.704e+01  (n=7000)
Epoch 00015: Time=   5.2s, Loss=4.61e+01, Inv=4.61e+01, For=5.10e+00, Power=6.50e+00
  [eval] val_mse=1.512e+01  (n=7000)
Epoch 00016: Time=   5.3s, Loss=4.05e+01, Inv=4.05e+01, For=5.11e+00, Power=5.68e+00
  [eval] val_mse=1.346e+01  (n=7000)
Epoch 00017: Time=   5.3s, Loss=3.59e+01, Inv=3.59e+01, For=5.14e+00, Power=5.06e+00
  [eval] val_mse=1.206e+01  (n=7000)
Epoch 00018: Time=   5.3s, Loss=3.21e+01, Inv=3.21e+01, For=5.18e+00, Power=4.48e+00
  [eval] val_mse=1.084e+01  (n=7000)
Epoch 00019: Time=   5.4s, Loss=2.89e+01, Inv=2.89e+01, For=5.17e+00, Power=4.01e+00
  [eval] val_mse=9.812e+00  (n=7000)
Epoch 00020: Time=   5.4s, Loss=2.60e+01, Inv=2.60e+01, For=5.23e+00, Power=3.61e+00
  [eval] val_mse=8.926e+00  (n=7000)
Epoch 00021: Time=   5.4s, Loss=2.37e+01, Inv=2.37e+01, For=5.27e+00, Power=3.30e+00
  [eval] val_mse=8.144e+00  (n=7000)
Epoch 00022: Time=   5.4s, Loss=2.17e+01, Inv=2.17e+01, For=5.31e+00, Power=3.01e+00
  [eval] val_mse=7.467e+00  (n=7000)
Epoch 00023: Time=   5.5s, Loss=1.99e+01, Inv=1.99e+01, For=5.39e+00, Power=2.77e+00
  [eval] val_mse=6.869e+00  (n=7000)
Epoch 00024: Time=   5.5s, Loss=1.84e+01, Inv=1.84e+01, For=5.44e+00, Power=2.54e+00
  [eval] val_mse=6.355e+00  (n=7000)
Epoch 00025: Time=   5.5s, Loss=1.71e+01, Inv=1.71e+01, For=5.51e+00, Power=2.35e+00
  [eval] val_mse=5.897e+00  (n=7000)
Epoch 00026: Time=   5.5s, Loss=1.60e+01, Inv=1.60e+01, For=5.60e+00, Power=2.20e+00
  [eval] val_mse=5.493e+00  (n=7000)
Epoch 00027: Time=   5.6s, Loss=1.49e+01, Inv=1.49e+01, For=5.70e+00, Power=2.05e+00
  [eval] val_mse=5.133e+00  (n=7000)
Epoch 00028: Time=   5.6s, Loss=1.40e+01, Inv=1.40e+01, For=5.81e+00, Power=1.94e+00
  [eval] val_mse=4.818e+00  (n=7000)
Epoch 00029: Time=   5.6s, Loss=1.33e+01, Inv=1.33e+01, For=5.92e+00, Power=1.82e+00
  [eval] val_mse=4.524e+00  (n=7000)
Epoch 00030: Time=   5.7s, Loss=1.26e+01, Inv=1.26e+01, For=6.05e+00, Power=1.73e+00
  [eval] val_mse=4.267e+00  (n=7000)
Epoch 00031: Time=   5.7s, Loss=1.19e+01, Inv=1.19e+01, For=6.21e+00, Power=1.64e+00
  [eval] val_mse=4.036e+00  (n=7000)
Epoch 00032: Time=   5.7s, Loss=1.13e+01, Inv=1.13e+01, For=6.37e+00, Power=1.56e+00
  [eval] val_mse=3.826e+00  (n=7000)
Epoch 00033: Time=   5.7s, Loss=1.08e+01, Inv=1.08e+01, For=6.55e+00, Power=1.48e+00
  [eval] val_mse=3.635e+00  (n=7000)
Epoch 00034: Time=   5.8s, Loss=1.04e+01, Inv=1.04e+01, For=6.70e+00, Power=1.43e+00
  [eval] val_mse=3.460e+00  (n=7000)
Epoch 00035: Time=   5.8s, Loss=9.93e+00, Inv=9.93e+00, For=6.87e+00, Power=1.37e+00
  [eval] val_mse=3.297e+00  (n=7000)
Epoch 00036: Time=   5.8s, Loss=9.53e+00, Inv=9.53e+00, For=7.08e+00, Power=1.32e+00
  [eval] val_mse=3.147e+00  (n=7000)
Epoch 00037: Time=   5.9s, Loss=9.17e+00, Inv=9.17e+00, For=7.25e+00, Power=1.27e+00
  [eval] val_mse=3.008e+00  (n=7000)
Epoch 00038: Time=   5.9s, Loss=8.83e+00, Inv=8.83e+00, For=7.50e+00, Power=1.23e+00
  [eval] val_mse=2.884e+00  (n=7000)
Epoch 00039: Time=   5.9s, Loss=8.54e+00, Inv=8.54e+00, For=7.72e+00, Power=1.19e+00
  [eval] val_mse=2.769e+00  (n=7000)
Epoch 00040: Time=   5.9s, Loss=8.24e+00, Inv=8.24e+00, For=7.95e+00, Power=1.15e+00
  [eval] val_mse=2.657e+00  (n=7000)
Epoch 00041: Time=   6.0s, Loss=8.02e+00, Inv=8.02e+00, For=8.20e+00, Power=1.13e+00
  [eval] val_mse=2.555e+00  (n=7000)
Epoch 00042: Time=   6.0s, Loss=7.75e+00, Inv=7.75e+00, For=8.41e+00, Power=1.10e+00
  [eval] val_mse=2.459e+00  (n=7000)
Epoch 00043: Time=   6.0s, Loss=7.55e+00, Inv=7.55e+00, For=8.69e+00, Power=1.08e+00
  [eval] val_mse=2.370e+00  (n=7000)
Epoch 00044: Time=   6.0s, Loss=7.35e+00, Inv=7.35e+00, For=8.97e+00, Power=1.04e+00
  [eval] val_mse=2.289e+00  (n=7000)
Epoch 00045: Time=   6.1s, Loss=7.15e+00, Inv=7.15e+00, For=9.21e+00, Power=1.02e+00
  [eval] val_mse=2.209e+00  (n=7000)
Epoch 00046: Time=   6.1s, Loss=6.97e+00, Inv=6.97e+00, For=9.49e+00, Power=1.00e+00
  [eval] val_mse=2.137e+00  (n=7000)
Epoch 00047: Time=   6.1s, Loss=6.80e+00, Inv=6.80e+00, For=9.82e+00, Power=9.82e-01
  [eval] val_mse=2.065e+00  (n=7000)
Epoch 00048: Time=   6.2s, Loss=6.64e+00, Inv=6.64e+00, For=1.00e+01, Power=9.64e-01
  [eval] val_mse=2.000e+00  (n=7000)
Epoch 00049: Time=   6.2s, Loss=6.49e+00, Inv=6.49e+00, For=1.03e+01, Power=9.48e-01
  [eval] val_mse=1.939e+00  (n=7000)
Epoch 00050: Time=   6.2s, Loss=6.36e+00, Inv=6.36e+00, For=1.06e+01, Power=9.36e-01
  [eval] val_mse=1.880e+00  (n=7000)
Epoch 00051: Time=   6.2s, Loss=6.23e+00, Inv=6.23e+00, For=1.09e+01, Power=9.18e-01
  [eval] val_mse=1.826e+00  (n=7000)
Epoch 00052: Time=   6.3s, Loss=6.10e+00, Inv=6.10e+00, For=1.13e+01, Power=9.07e-01
  [eval] val_mse=1.773e+00  (n=7000)
Epoch 00053: Time=   6.3s, Loss=6.00e+00, Inv=6.00e+00, For=1.16e+01, Power=8.97e-01
  [eval] val_mse=1.723e+00  (n=7000)
Epoch 00054: Time=   6.3s, Loss=5.89e+00, Inv=5.89e+00, For=1.18e+01, Power=8.84e-01
  [eval] val_mse=1.677e+00  (n=7000)
Epoch 00055: Time=   6.3s, Loss=5.79e+00, Inv=5.79e+00, For=1.23e+01, Power=8.76e-01
  [eval] val_mse=1.633e+00  (n=7000)
Epoch 00056: Time=   6.4s, Loss=5.68e+00, Inv=5.68e+00, For=1.25e+01, Power=8.65e-01
  [eval] val_mse=1.591e+00  (n=7000)
Epoch 00057: Time=   6.4s, Loss=5.59e+00, Inv=5.59e+00, For=1.29e+01, Power=8.59e-01
  [eval] val_mse=1.550e+00  (n=7000)
Epoch 00058: Time=   6.4s, Loss=5.49e+00, Inv=5.49e+00, For=1.31e+01, Power=8.48e-01
  [eval] val_mse=1.510e+00  (n=7000)
Epoch 00059: Time=   6.5s, Loss=5.42e+00, Inv=5.42e+00, For=1.35e+01, Power=8.44e-01
  [eval] val_mse=1.475e+00  (n=7000)
Epoch 00060: Time=   6.5s, Loss=5.35e+00, Inv=5.35e+00, For=1.39e+01, Power=8.37e-01
  [eval] val_mse=1.441e+00  (n=7000)
Epoch 00061: Time=   6.5s, Loss=5.27e+00, Inv=5.27e+00, For=1.41e+01, Power=8.29e-01
  [eval] val_mse=1.407e+00  (n=7000)
Epoch 00062: Time=   6.5s, Loss=5.19e+00, Inv=5.19e+00, For=1.46e+01, Power=8.21e-01
  [eval] val_mse=1.375e+00  (n=7000)
Epoch 00063: Time=   6.6s, Loss=5.13e+00, Inv=5.13e+00, For=1.49e+01, Power=8.13e-01
  [eval] val_mse=1.343e+00  (n=7000)
Epoch 00064: Time=   6.6s, Loss=5.05e+00, Inv=5.05e+00, For=1.52e+01, Power=8.08e-01
  [eval] val_mse=1.315e+00  (n=7000)
Epoch 00065: Time=   6.6s, Loss=4.99e+00, Inv=4.99e+00, For=1.55e+01, Power=8.03e-01
  [eval] val_mse=1.287e+00  (n=7000)
Epoch 00066: Time=   6.7s, Loss=4.93e+00, Inv=4.93e+00, For=1.59e+01, Power=7.99e-01
  [eval] val_mse=1.259e+00  (n=7000)
Epoch 00067: Time=   6.7s, Loss=4.87e+00, Inv=4.87e+00, For=1.63e+01, Power=7.97e-01
  [eval] val_mse=1.234e+00  (n=7000)
Epoch 00068: Time=   6.7s, Loss=4.81e+00, Inv=4.81e+00, For=1.64e+01, Power=7.89e-01
  [eval] val_mse=1.210e+00  (n=7000)
Epoch 00069: Time=   6.8s, Loss=4.77e+00, Inv=4.77e+00, For=1.72e+01, Power=7.82e-01
  [eval] val_mse=1.186e+00  (n=7000)
Epoch 00070: Time=   6.8s, Loss=4.71e+00, Inv=4.71e+00, For=1.74e+01, Power=7.80e-01
  [eval] val_mse=1.162e+00  (n=7000)
Epoch 00071: Time=   6.8s, Loss=4.66e+00, Inv=4.66e+00, For=1.77e+01, Power=7.80e-01
  [eval] val_mse=1.139e+00  (n=7000)
Epoch 00072: Time=   6.9s, Loss=4.61e+00, Inv=4.61e+00, For=1.80e+01, Power=7.74e-01
  [eval] val_mse=1.119e+00  (n=7000)
Epoch 00073: Time=   6.9s, Loss=4.57e+00, Inv=4.57e+00, For=1.84e+01, Power=7.70e-01
  [eval] val_mse=1.099e+00  (n=7000)
Epoch 00074: Time=   6.9s, Loss=4.52e+00, Inv=4.52e+00, For=1.88e+01, Power=7.65e-01
  [eval] val_mse=1.081e+00  (n=7000)
Epoch 00075: Time=   7.0s, Loss=4.47e+00, Inv=4.47e+00, For=1.90e+01, Power=7.62e-01
  [eval] val_mse=1.060e+00  (n=7000)
Epoch 00076: Time=   7.0s, Loss=4.44e+00, Inv=4.44e+00, For=1.94e+01, Power=7.62e-01
  [eval] val_mse=1.042e+00  (n=7000)
Epoch 00077: Time=   7.0s, Loss=4.40e+00, Inv=4.40e+00, For=2.00e+01, Power=7.60e-01
  [eval] val_mse=1.026e+00  (n=7000)
Epoch 00078: Time=   7.1s, Loss=4.36e+00, Inv=4.36e+00, For=2.02e+01, Power=7.56e-01
  [eval] val_mse=1.010e+00  (n=7000)
Epoch 00079: Time=   7.1s, Loss=4.32e+00, Inv=4.32e+00, For=2.08e+01, Power=7.49e-01
  [eval] val_mse=9.934e-01  (n=7000)
Epoch 00080: Time=   7.1s, Loss=4.29e+00, Inv=4.29e+00, For=2.09e+01, Power=7.53e-01
  [eval] val_mse=9.783e-01  (n=7000)
Epoch 00081: Time=   7.1s, Loss=4.26e+00, Inv=4.26e+00, For=2.16e+01, Power=7.48e-01
  [eval] val_mse=9.619e-01  (n=7000)
Epoch 00082: Time=   7.2s, Loss=4.23e+00, Inv=4.23e+00, For=2.18e+01, Power=7.48e-01
  [eval] val_mse=9.480e-01  (n=7000)
Epoch 00083: Time=   7.2s, Loss=4.19e+00, Inv=4.19e+00, For=2.23e+01, Power=7.46e-01
  [eval] val_mse=9.331e-01  (n=7000)
Epoch 00084: Time=   7.2s, Loss=4.16e+00, Inv=4.16e+00, For=2.25e+01, Power=7.44e-01
  [eval] val_mse=9.203e-01  (n=7000)
Epoch 00085: Time=   7.3s, Loss=4.13e+00, Inv=4.13e+00, For=2.31e+01, Power=7.40e-01
  [eval] val_mse=9.062e-01  (n=7000)
Epoch 00086: Time=   7.3s, Loss=4.10e+00, Inv=4.10e+00, For=2.36e+01, Power=7.40e-01
  [eval] val_mse=8.936e-01  (n=7000)
Epoch 00087: Time=   7.3s, Loss=4.08e+00, Inv=4.08e+00, For=2.37e+01, Power=7.39e-01
  [eval] val_mse=8.813e-01  (n=7000)
Epoch 00088: Time=   7.3s, Loss=4.05e+00, Inv=4.05e+00, For=2.41e+01, Power=7.36e-01
  [eval] val_mse=8.694e-01  (n=7000)
Epoch 00089: Time=   7.4s, Loss=4.02e+00, Inv=4.02e+00, For=2.46e+01, Power=7.34e-01
  [eval] val_mse=8.574e-01  (n=7000)
Epoch 00090: Time=   7.4s, Loss=3.99e+00, Inv=3.99e+00, For=2.51e+01, Power=7.31e-01
  [eval] val_mse=8.460e-01  (n=7000)
Epoch 00091: Time=   7.4s, Loss=3.97e+00, Inv=3.97e+00, For=2.55e+01, Power=7.34e-01
  [eval] val_mse=8.348e-01  (n=7000)
Epoch 00092: Time=   7.5s, Loss=3.95e+00, Inv=3.95e+00, For=2.58e+01, Power=7.32e-01
  [eval] val_mse=8.248e-01  (n=7000)
Epoch 00093: Time=   7.5s, Loss=3.93e+00, Inv=3.93e+00, For=2.61e+01, Power=7.29e-01
  [eval] val_mse=8.145e-01  (n=7000)
Epoch 00094: Time=   7.5s, Loss=3.91e+00, Inv=3.91e+00, For=2.69e+01, Power=7.28e-01
  [eval] val_mse=8.040e-01  (n=7000)
Epoch 00095: Time=   7.5s, Loss=3.88e+00, Inv=3.88e+00, For=2.69e+01, Power=7.24e-01
  [eval] val_mse=7.940e-01  (n=7000)
Epoch 00096: Time=   7.6s, Loss=3.86e+00, Inv=3.86e+00, For=2.78e+01, Power=7.24e-01
  [eval] val_mse=7.849e-01  (n=7000)
Epoch 00097: Time=   7.6s, Loss=3.84e+00, Inv=3.84e+00, For=2.80e+01, Power=7.26e-01
  [eval] val_mse=7.749e-01  (n=7000)
Epoch 00098: Time=   7.6s, Loss=3.82e+00, Inv=3.82e+00, For=2.85e+01, Power=7.24e-01
  [eval] val_mse=7.665e-01  (n=7000)
Epoch 00099: Time=   7.7s, Loss=3.81e+00, Inv=3.81e+00, For=2.90e+01, Power=7.23e-01
  [eval] val_mse=7.578e-01  (n=7000)
Epoch 00100: Time=   7.7s, Loss=3.79e+00, Inv=3.79e+00, For=2.93e+01, Power=7.19e-01
  [eval] val_mse=7.480e-01  (n=7000)
Epoch 00101: Time=   7.7s, Loss=3.77e+00, Inv=3.77e+00, For=2.99e+01, Power=7.20e-01
  [eval] val_mse=7.401e-01  (n=7000)
Epoch 00102: Time=   7.7s, Loss=3.75e+00, Inv=3.75e+00, For=3.00e+01, Power=7.19e-01
  [eval] val_mse=7.318e-01  (n=7000)
Epoch 00103: Time=   7.8s, Loss=3.74e+00, Inv=3.74e+00, For=3.06e+01, Power=7.16e-01
  [eval] val_mse=7.236e-01  (n=7000)
Epoch 00104: Time=   7.8s, Loss=3.72e+00, Inv=3.72e+00, For=3.13e+01, Power=7.17e-01
  [eval] val_mse=7.179e-01  (n=7000)
Epoch 00105: Time=   7.8s, Loss=3.70e+00, Inv=3.70e+00, For=3.17e+01, Power=7.17e-01
  [eval] val_mse=7.094e-01  (n=7000)
Epoch 00106: Time=   7.9s, Loss=3.69e+00, Inv=3.69e+00, For=3.20e+01, Power=7.15e-01
  [eval] val_mse=7.023e-01  (n=7000)
Epoch 00107: Time=   7.9s, Loss=3.67e+00, Inv=3.67e+00, For=3.25e+01, Power=7.15e-01
  [eval] val_mse=6.939e-01  (n=7000)
Epoch 00108: Time=   7.9s, Loss=3.65e+00, Inv=3.65e+00, For=3.30e+01, Power=7.12e-01
  [eval] val_mse=6.868e-01  (n=7000)
Epoch 00109: Time=   7.9s, Loss=3.65e+00, Inv=3.65e+00, For=3.35e+01, Power=7.14e-01
  [eval] val_mse=6.796e-01  (n=7000)
Epoch 00110: Time=   8.0s, Loss=3.63e+00, Inv=3.63e+00, For=3.37e+01, Power=7.12e-01
  [eval] val_mse=6.736e-01  (n=7000)
Epoch 00111: Time=   8.0s, Loss=3.62e+00, Inv=3.62e+00, For=3.43e+01, Power=7.15e-01
  [eval] val_mse=6.676e-01  (n=7000)
Epoch 00112: Time=   8.0s, Loss=3.61e+00, Inv=3.61e+00, For=3.54e+01, Power=7.13e-01
  [eval] val_mse=6.607e-01  (n=7000)
Epoch 00113: Time=   8.0s, Loss=3.60e+00, Inv=3.60e+00, For=3.54e+01, Power=7.12e-01
  [eval] val_mse=6.547e-01  (n=7000)
Epoch 00114: Time=   8.1s, Loss=3.58e+00, Inv=3.58e+00, For=3.59e+01, Power=7.14e-01
  [eval] val_mse=6.487e-01  (n=7000)
Epoch 00115: Time=   8.1s, Loss=3.57e+00, Inv=3.57e+00, For=3.67e+01, Power=7.12e-01
  [eval] val_mse=6.429e-01  (n=7000)
Epoch 00116: Time=   8.1s, Loss=3.56e+00, Inv=3.56e+00, For=3.71e+01, Power=7.05e-01
  [eval] val_mse=6.372e-01  (n=7000)
Epoch 00117: Time=   8.2s, Loss=3.55e+00, Inv=3.55e+00, For=3.77e+01, Power=7.09e-01
  [eval] val_mse=6.312e-01  (n=7000)
Epoch 00118: Time=   8.2s, Loss=3.54e+00, Inv=3.54e+00, For=3.80e+01, Power=7.08e-01
  [eval] val_mse=6.261e-01  (n=7000)
Epoch 00119: Time=   8.2s, Loss=3.53e+00, Inv=3.53e+00, For=3.87e+01, Power=7.09e-01
  [eval] val_mse=6.206e-01  (n=7000)
Epoch 00120: Time=   8.2s, Loss=3.52e+00, Inv=3.52e+00, For=3.93e+01, Power=7.08e-01
  [eval] val_mse=6.158e-01  (n=7000)
Epoch 00121: Time=   8.3s, Loss=3.51e+00, Inv=3.51e+00, For=3.98e+01, Power=7.06e-01
  [eval] val_mse=6.105e-01  (n=7000)
Epoch 00122: Time=   8.3s, Loss=3.50e+00, Inv=3.50e+00, For=4.04e+01, Power=7.04e-01
  [eval] val_mse=6.053e-01  (n=7000)
Epoch 00123: Time=   8.3s, Loss=3.50e+00, Inv=3.50e+00, For=4.09e+01, Power=7.04e-01
  [eval] val_mse=6.006e-01  (n=7000)
Epoch 00124: Time=   8.4s, Loss=3.48e+00, Inv=3.48e+00, For=4.17e+01, Power=7.04e-01
  [eval] val_mse=5.957e-01  (n=7000)
Epoch 00125: Time=   8.4s, Loss=3.47e+00, Inv=3.47e+00, For=4.20e+01, Power=7.04e-01
  [eval] val_mse=5.909e-01  (n=7000)
Epoch 00126: Time=   8.4s, Loss=3.47e+00, Inv=3.47e+00, For=4.26e+01, Power=7.06e-01
  [eval] val_mse=5.864e-01  (n=7000)
Epoch 00127: Time=   8.5s, Loss=3.46e+00, Inv=3.46e+00, For=4.34e+01, Power=7.05e-01
  [eval] val_mse=5.816e-01  (n=7000)
Epoch 00128: Time=   8.5s, Loss=3.44e+00, Inv=3.44e+00, For=4.38e+01, Power=7.01e-01
  [eval] val_mse=5.776e-01  (n=7000)
Epoch 00129: Time=   8.5s, Loss=3.44e+00, Inv=3.44e+00, For=4.44e+01, Power=7.05e-01
  [eval] val_mse=5.734e-01  (n=7000)
Epoch 00130: Time=   8.5s, Loss=3.43e+00, Inv=3.43e+00, For=4.49e+01, Power=7.02e-01
  [eval] val_mse=5.689e-01  (n=7000)
Epoch 00131: Time=   8.6s, Loss=3.43e+00, Inv=3.43e+00, For=4.57e+01, Power=7.05e-01
  [eval] val_mse=5.654e-01  (n=7000)
Epoch 00132: Time=   8.6s, Loss=3.42e+00, Inv=3.42e+00, For=4.64e+01, Power=7.05e-01
  [eval] val_mse=5.611e-01  (n=7000)
Epoch 00133: Time=   8.6s, Loss=3.41e+00, Inv=3.41e+00, For=4.71e+01, Power=7.03e-01
  [eval] val_mse=5.579e-01  (n=7000)
Epoch 00134: Time=   8.7s, Loss=3.40e+00, Inv=3.40e+00, For=4.74e+01, Power=7.01e-01
  [eval] val_mse=5.534e-01  (n=7000)
Epoch 00135: Time=   8.7s, Loss=3.39e+00, Inv=3.39e+00, For=4.84e+01, Power=7.01e-01
  [eval] val_mse=5.498e-01  (n=7000)
Epoch 00136: Time=   8.7s, Loss=3.39e+00, Inv=3.39e+00, For=4.88e+01, Power=7.02e-01
  [eval] val_mse=5.463e-01  (n=7000)
Epoch 00137: Time=   8.7s, Loss=3.38e+00, Inv=3.38e+00, For=4.99e+01, Power=7.00e-01
  [eval] val_mse=5.435e-01  (n=7000)
Epoch 00138: Time=   8.8s, Loss=3.38e+00, Inv=3.38e+00, For=5.00e+01, Power=6.99e-01
  [eval] val_mse=5.404e-01  (n=7000)
Epoch 00139: Time=   8.8s, Loss=3.37e+00, Inv=3.37e+00, For=5.13e+01, Power=6.98e-01
  [eval] val_mse=5.366e-01  (n=7000)
Epoch 00140: Time=   8.8s, Loss=3.36e+00, Inv=3.36e+00, For=5.12e+01, Power=7.00e-01
  [eval] val_mse=5.329e-01  (n=7000)
Epoch 00141: Time=   8.9s, Loss=3.35e+00, Inv=3.35e+00, For=5.26e+01, Power=6.99e-01
  [eval] val_mse=5.293e-01  (n=7000)
Epoch 00142: Time=   8.9s, Loss=3.35e+00, Inv=3.35e+00, For=5.30e+01, Power=6.99e-01
  [eval] val_mse=5.262e-01  (n=7000)
Epoch 00143: Time=   8.9s, Loss=3.34e+00, Inv=3.34e+00, For=5.31e+01, Power=7.00e-01
  [eval] val_mse=5.238e-01  (n=7000)
Epoch 00144: Time=   9.0s, Loss=3.34e+00, Inv=3.34e+00, For=5.43e+01, Power=6.95e-01
  [eval] val_mse=5.196e-01  (n=7000)
Epoch 00145: Time=   9.0s, Loss=3.33e+00, Inv=3.33e+00, For=5.55e+01, Power=6.98e-01
  [eval] val_mse=5.172e-01  (n=7000)
Epoch 00146: Time=   9.0s, Loss=3.33e+00, Inv=3.33e+00, For=5.55e+01, Power=6.98e-01
  [eval] val_mse=5.139e-01  (n=7000)
Epoch 00147: Time=   9.1s, Loss=3.32e+00, Inv=3.32e+00, For=5.68e+01, Power=6.97e-01
  [eval] val_mse=5.114e-01  (n=7000)
Epoch 00148: Time=   9.1s, Loss=3.32e+00, Inv=3.32e+00, For=5.75e+01, Power=6.99e-01
  [eval] val_mse=5.085e-01  (n=7000)
Epoch 00149: Time=   9.1s, Loss=3.31e+00, Inv=3.31e+00, For=5.78e+01, Power=6.96e-01
  [eval] val_mse=5.062e-01  (n=7000)
Epoch 00150: Time=   9.1s, Loss=3.31e+00, Inv=3.31e+00, For=5.87e+01, Power=6.98e-01
  [eval] val_mse=5.027e-01  (n=7000)
Epoch 00151: Time=   9.2s, Loss=3.30e+00, Inv=3.30e+00, For=5.95e+01, Power=6.98e-01
  [eval] val_mse=5.002e-01  (n=7000)
Epoch 00152: Time=   9.2s, Loss=3.30e+00, Inv=3.30e+00, For=6.01e+01, Power=6.95e-01
  [eval] val_mse=4.974e-01  (n=7000)
Epoch 00153: Time=   9.2s, Loss=3.29e+00, Inv=3.29e+00, For=6.11e+01, Power=6.96e-01
  [eval] val_mse=4.954e-01  (n=7000)
Epoch 00154: Time=   9.3s, Loss=3.29e+00, Inv=3.29e+00, For=6.22e+01, Power=6.95e-01
  [eval] val_mse=4.930e-01  (n=7000)
Epoch 00155: Time=   9.3s, Loss=3.28e+00, Inv=3.28e+00, For=6.24e+01, Power=6.97e-01
  [eval] val_mse=4.903e-01  (n=7000)
Epoch 00156: Time=   9.3s, Loss=3.28e+00, Inv=3.28e+00, For=6.37e+01, Power=6.96e-01
  [eval] val_mse=4.877e-01  (n=7000)
Epoch 00157: Time=   9.4s, Loss=3.27e+00, Inv=3.27e+00, For=6.41e+01, Power=6.94e-01
  [eval] val_mse=4.861e-01  (n=7000)
Epoch 00158: Time=   9.4s, Loss=3.26e+00, Inv=3.26e+00, For=6.50e+01, Power=6.94e-01
  [eval] val_mse=4.838e-01  (n=7000)
Epoch 00159: Time=   9.4s, Loss=3.27e+00, Inv=3.27e+00, For=6.50e+01, Power=6.96e-01
  [eval] val_mse=4.811e-01  (n=7000)
Epoch 00160: Time=   9.4s, Loss=3.26e+00, Inv=3.26e+00, For=6.71e+01, Power=6.94e-01
  [eval] val_mse=4.789e-01  (n=7000)
Epoch 00161: Time=   9.5s, Loss=3.26e+00, Inv=3.26e+00, For=6.70e+01, Power=6.94e-01
  [eval] val_mse=4.769e-01  (n=7000)
Epoch 00162: Time=   9.5s, Loss=3.25e+00, Inv=3.25e+00, For=6.87e+01, Power=6.96e-01
  [eval] val_mse=4.744e-01  (n=7000)
Epoch 00163: Time=   9.5s, Loss=3.25e+00, Inv=3.25e+00, For=6.82e+01, Power=6.95e-01
  [eval] val_mse=4.723e-01  (n=7000)
Epoch 00164: Time=   9.6s, Loss=3.24e+00, Inv=3.24e+00, For=6.99e+01, Power=6.92e-01
  [eval] val_mse=4.702e-01  (n=7000)
Epoch 00165: Time=   9.6s, Loss=3.24e+00, Inv=3.24e+00, For=7.05e+01, Power=6.94e-01
  [eval] val_mse=4.686e-01  (n=7000)
Epoch 00166: Time=   9.6s, Loss=3.24e+00, Inv=3.24e+00, For=7.19e+01, Power=6.93e-01
  [eval] val_mse=4.665e-01  (n=7000)
Epoch 00167: Time=   9.6s, Loss=3.23e+00, Inv=3.23e+00, For=7.23e+01, Power=6.93e-01
  [eval] val_mse=4.645e-01  (n=7000)
Epoch 00168: Time=   9.7s, Loss=3.23e+00, Inv=3.23e+00, For=7.26e+01, Power=6.94e-01
  [eval] val_mse=4.626e-01  (n=7000)
Epoch 00169: Time=   9.7s, Loss=3.22e+00, Inv=3.22e+00, For=7.34e+01, Power=6.89e-01
  [eval] val_mse=4.605e-01  (n=7000)
Epoch 00170: Time=   9.7s, Loss=3.22e+00, Inv=3.22e+00, For=7.49e+01, Power=6.91e-01
  [eval] val_mse=4.585e-01  (n=7000)
Epoch 00171: Time=   9.8s, Loss=3.22e+00, Inv=3.22e+00, For=7.63e+01, Power=6.94e-01
  [eval] val_mse=4.570e-01  (n=7000)
Epoch 00172: Time=   9.8s, Loss=3.21e+00, Inv=3.21e+00, For=7.66e+01, Power=6.94e-01
  [eval] val_mse=4.556e-01  (n=7000)
Epoch 00173: Time=   9.8s, Loss=3.21e+00, Inv=3.21e+00, For=7.72e+01, Power=6.93e-01
  [eval] val_mse=4.530e-01  (n=7000)
Epoch 00174: Time=   9.8s, Loss=3.21e+00, Inv=3.21e+00, For=7.83e+01, Power=6.92e-01
  [eval] val_mse=4.512e-01  (n=7000)
Epoch 00175: Time=   9.9s, Loss=3.20e+00, Inv=3.20e+00, For=7.86e+01, Power=6.89e-01
  [eval] val_mse=4.496e-01  (n=7000)
Epoch 00176: Time=   9.9s, Loss=3.19e+00, Inv=3.19e+00, For=8.03e+01, Power=6.90e-01
  [eval] val_mse=4.477e-01  (n=7000)
Epoch 00177: Time=   9.9s, Loss=3.19e+00, Inv=3.19e+00, For=8.08e+01, Power=6.90e-01
  [eval] val_mse=4.463e-01  (n=7000)
Epoch 00178: Time=  10.0s, Loss=3.19e+00, Inv=3.19e+00, For=8.11e+01, Power=6.91e-01
  [eval] val_mse=4.452e-01  (n=7000)
Epoch 00179: Time=  10.0s, Loss=3.19e+00, Inv=3.19e+00, For=8.39e+01, Power=6.88e-01
  [eval] val_mse=4.424e-01  (n=7000)
Epoch 00180: Time=  10.0s, Loss=3.18e+00, Inv=3.18e+00, For=8.38e+01, Power=6.92e-01
  [eval] val_mse=4.415e-01  (n=7000)
Epoch 00181: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=8.46e+01, Power=6.92e-01
  [eval] val_mse=4.399e-01  (n=7000)
Epoch 00182: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=8.52e+01, Power=6.91e-01
  [eval] val_mse=4.387e-01  (n=7000)
Epoch 00183: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=8.61e+01, Power=6.91e-01
  [eval] val_mse=4.373e-01  (n=7000)
Epoch 00184: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=8.76e+01, Power=6.90e-01
  [eval] val_mse=4.350e-01  (n=7000)
Epoch 00185: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=8.75e+01, Power=6.92e-01
  [eval] val_mse=4.337e-01  (n=7000)
Epoch 00186: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=8.91e+01, Power=6.91e-01
  [eval] val_mse=4.318e-01  (n=7000)
Epoch 00187: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=8.95e+01, Power=6.89e-01
  [eval] val_mse=4.314e-01  (n=7000)
Epoch 00188: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=9.13e+01, Power=6.89e-01
  [eval] val_mse=4.292e-01  (n=7000)
Epoch 00189: Time=  10.3s, Loss=3.16e+00, Inv=3.16e+00, For=9.20e+01, Power=6.90e-01
  [eval] val_mse=4.280e-01  (n=7000)
Epoch 00190: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=9.32e+01, Power=6.88e-01
  [eval] val_mse=4.260e-01  (n=7000)
Epoch 00191: Time=  10.4s, Loss=3.15e+00, Inv=3.15e+00, For=9.34e+01, Power=6.88e-01
  [eval] val_mse=4.245e-01  (n=7000)
Epoch 00192: Time=  10.4s, Loss=3.15e+00, Inv=3.15e+00, For=9.48e+01, Power=6.89e-01
  [eval] val_mse=4.237e-01  (n=7000)
Epoch 00193: Time=  10.4s, Loss=3.15e+00, Inv=3.15e+00, For=9.58e+01, Power=6.91e-01
  [eval] val_mse=4.227e-01  (n=7000)
Epoch 00194: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=9.69e+01, Power=6.89e-01
  [eval] val_mse=4.210e-01  (n=7000)
Epoch 00195: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=9.75e+01, Power=6.91e-01
  [eval] val_mse=4.193e-01  (n=7000)
Epoch 00196: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=9.74e+01, Power=6.90e-01
  [eval] val_mse=4.177e-01  (n=7000)
Epoch 00197: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=9.98e+01, Power=6.90e-01
  [eval] val_mse=4.167e-01  (n=7000)
Epoch 00198: Time=  10.6s, Loss=3.14e+00, Inv=3.14e+00, For=1.01e+02, Power=6.89e-01
  [eval] val_mse=4.167e-01  (n=7000)
Epoch 00199: Time=  10.6s, Loss=3.13e+00, Inv=3.13e+00, For=1.02e+02, Power=6.89e-01
  [eval] val_mse=4.142e-01  (n=7000)
Epoch 00200: Time=  10.6s, Loss=3.13e+00, Inv=3.13e+00, For=1.02e+02, Power=6.90e-01
  [eval] val_mse=4.135e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 2.625e-01
Torque MSE  = 2.413e-01
Torque RMSE = 4.912e-01
Per-joint MSE : 9.859e-02 7.720e-01 5.127e-02 3.396e-02 4.718e-01 2.039e-02
Per-joint RMSE: 3.140e-01 8.786e-01 2.264e-01 1.843e-01 6.869e-01 1.428e-01
Comp Time per Sample = 2.847e-04s / 3511.9Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-cf72l3vk because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7888cb99e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:45:34.718873: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:45:36.351458: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.0s, Loss=7.43e+03, Inv=7.43e+03, For=5.86e+00, Power=9.63e+02
  [eval] val_mse=3.434e+02  (n=7000)
Epoch 00002: Time=   4.5s, Loss=1.58e+03, Inv=1.58e+03, For=5.72e+00, Power=2.11e+02
  [eval] val_mse=2.170e+02  (n=7000)
Epoch 00003: Time=   4.5s, Loss=7.76e+02, Inv=7.76e+02, For=5.62e+00, Power=1.23e+02
  [eval] val_mse=1.545e+02  (n=7000)
Epoch 00004: Time=   4.5s, Loss=4.81e+02, Inv=4.81e+02, For=5.52e+00, Power=8.07e+01
  [eval] val_mse=1.132e+02  (n=7000)
Epoch 00005: Time=   4.6s, Loss=3.29e+02, Inv=3.29e+02, For=5.45e+00, Power=5.64e+01
  [eval] val_mse=8.458e+01  (n=7000)
Epoch 00006: Time=   4.6s, Loss=2.37e+02, Inv=2.37e+02, For=5.36e+00, Power=4.09e+01
  [eval] val_mse=6.421e+01  (n=7000)
Epoch 00007: Time=   4.6s, Loss=1.77e+02, Inv=1.77e+02, For=5.30e+00, Power=3.08e+01
  [eval] val_mse=4.979e+01  (n=7000)
Epoch 00008: Time=   4.7s, Loss=1.37e+02, Inv=1.37e+02, For=5.24e+00, Power=2.37e+01
  [eval] val_mse=3.940e+01  (n=7000)
Epoch 00009: Time=   4.7s, Loss=1.09e+02, Inv=1.09e+02, For=5.23e+00, Power=1.88e+01
  [eval] val_mse=3.177e+01  (n=7000)
Epoch 00010: Time=   4.7s, Loss=8.82e+01, Inv=8.82e+01, For=5.20e+00, Power=1.53e+01
  [eval] val_mse=2.598e+01  (n=7000)
Epoch 00011: Time=   4.7s, Loss=7.29e+01, Inv=7.29e+01, For=5.20e+00, Power=1.25e+01
  [eval] val_mse=2.159e+01  (n=7000)
Epoch 00012: Time=   4.8s, Loss=6.12e+01, Inv=6.12e+01, For=5.17e+00, Power=1.04e+01
  [eval] val_mse=1.822e+01  (n=7000)
Epoch 00013: Time=   4.8s, Loss=5.22e+01, Inv=5.22e+01, For=5.19e+00, Power=8.80e+00
  [eval] val_mse=1.555e+01  (n=7000)
Epoch 00014: Time=   4.8s, Loss=4.52e+01, Inv=4.52e+01, For=5.19e+00, Power=7.53e+00
  [eval] val_mse=1.342e+01  (n=7000)
Epoch 00015: Time=   4.9s, Loss=3.95e+01, Inv=3.95e+01, For=5.20e+00, Power=6.52e+00
  [eval] val_mse=1.171e+01  (n=7000)
Epoch 00016: Time=   4.9s, Loss=3.48e+01, Inv=3.48e+01, For=5.25e+00, Power=5.71e+00
  [eval] val_mse=1.031e+01  (n=7000)
Epoch 00017: Time=   4.9s, Loss=3.11e+01, Inv=3.11e+01, For=5.31e+00, Power=5.03e+00
  [eval] val_mse=9.141e+00  (n=7000)
Epoch 00018: Time=   5.0s, Loss=2.78e+01, Inv=2.78e+01, For=5.35e+00, Power=4.47e+00
  [eval] val_mse=8.179e+00  (n=7000)
Epoch 00019: Time=   5.0s, Loss=2.51e+01, Inv=2.51e+01, For=5.39e+00, Power=4.02e+00
  [eval] val_mse=7.359e+00  (n=7000)
Epoch 00020: Time=   5.0s, Loss=2.28e+01, Inv=2.28e+01, For=5.47e+00, Power=3.61e+00
  [eval] val_mse=6.659e+00  (n=7000)
Epoch 00021: Time=   5.0s, Loss=2.09e+01, Inv=2.09e+01, For=5.52e+00, Power=3.27e+00
  [eval] val_mse=6.056e+00  (n=7000)
Epoch 00022: Time=   5.1s, Loss=1.92e+01, Inv=1.92e+01, For=5.61e+00, Power=3.01e+00
  [eval] val_mse=5.547e+00  (n=7000)
Epoch 00023: Time=   5.1s, Loss=1.78e+01, Inv=1.78e+01, For=5.68e+00, Power=2.75e+00
  [eval] val_mse=5.104e+00  (n=7000)
Epoch 00024: Time=   5.1s, Loss=1.65e+01, Inv=1.65e+01, For=5.77e+00, Power=2.55e+00
  [eval] val_mse=4.706e+00  (n=7000)
Epoch 00025: Time=   5.2s, Loss=1.54e+01, Inv=1.54e+01, For=5.85e+00, Power=2.36e+00
  [eval] val_mse=4.367e+00  (n=7000)
Epoch 00026: Time=   5.2s, Loss=1.45e+01, Inv=1.45e+01, For=5.97e+00, Power=2.20e+00
  [eval] val_mse=4.060e+00  (n=7000)
Epoch 00027: Time=   5.2s, Loss=1.36e+01, Inv=1.36e+01, For=6.08e+00, Power=2.05e+00
  [eval] val_mse=3.791e+00  (n=7000)
Epoch 00028: Time=   5.2s, Loss=1.28e+01, Inv=1.28e+01, For=6.20e+00, Power=1.93e+00
  [eval] val_mse=3.548e+00  (n=7000)
Epoch 00029: Time=   5.3s, Loss=1.22e+01, Inv=1.22e+01, For=6.33e+00, Power=1.82e+00
  [eval] val_mse=3.329e+00  (n=7000)
Epoch 00030: Time=   5.3s, Loss=1.16e+01, Inv=1.16e+01, For=6.48e+00, Power=1.72e+00
  [eval] val_mse=3.137e+00  (n=7000)
Epoch 00031: Time=   5.3s, Loss=1.10e+01, Inv=1.10e+01, For=6.63e+00, Power=1.64e+00
  [eval] val_mse=2.965e+00  (n=7000)
Epoch 00032: Time=   5.4s, Loss=1.05e+01, Inv=1.05e+01, For=6.80e+00, Power=1.56e+00
  [eval] val_mse=2.807e+00  (n=7000)
Epoch 00033: Time=   5.4s, Loss=1.01e+01, Inv=1.01e+01, For=6.94e+00, Power=1.48e+00
  [eval] val_mse=2.662e+00  (n=7000)
Epoch 00034: Time=   5.4s, Loss=9.67e+00, Inv=9.67e+00, For=7.16e+00, Power=1.42e+00
  [eval] val_mse=2.533e+00  (n=7000)
Epoch 00035: Time=   5.5s, Loss=9.29e+00, Inv=9.29e+00, For=7.34e+00, Power=1.36e+00
  [eval] val_mse=2.416e+00  (n=7000)
Epoch 00036: Time=   5.5s, Loss=8.97e+00, Inv=8.97e+00, For=7.59e+00, Power=1.31e+00
  [eval] val_mse=2.307e+00  (n=7000)
Epoch 00037: Time=   5.5s, Loss=8.64e+00, Inv=8.64e+00, For=7.77e+00, Power=1.26e+00
  [eval] val_mse=2.205e+00  (n=7000)
Epoch 00038: Time=   5.6s, Loss=8.37e+00, Inv=8.37e+00, For=8.04e+00, Power=1.23e+00
  [eval] val_mse=2.116e+00  (n=7000)
Epoch 00039: Time=   5.6s, Loss=8.11e+00, Inv=8.11e+00, For=8.30e+00, Power=1.19e+00
  [eval] val_mse=2.030e+00  (n=7000)
Epoch 00040: Time=   5.6s, Loss=7.86e+00, Inv=7.86e+00, For=8.52e+00, Power=1.15e+00
  [eval] val_mse=1.952e+00  (n=7000)
Epoch 00041: Time=   5.7s, Loss=7.65e+00, Inv=7.65e+00, For=8.81e+00, Power=1.12e+00
  [eval] val_mse=1.880e+00  (n=7000)
Epoch 00042: Time=   5.7s, Loss=7.44e+00, Inv=7.44e+00, For=9.06e+00, Power=1.09e+00
  [eval] val_mse=1.811e+00  (n=7000)
Epoch 00043: Time=   5.7s, Loss=7.24e+00, Inv=7.24e+00, For=9.38e+00, Power=1.06e+00
  [eval] val_mse=1.748e+00  (n=7000)
Epoch 00044: Time=   5.8s, Loss=7.07e+00, Inv=7.07e+00, For=9.68e+00, Power=1.04e+00
  [eval] val_mse=1.688e+00  (n=7000)
Epoch 00045: Time=   5.8s, Loss=6.89e+00, Inv=6.89e+00, For=9.99e+00, Power=1.02e+00
  [eval] val_mse=1.632e+00  (n=7000)
Epoch 00046: Time=   5.8s, Loss=6.74e+00, Inv=6.74e+00, For=1.03e+01, Power=9.96e-01
  [eval] val_mse=1.581e+00  (n=7000)
Epoch 00047: Time=   5.9s, Loss=6.59e+00, Inv=6.59e+00, For=1.07e+01, Power=9.80e-01
  [eval] val_mse=1.531e+00  (n=7000)
Epoch 00048: Time=   5.9s, Loss=6.45e+00, Inv=6.45e+00, For=1.10e+01, Power=9.57e-01
  [eval] val_mse=1.484e+00  (n=7000)
Epoch 00049: Time=   5.9s, Loss=6.33e+00, Inv=6.33e+00, For=1.14e+01, Power=9.47e-01
  [eval] val_mse=1.440e+00  (n=7000)
Epoch 00050: Time=   5.9s, Loss=6.21e+00, Inv=6.21e+00, For=1.17e+01, Power=9.31e-01
  [eval] val_mse=1.400e+00  (n=7000)
Epoch 00051: Time=   6.0s, Loss=6.09e+00, Inv=6.09e+00, For=1.21e+01, Power=9.17e-01
  [eval] val_mse=1.359e+00  (n=7000)
Epoch 00052: Time=   6.0s, Loss=5.98e+00, Inv=5.98e+00, For=1.25e+01, Power=9.05e-01
  [eval] val_mse=1.324e+00  (n=7000)
Epoch 00053: Time=   6.0s, Loss=5.88e+00, Inv=5.88e+00, For=1.29e+01, Power=8.94e-01
  [eval] val_mse=1.288e+00  (n=7000)
Epoch 00054: Time=   6.1s, Loss=5.78e+00, Inv=5.78e+00, For=1.33e+01, Power=8.79e-01
  [eval] val_mse=1.255e+00  (n=7000)
Epoch 00055: Time=   6.1s, Loss=5.69e+00, Inv=5.69e+00, For=1.38e+01, Power=8.71e-01
  [eval] val_mse=1.222e+00  (n=7000)
Epoch 00056: Time=   6.1s, Loss=5.60e+00, Inv=5.60e+00, For=1.42e+01, Power=8.57e-01
  [eval] val_mse=1.195e+00  (n=7000)
Epoch 00057: Time=   6.2s, Loss=5.52e+00, Inv=5.52e+00, For=1.47e+01, Power=8.51e-01
  [eval] val_mse=1.164e+00  (n=7000)
Epoch 00058: Time=   6.2s, Loss=5.44e+00, Inv=5.44e+00, For=1.51e+01, Power=8.44e-01
  [eval] val_mse=1.137e+00  (n=7000)
Epoch 00059: Time=   6.2s, Loss=5.36e+00, Inv=5.36e+00, For=1.56e+01, Power=8.35e-01
  [eval] val_mse=1.112e+00  (n=7000)
Epoch 00060: Time=   6.2s, Loss=5.29e+00, Inv=5.29e+00, For=1.60e+01, Power=8.30e-01
  [eval] val_mse=1.086e+00  (n=7000)
Epoch 00061: Time=   6.3s, Loss=5.22e+00, Inv=5.22e+00, For=1.66e+01, Power=8.19e-01
  [eval] val_mse=1.063e+00  (n=7000)
Epoch 00062: Time=   6.3s, Loss=5.16e+00, Inv=5.16e+00, For=1.71e+01, Power=8.14e-01
  [eval] val_mse=1.040e+00  (n=7000)
Epoch 00063: Time=   6.3s, Loss=5.09e+00, Inv=5.09e+00, For=1.76e+01, Power=8.08e-01
  [eval] val_mse=1.019e+00  (n=7000)
Epoch 00064: Time=   6.4s, Loss=5.03e+00, Inv=5.03e+00, For=1.81e+01, Power=8.03e-01
  [eval] val_mse=9.995e-01  (n=7000)
Epoch 00065: Time=   6.4s, Loss=4.97e+00, Inv=4.97e+00, For=1.87e+01, Power=7.96e-01
  [eval] val_mse=9.796e-01  (n=7000)
Epoch 00066: Time=   6.4s, Loss=4.92e+00, Inv=4.92e+00, For=1.93e+01, Power=7.95e-01
  [eval] val_mse=9.604e-01  (n=7000)
Epoch 00067: Time=   6.5s, Loss=4.86e+00, Inv=4.86e+00, For=1.98e+01, Power=7.87e-01
  [eval] val_mse=9.420e-01  (n=7000)
Epoch 00068: Time=   6.5s, Loss=4.82e+00, Inv=4.82e+00, For=2.04e+01, Power=7.82e-01
  [eval] val_mse=9.244e-01  (n=7000)
Epoch 00069: Time=   6.5s, Loss=4.77e+00, Inv=4.77e+00, For=2.10e+01, Power=7.77e-01
  [eval] val_mse=9.093e-01  (n=7000)
Epoch 00070: Time=   6.6s, Loss=4.72e+00, Inv=4.72e+00, For=2.15e+01, Power=7.73e-01
  [eval] val_mse=8.920e-01  (n=7000)
Epoch 00071: Time=   6.6s, Loss=4.68e+00, Inv=4.68e+00, For=2.22e+01, Power=7.70e-01
  [eval] val_mse=8.782e-01  (n=7000)
Epoch 00072: Time=   6.6s, Loss=4.62e+00, Inv=4.62e+00, For=2.28e+01, Power=7.62e-01
  [eval] val_mse=8.629e-01  (n=7000)
Epoch 00073: Time=   6.6s, Loss=4.59e+00, Inv=4.59e+00, For=2.35e+01, Power=7.64e-01
  [eval] val_mse=8.483e-01  (n=7000)
Epoch 00074: Time=   6.7s, Loss=4.54e+00, Inv=4.54e+00, For=2.41e+01, Power=7.57e-01
  [eval] val_mse=8.359e-01  (n=7000)
Epoch 00075: Time=   6.7s, Loss=4.51e+00, Inv=4.51e+00, For=2.48e+01, Power=7.58e-01
  [eval] val_mse=8.233e-01  (n=7000)
Epoch 00076: Time=   6.7s, Loss=4.47e+00, Inv=4.47e+00, For=2.55e+01, Power=7.55e-01
  [eval] val_mse=8.107e-01  (n=7000)
Epoch 00077: Time=   6.8s, Loss=4.43e+00, Inv=4.43e+00, For=2.61e+01, Power=7.46e-01
  [eval] val_mse=7.992e-01  (n=7000)
Epoch 00078: Time=   6.8s, Loss=4.40e+00, Inv=4.40e+00, For=2.69e+01, Power=7.50e-01
  [eval] val_mse=7.870e-01  (n=7000)
Epoch 00079: Time=   6.8s, Loss=4.37e+00, Inv=4.37e+00, For=2.76e+01, Power=7.46e-01
  [eval] val_mse=7.766e-01  (n=7000)
Epoch 00080: Time=   6.9s, Loss=4.33e+00, Inv=4.33e+00, For=2.84e+01, Power=7.44e-01
  [eval] val_mse=7.650e-01  (n=7000)
Epoch 00081: Time=   6.9s, Loss=4.30e+00, Inv=4.30e+00, For=2.91e+01, Power=7.40e-01
  [eval] val_mse=7.554e-01  (n=7000)
Epoch 00082: Time=   6.9s, Loss=4.28e+00, Inv=4.28e+00, For=2.99e+01, Power=7.41e-01
  [eval] val_mse=7.456e-01  (n=7000)
Epoch 00083: Time=   7.0s, Loss=4.24e+00, Inv=4.24e+00, For=3.08e+01, Power=7.40e-01
  [eval] val_mse=7.367e-01  (n=7000)
Epoch 00084: Time=   7.0s, Loss=4.22e+00, Inv=4.22e+00, For=3.15e+01, Power=7.36e-01
  [eval] val_mse=7.267e-01  (n=7000)
Epoch 00085: Time=   7.0s, Loss=4.19e+00, Inv=4.19e+00, For=3.24e+01, Power=7.36e-01
  [eval] val_mse=7.182e-01  (n=7000)
Epoch 00086: Time=   7.0s, Loss=4.16e+00, Inv=4.16e+00, For=3.30e+01, Power=7.33e-01
  [eval] val_mse=7.099e-01  (n=7000)
Epoch 00087: Time=   7.1s, Loss=4.13e+00, Inv=4.13e+00, For=3.40e+01, Power=7.31e-01
  [eval] val_mse=7.024e-01  (n=7000)
Epoch 00088: Time=   7.1s, Loss=4.11e+00, Inv=4.11e+00, For=3.48e+01, Power=7.29e-01
  [eval] val_mse=6.939e-01  (n=7000)
Epoch 00089: Time=   7.1s, Loss=4.08e+00, Inv=4.08e+00, For=3.58e+01, Power=7.29e-01
  [eval] val_mse=6.856e-01  (n=7000)
Epoch 00090: Time=   7.2s, Loss=4.06e+00, Inv=4.06e+00, For=3.66e+01, Power=7.28e-01
  [eval] val_mse=6.781e-01  (n=7000)
Epoch 00091: Time=   7.2s, Loss=4.04e+00, Inv=4.04e+00, For=3.74e+01, Power=7.23e-01
  [eval] val_mse=6.716e-01  (n=7000)
Epoch 00092: Time=   7.2s, Loss=4.02e+00, Inv=4.02e+00, For=3.85e+01, Power=7.25e-01
  [eval] val_mse=6.640e-01  (n=7000)
Epoch 00093: Time=   7.2s, Loss=3.99e+00, Inv=3.99e+00, For=3.92e+01, Power=7.19e-01
  [eval] val_mse=6.572e-01  (n=7000)
Epoch 00094: Time=   7.3s, Loss=3.96e+00, Inv=3.96e+00, For=4.02e+01, Power=7.19e-01
  [eval] val_mse=6.504e-01  (n=7000)
Epoch 00095: Time=   7.3s, Loss=3.95e+00, Inv=3.95e+00, For=4.11e+01, Power=7.21e-01
  [eval] val_mse=6.446e-01  (n=7000)
Epoch 00096: Time=   7.3s, Loss=3.93e+00, Inv=3.93e+00, For=4.22e+01, Power=7.20e-01
  [eval] val_mse=6.376e-01  (n=7000)
Epoch 00097: Time=   7.4s, Loss=3.91e+00, Inv=3.91e+00, For=4.31e+01, Power=7.19e-01
  [eval] val_mse=6.320e-01  (n=7000)
Epoch 00098: Time=   7.4s, Loss=3.90e+00, Inv=3.90e+00, For=4.41e+01, Power=7.19e-01
  [eval] val_mse=6.262e-01  (n=7000)
Epoch 00099: Time=   7.4s, Loss=3.87e+00, Inv=3.87e+00, For=4.51e+01, Power=7.13e-01
  [eval] val_mse=6.204e-01  (n=7000)
Epoch 00100: Time=   7.4s, Loss=3.86e+00, Inv=3.86e+00, For=4.62e+01, Power=7.17e-01
  [eval] val_mse=6.147e-01  (n=7000)
Epoch 00101: Time=   7.5s, Loss=3.84e+00, Inv=3.84e+00, For=4.71e+01, Power=7.13e-01
  [eval] val_mse=6.092e-01  (n=7000)
Epoch 00102: Time=   7.5s, Loss=3.82e+00, Inv=3.82e+00, For=4.83e+01, Power=7.15e-01
  [eval] val_mse=6.042e-01  (n=7000)
Epoch 00103: Time=   7.5s, Loss=3.81e+00, Inv=3.81e+00, For=4.95e+01, Power=7.12e-01
  [eval] val_mse=5.994e-01  (n=7000)
Epoch 00104: Time=   7.6s, Loss=3.79e+00, Inv=3.79e+00, For=5.05e+01, Power=7.15e-01
  [eval] val_mse=5.941e-01  (n=7000)
Epoch 00105: Time=   7.6s, Loss=3.78e+00, Inv=3.78e+00, For=5.14e+01, Power=7.12e-01
  [eval] val_mse=5.886e-01  (n=7000)
Epoch 00106: Time=   7.6s, Loss=3.76e+00, Inv=3.76e+00, For=5.25e+01, Power=7.12e-01
  [eval] val_mse=5.839e-01  (n=7000)
Epoch 00107: Time=   7.6s, Loss=3.74e+00, Inv=3.74e+00, For=5.38e+01, Power=7.09e-01
  [eval] val_mse=5.798e-01  (n=7000)
Epoch 00108: Time=   7.7s, Loss=3.73e+00, Inv=3.73e+00, For=5.50e+01, Power=7.12e-01
  [eval] val_mse=5.756e-01  (n=7000)
Epoch 00109: Time=   7.7s, Loss=3.72e+00, Inv=3.72e+00, For=5.59e+01, Power=7.10e-01
  [eval] val_mse=5.704e-01  (n=7000)
Epoch 00110: Time=   7.7s, Loss=3.70e+00, Inv=3.70e+00, For=5.73e+01, Power=7.08e-01
  [eval] val_mse=5.666e-01  (n=7000)
Epoch 00111: Time=   7.8s, Loss=3.70e+00, Inv=3.70e+00, For=5.84e+01, Power=7.10e-01
  [eval] val_mse=5.618e-01  (n=7000)
Epoch 00112: Time=   7.8s, Loss=3.67e+00, Inv=3.67e+00, For=5.93e+01, Power=7.05e-01
  [eval] val_mse=5.585e-01  (n=7000)
Epoch 00113: Time=   7.8s, Loss=3.66e+00, Inv=3.66e+00, For=6.09e+01, Power=7.07e-01
  [eval] val_mse=5.547e-01  (n=7000)
Epoch 00114: Time=   7.9s, Loss=3.66e+00, Inv=3.66e+00, For=6.20e+01, Power=7.06e-01
  [eval] val_mse=5.500e-01  (n=7000)
Epoch 00115: Time=   7.9s, Loss=3.64e+00, Inv=3.64e+00, For=6.33e+01, Power=7.07e-01
  [eval] val_mse=5.460e-01  (n=7000)
Epoch 00116: Time=   7.9s, Loss=3.63e+00, Inv=3.63e+00, For=6.44e+01, Power=7.07e-01
  [eval] val_mse=5.422e-01  (n=7000)
Epoch 00117: Time=   7.9s, Loss=3.62e+00, Inv=3.62e+00, For=6.61e+01, Power=7.07e-01
  [eval] val_mse=5.388e-01  (n=7000)
Epoch 00118: Time=   8.0s, Loss=3.61e+00, Inv=3.61e+00, For=6.69e+01, Power=7.01e-01
  [eval] val_mse=5.347e-01  (n=7000)
Epoch 00119: Time=   8.0s, Loss=3.60e+00, Inv=3.60e+00, For=6.85e+01, Power=7.04e-01
  [eval] val_mse=5.318e-01  (n=7000)
Epoch 00120: Time=   8.0s, Loss=3.58e+00, Inv=3.58e+00, For=7.00e+01, Power=7.02e-01
  [eval] val_mse=5.280e-01  (n=7000)
Epoch 00121: Time=   8.1s, Loss=3.58e+00, Inv=3.58e+00, For=7.13e+01, Power=7.04e-01
  [eval] val_mse=5.248e-01  (n=7000)
Epoch 00122: Time=   8.1s, Loss=3.56e+00, Inv=3.56e+00, For=7.28e+01, Power=7.03e-01
  [eval] val_mse=5.208e-01  (n=7000)
Epoch 00123: Time=   8.1s, Loss=3.55e+00, Inv=3.55e+00, For=7.37e+01, Power=7.00e-01
  [eval] val_mse=5.182e-01  (n=7000)
Epoch 00124: Time=   8.1s, Loss=3.54e+00, Inv=3.54e+00, For=7.55e+01, Power=7.03e-01
  [eval] val_mse=5.142e-01  (n=7000)
Epoch 00125: Time=   8.2s, Loss=3.53e+00, Inv=3.53e+00, For=7.66e+01, Power=7.01e-01
  [eval] val_mse=5.116e-01  (n=7000)
Epoch 00126: Time=   8.2s, Loss=3.52e+00, Inv=3.52e+00, For=7.81e+01, Power=7.01e-01
  [eval] val_mse=5.083e-01  (n=7000)
Epoch 00127: Time=   8.2s, Loss=3.52e+00, Inv=3.52e+00, For=7.98e+01, Power=7.01e-01
  [eval] val_mse=5.060e-01  (n=7000)
Epoch 00128: Time=   8.3s, Loss=3.50e+00, Inv=3.50e+00, For=8.11e+01, Power=7.00e-01
  [eval] val_mse=5.022e-01  (n=7000)
Epoch 00129: Time=   8.3s, Loss=3.50e+00, Inv=3.50e+00, For=8.25e+01, Power=7.02e-01
  [eval] val_mse=4.994e-01  (n=7000)
Epoch 00130: Time=   8.3s, Loss=3.49e+00, Inv=3.49e+00, For=8.45e+01, Power=6.99e-01
  [eval] val_mse=4.965e-01  (n=7000)
Epoch 00131: Time=   8.4s, Loss=3.48e+00, Inv=3.48e+00, For=8.51e+01, Power=7.00e-01
  [eval] val_mse=4.944e-01  (n=7000)
Epoch 00132: Time=   8.4s, Loss=3.47e+00, Inv=3.47e+00, For=8.79e+01, Power=6.99e-01
  [eval] val_mse=4.912e-01  (n=7000)
Epoch 00133: Time=   8.4s, Loss=3.47e+00, Inv=3.47e+00, For=8.89e+01, Power=7.01e-01
  [eval] val_mse=4.886e-01  (n=7000)
Epoch 00134: Time=   8.5s, Loss=3.46e+00, Inv=3.46e+00, For=9.01e+01, Power=7.03e-01
  [eval] val_mse=4.857e-01  (n=7000)
Epoch 00135: Time=   8.5s, Loss=3.45e+00, Inv=3.45e+00, For=9.19e+01, Power=7.00e-01
  [eval] val_mse=4.835e-01  (n=7000)
Epoch 00136: Time=   8.5s, Loss=3.44e+00, Inv=3.44e+00, For=9.39e+01, Power=6.97e-01
  [eval] val_mse=4.812e-01  (n=7000)
Epoch 00137: Time=   8.5s, Loss=3.44e+00, Inv=3.44e+00, For=9.55e+01, Power=7.00e-01
  [eval] val_mse=4.784e-01  (n=7000)
Epoch 00138: Time=   8.6s, Loss=3.43e+00, Inv=3.43e+00, For=9.78e+01, Power=7.00e-01
  [eval] val_mse=4.758e-01  (n=7000)
Epoch 00139: Time=   8.6s, Loss=3.42e+00, Inv=3.42e+00, For=9.88e+01, Power=6.98e-01
  [eval] val_mse=4.741e-01  (n=7000)
Epoch 00140: Time=   8.6s, Loss=3.41e+00, Inv=3.41e+00, For=1.00e+02, Power=6.95e-01
  [eval] val_mse=4.718e-01  (n=7000)
Epoch 00141: Time=   8.7s, Loss=3.41e+00, Inv=3.41e+00, For=1.03e+02, Power=6.98e-01
  [eval] val_mse=4.690e-01  (n=7000)
Epoch 00142: Time=   8.7s, Loss=3.40e+00, Inv=3.40e+00, For=1.04e+02, Power=6.96e-01
  [eval] val_mse=4.664e-01  (n=7000)
Epoch 00143: Time=   8.7s, Loss=3.39e+00, Inv=3.39e+00, For=1.06e+02, Power=6.94e-01
  [eval] val_mse=4.649e-01  (n=7000)
Epoch 00144: Time=   8.8s, Loss=3.38e+00, Inv=3.38e+00, For=1.08e+02, Power=6.93e-01
  [eval] val_mse=4.634e-01  (n=7000)
Epoch 00145: Time=   8.8s, Loss=3.38e+00, Inv=3.38e+00, For=1.09e+02, Power=6.97e-01
  [eval] val_mse=4.604e-01  (n=7000)
Epoch 00146: Time=   8.8s, Loss=3.37e+00, Inv=3.37e+00, For=1.12e+02, Power=6.97e-01
  [eval] val_mse=4.590e-01  (n=7000)
Epoch 00147: Time=   8.8s, Loss=3.36e+00, Inv=3.36e+00, For=1.13e+02, Power=6.95e-01
  [eval] val_mse=4.561e-01  (n=7000)
Epoch 00148: Time=   8.9s, Loss=3.36e+00, Inv=3.36e+00, For=1.16e+02, Power=6.93e-01
  [eval] val_mse=4.544e-01  (n=7000)
Epoch 00149: Time=   8.9s, Loss=3.35e+00, Inv=3.35e+00, For=1.18e+02, Power=6.94e-01
  [eval] val_mse=4.532e-01  (n=7000)
Epoch 00150: Time=   8.9s, Loss=3.34e+00, Inv=3.34e+00, For=1.20e+02, Power=6.95e-01
  [eval] val_mse=4.505e-01  (n=7000)
Epoch 00151: Time=   9.0s, Loss=3.34e+00, Inv=3.34e+00, For=1.22e+02, Power=6.95e-01
  [eval] val_mse=4.491e-01  (n=7000)
Epoch 00152: Time=   9.0s, Loss=3.34e+00, Inv=3.34e+00, For=1.23e+02, Power=6.95e-01
  [eval] val_mse=4.474e-01  (n=7000)
Epoch 00153: Time=   9.0s, Loss=3.33e+00, Inv=3.33e+00, For=1.25e+02, Power=6.94e-01
  [eval] val_mse=4.450e-01  (n=7000)
Epoch 00154: Time=   9.1s, Loss=3.32e+00, Inv=3.32e+00, For=1.27e+02, Power=6.96e-01
  [eval] val_mse=4.430e-01  (n=7000)
Epoch 00155: Time=   9.1s, Loss=3.32e+00, Inv=3.32e+00, For=1.30e+02, Power=6.95e-01
  [eval] val_mse=4.415e-01  (n=7000)
Epoch 00156: Time=   9.1s, Loss=3.31e+00, Inv=3.31e+00, For=1.31e+02, Power=6.94e-01
  [eval] val_mse=4.395e-01  (n=7000)
Epoch 00157: Time=   9.1s, Loss=3.30e+00, Inv=3.30e+00, For=1.34e+02, Power=6.93e-01
  [eval] val_mse=4.376e-01  (n=7000)
Epoch 00158: Time=   9.2s, Loss=3.30e+00, Inv=3.30e+00, For=1.36e+02, Power=6.92e-01
  [eval] val_mse=4.366e-01  (n=7000)
Epoch 00159: Time=   9.2s, Loss=3.29e+00, Inv=3.29e+00, For=1.38e+02, Power=6.93e-01
  [eval] val_mse=4.350e-01  (n=7000)
Epoch 00160: Time=   9.2s, Loss=3.29e+00, Inv=3.29e+00, For=1.40e+02, Power=6.93e-01
  [eval] val_mse=4.331e-01  (n=7000)
Epoch 00161: Time=   9.3s, Loss=3.29e+00, Inv=3.29e+00, For=1.43e+02, Power=6.93e-01
  [eval] val_mse=4.314e-01  (n=7000)
Epoch 00162: Time=   9.3s, Loss=3.28e+00, Inv=3.28e+00, For=1.44e+02, Power=6.95e-01
  [eval] val_mse=4.299e-01  (n=7000)
Epoch 00163: Time=   9.3s, Loss=3.27e+00, Inv=3.27e+00, For=1.47e+02, Power=6.93e-01
  [eval] val_mse=4.291e-01  (n=7000)
Epoch 00164: Time=   9.4s, Loss=3.27e+00, Inv=3.27e+00, For=1.47e+02, Power=6.93e-01
  [eval] val_mse=4.271e-01  (n=7000)
Epoch 00165: Time=   9.4s, Loss=3.27e+00, Inv=3.27e+00, For=1.52e+02, Power=6.94e-01
  [eval] val_mse=4.254e-01  (n=7000)
Epoch 00166: Time=   9.4s, Loss=3.26e+00, Inv=3.26e+00, For=1.52e+02, Power=6.93e-01
  [eval] val_mse=4.242e-01  (n=7000)
Epoch 00167: Time=   9.4s, Loss=3.26e+00, Inv=3.26e+00, For=1.56e+02, Power=6.93e-01
  [eval] val_mse=4.225e-01  (n=7000)
Epoch 00168: Time=   9.5s, Loss=3.26e+00, Inv=3.26e+00, For=1.58e+02, Power=6.95e-01
  [eval] val_mse=4.213e-01  (n=7000)
Epoch 00169: Time=   9.5s, Loss=3.25e+00, Inv=3.25e+00, For=1.60e+02, Power=6.93e-01
  [eval] val_mse=4.194e-01  (n=7000)
Epoch 00170: Time=   9.5s, Loss=3.24e+00, Inv=3.24e+00, For=1.62e+02, Power=6.93e-01
  [eval] val_mse=4.184e-01  (n=7000)
Epoch 00171: Time=   9.6s, Loss=3.23e+00, Inv=3.23e+00, For=1.64e+02, Power=6.89e-01
  [eval] val_mse=4.170e-01  (n=7000)
Epoch 00172: Time=   9.6s, Loss=3.24e+00, Inv=3.24e+00, For=1.68e+02, Power=6.95e-01
  [eval] val_mse=4.157e-01  (n=7000)
Epoch 00173: Time=   9.6s, Loss=3.23e+00, Inv=3.23e+00, For=1.70e+02, Power=6.90e-01
  [eval] val_mse=4.143e-01  (n=7000)
Epoch 00174: Time=   9.6s, Loss=3.23e+00, Inv=3.23e+00, For=1.72e+02, Power=6.92e-01
  [eval] val_mse=4.131e-01  (n=7000)
Epoch 00175: Time=   9.7s, Loss=3.23e+00, Inv=3.23e+00, For=1.75e+02, Power=6.96e-01
  [eval] val_mse=4.110e-01  (n=7000)
Epoch 00176: Time=   9.7s, Loss=3.22e+00, Inv=3.22e+00, For=1.76e+02, Power=6.90e-01
  [eval] val_mse=4.103e-01  (n=7000)
Epoch 00177: Time=   9.7s, Loss=3.21e+00, Inv=3.21e+00, For=1.81e+02, Power=6.91e-01
  [eval] val_mse=4.092e-01  (n=7000)
Epoch 00178: Time=   9.8s, Loss=3.21e+00, Inv=3.21e+00, For=1.81e+02, Power=6.90e-01
  [eval] val_mse=4.080e-01  (n=7000)
Epoch 00179: Time=   9.8s, Loss=3.20e+00, Inv=3.20e+00, For=1.86e+02, Power=6.88e-01
  [eval] val_mse=4.067e-01  (n=7000)
Epoch 00180: Time=   9.8s, Loss=3.20e+00, Inv=3.20e+00, For=1.87e+02, Power=6.91e-01
  [eval] val_mse=4.055e-01  (n=7000)
Epoch 00181: Time=   9.8s, Loss=3.20e+00, Inv=3.20e+00, For=1.89e+02, Power=6.90e-01
  [eval] val_mse=4.044e-01  (n=7000)
Epoch 00182: Time=   9.9s, Loss=3.20e+00, Inv=3.20e+00, For=1.92e+02, Power=6.90e-01
  [eval] val_mse=4.031e-01  (n=7000)
Epoch 00183: Time=   9.9s, Loss=3.19e+00, Inv=3.19e+00, For=1.94e+02, Power=6.90e-01
  [eval] val_mse=4.023e-01  (n=7000)
Epoch 00184: Time=   9.9s, Loss=3.19e+00, Inv=3.19e+00, For=1.96e+02, Power=6.93e-01
  [eval] val_mse=4.012e-01  (n=7000)
Epoch 00185: Time=  10.0s, Loss=3.18e+00, Inv=3.18e+00, For=1.99e+02, Power=6.90e-01
  [eval] val_mse=4.001e-01  (n=7000)
Epoch 00186: Time=  10.0s, Loss=3.18e+00, Inv=3.18e+00, For=2.02e+02, Power=6.90e-01
  [eval] val_mse=3.992e-01  (n=7000)
Epoch 00187: Time=  10.0s, Loss=3.18e+00, Inv=3.18e+00, For=2.04e+02, Power=6.89e-01
  [eval] val_mse=3.980e-01  (n=7000)
Epoch 00188: Time=  10.0s, Loss=3.17e+00, Inv=3.17e+00, For=2.07e+02, Power=6.90e-01
  [eval] val_mse=3.964e-01  (n=7000)
Epoch 00189: Time=  10.1s, Loss=3.17e+00, Inv=3.17e+00, For=2.09e+02, Power=6.90e-01
  [eval] val_mse=3.954e-01  (n=7000)
Epoch 00190: Time=  10.1s, Loss=3.16e+00, Inv=3.16e+00, For=2.13e+02, Power=6.88e-01
  [eval] val_mse=3.948e-01  (n=7000)
Epoch 00191: Time=  10.1s, Loss=3.16e+00, Inv=3.16e+00, For=2.14e+02, Power=6.89e-01
  [eval] val_mse=3.932e-01  (n=7000)
Epoch 00192: Time=  10.2s, Loss=3.16e+00, Inv=3.16e+00, For=2.18e+02, Power=6.90e-01
  [eval] val_mse=3.932e-01  (n=7000)
Epoch 00193: Time=  10.2s, Loss=3.16e+00, Inv=3.16e+00, For=2.19e+02, Power=6.90e-01
  [eval] val_mse=3.918e-01  (n=7000)
Epoch 00194: Time=  10.2s, Loss=3.16e+00, Inv=3.16e+00, For=2.23e+02, Power=6.90e-01
  [eval] val_mse=3.910e-01  (n=7000)
Epoch 00195: Time=  10.2s, Loss=3.15e+00, Inv=3.15e+00, For=2.25e+02, Power=6.89e-01
  [eval] val_mse=3.896e-01  (n=7000)
Epoch 00196: Time=  10.3s, Loss=3.15e+00, Inv=3.15e+00, For=2.28e+02, Power=6.92e-01
  [eval] val_mse=3.895e-01  (n=7000)
Epoch 00197: Time=  10.3s, Loss=3.15e+00, Inv=3.15e+00, For=2.30e+02, Power=6.90e-01
  [eval] val_mse=3.878e-01  (n=7000)
Epoch 00198: Time=  10.3s, Loss=3.14e+00, Inv=3.14e+00, For=2.34e+02, Power=6.87e-01
  [eval] val_mse=3.877e-01  (n=7000)
Epoch 00199: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=2.33e+02, Power=6.91e-01
  [eval] val_mse=3.862e-01  (n=7000)
Epoch 00200: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=2.39e+02, Power=6.88e-01
  [eval] val_mse=3.854e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 2.535e-01
Torque MSE  = 9.645e-02
Torque RMSE = 3.106e-01
Per-joint MSE : 8.139e-02 1.806e-01 5.270e-02 2.178e-02 2.256e-01 1.664e-02
Per-joint RMSE: 2.853e-01 4.249e-01 2.296e-01 1.476e-01 4.750e-01 1.290e-01
Comp Time per Sample = 2.778e-04s / 3599.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-0gkn52xb because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x78a7eedd28c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:45:54.480395: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:45:56.146721: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.0s, Loss=1.71e+04, Inv=1.71e+04, For=5.85e+00, Power=1.54e+03
  [eval] val_mse=3.877e+02  (n=7000)
Epoch 00002: Time=   4.5s, Loss=3.91e+03, Inv=3.91e+03, For=5.81e+00, Power=3.11e+02
  [eval] val_mse=1.816e+02  (n=7000)
Epoch 00003: Time=   4.6s, Loss=1.62e+03, Inv=1.62e+03, For=5.86e+00, Power=1.34e+02
  [eval] val_mse=1.237e+02  (n=7000)
Epoch 00004: Time=   4.6s, Loss=9.10e+02, Inv=9.10e+02, For=5.96e+00, Power=7.94e+01
  [eval] val_mse=9.339e+01  (n=7000)
Epoch 00005: Time=   4.6s, Loss=5.86e+02, Inv=5.86e+02, For=6.09e+00, Power=5.39e+01
  [eval] val_mse=7.432e+01  (n=7000)
Epoch 00006: Time=   4.7s, Loss=4.10e+02, Inv=4.10e+02, For=6.19e+00, Power=3.98e+01
  [eval] val_mse=6.056e+01  (n=7000)
Epoch 00007: Time=   4.7s, Loss=3.04e+02, Inv=3.04e+02, For=6.34e+00, Power=3.05e+01
  [eval] val_mse=5.009e+01  (n=7000)
Epoch 00008: Time=   4.7s, Loss=2.34e+02, Inv=2.34e+02, For=6.52e+00, Power=2.42e+01
  [eval] val_mse=4.186e+01  (n=7000)
Epoch 00009: Time=   4.8s, Loss=1.86e+02, Inv=1.86e+02, For=6.71e+00, Power=1.95e+01
  [eval] val_mse=3.523e+01  (n=7000)
Epoch 00010: Time=   4.8s, Loss=1.50e+02, Inv=1.50e+02, For=6.90e+00, Power=1.60e+01
  [eval] val_mse=2.998e+01  (n=7000)
Epoch 00011: Time=   4.8s, Loss=1.24e+02, Inv=1.24e+02, For=7.10e+00, Power=1.34e+01
  [eval] val_mse=2.567e+01  (n=7000)
Epoch 00012: Time=   4.8s, Loss=1.04e+02, Inv=1.04e+02, For=7.29e+00, Power=1.13e+01
  [eval] val_mse=2.219e+01  (n=7000)
Epoch 00013: Time=   4.9s, Loss=8.83e+01, Inv=8.83e+01, For=7.52e+00, Power=9.63e+00
  [eval] val_mse=1.934e+01  (n=7000)
Epoch 00014: Time=   4.9s, Loss=7.59e+01, Inv=7.59e+01, For=7.75e+00, Power=8.27e+00
  [eval] val_mse=1.698e+01  (n=7000)
Epoch 00015: Time=   4.9s, Loss=6.59e+01, Inv=6.59e+01, For=8.01e+00, Power=7.25e+00
  [eval] val_mse=1.501e+01  (n=7000)
Epoch 00016: Time=   5.0s, Loss=5.83e+01, Inv=5.83e+01, For=8.29e+00, Power=6.39e+00
  [eval] val_mse=1.334e+01  (n=7000)
Epoch 00017: Time=   5.0s, Loss=5.15e+01, Inv=5.15e+01, For=8.54e+00, Power=5.72e+00
  [eval] val_mse=1.193e+01  (n=7000)
Epoch 00018: Time=   5.0s, Loss=4.58e+01, Inv=4.58e+01, For=8.82e+00, Power=5.07e+00
  [eval] val_mse=1.071e+01  (n=7000)
Epoch 00019: Time=   5.1s, Loss=4.11e+01, Inv=4.11e+01, For=9.02e+00, Power=4.60e+00
  [eval] val_mse=9.666e+00  (n=7000)
Epoch 00020: Time=   5.1s, Loss=3.71e+01, Inv=3.71e+01, For=9.31e+00, Power=4.15e+00
  [eval] val_mse=8.757e+00  (n=7000)
Epoch 00021: Time=   5.1s, Loss=3.38e+01, Inv=3.38e+01, For=9.50e+00, Power=3.74e+00
  [eval] val_mse=7.969e+00  (n=7000)
Epoch 00022: Time=   5.1s, Loss=3.07e+01, Inv=3.07e+01, For=9.74e+00, Power=3.45e+00
  [eval] val_mse=7.278e+00  (n=7000)
Epoch 00023: Time=   5.2s, Loss=2.83e+01, Inv=2.83e+01, For=9.95e+00, Power=3.19e+00
  [eval] val_mse=6.670e+00  (n=7000)
Epoch 00024: Time=   5.2s, Loss=2.60e+01, Inv=2.60e+01, For=1.02e+01, Power=2.93e+00
  [eval] val_mse=6.130e+00  (n=7000)
Epoch 00025: Time=   5.2s, Loss=2.41e+01, Inv=2.41e+01, For=1.04e+01, Power=2.73e+00
  [eval] val_mse=5.657e+00  (n=7000)
Epoch 00026: Time=   5.3s, Loss=2.23e+01, Inv=2.23e+01, For=1.06e+01, Power=2.53e+00
  [eval] val_mse=5.237e+00  (n=7000)
Epoch 00027: Time=   5.3s, Loss=2.08e+01, Inv=2.08e+01, For=1.08e+01, Power=2.37e+00
  [eval] val_mse=4.861e+00  (n=7000)
Epoch 00028: Time=   5.3s, Loss=1.95e+01, Inv=1.95e+01, For=1.11e+01, Power=2.22e+00
  [eval] val_mse=4.529e+00  (n=7000)
Epoch 00029: Time=   5.4s, Loss=1.83e+01, Inv=1.83e+01, For=1.14e+01, Power=2.08e+00
  [eval] val_mse=4.237e+00  (n=7000)
Epoch 00030: Time=   5.4s, Loss=1.73e+01, Inv=1.73e+01, For=1.17e+01, Power=1.97e+00
  [eval] val_mse=3.960e+00  (n=7000)
Epoch 00031: Time=   5.4s, Loss=1.63e+01, Inv=1.63e+01, For=1.21e+01, Power=1.87e+00
  [eval] val_mse=3.716e+00  (n=7000)
Epoch 00032: Time=   5.5s, Loss=1.54e+01, Inv=1.54e+01, For=1.25e+01, Power=1.77e+00
  [eval] val_mse=3.498e+00  (n=7000)
Epoch 00033: Time=   5.5s, Loss=1.46e+01, Inv=1.46e+01, For=1.29e+01, Power=1.69e+00
  [eval] val_mse=3.299e+00  (n=7000)
Epoch 00034: Time=   5.5s, Loss=1.39e+01, Inv=1.39e+01, For=1.34e+01, Power=1.61e+00
  [eval] val_mse=3.117e+00  (n=7000)
Epoch 00035: Time=   5.6s, Loss=1.33e+01, Inv=1.33e+01, For=1.38e+01, Power=1.54e+00
  [eval] val_mse=2.951e+00  (n=7000)
Epoch 00036: Time=   5.6s, Loss=1.27e+01, Inv=1.27e+01, For=1.43e+01, Power=1.48e+00
  [eval] val_mse=2.802e+00  (n=7000)
Epoch 00037: Time=   5.6s, Loss=1.21e+01, Inv=1.21e+01, For=1.48e+01, Power=1.43e+00
  [eval] val_mse=2.662e+00  (n=7000)
Epoch 00038: Time=   5.7s, Loss=1.16e+01, Inv=1.16e+01, For=1.54e+01, Power=1.36e+00
  [eval] val_mse=2.533e+00  (n=7000)
Epoch 00039: Time=   5.7s, Loss=1.11e+01, Inv=1.11e+01, For=1.60e+01, Power=1.32e+00
  [eval] val_mse=2.412e+00  (n=7000)
Epoch 00040: Time=   5.7s, Loss=1.07e+01, Inv=1.07e+01, For=1.66e+01, Power=1.28e+00
  [eval] val_mse=2.306e+00  (n=7000)
Epoch 00041: Time=   5.8s, Loss=1.03e+01, Inv=1.03e+01, For=1.72e+01, Power=1.24e+00
  [eval] val_mse=2.203e+00  (n=7000)
Epoch 00042: Time=   5.8s, Loss=9.96e+00, Inv=9.96e+00, For=1.79e+01, Power=1.20e+00
  [eval] val_mse=2.110e+00  (n=7000)
Epoch 00043: Time=   5.8s, Loss=9.62e+00, Inv=9.62e+00, For=1.87e+01, Power=1.17e+00
  [eval] val_mse=2.024e+00  (n=7000)
Epoch 00044: Time=   5.9s, Loss=9.32e+00, Inv=9.32e+00, For=1.94e+01, Power=1.14e+00
  [eval] val_mse=1.941e+00  (n=7000)
Epoch 00045: Time=   5.9s, Loss=9.02e+00, Inv=9.02e+00, For=2.02e+01, Power=1.11e+00
  [eval] val_mse=1.866e+00  (n=7000)
Epoch 00046: Time=   5.9s, Loss=8.75e+00, Inv=8.75e+00, For=2.09e+01, Power=1.08e+00
  [eval] val_mse=1.794e+00  (n=7000)
Epoch 00047: Time=   5.9s, Loss=8.50e+00, Inv=8.50e+00, For=2.17e+01, Power=1.06e+00
  [eval] val_mse=1.728e+00  (n=7000)
Epoch 00048: Time=   6.0s, Loss=8.26e+00, Inv=8.26e+00, For=2.27e+01, Power=1.04e+00
  [eval] val_mse=1.664e+00  (n=7000)
Epoch 00049: Time=   6.0s, Loss=8.02e+00, Inv=8.02e+00, For=2.35e+01, Power=1.01e+00
  [eval] val_mse=1.605e+00  (n=7000)
Epoch 00050: Time=   6.0s, Loss=7.82e+00, Inv=7.82e+00, For=2.44e+01, Power=9.95e-01
  [eval] val_mse=1.551e+00  (n=7000)
Epoch 00051: Time=   6.1s, Loss=7.60e+00, Inv=7.60e+00, For=2.53e+01, Power=9.79e-01
  [eval] val_mse=1.500e+00  (n=7000)
Epoch 00052: Time=   6.1s, Loss=7.43e+00, Inv=7.43e+00, For=2.64e+01, Power=9.61e-01
  [eval] val_mse=1.451e+00  (n=7000)
Epoch 00053: Time=   6.1s, Loss=7.25e+00, Inv=7.25e+00, For=2.73e+01, Power=9.46e-01
  [eval] val_mse=1.404e+00  (n=7000)
Epoch 00054: Time=   6.2s, Loss=7.08e+00, Inv=7.08e+00, For=2.84e+01, Power=9.28e-01
  [eval] val_mse=1.362e+00  (n=7000)
Epoch 00055: Time=   6.2s, Loss=6.95e+00, Inv=6.95e+00, For=2.94e+01, Power=9.20e-01
  [eval] val_mse=1.322e+00  (n=7000)
Epoch 00056: Time=   6.2s, Loss=6.80e+00, Inv=6.80e+00, For=3.05e+01, Power=9.05e-01
  [eval] val_mse=1.284e+00  (n=7000)
Epoch 00057: Time=   6.3s, Loss=6.66e+00, Inv=6.66e+00, For=3.17e+01, Power=8.96e-01
  [eval] val_mse=1.247e+00  (n=7000)
Epoch 00058: Time=   6.3s, Loss=6.53e+00, Inv=6.53e+00, For=3.27e+01, Power=8.81e-01
  [eval] val_mse=1.212e+00  (n=7000)
Epoch 00059: Time=   6.3s, Loss=6.39e+00, Inv=6.39e+00, For=3.39e+01, Power=8.75e-01
  [eval] val_mse=1.179e+00  (n=7000)
Epoch 00060: Time=   6.3s, Loss=6.29e+00, Inv=6.29e+00, For=3.52e+01, Power=8.63e-01
  [eval] val_mse=1.147e+00  (n=7000)
Epoch 00061: Time=   6.4s, Loss=6.17e+00, Inv=6.17e+00, For=3.64e+01, Power=8.52e-01
  [eval] val_mse=1.118e+00  (n=7000)
Epoch 00062: Time=   6.4s, Loss=6.07e+00, Inv=6.07e+00, For=3.78e+01, Power=8.44e-01
  [eval] val_mse=1.090e+00  (n=7000)
Epoch 00063: Time=   6.4s, Loss=5.97e+00, Inv=5.97e+00, For=3.91e+01, Power=8.31e-01
  [eval] val_mse=1.064e+00  (n=7000)
Epoch 00064: Time=   6.5s, Loss=5.88e+00, Inv=5.88e+00, For=4.03e+01, Power=8.28e-01
  [eval] val_mse=1.037e+00  (n=7000)
Epoch 00065: Time=   6.5s, Loss=5.78e+00, Inv=5.78e+00, For=4.17e+01, Power=8.17e-01
  [eval] val_mse=1.014e+00  (n=7000)
Epoch 00066: Time=   6.5s, Loss=5.69e+00, Inv=5.69e+00, For=4.31e+01, Power=8.15e-01
  [eval] val_mse=9.915e-01  (n=7000)
Epoch 00067: Time=   6.6s, Loss=5.62e+00, Inv=5.62e+00, For=4.45e+01, Power=8.05e-01
  [eval] val_mse=9.695e-01  (n=7000)
Epoch 00068: Time=   6.6s, Loss=5.53e+00, Inv=5.53e+00, For=4.60e+01, Power=7.99e-01
  [eval] val_mse=9.481e-01  (n=7000)
Epoch 00069: Time=   6.6s, Loss=5.46e+00, Inv=5.46e+00, For=4.73e+01, Power=7.93e-01
  [eval] val_mse=9.277e-01  (n=7000)
Epoch 00070: Time=   6.6s, Loss=5.39e+00, Inv=5.39e+00, For=4.90e+01, Power=7.94e-01
  [eval] val_mse=9.088e-01  (n=7000)
Epoch 00071: Time=   6.7s, Loss=5.32e+00, Inv=5.32e+00, For=5.05e+01, Power=7.86e-01
  [eval] val_mse=8.899e-01  (n=7000)
Epoch 00072: Time=   6.7s, Loss=5.24e+00, Inv=5.24e+00, For=5.20e+01, Power=7.80e-01
  [eval] val_mse=8.732e-01  (n=7000)
Epoch 00073: Time=   6.7s, Loss=5.18e+00, Inv=5.18e+00, For=5.37e+01, Power=7.76e-01
  [eval] val_mse=8.563e-01  (n=7000)
Epoch 00074: Time=   6.8s, Loss=5.13e+00, Inv=5.13e+00, For=5.51e+01, Power=7.71e-01
  [eval] val_mse=8.394e-01  (n=7000)
Epoch 00075: Time=   6.8s, Loss=5.07e+00, Inv=5.07e+00, For=5.70e+01, Power=7.68e-01
  [eval] val_mse=8.250e-01  (n=7000)
Epoch 00076: Time=   6.8s, Loss=5.01e+00, Inv=5.01e+00, For=5.86e+01, Power=7.63e-01
  [eval] val_mse=8.110e-01  (n=7000)
Epoch 00077: Time=   6.8s, Loss=4.95e+00, Inv=4.95e+00, For=6.03e+01, Power=7.62e-01
  [eval] val_mse=7.966e-01  (n=7000)
Epoch 00078: Time=   6.9s, Loss=4.90e+00, Inv=4.90e+00, For=6.22e+01, Power=7.55e-01
  [eval] val_mse=7.830e-01  (n=7000)
Epoch 00079: Time=   6.9s, Loss=4.85e+00, Inv=4.85e+00, For=6.38e+01, Power=7.52e-01
  [eval] val_mse=7.703e-01  (n=7000)
Epoch 00080: Time=   6.9s, Loss=4.80e+00, Inv=4.80e+00, For=6.55e+01, Power=7.47e-01
  [eval] val_mse=7.568e-01  (n=7000)
Epoch 00081: Time=   7.0s, Loss=4.75e+00, Inv=4.75e+00, For=6.76e+01, Power=7.50e-01
  [eval] val_mse=7.455e-01  (n=7000)
Epoch 00082: Time=   7.0s, Loss=4.70e+00, Inv=4.70e+00, For=6.92e+01, Power=7.41e-01
  [eval] val_mse=7.331e-01  (n=7000)
Epoch 00083: Time=   7.0s, Loss=4.66e+00, Inv=4.66e+00, For=7.13e+01, Power=7.37e-01
  [eval] val_mse=7.222e-01  (n=7000)
Epoch 00084: Time=   7.0s, Loss=4.61e+00, Inv=4.61e+00, For=7.29e+01, Power=7.37e-01
  [eval] val_mse=7.116e-01  (n=7000)
Epoch 00085: Time=   7.1s, Loss=4.58e+00, Inv=4.58e+00, For=7.51e+01, Power=7.34e-01
  [eval] val_mse=7.020e-01  (n=7000)
Epoch 00086: Time=   7.1s, Loss=4.54e+00, Inv=4.54e+00, For=7.68e+01, Power=7.34e-01
  [eval] val_mse=6.921e-01  (n=7000)
Epoch 00087: Time=   7.1s, Loss=4.50e+00, Inv=4.50e+00, For=7.90e+01, Power=7.26e-01
  [eval] val_mse=6.837e-01  (n=7000)
Epoch 00088: Time=   7.2s, Loss=4.46e+00, Inv=4.46e+00, For=8.13e+01, Power=7.30e-01
  [eval] val_mse=6.748e-01  (n=7000)
Epoch 00089: Time=   7.2s, Loss=4.42e+00, Inv=4.42e+00, For=8.32e+01, Power=7.26e-01
  [eval] val_mse=6.660e-01  (n=7000)
Epoch 00090: Time=   7.2s, Loss=4.38e+00, Inv=4.38e+00, For=8.53e+01, Power=7.22e-01
  [eval] val_mse=6.568e-01  (n=7000)
Epoch 00091: Time=   7.2s, Loss=4.35e+00, Inv=4.35e+00, For=8.72e+01, Power=7.22e-01
  [eval] val_mse=6.485e-01  (n=7000)
Epoch 00092: Time=   7.3s, Loss=4.31e+00, Inv=4.31e+00, For=8.93e+01, Power=7.21e-01
  [eval] val_mse=6.409e-01  (n=7000)
Epoch 00093: Time=   7.3s, Loss=4.28e+00, Inv=4.28e+00, For=9.17e+01, Power=7.17e-01
  [eval] val_mse=6.343e-01  (n=7000)
Epoch 00094: Time=   7.3s, Loss=4.25e+00, Inv=4.25e+00, For=9.35e+01, Power=7.17e-01
  [eval] val_mse=6.277e-01  (n=7000)
Epoch 00095: Time=   7.4s, Loss=4.22e+00, Inv=4.22e+00, For=9.65e+01, Power=7.16e-01
  [eval] val_mse=6.206e-01  (n=7000)
Epoch 00096: Time=   7.4s, Loss=4.19e+00, Inv=4.19e+00, For=9.87e+01, Power=7.15e-01
  [eval] val_mse=6.140e-01  (n=7000)
Epoch 00097: Time=   7.4s, Loss=4.16e+00, Inv=4.16e+00, For=1.01e+02, Power=7.11e-01
  [eval] val_mse=6.079e-01  (n=7000)
Epoch 00098: Time=   7.4s, Loss=4.14e+00, Inv=4.14e+00, For=1.03e+02, Power=7.09e-01
  [eval] val_mse=6.020e-01  (n=7000)
Epoch 00099: Time=   7.5s, Loss=4.11e+00, Inv=4.11e+00, For=1.06e+02, Power=7.10e-01
  [eval] val_mse=5.959e-01  (n=7000)
Epoch 00100: Time=   7.5s, Loss=4.08e+00, Inv=4.08e+00, For=1.08e+02, Power=7.09e-01
  [eval] val_mse=5.903e-01  (n=7000)
Epoch 00101: Time=   7.5s, Loss=4.05e+00, Inv=4.05e+00, For=1.10e+02, Power=7.07e-01
  [eval] val_mse=5.846e-01  (n=7000)
Epoch 00102: Time=   7.6s, Loss=4.03e+00, Inv=4.03e+00, For=1.13e+02, Power=7.04e-01
  [eval] val_mse=5.797e-01  (n=7000)
Epoch 00103: Time=   7.6s, Loss=4.00e+00, Inv=4.00e+00, For=1.15e+02, Power=7.04e-01
  [eval] val_mse=5.743e-01  (n=7000)
Epoch 00104: Time=   7.6s, Loss=3.98e+00, Inv=3.98e+00, For=1.18e+02, Power=7.05e-01
  [eval] val_mse=5.694e-01  (n=7000)
Epoch 00105: Time=   7.6s, Loss=3.95e+00, Inv=3.95e+00, For=1.20e+02, Power=7.03e-01
  [eval] val_mse=5.642e-01  (n=7000)
Epoch 00106: Time=   7.7s, Loss=3.94e+00, Inv=3.94e+00, For=1.23e+02, Power=6.98e-01
  [eval] val_mse=5.599e-01  (n=7000)
Epoch 00107: Time=   7.7s, Loss=3.92e+00, Inv=3.92e+00, For=1.25e+02, Power=7.00e-01
  [eval] val_mse=5.553e-01  (n=7000)
Epoch 00108: Time=   7.7s, Loss=3.89e+00, Inv=3.89e+00, For=1.28e+02, Power=6.98e-01
  [eval] val_mse=5.510e-01  (n=7000)
Epoch 00109: Time=   7.7s, Loss=3.88e+00, Inv=3.88e+00, For=1.31e+02, Power=7.01e-01
  [eval] val_mse=5.480e-01  (n=7000)
Epoch 00110: Time=   7.8s, Loss=3.86e+00, Inv=3.86e+00, For=1.33e+02, Power=6.99e-01
  [eval] val_mse=5.433e-01  (n=7000)
Epoch 00111: Time=   7.8s, Loss=3.85e+00, Inv=3.85e+00, For=1.36e+02, Power=6.98e-01
  [eval] val_mse=5.396e-01  (n=7000)
Epoch 00112: Time=   7.8s, Loss=3.83e+00, Inv=3.83e+00, For=1.39e+02, Power=6.99e-01
  [eval] val_mse=5.358e-01  (n=7000)
Epoch 00113: Time=   7.9s, Loss=3.81e+00, Inv=3.81e+00, For=1.41e+02, Power=6.96e-01
  [eval] val_mse=5.323e-01  (n=7000)
Epoch 00114: Time=   7.9s, Loss=3.79e+00, Inv=3.79e+00, For=1.44e+02, Power=6.97e-01
  [eval] val_mse=5.282e-01  (n=7000)
Epoch 00115: Time=   7.9s, Loss=3.78e+00, Inv=3.78e+00, For=1.47e+02, Power=6.95e-01
  [eval] val_mse=5.254e-01  (n=7000)
Epoch 00116: Time=   7.9s, Loss=3.77e+00, Inv=3.77e+00, For=1.49e+02, Power=6.96e-01
  [eval] val_mse=5.220e-01  (n=7000)
Epoch 00117: Time=   8.0s, Loss=3.74e+00, Inv=3.74e+00, For=1.53e+02, Power=6.92e-01
  [eval] val_mse=5.186e-01  (n=7000)
Epoch 00118: Time=   8.0s, Loss=3.73e+00, Inv=3.73e+00, For=1.55e+02, Power=6.93e-01
  [eval] val_mse=5.153e-01  (n=7000)
Epoch 00119: Time=   8.0s, Loss=3.72e+00, Inv=3.72e+00, For=1.58e+02, Power=6.94e-01
  [eval] val_mse=5.129e-01  (n=7000)
Epoch 00120: Time=   8.1s, Loss=3.71e+00, Inv=3.71e+00, For=1.61e+02, Power=6.93e-01
  [eval] val_mse=5.090e-01  (n=7000)
Epoch 00121: Time=   8.1s, Loss=3.69e+00, Inv=3.69e+00, For=1.65e+02, Power=6.96e-01
  [eval] val_mse=5.069e-01  (n=7000)
Epoch 00122: Time=   8.1s, Loss=3.68e+00, Inv=3.68e+00, For=1.67e+02, Power=6.94e-01
  [eval] val_mse=5.032e-01  (n=7000)
Epoch 00123: Time=   8.1s, Loss=3.67e+00, Inv=3.67e+00, For=1.70e+02, Power=6.93e-01
  [eval] val_mse=5.002e-01  (n=7000)
Epoch 00124: Time=   8.2s, Loss=3.66e+00, Inv=3.66e+00, For=1.73e+02, Power=6.93e-01
  [eval] val_mse=4.972e-01  (n=7000)
Epoch 00125: Time=   8.2s, Loss=3.65e+00, Inv=3.65e+00, For=1.74e+02, Power=6.91e-01
  [eval] val_mse=4.944e-01  (n=7000)
Epoch 00126: Time=   8.2s, Loss=3.64e+00, Inv=3.64e+00, For=1.80e+02, Power=6.95e-01
  [eval] val_mse=4.927e-01  (n=7000)
Epoch 00127: Time=   8.3s, Loss=3.62e+00, Inv=3.62e+00, For=1.81e+02, Power=6.92e-01
  [eval] val_mse=4.896e-01  (n=7000)
Epoch 00128: Time=   8.3s, Loss=3.61e+00, Inv=3.61e+00, For=1.84e+02, Power=6.91e-01
  [eval] val_mse=4.865e-01  (n=7000)
Epoch 00129: Time=   8.3s, Loss=3.60e+00, Inv=3.60e+00, For=1.86e+02, Power=6.92e-01
  [eval] val_mse=4.842e-01  (n=7000)
Epoch 00130: Time=   8.4s, Loss=3.60e+00, Inv=3.60e+00, For=1.89e+02, Power=6.91e-01
  [eval] val_mse=4.818e-01  (n=7000)
Epoch 00131: Time=   8.4s, Loss=3.58e+00, Inv=3.58e+00, For=1.92e+02, Power=6.91e-01
  [eval] val_mse=4.793e-01  (n=7000)
Epoch 00132: Time=   8.4s, Loss=3.57e+00, Inv=3.57e+00, For=1.94e+02, Power=6.89e-01
  [eval] val_mse=4.763e-01  (n=7000)
Epoch 00133: Time=   8.5s, Loss=3.56e+00, Inv=3.56e+00, For=1.98e+02, Power=6.91e-01
  [eval] val_mse=4.747e-01  (n=7000)
Epoch 00134: Time=   8.5s, Loss=3.56e+00, Inv=3.56e+00, For=2.00e+02, Power=6.90e-01
  [eval] val_mse=4.723e-01  (n=7000)
Epoch 00135: Time=   8.5s, Loss=3.54e+00, Inv=3.54e+00, For=2.04e+02, Power=6.90e-01
  [eval] val_mse=4.698e-01  (n=7000)
Epoch 00136: Time=   8.5s, Loss=3.54e+00, Inv=3.54e+00, For=2.07e+02, Power=6.89e-01
  [eval] val_mse=4.672e-01  (n=7000)
Epoch 00137: Time=   8.6s, Loss=3.53e+00, Inv=3.53e+00, For=2.07e+02, Power=6.90e-01
  [eval] val_mse=4.647e-01  (n=7000)
Epoch 00138: Time=   8.6s, Loss=3.52e+00, Inv=3.52e+00, For=2.11e+02, Power=6.91e-01
  [eval] val_mse=4.634e-01  (n=7000)
Epoch 00139: Time=   8.6s, Loss=3.51e+00, Inv=3.51e+00, For=2.14e+02, Power=6.90e-01
  [eval] val_mse=4.613e-01  (n=7000)
Epoch 00140: Time=   8.7s, Loss=3.50e+00, Inv=3.50e+00, For=2.15e+02, Power=6.86e-01
  [eval] val_mse=4.593e-01  (n=7000)
Epoch 00141: Time=   8.7s, Loss=3.50e+00, Inv=3.50e+00, For=2.21e+02, Power=6.90e-01
  [eval] val_mse=4.571e-01  (n=7000)
Epoch 00142: Time=   8.7s, Loss=3.49e+00, Inv=3.49e+00, For=2.21e+02, Power=6.90e-01
  [eval] val_mse=4.543e-01  (n=7000)
Epoch 00143: Time=   8.8s, Loss=3.48e+00, Inv=3.48e+00, For=2.24e+02, Power=6.91e-01
  [eval] val_mse=4.524e-01  (n=7000)
Epoch 00144: Time=   8.8s, Loss=3.47e+00, Inv=3.47e+00, For=2.26e+02, Power=6.87e-01
  [eval] val_mse=4.504e-01  (n=7000)
Epoch 00145: Time=   8.8s, Loss=3.47e+00, Inv=3.47e+00, For=2.29e+02, Power=6.90e-01
  [eval] val_mse=4.490e-01  (n=7000)
Epoch 00146: Time=   8.9s, Loss=3.46e+00, Inv=3.46e+00, For=2.32e+02, Power=6.90e-01
  [eval] val_mse=4.469e-01  (n=7000)
Epoch 00147: Time=   8.9s, Loss=3.45e+00, Inv=3.45e+00, For=2.34e+02, Power=6.87e-01
  [eval] val_mse=4.452e-01  (n=7000)
Epoch 00148: Time=   8.9s, Loss=3.44e+00, Inv=3.44e+00, For=2.36e+02, Power=6.85e-01
  [eval] val_mse=4.439e-01  (n=7000)
Epoch 00149: Time=   8.9s, Loss=3.44e+00, Inv=3.44e+00, For=2.38e+02, Power=6.87e-01
  [eval] val_mse=4.416e-01  (n=7000)
Epoch 00150: Time=   9.0s, Loss=3.43e+00, Inv=3.43e+00, For=2.43e+02, Power=6.87e-01
  [eval] val_mse=4.400e-01  (n=7000)
Epoch 00151: Time=   9.0s, Loss=3.42e+00, Inv=3.42e+00, For=2.43e+02, Power=6.87e-01
  [eval] val_mse=4.374e-01  (n=7000)
Epoch 00152: Time=   9.0s, Loss=3.42e+00, Inv=3.42e+00, For=2.47e+02, Power=6.86e-01
  [eval] val_mse=4.365e-01  (n=7000)
Epoch 00153: Time=   9.1s, Loss=3.41e+00, Inv=3.41e+00, For=2.46e+02, Power=6.88e-01
  [eval] val_mse=4.347e-01  (n=7000)
Epoch 00154: Time=   9.1s, Loss=3.41e+00, Inv=3.41e+00, For=2.50e+02, Power=6.86e-01
  [eval] val_mse=4.331e-01  (n=7000)
Epoch 00155: Time=   9.1s, Loss=3.40e+00, Inv=3.40e+00, For=2.53e+02, Power=6.88e-01
  [eval] val_mse=4.318e-01  (n=7000)
Epoch 00156: Time=   9.1s, Loss=3.40e+00, Inv=3.40e+00, For=2.55e+02, Power=6.89e-01
  [eval] val_mse=4.297e-01  (n=7000)
Epoch 00157: Time=   9.2s, Loss=3.39e+00, Inv=3.39e+00, For=2.59e+02, Power=6.90e-01
  [eval] val_mse=4.290e-01  (n=7000)
Epoch 00158: Time=   9.2s, Loss=3.38e+00, Inv=3.38e+00, For=2.59e+02, Power=6.86e-01
  [eval] val_mse=4.259e-01  (n=7000)
Epoch 00159: Time=   9.2s, Loss=3.38e+00, Inv=3.38e+00, For=2.62e+02, Power=6.86e-01
  [eval] val_mse=4.251e-01  (n=7000)
Epoch 00160: Time=   9.3s, Loss=3.37e+00, Inv=3.37e+00, For=2.63e+02, Power=6.88e-01
  [eval] val_mse=4.237e-01  (n=7000)
Epoch 00161: Time=   9.3s, Loss=3.37e+00, Inv=3.37e+00, For=2.66e+02, Power=6.87e-01
  [eval] val_mse=4.224e-01  (n=7000)
Epoch 00162: Time=   9.3s, Loss=3.36e+00, Inv=3.36e+00, For=2.63e+02, Power=6.86e-01
  [eval] val_mse=4.206e-01  (n=7000)
Epoch 00163: Time=   9.4s, Loss=3.35e+00, Inv=3.35e+00, For=2.70e+02, Power=6.87e-01
  [eval] val_mse=4.200e-01  (n=7000)
Epoch 00164: Time=   9.4s, Loss=3.35e+00, Inv=3.35e+00, For=2.70e+02, Power=6.86e-01
  [eval] val_mse=4.177e-01  (n=7000)
Epoch 00165: Time=   9.4s, Loss=3.35e+00, Inv=3.35e+00, For=2.74e+02, Power=6.88e-01
  [eval] val_mse=4.169e-01  (n=7000)
Epoch 00166: Time=   9.4s, Loss=3.34e+00, Inv=3.34e+00, For=2.81e+02, Power=6.86e-01
  [eval] val_mse=4.162e-01  (n=7000)
Epoch 00167: Time=   9.5s, Loss=3.33e+00, Inv=3.33e+00, For=2.73e+02, Power=6.87e-01
  [eval] val_mse=4.146e-01  (n=7000)
Epoch 00168: Time=   9.5s, Loss=3.33e+00, Inv=3.33e+00, For=2.82e+02, Power=6.87e-01
  [eval] val_mse=4.142e-01  (n=7000)
Epoch 00169: Time=   9.5s, Loss=3.32e+00, Inv=3.32e+00, For=2.81e+02, Power=6.82e-01
  [eval] val_mse=4.125e-01  (n=7000)
Epoch 00170: Time=   9.6s, Loss=3.32e+00, Inv=3.32e+00, For=2.83e+02, Power=6.86e-01
  [eval] val_mse=4.109e-01  (n=7000)
Epoch 00171: Time=   9.6s, Loss=3.32e+00, Inv=3.32e+00, For=2.85e+02, Power=6.86e-01
  [eval] val_mse=4.087e-01  (n=7000)
Epoch 00172: Time=   9.6s, Loss=3.31e+00, Inv=3.31e+00, For=2.84e+02, Power=6.85e-01
  [eval] val_mse=4.084e-01  (n=7000)
Epoch 00173: Time=   9.6s, Loss=3.31e+00, Inv=3.31e+00, For=2.90e+02, Power=6.87e-01
  [eval] val_mse=4.075e-01  (n=7000)
Epoch 00174: Time=   9.7s, Loss=3.30e+00, Inv=3.30e+00, For=2.91e+02, Power=6.87e-01
  [eval] val_mse=4.064e-01  (n=7000)
Epoch 00175: Time=   9.7s, Loss=3.30e+00, Inv=3.30e+00, For=2.93e+02, Power=6.84e-01
  [eval] val_mse=4.061e-01  (n=7000)
Epoch 00176: Time=   9.7s, Loss=3.29e+00, Inv=3.29e+00, For=2.93e+02, Power=6.89e-01
  [eval] val_mse=4.045e-01  (n=7000)
Epoch 00177: Time=   9.8s, Loss=3.29e+00, Inv=3.29e+00, For=2.95e+02, Power=6.82e-01
  [eval] val_mse=4.032e-01  (n=7000)
Epoch 00178: Time=   9.8s, Loss=3.28e+00, Inv=3.28e+00, For=2.96e+02, Power=6.83e-01
  [eval] val_mse=4.008e-01  (n=7000)
Epoch 00179: Time=   9.8s, Loss=3.28e+00, Inv=3.28e+00, For=2.97e+02, Power=6.85e-01
  [eval] val_mse=4.021e-01  (n=7000)
Epoch 00180: Time=   9.8s, Loss=3.28e+00, Inv=3.28e+00, For=2.96e+02, Power=6.84e-01
  [eval] val_mse=3.996e-01  (n=7000)
Epoch 00181: Time=   9.9s, Loss=3.27e+00, Inv=3.27e+00, For=3.01e+02, Power=6.86e-01
  [eval] val_mse=3.992e-01  (n=7000)
Epoch 00182: Time=   9.9s, Loss=3.26e+00, Inv=3.26e+00, For=3.01e+02, Power=6.81e-01
  [eval] val_mse=3.986e-01  (n=7000)
Epoch 00183: Time=   9.9s, Loss=3.26e+00, Inv=3.26e+00, For=3.03e+02, Power=6.88e-01
  [eval] val_mse=3.973e-01  (n=7000)
Epoch 00184: Time=  10.0s, Loss=3.26e+00, Inv=3.26e+00, For=3.04e+02, Power=6.82e-01
  [eval] val_mse=3.967e-01  (n=7000)
Epoch 00185: Time=  10.0s, Loss=3.25e+00, Inv=3.25e+00, For=3.08e+02, Power=6.85e-01
  [eval] val_mse=3.959e-01  (n=7000)
Epoch 00186: Time=  10.0s, Loss=3.25e+00, Inv=3.25e+00, For=3.05e+02, Power=6.80e-01
  [eval] val_mse=3.940e-01  (n=7000)
Epoch 00187: Time=  10.1s, Loss=3.25e+00, Inv=3.25e+00, For=3.07e+02, Power=6.84e-01
  [eval] val_mse=3.944e-01  (n=7000)
Epoch 00188: Time=  10.1s, Loss=3.24e+00, Inv=3.24e+00, For=3.05e+02, Power=6.84e-01
  [eval] val_mse=3.925e-01  (n=7000)
Epoch 00189: Time=  10.1s, Loss=3.24e+00, Inv=3.24e+00, For=3.17e+02, Power=6.83e-01
  [eval] val_mse=3.926e-01  (n=7000)
Epoch 00190: Time=  10.1s, Loss=3.23e+00, Inv=3.23e+00, For=3.09e+02, Power=6.82e-01
  [eval] val_mse=3.911e-01  (n=7000)
Epoch 00191: Time=  10.2s, Loss=3.24e+00, Inv=3.24e+00, For=3.15e+02, Power=6.85e-01
  [eval] val_mse=3.905e-01  (n=7000)
Epoch 00192: Time=  10.2s, Loss=3.23e+00, Inv=3.23e+00, For=3.17e+02, Power=6.84e-01
  [eval] val_mse=3.898e-01  (n=7000)
Epoch 00193: Time=  10.2s, Loss=3.22e+00, Inv=3.22e+00, For=3.16e+02, Power=6.83e-01
  [eval] val_mse=3.887e-01  (n=7000)
Epoch 00194: Time=  10.3s, Loss=3.22e+00, Inv=3.22e+00, For=3.20e+02, Power=6.83e-01
  [eval] val_mse=3.878e-01  (n=7000)
Epoch 00195: Time=  10.3s, Loss=3.22e+00, Inv=3.22e+00, For=3.22e+02, Power=6.83e-01
  [eval] val_mse=3.888e-01  (n=7000)
Epoch 00196: Time=  10.3s, Loss=3.21e+00, Inv=3.21e+00, For=3.18e+02, Power=6.83e-01
  [eval] val_mse=3.861e-01  (n=7000)
Epoch 00197: Time=  10.4s, Loss=3.21e+00, Inv=3.21e+00, For=3.23e+02, Power=6.81e-01
  [eval] val_mse=3.866e-01  (n=7000)
Epoch 00198: Time=  10.4s, Loss=3.21e+00, Inv=3.21e+00, For=3.28e+02, Power=6.84e-01
  [eval] val_mse=3.856e-01  (n=7000)
Epoch 00199: Time=  10.4s, Loss=3.20e+00, Inv=3.20e+00, For=3.25e+02, Power=6.84e-01
  [eval] val_mse=3.841e-01  (n=7000)
Epoch 00200: Time=  10.5s, Loss=3.20e+00, Inv=3.20e+00, For=3.31e+02, Power=6.84e-01
  [eval] val_mse=3.844e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 2.530e-01
Torque MSE  = 9.522e-02
Torque RMSE = 3.086e-01
Per-joint MSE : 8.369e-02 2.001e-01 8.492e-02 3.392e-02 1.509e-01 1.783e-02
Per-joint RMSE: 2.893e-01 4.473e-01 2.914e-01 1.842e-01 3.884e-01 1.335e-01
Comp Time per Sample = 2.687e-04s / 3721.6Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 1 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-mj6i3jis because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7cb0fd40e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:46:15.637679: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:46:17.300008: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.0s, Loss=1.20e+04, Inv=1.20e+04, For=5.81e+00, Power=7.99e+02
  [eval] val_mse=2.590e+02  (n=2997)
Epoch 00002: Time=   4.3s, Loss=1.94e+03, Inv=1.94e+03, For=5.63e+00, Power=1.92e+02
  [eval] val_mse=1.255e+02  (n=2997)
Epoch 00003: Time=   4.3s, Loss=8.37e+02, Inv=8.37e+02, For=5.55e+00, Power=1.08e+02
  [eval] val_mse=7.697e+01  (n=2997)
Epoch 00004: Time=   4.4s, Loss=4.71e+02, Inv=4.71e+02, For=5.47e+00, Power=7.02e+01
  [eval] val_mse=5.206e+01  (n=2997)
Epoch 00005: Time=   4.4s, Loss=3.02e+02, Inv=3.02e+02, For=5.40e+00, Power=4.81e+01
  [eval] val_mse=3.766e+01  (n=2997)
Epoch 00006: Time=   4.4s, Loss=2.10e+02, Inv=2.10e+02, For=5.33e+00, Power=3.47e+01
  [eval] val_mse=2.884e+01  (n=2997)
Epoch 00007: Time=   4.5s, Loss=1.54e+02, Inv=1.54e+02, For=5.27e+00, Power=2.59e+01
  [eval] val_mse=2.316e+01  (n=2997)
Epoch 00008: Time=   4.5s, Loss=1.19e+02, Inv=1.19e+02, For=5.23e+00, Power=2.00e+01
  [eval] val_mse=1.932e+01  (n=2997)
Epoch 00009: Time=   4.5s, Loss=9.50e+01, Inv=9.50e+01, For=5.20e+00, Power=1.59e+01
  [eval] val_mse=1.653e+01  (n=2997)
Epoch 00010: Time=   4.6s, Loss=7.78e+01, Inv=7.78e+01, For=5.17e+00, Power=1.29e+01
  [eval] val_mse=1.456e+01  (n=2997)
Epoch 00011: Time=   4.6s, Loss=6.52e+01, Inv=6.52e+01, For=5.15e+00, Power=1.07e+01
  [eval] val_mse=1.301e+01  (n=2997)
Epoch 00012: Time=   4.6s, Loss=5.55e+01, Inv=5.55e+01, For=5.12e+00, Power=8.98e+00
  [eval] val_mse=1.181e+01  (n=2997)
Epoch 00013: Time=   4.7s, Loss=4.80e+01, Inv=4.80e+01, For=5.13e+00, Power=7.65e+00
  [eval] val_mse=1.082e+01  (n=2997)
Epoch 00014: Time=   4.7s, Loss=4.21e+01, Inv=4.21e+01, For=5.12e+00, Power=6.59e+00
  [eval] val_mse=1.003e+01  (n=2997)
Epoch 00015: Time=   4.7s, Loss=3.72e+01, Inv=3.72e+01, For=5.14e+00, Power=5.77e+00
  [eval] val_mse=9.331e+00  (n=2997)
Epoch 00016: Time=   4.7s, Loss=3.31e+01, Inv=3.31e+01, For=5.17e+00, Power=5.07e+00
  [eval] val_mse=8.740e+00  (n=2997)
Epoch 00017: Time=   4.8s, Loss=2.98e+01, Inv=2.98e+01, For=5.20e+00, Power=4.49e+00
  [eval] val_mse=8.223e+00  (n=2997)
Epoch 00018: Time=   4.8s, Loss=2.69e+01, Inv=2.69e+01, For=5.24e+00, Power=4.01e+00
  [eval] val_mse=7.757e+00  (n=2997)
Epoch 00019: Time=   4.8s, Loss=2.45e+01, Inv=2.45e+01, For=5.29e+00, Power=3.61e+00
  [eval] val_mse=7.349e+00  (n=2997)
Epoch 00020: Time=   4.9s, Loss=2.23e+01, Inv=2.23e+01, For=5.35e+00, Power=3.26e+00
  [eval] val_mse=6.981e+00  (n=2997)
Epoch 00021: Time=   4.9s, Loss=2.06e+01, Inv=2.06e+01, For=5.44e+00, Power=2.97e+00
  [eval] val_mse=6.647e+00  (n=2997)
Epoch 00022: Time=   4.9s, Loss=1.90e+01, Inv=1.90e+01, For=5.49e+00, Power=2.72e+00
  [eval] val_mse=6.344e+00  (n=2997)
Epoch 00023: Time=   5.0s, Loss=1.76e+01, Inv=1.76e+01, For=5.60e+00, Power=2.51e+00
  [eval] val_mse=6.069e+00  (n=2997)
Epoch 00024: Time=   5.0s, Loss=1.64e+01, Inv=1.64e+01, For=5.70e+00, Power=2.31e+00
  [eval] val_mse=5.817e+00  (n=2997)
Epoch 00025: Time=   5.0s, Loss=1.53e+01, Inv=1.53e+01, For=5.83e+00, Power=2.15e+00
  [eval] val_mse=5.599e+00  (n=2997)
Epoch 00026: Time=   5.1s, Loss=1.44e+01, Inv=1.44e+01, For=5.97e+00, Power=2.00e+00
  [eval] val_mse=5.396e+00  (n=2997)
Epoch 00027: Time=   5.1s, Loss=1.35e+01, Inv=1.35e+01, For=6.12e+00, Power=1.88e+00
  [eval] val_mse=5.215e+00  (n=2997)
Epoch 00028: Time=   5.1s, Loss=1.28e+01, Inv=1.28e+01, For=6.28e+00, Power=1.76e+00
  [eval] val_mse=5.059e+00  (n=2997)
Epoch 00029: Time=   5.1s, Loss=1.22e+01, Inv=1.22e+01, For=6.48e+00, Power=1.66e+00
  [eval] val_mse=4.908e+00  (n=2997)
Epoch 00030: Time=   5.2s, Loss=1.16e+01, Inv=1.16e+01, For=6.67e+00, Power=1.57e+00
  [eval] val_mse=4.771e+00  (n=2997)
Epoch 00031: Time=   5.2s, Loss=1.10e+01, Inv=1.10e+01, For=6.89e+00, Power=1.49e+00
  [eval] val_mse=4.658e+00  (n=2997)
Epoch 00032: Time=   5.2s, Loss=1.06e+01, Inv=1.06e+01, For=7.13e+00, Power=1.42e+00
  [eval] val_mse=4.546e+00  (n=2997)
Epoch 00033: Time=   5.3s, Loss=1.01e+01, Inv=1.01e+01, For=7.37e+00, Power=1.35e+00
  [eval] val_mse=4.443e+00  (n=2997)
Epoch 00034: Time=   5.3s, Loss=9.75e+00, Inv=9.75e+00, For=7.64e+00, Power=1.30e+00
  [eval] val_mse=4.348e+00  (n=2997)
Epoch 00035: Time=   5.3s, Loss=9.39e+00, Inv=9.39e+00, For=7.93e+00, Power=1.25e+00
  [eval] val_mse=4.252e+00  (n=2997)
Epoch 00036: Time=   5.4s, Loss=9.08e+00, Inv=9.08e+00, For=8.19e+00, Power=1.20e+00
  [eval] val_mse=4.168e+00  (n=2997)
Epoch 00037: Time=   5.4s, Loss=8.77e+00, Inv=8.77e+00, For=8.48e+00, Power=1.16e+00
  [eval] val_mse=4.092e+00  (n=2997)
Epoch 00038: Time=   5.4s, Loss=8.50e+00, Inv=8.50e+00, For=8.78e+00, Power=1.12e+00
  [eval] val_mse=4.011e+00  (n=2997)
Epoch 00039: Time=   5.5s, Loss=8.25e+00, Inv=8.25e+00, For=9.11e+00, Power=1.09e+00
  [eval] val_mse=3.937e+00  (n=2997)
Epoch 00040: Time=   5.5s, Loss=8.02e+00, Inv=8.02e+00, For=9.43e+00, Power=1.06e+00
  [eval] val_mse=3.869e+00  (n=2997)
Epoch 00041: Time=   5.5s, Loss=7.81e+00, Inv=7.81e+00, For=9.78e+00, Power=1.03e+00
  [eval] val_mse=3.806e+00  (n=2997)
Epoch 00042: Time=   5.6s, Loss=7.61e+00, Inv=7.61e+00, For=1.01e+01, Power=1.00e+00
  [eval] val_mse=3.734e+00  (n=2997)
Epoch 00043: Time=   5.6s, Loss=7.43e+00, Inv=7.43e+00, For=1.05e+01, Power=9.78e-01
  [eval] val_mse=3.675e+00  (n=2997)
Epoch 00044: Time=   5.6s, Loss=7.25e+00, Inv=7.25e+00, For=1.08e+01, Power=9.55e-01
  [eval] val_mse=3.614e+00  (n=2997)
Epoch 00045: Time=   5.6s, Loss=7.10e+00, Inv=7.10e+00, For=1.12e+01, Power=9.35e-01
  [eval] val_mse=3.553e+00  (n=2997)
Epoch 00046: Time=   5.7s, Loss=6.93e+00, Inv=6.93e+00, For=1.16e+01, Power=9.17e-01
  [eval] val_mse=3.500e+00  (n=2997)
Epoch 00047: Time=   5.7s, Loss=6.79e+00, Inv=6.79e+00, For=1.20e+01, Power=8.99e-01
  [eval] val_mse=3.444e+00  (n=2997)
Epoch 00048: Time=   5.7s, Loss=6.66e+00, Inv=6.66e+00, For=1.24e+01, Power=8.83e-01
  [eval] val_mse=3.400e+00  (n=2997)
Epoch 00049: Time=   5.8s, Loss=6.54e+00, Inv=6.54e+00, For=1.28e+01, Power=8.68e-01
  [eval] val_mse=3.342e+00  (n=2997)
Epoch 00050: Time=   5.8s, Loss=6.42e+00, Inv=6.42e+00, For=1.32e+01, Power=8.55e-01
  [eval] val_mse=3.299e+00  (n=2997)
Epoch 00051: Time=   5.8s, Loss=6.31e+00, Inv=6.31e+00, For=1.37e+01, Power=8.44e-01
  [eval] val_mse=3.253e+00  (n=2997)
Epoch 00052: Time=   5.9s, Loss=6.20e+00, Inv=6.20e+00, For=1.41e+01, Power=8.31e-01
  [eval] val_mse=3.207e+00  (n=2997)
Epoch 00053: Time=   5.9s, Loss=6.10e+00, Inv=6.10e+00, For=1.46e+01, Power=8.19e-01
  [eval] val_mse=3.162e+00  (n=2997)
Epoch 00054: Time=   5.9s, Loss=6.01e+00, Inv=6.01e+00, For=1.50e+01, Power=8.10e-01
  [eval] val_mse=3.121e+00  (n=2997)
Epoch 00055: Time=   6.0s, Loss=5.92e+00, Inv=5.92e+00, For=1.55e+01, Power=8.01e-01
  [eval] val_mse=3.086e+00  (n=2997)
Epoch 00056: Time=   6.0s, Loss=5.83e+00, Inv=5.83e+00, For=1.60e+01, Power=7.92e-01
  [eval] val_mse=3.049e+00  (n=2997)
Epoch 00057: Time=   6.0s, Loss=5.75e+00, Inv=5.75e+00, For=1.65e+01, Power=7.83e-01
  [eval] val_mse=3.008e+00  (n=2997)
Epoch 00058: Time=   6.1s, Loss=5.68e+00, Inv=5.68e+00, For=1.70e+01, Power=7.76e-01
  [eval] val_mse=2.970e+00  (n=2997)
Epoch 00059: Time=   6.1s, Loss=5.60e+00, Inv=5.60e+00, For=1.75e+01, Power=7.67e-01
  [eval] val_mse=2.941e+00  (n=2997)
Epoch 00060: Time=   6.1s, Loss=5.53e+00, Inv=5.53e+00, For=1.79e+01, Power=7.61e-01
  [eval] val_mse=2.904e+00  (n=2997)
Epoch 00061: Time=   6.1s, Loss=5.46e+00, Inv=5.46e+00, For=1.85e+01, Power=7.55e-01
  [eval] val_mse=2.867e+00  (n=2997)
Epoch 00062: Time=   6.2s, Loss=5.40e+00, Inv=5.40e+00, For=1.90e+01, Power=7.50e-01
  [eval] val_mse=2.844e+00  (n=2997)
Epoch 00063: Time=   6.2s, Loss=5.34e+00, Inv=5.34e+00, For=1.96e+01, Power=7.43e-01
  [eval] val_mse=2.810e+00  (n=2997)
Epoch 00064: Time=   6.2s, Loss=5.28e+00, Inv=5.28e+00, For=2.01e+01, Power=7.38e-01
  [eval] val_mse=2.780e+00  (n=2997)
Epoch 00065: Time=   6.3s, Loss=5.23e+00, Inv=5.23e+00, For=2.06e+01, Power=7.34e-01
  [eval] val_mse=2.755e+00  (n=2997)
Epoch 00066: Time=   6.3s, Loss=5.17e+00, Inv=5.17e+00, For=2.12e+01, Power=7.28e-01
  [eval] val_mse=2.726e+00  (n=2997)
Epoch 00067: Time=   6.3s, Loss=5.12e+00, Inv=5.12e+00, For=2.18e+01, Power=7.23e-01
  [eval] val_mse=2.701e+00  (n=2997)
Epoch 00068: Time=   6.4s, Loss=5.07e+00, Inv=5.07e+00, For=2.22e+01, Power=7.20e-01
  [eval] val_mse=2.676e+00  (n=2997)
Epoch 00069: Time=   6.4s, Loss=5.02e+00, Inv=5.02e+00, For=2.28e+01, Power=7.16e-01
  [eval] val_mse=2.648e+00  (n=2997)
Epoch 00070: Time=   6.4s, Loss=4.97e+00, Inv=4.97e+00, For=2.34e+01, Power=7.11e-01
  [eval] val_mse=2.625e+00  (n=2997)
Epoch 00071: Time=   6.5s, Loss=4.94e+00, Inv=4.94e+00, For=2.39e+01, Power=7.08e-01
  [eval] val_mse=2.604e+00  (n=2997)
Epoch 00072: Time=   6.5s, Loss=4.89e+00, Inv=4.89e+00, For=2.45e+01, Power=7.04e-01
  [eval] val_mse=2.580e+00  (n=2997)
Epoch 00073: Time=   6.5s, Loss=4.85e+00, Inv=4.85e+00, For=2.51e+01, Power=7.01e-01
  [eval] val_mse=2.559e+00  (n=2997)
Epoch 00074: Time=   6.6s, Loss=4.81e+00, Inv=4.81e+00, For=2.57e+01, Power=6.98e-01
  [eval] val_mse=2.542e+00  (n=2997)
Epoch 00075: Time=   6.6s, Loss=4.77e+00, Inv=4.77e+00, For=2.62e+01, Power=6.95e-01
  [eval] val_mse=2.515e+00  (n=2997)
Epoch 00076: Time=   6.6s, Loss=4.73e+00, Inv=4.73e+00, For=2.67e+01, Power=6.91e-01
  [eval] val_mse=2.497e+00  (n=2997)
Epoch 00077: Time=   6.7s, Loss=4.70e+00, Inv=4.70e+00, For=2.74e+01, Power=6.89e-01
  [eval] val_mse=2.479e+00  (n=2997)
Epoch 00078: Time=   6.7s, Loss=4.66e+00, Inv=4.66e+00, For=2.79e+01, Power=6.85e-01
  [eval] val_mse=2.456e+00  (n=2997)
Epoch 00079: Time=   6.7s, Loss=4.63e+00, Inv=4.63e+00, For=2.85e+01, Power=6.84e-01
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00080: Time=   6.7s, Loss=4.60e+00, Inv=4.60e+00, For=2.91e+01, Power=6.80e-01
  [eval] val_mse=2.420e+00  (n=2997)
Epoch 00081: Time=   6.8s, Loss=4.57e+00, Inv=4.57e+00, For=2.96e+01, Power=6.79e-01
  [eval] val_mse=2.410e+00  (n=2997)
Epoch 00082: Time=   6.8s, Loss=4.54e+00, Inv=4.54e+00, For=3.02e+01, Power=6.76e-01
  [eval] val_mse=2.392e+00  (n=2997)
Epoch 00083: Time=   6.8s, Loss=4.51e+00, Inv=4.51e+00, For=3.08e+01, Power=6.74e-01
  [eval] val_mse=2.377e+00  (n=2997)
Epoch 00084: Time=   6.9s, Loss=4.48e+00, Inv=4.48e+00, For=3.13e+01, Power=6.72e-01
  [eval] val_mse=2.362e+00  (n=2997)
Epoch 00085: Time=   6.9s, Loss=4.45e+00, Inv=4.45e+00, For=3.19e+01, Power=6.71e-01
  [eval] val_mse=2.342e+00  (n=2997)
Epoch 00086: Time=   6.9s, Loss=4.42e+00, Inv=4.42e+00, For=3.23e+01, Power=6.67e-01
  [eval] val_mse=2.333e+00  (n=2997)
Epoch 00087: Time=   7.0s, Loss=4.40e+00, Inv=4.40e+00, For=3.30e+01, Power=6.67e-01
  [eval] val_mse=2.324e+00  (n=2997)
Epoch 00088: Time=   7.0s, Loss=4.37e+00, Inv=4.37e+00, For=3.37e+01, Power=6.63e-01
  [eval] val_mse=2.308e+00  (n=2997)
Epoch 00089: Time=   7.0s, Loss=4.35e+00, Inv=4.35e+00, For=3.42e+01, Power=6.62e-01
  [eval] val_mse=2.301e+00  (n=2997)
Epoch 00090: Time=   7.1s, Loss=4.33e+00, Inv=4.33e+00, For=3.46e+01, Power=6.61e-01
  [eval] val_mse=2.283e+00  (n=2997)
Epoch 00091: Time=   7.1s, Loss=4.31e+00, Inv=4.31e+00, For=3.51e+01, Power=6.58e-01
  [eval] val_mse=2.283e+00  (n=2997)
Epoch 00092: Time=   7.1s, Loss=4.28e+00, Inv=4.28e+00, For=3.56e+01, Power=6.56e-01
  [eval] val_mse=2.263e+00  (n=2997)
Epoch 00093: Time=   7.2s, Loss=4.26e+00, Inv=4.26e+00, For=3.62e+01, Power=6.57e-01
  [eval] val_mse=2.261e+00  (n=2997)
Epoch 00094: Time=   7.2s, Loss=4.24e+00, Inv=4.24e+00, For=3.68e+01, Power=6.55e-01
  [eval] val_mse=2.247e+00  (n=2997)
Epoch 00095: Time=   7.2s, Loss=4.22e+00, Inv=4.22e+00, For=3.70e+01, Power=6.53e-01
  [eval] val_mse=2.241e+00  (n=2997)
Epoch 00096: Time=   7.2s, Loss=4.20e+00, Inv=4.20e+00, For=3.76e+01, Power=6.52e-01
  [eval] val_mse=2.233e+00  (n=2997)
Epoch 00097: Time=   7.3s, Loss=4.18e+00, Inv=4.18e+00, For=3.79e+01, Power=6.51e-01
  [eval] val_mse=2.225e+00  (n=2997)
Epoch 00098: Time=   7.3s, Loss=4.17e+00, Inv=4.17e+00, For=3.86e+01, Power=6.48e-01
  [eval] val_mse=2.218e+00  (n=2997)
Epoch 00099: Time=   7.3s, Loss=4.15e+00, Inv=4.15e+00, For=3.91e+01, Power=6.47e-01
  [eval] val_mse=2.219e+00  (n=2997)
Epoch 00100: Time=   7.4s, Loss=4.13e+00, Inv=4.13e+00, For=3.95e+01, Power=6.46e-01
  [eval] val_mse=2.205e+00  (n=2997)
Epoch 00101: Time=   7.4s, Loss=4.11e+00, Inv=4.11e+00, For=3.98e+01, Power=6.43e-01
  [eval] val_mse=2.209e+00  (n=2997)
Epoch 00102: Time=   7.4s, Loss=4.10e+00, Inv=4.10e+00, For=4.03e+01, Power=6.43e-01
  [eval] val_mse=2.192e+00  (n=2997)
Epoch 00103: Time=   7.5s, Loss=4.08e+00, Inv=4.08e+00, For=4.07e+01, Power=6.43e-01
  [eval] val_mse=2.198e+00  (n=2997)
Epoch 00104: Time=   7.5s, Loss=4.07e+00, Inv=4.07e+00, For=4.11e+01, Power=6.42e-01
  [eval] val_mse=2.198e+00  (n=2997)
Epoch 00105: Time=   7.5s, Loss=4.05e+00, Inv=4.05e+00, For=4.14e+01, Power=6.39e-01
  [eval] val_mse=2.188e+00  (n=2997)
Epoch 00106: Time=   7.6s, Loss=4.04e+00, Inv=4.04e+00, For=4.17e+01, Power=6.39e-01
  [eval] val_mse=2.185e+00  (n=2997)
Epoch 00107: Time=   7.6s, Loss=4.02e+00, Inv=4.02e+00, For=4.22e+01, Power=6.37e-01
  [eval] val_mse=2.181e+00  (n=2997)
Epoch 00108: Time=   7.6s, Loss=4.01e+00, Inv=4.01e+00, For=4.25e+01, Power=6.36e-01
  [eval] val_mse=2.173e+00  (n=2997)
Epoch 00109: Time=   7.7s, Loss=3.99e+00, Inv=3.99e+00, For=4.27e+01, Power=6.36e-01
  [eval] val_mse=2.179e+00  (n=2997)
Epoch 00110: Time=   7.7s, Loss=3.98e+00, Inv=3.98e+00, For=4.31e+01, Power=6.34e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00111: Time=   7.7s, Loss=3.97e+00, Inv=3.97e+00, For=4.33e+01, Power=6.33e-01
  [eval] val_mse=2.170e+00  (n=2997)
Epoch 00112: Time=   7.8s, Loss=3.96e+00, Inv=3.96e+00, For=4.37e+01, Power=6.33e-01
  [eval] val_mse=2.175e+00  (n=2997)
Epoch 00113: Time=   7.8s, Loss=3.95e+00, Inv=3.95e+00, For=4.40e+01, Power=6.31e-01
  [eval] val_mse=2.182e+00  (n=2997)
Epoch 00114: Time=   7.8s, Loss=3.93e+00, Inv=3.93e+00, For=4.42e+01, Power=6.31e-01
  [eval] val_mse=2.189e+00  (n=2997)
Epoch 00115: Time=   7.9s, Loss=3.92e+00, Inv=3.92e+00, For=4.45e+01, Power=6.30e-01
  [eval] val_mse=2.185e+00  (n=2997)
Epoch 00116: Time=   7.9s, Loss=3.91e+00, Inv=3.91e+00, For=4.47e+01, Power=6.29e-01
  [eval] val_mse=2.184e+00  (n=2997)
Epoch 00117: Time=   7.9s, Loss=3.89e+00, Inv=3.89e+00, For=4.50e+01, Power=6.26e-01
  [eval] val_mse=2.193e+00  (n=2997)
Epoch 00118: Time=   8.0s, Loss=3.89e+00, Inv=3.89e+00, For=4.49e+01, Power=6.26e-01
  [eval] val_mse=2.190e+00  (n=2997)
Epoch 00119: Time=   8.0s, Loss=3.87e+00, Inv=3.87e+00, For=4.51e+01, Power=6.26e-01
  [eval] val_mse=2.185e+00  (n=2997)
Epoch 00120: Time=   8.1s, Loss=3.87e+00, Inv=3.87e+00, For=4.56e+01, Power=6.25e-01
  [eval] val_mse=2.192e+00  (n=2997)
Epoch 00121: Time=   8.1s, Loss=3.85e+00, Inv=3.85e+00, For=4.55e+01, Power=6.24e-01
  [eval] val_mse=2.194e+00  (n=2997)
  [early_stop] stop at epoch=121 (best_epoch=111, best_val_mse=2.170e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 6.014e-01
Torque MSE  = 1.232e-01
Torque RMSE = 3.510e-01
Per-joint MSE : 1.692e-01 2.689e-01 1.336e-01 6.394e-02 5.191e-02 5.179e-02
Per-joint RMSE: 4.113e-01 5.185e-01 3.655e-01 2.529e-01 2.278e-01 2.276e-01
Comp Time per Sample = 2.164e-04s / 4621.0Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-jg_sme39 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x794289e628c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:46:33.097051: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:46:34.709388: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.0s, Loss=7.11e+03, Inv=7.11e+03, For=6.02e+00, Power=1.10e+03
  [eval] val_mse=2.520e+02  (n=2997)
Epoch 00002: Time=   4.3s, Loss=1.34e+03, Inv=1.34e+03, For=5.82e+00, Power=2.18e+02
  [eval] val_mse=1.118e+02  (n=2997)
Epoch 00003: Time=   4.3s, Loss=5.66e+02, Inv=5.66e+02, For=5.66e+00, Power=9.94e+01
  [eval] val_mse=6.588e+01  (n=2997)
Epoch 00004: Time=   4.3s, Loss=3.17e+02, Inv=3.17e+02, For=5.53e+00, Power=5.75e+01
  [eval] val_mse=4.322e+01  (n=2997)
Epoch 00005: Time=   4.4s, Loss=2.02e+02, Inv=2.02e+02, For=5.43e+00, Power=3.72e+01
  [eval] val_mse=3.080e+01  (n=2997)
Epoch 00006: Time=   4.4s, Loss=1.41e+02, Inv=1.41e+02, For=5.36e+00, Power=2.58e+01
  [eval] val_mse=2.335e+01  (n=2997)
Epoch 00007: Time=   4.4s, Loss=1.04e+02, Inv=1.04e+02, For=5.32e+00, Power=1.88e+01
  [eval] val_mse=1.849e+01  (n=2997)
Epoch 00008: Time=   4.4s, Loss=8.04e+01, Inv=8.04e+01, For=5.31e+00, Power=1.42e+01
  [eval] val_mse=1.515e+01  (n=2997)
Epoch 00009: Time=   4.5s, Loss=6.41e+01, Inv=6.41e+01, For=5.31e+00, Power=1.11e+01
  [eval] val_mse=1.283e+01  (n=2997)
Epoch 00010: Time=   4.5s, Loss=5.23e+01, Inv=5.23e+01, For=5.34e+00, Power=8.85e+00
  [eval] val_mse=1.114e+01  (n=2997)
Epoch 00011: Time=   4.5s, Loss=4.38e+01, Inv=4.38e+01, For=5.41e+00, Power=7.27e+00
  [eval] val_mse=9.835e+00  (n=2997)
Epoch 00012: Time=   4.6s, Loss=3.72e+01, Inv=3.72e+01, For=5.48e+00, Power=6.03e+00
  [eval] val_mse=8.841e+00  (n=2997)
Epoch 00013: Time=   4.6s, Loss=3.21e+01, Inv=3.21e+01, For=5.56e+00, Power=5.09e+00
  [eval] val_mse=8.026e+00  (n=2997)
Epoch 00014: Time=   4.6s, Loss=2.80e+01, Inv=2.80e+01, For=5.67e+00, Power=4.37e+00
  [eval] val_mse=7.387e+00  (n=2997)
Epoch 00015: Time=   4.7s, Loss=2.47e+01, Inv=2.47e+01, For=5.78e+00, Power=3.79e+00
  [eval] val_mse=6.831e+00  (n=2997)
Epoch 00016: Time=   4.7s, Loss=2.21e+01, Inv=2.21e+01, For=5.93e+00, Power=3.33e+00
  [eval] val_mse=6.362e+00  (n=2997)
Epoch 00017: Time=   4.7s, Loss=1.98e+01, Inv=1.98e+01, For=6.06e+00, Power=2.95e+00
  [eval] val_mse=5.961e+00  (n=2997)
Epoch 00018: Time=   4.8s, Loss=1.80e+01, Inv=1.80e+01, For=6.23e+00, Power=2.64e+00
  [eval] val_mse=5.606e+00  (n=2997)
Epoch 00019: Time=   4.8s, Loss=1.64e+01, Inv=1.64e+01, For=6.38e+00, Power=2.37e+00
  [eval] val_mse=5.299e+00  (n=2997)
Epoch 00020: Time=   4.8s, Loss=1.51e+01, Inv=1.51e+01, For=6.55e+00, Power=2.17e+00
  [eval] val_mse=5.020e+00  (n=2997)
Epoch 00021: Time=   4.9s, Loss=1.39e+01, Inv=1.39e+01, For=6.74e+00, Power=1.98e+00
  [eval] val_mse=4.776e+00  (n=2997)
Epoch 00022: Time=   4.9s, Loss=1.29e+01, Inv=1.29e+01, For=6.92e+00, Power=1.82e+00
  [eval] val_mse=4.549e+00  (n=2997)
Epoch 00023: Time=   4.9s, Loss=1.20e+01, Inv=1.20e+01, For=7.12e+00, Power=1.69e+00
  [eval] val_mse=4.356e+00  (n=2997)
Epoch 00024: Time=   5.0s, Loss=1.13e+01, Inv=1.13e+01, For=7.31e+00, Power=1.57e+00
  [eval] val_mse=4.175e+00  (n=2997)
Epoch 00025: Time=   5.0s, Loss=1.06e+01, Inv=1.06e+01, For=7.52e+00, Power=1.47e+00
  [eval] val_mse=4.021e+00  (n=2997)
Epoch 00026: Time=   5.0s, Loss=1.00e+01, Inv=1.00e+01, For=7.72e+00, Power=1.38e+00
  [eval] val_mse=3.873e+00  (n=2997)
Epoch 00027: Time=   5.1s, Loss=9.48e+00, Inv=9.48e+00, For=7.95e+00, Power=1.31e+00
  [eval] val_mse=3.746e+00  (n=2997)
Epoch 00028: Time=   5.1s, Loss=9.01e+00, Inv=9.01e+00, For=8.16e+00, Power=1.24e+00
  [eval] val_mse=3.627e+00  (n=2997)
Epoch 00029: Time=   5.1s, Loss=8.60e+00, Inv=8.60e+00, For=8.39e+00, Power=1.18e+00
  [eval] val_mse=3.529e+00  (n=2997)
Epoch 00030: Time=   5.2s, Loss=8.24e+00, Inv=8.24e+00, For=8.65e+00, Power=1.12e+00
  [eval] val_mse=3.442e+00  (n=2997)
Epoch 00031: Time=   5.2s, Loss=7.90e+00, Inv=7.90e+00, For=8.87e+00, Power=1.08e+00
  [eval] val_mse=3.360e+00  (n=2997)
Epoch 00032: Time=   5.2s, Loss=7.61e+00, Inv=7.61e+00, For=9.16e+00, Power=1.04e+00
  [eval] val_mse=3.283e+00  (n=2997)
Epoch 00033: Time=   5.3s, Loss=7.34e+00, Inv=7.34e+00, For=9.41e+00, Power=1.00e+00
  [eval] val_mse=3.217e+00  (n=2997)
Epoch 00034: Time=   5.3s, Loss=7.10e+00, Inv=7.10e+00, For=9.67e+00, Power=9.65e-01
  [eval] val_mse=3.155e+00  (n=2997)
Epoch 00035: Time=   5.3s, Loss=6.89e+00, Inv=6.89e+00, For=9.96e+00, Power=9.35e-01
  [eval] val_mse=3.103e+00  (n=2997)
Epoch 00036: Time=   5.4s, Loss=6.68e+00, Inv=6.68e+00, For=1.02e+01, Power=9.10e-01
  [eval] val_mse=3.052e+00  (n=2997)
Epoch 00037: Time=   5.4s, Loss=6.50e+00, Inv=6.50e+00, For=1.05e+01, Power=8.86e-01
  [eval] val_mse=3.005e+00  (n=2997)
Epoch 00038: Time=   5.4s, Loss=6.33e+00, Inv=6.33e+00, For=1.09e+01, Power=8.63e-01
  [eval] val_mse=2.955e+00  (n=2997)
Epoch 00039: Time=   5.5s, Loss=6.18e+00, Inv=6.18e+00, For=1.12e+01, Power=8.44e-01
  [eval] val_mse=2.920e+00  (n=2997)
Epoch 00040: Time=   5.5s, Loss=6.04e+00, Inv=6.04e+00, For=1.15e+01, Power=8.26e-01
  [eval] val_mse=2.879e+00  (n=2997)
Epoch 00041: Time=   5.5s, Loss=5.91e+00, Inv=5.91e+00, For=1.18e+01, Power=8.10e-01
  [eval] val_mse=2.847e+00  (n=2997)
Epoch 00042: Time=   5.6s, Loss=5.79e+00, Inv=5.79e+00, For=1.22e+01, Power=7.95e-01
  [eval] val_mse=2.806e+00  (n=2997)
Epoch 00043: Time=   5.6s, Loss=5.68e+00, Inv=5.68e+00, For=1.25e+01, Power=7.81e-01
  [eval] val_mse=2.770e+00  (n=2997)
Epoch 00044: Time=   5.6s, Loss=5.57e+00, Inv=5.57e+00, For=1.29e+01, Power=7.68e-01
  [eval] val_mse=2.740e+00  (n=2997)
Epoch 00045: Time=   5.6s, Loss=5.48e+00, Inv=5.48e+00, For=1.33e+01, Power=7.57e-01
  [eval] val_mse=2.712e+00  (n=2997)
Epoch 00046: Time=   5.7s, Loss=5.38e+00, Inv=5.38e+00, For=1.37e+01, Power=7.47e-01
  [eval] val_mse=2.691e+00  (n=2997)
Epoch 00047: Time=   5.7s, Loss=5.30e+00, Inv=5.30e+00, For=1.41e+01, Power=7.37e-01
  [eval] val_mse=2.657e+00  (n=2997)
Epoch 00048: Time=   5.7s, Loss=5.22e+00, Inv=5.22e+00, For=1.45e+01, Power=7.28e-01
  [eval] val_mse=2.631e+00  (n=2997)
Epoch 00049: Time=   5.8s, Loss=5.14e+00, Inv=5.14e+00, For=1.49e+01, Power=7.20e-01
  [eval] val_mse=2.609e+00  (n=2997)
Epoch 00050: Time=   5.8s, Loss=5.08e+00, Inv=5.08e+00, For=1.53e+01, Power=7.12e-01
  [eval] val_mse=2.586e+00  (n=2997)
Epoch 00051: Time=   5.8s, Loss=5.01e+00, Inv=5.01e+00, For=1.57e+01, Power=7.04e-01
  [eval] val_mse=2.561e+00  (n=2997)
Epoch 00052: Time=   5.9s, Loss=4.94e+00, Inv=4.94e+00, For=1.62e+01, Power=6.98e-01
  [eval] val_mse=2.537e+00  (n=2997)
Epoch 00053: Time=   5.9s, Loss=4.89e+00, Inv=4.89e+00, For=1.66e+01, Power=6.92e-01
  [eval] val_mse=2.517e+00  (n=2997)
Epoch 00054: Time=   5.9s, Loss=4.83e+00, Inv=4.83e+00, For=1.70e+01, Power=6.86e-01
  [eval] val_mse=2.499e+00  (n=2997)
Epoch 00055: Time=   6.0s, Loss=4.78e+00, Inv=4.78e+00, For=1.76e+01, Power=6.80e-01
  [eval] val_mse=2.483e+00  (n=2997)
Epoch 00056: Time=   6.0s, Loss=4.73e+00, Inv=4.73e+00, For=1.80e+01, Power=6.75e-01
  [eval] val_mse=2.457e+00  (n=2997)
Epoch 00057: Time=   6.0s, Loss=4.68e+00, Inv=4.68e+00, For=1.85e+01, Power=6.72e-01
  [eval] val_mse=2.443e+00  (n=2997)
Epoch 00058: Time=   6.1s, Loss=4.64e+00, Inv=4.64e+00, For=1.90e+01, Power=6.67e-01
  [eval] val_mse=2.428e+00  (n=2997)
Epoch 00059: Time=   6.1s, Loss=4.60e+00, Inv=4.60e+00, For=1.95e+01, Power=6.61e-01
  [eval] val_mse=2.413e+00  (n=2997)
Epoch 00060: Time=   6.1s, Loss=4.55e+00, Inv=4.55e+00, For=2.00e+01, Power=6.58e-01
  [eval] val_mse=2.400e+00  (n=2997)
Epoch 00061: Time=   6.1s, Loss=4.51e+00, Inv=4.51e+00, For=2.05e+01, Power=6.56e-01
  [eval] val_mse=2.372e+00  (n=2997)
Epoch 00062: Time=   6.2s, Loss=4.48e+00, Inv=4.48e+00, For=2.11e+01, Power=6.52e-01
  [eval] val_mse=2.365e+00  (n=2997)
Epoch 00063: Time=   6.2s, Loss=4.44e+00, Inv=4.44e+00, For=2.16e+01, Power=6.49e-01
  [eval] val_mse=2.356e+00  (n=2997)
Epoch 00064: Time=   6.2s, Loss=4.41e+00, Inv=4.41e+00, For=2.22e+01, Power=6.45e-01
  [eval] val_mse=2.338e+00  (n=2997)
Epoch 00065: Time=   6.3s, Loss=4.38e+00, Inv=4.38e+00, For=2.28e+01, Power=6.43e-01
  [eval] val_mse=2.334e+00  (n=2997)
Epoch 00066: Time=   6.3s, Loss=4.35e+00, Inv=4.35e+00, For=2.34e+01, Power=6.40e-01
  [eval] val_mse=2.323e+00  (n=2997)
Epoch 00067: Time=   6.3s, Loss=4.32e+00, Inv=4.32e+00, For=2.40e+01, Power=6.38e-01
  [eval] val_mse=2.309e+00  (n=2997)
Epoch 00068: Time=   6.4s, Loss=4.29e+00, Inv=4.29e+00, For=2.44e+01, Power=6.35e-01
  [eval] val_mse=2.301e+00  (n=2997)
Epoch 00069: Time=   6.4s, Loss=4.26e+00, Inv=4.26e+00, For=2.52e+01, Power=6.32e-01
  [eval] val_mse=2.284e+00  (n=2997)
Epoch 00070: Time=   6.4s, Loss=4.23e+00, Inv=4.23e+00, For=2.58e+01, Power=6.31e-01
  [eval] val_mse=2.271e+00  (n=2997)
Epoch 00071: Time=   6.4s, Loss=4.21e+00, Inv=4.21e+00, For=2.64e+01, Power=6.29e-01
  [eval] val_mse=2.264e+00  (n=2997)
Epoch 00072: Time=   6.5s, Loss=4.18e+00, Inv=4.18e+00, For=2.72e+01, Power=6.26e-01
  [eval] val_mse=2.261e+00  (n=2997)
Epoch 00073: Time=   6.5s, Loss=4.16e+00, Inv=4.16e+00, For=2.78e+01, Power=6.25e-01
  [eval] val_mse=2.239e+00  (n=2997)
Epoch 00074: Time=   6.5s, Loss=4.14e+00, Inv=4.14e+00, For=2.86e+01, Power=6.23e-01
  [eval] val_mse=2.237e+00  (n=2997)
Epoch 00075: Time=   6.6s, Loss=4.12e+00, Inv=4.12e+00, For=2.93e+01, Power=6.22e-01
  [eval] val_mse=2.234e+00  (n=2997)
Epoch 00076: Time=   6.6s, Loss=4.10e+00, Inv=4.10e+00, For=2.99e+01, Power=6.20e-01
  [eval] val_mse=2.216e+00  (n=2997)
Epoch 00077: Time=   6.6s, Loss=4.07e+00, Inv=4.07e+00, For=3.05e+01, Power=6.19e-01
  [eval] val_mse=2.225e+00  (n=2997)
Epoch 00078: Time=   6.6s, Loss=4.06e+00, Inv=4.06e+00, For=3.14e+01, Power=6.16e-01
  [eval] val_mse=2.203e+00  (n=2997)
Epoch 00079: Time=   6.7s, Loss=4.04e+00, Inv=4.04e+00, For=3.21e+01, Power=6.14e-01
  [eval] val_mse=2.214e+00  (n=2997)
Epoch 00080: Time=   6.7s, Loss=4.02e+00, Inv=4.02e+00, For=3.28e+01, Power=6.14e-01
  [eval] val_mse=2.193e+00  (n=2997)
Epoch 00081: Time=   6.7s, Loss=4.00e+00, Inv=4.00e+00, For=3.38e+01, Power=6.11e-01
  [eval] val_mse=2.198e+00  (n=2997)
Epoch 00082: Time=   6.8s, Loss=3.99e+00, Inv=3.99e+00, For=3.44e+01, Power=6.11e-01
  [eval] val_mse=2.187e+00  (n=2997)
Epoch 00083: Time=   6.8s, Loss=3.97e+00, Inv=3.97e+00, For=3.52e+01, Power=6.10e-01
  [eval] val_mse=2.178e+00  (n=2997)
Epoch 00084: Time=   6.8s, Loss=3.95e+00, Inv=3.95e+00, For=3.62e+01, Power=6.09e-01
  [eval] val_mse=2.171e+00  (n=2997)
Epoch 00085: Time=   6.9s, Loss=3.94e+00, Inv=3.94e+00, For=3.67e+01, Power=6.07e-01
  [eval] val_mse=2.174e+00  (n=2997)
Epoch 00086: Time=   6.9s, Loss=3.92e+00, Inv=3.92e+00, For=3.79e+01, Power=6.06e-01
  [eval] val_mse=2.168e+00  (n=2997)
Epoch 00087: Time=   6.9s, Loss=3.91e+00, Inv=3.91e+00, For=3.82e+01, Power=6.06e-01
  [eval] val_mse=2.166e+00  (n=2997)
Epoch 00088: Time=   6.9s, Loss=3.90e+00, Inv=3.90e+00, For=3.97e+01, Power=6.04e-01
  [eval] val_mse=2.165e+00  (n=2997)
Epoch 00089: Time=   7.0s, Loss=3.88e+00, Inv=3.88e+00, For=3.99e+01, Power=6.04e-01
  [eval] val_mse=2.177e+00  (n=2997)
Epoch 00090: Time=   7.0s, Loss=3.87e+00, Inv=3.87e+00, For=4.12e+01, Power=6.04e-01
  [eval] val_mse=2.155e+00  (n=2997)
Epoch 00091: Time=   7.0s, Loss=3.85e+00, Inv=3.85e+00, For=4.19e+01, Power=6.01e-01
  [eval] val_mse=2.152e+00  (n=2997)
Epoch 00092: Time=   7.1s, Loss=3.84e+00, Inv=3.84e+00, For=4.28e+01, Power=6.02e-01
  [eval] val_mse=2.145e+00  (n=2997)
Epoch 00093: Time=   7.1s, Loss=3.83e+00, Inv=3.83e+00, For=4.35e+01, Power=6.01e-01
  [eval] val_mse=2.155e+00  (n=2997)
Epoch 00094: Time=   7.1s, Loss=3.82e+00, Inv=3.82e+00, For=4.47e+01, Power=6.00e-01
  [eval] val_mse=2.150e+00  (n=2997)
Epoch 00095: Time=   7.2s, Loss=3.81e+00, Inv=3.81e+00, For=4.54e+01, Power=5.99e-01
  [eval] val_mse=2.147e+00  (n=2997)
Epoch 00096: Time=   7.2s, Loss=3.80e+00, Inv=3.80e+00, For=4.68e+01, Power=5.98e-01
  [eval] val_mse=2.149e+00  (n=2997)
Epoch 00097: Time=   7.2s, Loss=3.79e+00, Inv=3.79e+00, For=4.72e+01, Power=5.98e-01
  [eval] val_mse=2.145e+00  (n=2997)
Epoch 00098: Time=   7.2s, Loss=3.78e+00, Inv=3.78e+00, For=4.82e+01, Power=5.97e-01
  [eval] val_mse=2.156e+00  (n=2997)
Epoch 00099: Time=   7.3s, Loss=3.76e+00, Inv=3.76e+00, For=4.94e+01, Power=5.95e-01
  [eval] val_mse=2.146e+00  (n=2997)
Epoch 00100: Time=   7.3s, Loss=3.76e+00, Inv=3.76e+00, For=5.00e+01, Power=5.96e-01
  [eval] val_mse=2.155e+00  (n=2997)
Epoch 00101: Time=   7.3s, Loss=3.75e+00, Inv=3.75e+00, For=5.12e+01, Power=5.95e-01
  [eval] val_mse=2.150e+00  (n=2997)
Epoch 00102: Time=   7.4s, Loss=3.74e+00, Inv=3.74e+00, For=5.20e+01, Power=5.95e-01
  [eval] val_mse=2.158e+00  (n=2997)
  [early_stop] stop at epoch=102 (best_epoch=92, best_val_mse=2.145e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 5.979e-01
Torque MSE  = 1.227e-01
Torque RMSE = 3.503e-01
Per-joint MSE : 1.690e-01 2.335e-01 1.458e-01 7.136e-02 5.659e-02 6.004e-02
Per-joint RMSE: 4.111e-01 4.832e-01 3.818e-01 2.671e-01 2.379e-01 2.450e-01
Comp Time per Sample = 1.967e-04s / 5083.4Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-wmowswcg because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x754299a9e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:46:49.573168: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:46:51.222370: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   2.9s, Loss=1.49e+04, Inv=1.49e+04, For=5.82e+00, Power=1.17e+03
  [eval] val_mse=3.349e+02  (n=2997)
Epoch 00002: Time=   4.2s, Loss=3.94e+03, Inv=3.94e+03, For=5.74e+00, Power=3.99e+02
  [eval] val_mse=1.567e+02  (n=2997)
Epoch 00003: Time=   4.3s, Loss=1.82e+03, Inv=1.82e+03, For=5.65e+00, Power=2.15e+02
  [eval] val_mse=9.614e+01  (n=2997)
Epoch 00004: Time=   4.3s, Loss=1.03e+03, Inv=1.03e+03, For=5.57e+00, Power=1.34e+02
  [eval] val_mse=6.511e+01  (n=2997)
Epoch 00005: Time=   4.3s, Loss=6.54e+02, Inv=6.54e+02, For=5.50e+00, Power=8.87e+01
  [eval] val_mse=4.727e+01  (n=2997)
Epoch 00006: Time=   4.4s, Loss=4.41e+02, Inv=4.41e+02, For=5.41e+00, Power=6.10e+01
  [eval] val_mse=3.608e+01  (n=2997)
Epoch 00007: Time=   4.4s, Loss=3.14e+02, Inv=3.14e+02, For=5.35e+00, Power=4.40e+01
  [eval] val_mse=2.839e+01  (n=2997)
Epoch 00008: Time=   4.4s, Loss=2.33e+02, Inv=2.33e+02, For=5.27e+00, Power=3.27e+01
  [eval] val_mse=2.315e+01  (n=2997)
Epoch 00009: Time=   4.5s, Loss=1.79e+02, Inv=1.79e+02, For=5.23e+00, Power=2.50e+01
  [eval] val_mse=1.929e+01  (n=2997)
Epoch 00010: Time=   4.5s, Loss=1.41e+02, Inv=1.41e+02, For=5.21e+00, Power=1.95e+01
  [eval] val_mse=1.650e+01  (n=2997)
Epoch 00011: Time=   4.5s, Loss=1.14e+02, Inv=1.14e+02, For=5.18e+00, Power=1.57e+01
  [eval] val_mse=1.443e+01  (n=2997)
Epoch 00012: Time=   4.6s, Loss=9.37e+01, Inv=9.37e+01, For=5.18e+00, Power=1.27e+01
  [eval] val_mse=1.278e+01  (n=2997)
Epoch 00013: Time=   4.6s, Loss=7.85e+01, Inv=7.85e+01, For=5.20e+00, Power=1.06e+01
  [eval] val_mse=1.147e+01  (n=2997)
Epoch 00014: Time=   4.6s, Loss=6.67e+01, Inv=6.67e+01, For=5.23e+00, Power=8.87e+00
  [eval] val_mse=1.044e+01  (n=2997)
Epoch 00015: Time=   4.7s, Loss=5.73e+01, Inv=5.73e+01, For=5.26e+00, Power=7.54e+00
  [eval] val_mse=9.591e+00  (n=2997)
Epoch 00016: Time=   4.7s, Loss=4.98e+01, Inv=4.98e+01, For=5.32e+00, Power=6.48e+00
  [eval] val_mse=8.886e+00  (n=2997)
Epoch 00017: Time=   4.7s, Loss=4.37e+01, Inv=4.37e+01, For=5.39e+00, Power=5.64e+00
  [eval] val_mse=8.301e+00  (n=2997)
Epoch 00018: Time=   4.8s, Loss=3.87e+01, Inv=3.87e+01, For=5.45e+00, Power=4.96e+00
  [eval] val_mse=7.770e+00  (n=2997)
Epoch 00019: Time=   4.8s, Loss=3.44e+01, Inv=3.44e+01, For=5.54e+00, Power=4.38e+00
  [eval] val_mse=7.333e+00  (n=2997)
Epoch 00020: Time=   4.8s, Loss=3.09e+01, Inv=3.09e+01, For=5.64e+00, Power=3.88e+00
  [eval] val_mse=6.935e+00  (n=2997)
Epoch 00021: Time=   4.9s, Loss=2.79e+01, Inv=2.79e+01, For=5.76e+00, Power=3.51e+00
  [eval] val_mse=6.578e+00  (n=2997)
Epoch 00022: Time=   4.9s, Loss=2.53e+01, Inv=2.53e+01, For=5.88e+00, Power=3.16e+00
  [eval] val_mse=6.270e+00  (n=2997)
Epoch 00023: Time=   4.9s, Loss=2.31e+01, Inv=2.31e+01, For=6.02e+00, Power=2.88e+00
  [eval] val_mse=5.989e+00  (n=2997)
Epoch 00024: Time=   5.0s, Loss=2.12e+01, Inv=2.12e+01, For=6.18e+00, Power=2.63e+00
  [eval] val_mse=5.726e+00  (n=2997)
Epoch 00025: Time=   5.0s, Loss=1.95e+01, Inv=1.95e+01, For=6.35e+00, Power=2.41e+00
  [eval] val_mse=5.505e+00  (n=2997)
Epoch 00026: Time=   5.0s, Loss=1.81e+01, Inv=1.81e+01, For=6.54e+00, Power=2.23e+00
  [eval] val_mse=5.302e+00  (n=2997)
Epoch 00027: Time=   5.1s, Loss=1.68e+01, Inv=1.68e+01, For=6.72e+00, Power=2.07e+00
  [eval] val_mse=5.123e+00  (n=2997)
Epoch 00028: Time=   5.1s, Loss=1.57e+01, Inv=1.57e+01, For=6.95e+00, Power=1.92e+00
  [eval] val_mse=4.963e+00  (n=2997)
Epoch 00029: Time=   5.1s, Loss=1.47e+01, Inv=1.47e+01, For=7.16e+00, Power=1.80e+00
  [eval] val_mse=4.822e+00  (n=2997)
Epoch 00030: Time=   5.2s, Loss=1.39e+01, Inv=1.39e+01, For=7.42e+00, Power=1.69e+00
  [eval] val_mse=4.700e+00  (n=2997)
Epoch 00031: Time=   5.2s, Loss=1.31e+01, Inv=1.31e+01, For=7.66e+00, Power=1.59e+00
  [eval] val_mse=4.590e+00  (n=2997)
Epoch 00032: Time=   5.2s, Loss=1.24e+01, Inv=1.24e+01, For=7.94e+00, Power=1.51e+00
  [eval] val_mse=4.495e+00  (n=2997)
Epoch 00033: Time=   5.3s, Loss=1.18e+01, Inv=1.18e+01, For=8.22e+00, Power=1.43e+00
  [eval] val_mse=4.404e+00  (n=2997)
Epoch 00034: Time=   5.3s, Loss=1.12e+01, Inv=1.12e+01, For=8.50e+00, Power=1.36e+00
  [eval] val_mse=4.335e+00  (n=2997)
Epoch 00035: Time=   5.3s, Loss=1.07e+01, Inv=1.07e+01, For=8.83e+00, Power=1.30e+00
  [eval] val_mse=4.257e+00  (n=2997)
Epoch 00036: Time=   5.4s, Loss=1.03e+01, Inv=1.03e+01, For=9.14e+00, Power=1.24e+00
  [eval] val_mse=4.192e+00  (n=2997)
Epoch 00037: Time=   5.4s, Loss=9.85e+00, Inv=9.85e+00, For=9.45e+00, Power=1.20e+00
  [eval] val_mse=4.128e+00  (n=2997)
Epoch 00038: Time=   5.4s, Loss=9.49e+00, Inv=9.49e+00, For=9.74e+00, Power=1.15e+00
  [eval] val_mse=4.076e+00  (n=2997)
Epoch 00039: Time=   5.5s, Loss=9.14e+00, Inv=9.14e+00, For=1.01e+01, Power=1.11e+00
  [eval] val_mse=4.008e+00  (n=2997)
Epoch 00040: Time=   5.5s, Loss=8.84e+00, Inv=8.84e+00, For=1.05e+01, Power=1.07e+00
  [eval] val_mse=3.954e+00  (n=2997)
Epoch 00041: Time=   5.5s, Loss=8.56e+00, Inv=8.56e+00, For=1.08e+01, Power=1.04e+00
  [eval] val_mse=3.904e+00  (n=2997)
Epoch 00042: Time=   5.6s, Loss=8.29e+00, Inv=8.29e+00, For=1.12e+01, Power=1.01e+00
  [eval] val_mse=3.851e+00  (n=2997)
Epoch 00043: Time=   5.6s, Loss=8.05e+00, Inv=8.05e+00, For=1.15e+01, Power=9.82e-01
  [eval] val_mse=3.797e+00  (n=2997)
Epoch 00044: Time=   5.6s, Loss=7.83e+00, Inv=7.83e+00, For=1.19e+01, Power=9.58e-01
  [eval] val_mse=3.756e+00  (n=2997)
Epoch 00045: Time=   5.7s, Loss=7.61e+00, Inv=7.61e+00, For=1.22e+01, Power=9.34e-01
  [eval] val_mse=3.701e+00  (n=2997)
Epoch 00046: Time=   5.7s, Loss=7.41e+00, Inv=7.41e+00, For=1.26e+01, Power=9.13e-01
  [eval] val_mse=3.650e+00  (n=2997)
Epoch 00047: Time=   5.7s, Loss=7.23e+00, Inv=7.23e+00, For=1.30e+01, Power=8.94e-01
  [eval] val_mse=3.604e+00  (n=2997)
Epoch 00048: Time=   5.8s, Loss=7.06e+00, Inv=7.06e+00, For=1.34e+01, Power=8.77e-01
  [eval] val_mse=3.564e+00  (n=2997)
Epoch 00049: Time=   5.8s, Loss=6.90e+00, Inv=6.90e+00, For=1.37e+01, Power=8.61e-01
  [eval] val_mse=3.519e+00  (n=2997)
Epoch 00050: Time=   5.8s, Loss=6.75e+00, Inv=6.75e+00, For=1.41e+01, Power=8.44e-01
  [eval] val_mse=3.470e+00  (n=2997)
Epoch 00051: Time=   5.9s, Loss=6.61e+00, Inv=6.61e+00, For=1.45e+01, Power=8.30e-01
  [eval] val_mse=3.439e+00  (n=2997)
Epoch 00052: Time=   5.9s, Loss=6.48e+00, Inv=6.48e+00, For=1.48e+01, Power=8.17e-01
  [eval] val_mse=3.404e+00  (n=2997)
Epoch 00053: Time=   5.9s, Loss=6.35e+00, Inv=6.35e+00, For=1.53e+01, Power=8.05e-01
  [eval] val_mse=3.357e+00  (n=2997)
Epoch 00054: Time=   6.0s, Loss=6.23e+00, Inv=6.23e+00, For=1.57e+01, Power=7.92e-01
  [eval] val_mse=3.320e+00  (n=2997)
Epoch 00055: Time=   6.0s, Loss=6.12e+00, Inv=6.12e+00, For=1.60e+01, Power=7.83e-01
  [eval] val_mse=3.294e+00  (n=2997)
Epoch 00056: Time=   6.0s, Loss=6.02e+00, Inv=6.02e+00, For=1.64e+01, Power=7.73e-01
  [eval] val_mse=3.255e+00  (n=2997)
Epoch 00057: Time=   6.1s, Loss=5.92e+00, Inv=5.92e+00, For=1.68e+01, Power=7.63e-01
  [eval] val_mse=3.212e+00  (n=2997)
Epoch 00058: Time=   6.1s, Loss=5.82e+00, Inv=5.82e+00, For=1.72e+01, Power=7.54e-01
  [eval] val_mse=3.192e+00  (n=2997)
Epoch 00059: Time=   6.1s, Loss=5.73e+00, Inv=5.73e+00, For=1.75e+01, Power=7.45e-01
  [eval] val_mse=3.154e+00  (n=2997)
Epoch 00060: Time=   6.2s, Loss=5.65e+00, Inv=5.65e+00, For=1.80e+01, Power=7.39e-01
  [eval] val_mse=3.130e+00  (n=2997)
Epoch 00061: Time=   6.2s, Loss=5.57e+00, Inv=5.57e+00, For=1.83e+01, Power=7.32e-01
  [eval] val_mse=3.110e+00  (n=2997)
Epoch 00062: Time=   6.2s, Loss=5.49e+00, Inv=5.49e+00, For=1.86e+01, Power=7.25e-01
  [eval] val_mse=3.075e+00  (n=2997)
Epoch 00063: Time=   6.3s, Loss=5.41e+00, Inv=5.41e+00, For=1.92e+01, Power=7.18e-01
  [eval] val_mse=3.046e+00  (n=2997)
Epoch 00064: Time=   6.3s, Loss=5.34e+00, Inv=5.34e+00, For=1.95e+01, Power=7.12e-01
  [eval] val_mse=3.024e+00  (n=2997)
Epoch 00065: Time=   6.3s, Loss=5.28e+00, Inv=5.28e+00, For=1.98e+01, Power=7.06e-01
  [eval] val_mse=3.001e+00  (n=2997)
Epoch 00066: Time=   6.4s, Loss=5.21e+00, Inv=5.21e+00, For=2.03e+01, Power=7.00e-01
  [eval] val_mse=2.982e+00  (n=2997)
Epoch 00067: Time=   6.4s, Loss=5.15e+00, Inv=5.15e+00, For=2.06e+01, Power=6.95e-01
  [eval] val_mse=2.951e+00  (n=2997)
Epoch 00068: Time=   6.4s, Loss=5.09e+00, Inv=5.09e+00, For=2.10e+01, Power=6.91e-01
  [eval] val_mse=2.937e+00  (n=2997)
Epoch 00069: Time=   6.5s, Loss=5.04e+00, Inv=5.04e+00, For=2.14e+01, Power=6.86e-01
  [eval] val_mse=2.912e+00  (n=2997)
Epoch 00070: Time=   6.5s, Loss=4.98e+00, Inv=4.98e+00, For=2.16e+01, Power=6.83e-01
  [eval] val_mse=2.902e+00  (n=2997)
Epoch 00071: Time=   6.5s, Loss=4.93e+00, Inv=4.93e+00, For=2.21e+01, Power=6.78e-01
  [eval] val_mse=2.870e+00  (n=2997)
Epoch 00072: Time=   6.6s, Loss=4.88e+00, Inv=4.88e+00, For=2.26e+01, Power=6.74e-01
  [eval] val_mse=2.854e+00  (n=2997)
Epoch 00073: Time=   6.6s, Loss=4.83e+00, Inv=4.83e+00, For=2.29e+01, Power=6.70e-01
  [eval] val_mse=2.841e+00  (n=2997)
Epoch 00074: Time=   6.6s, Loss=4.78e+00, Inv=4.78e+00, For=2.31e+01, Power=6.66e-01
  [eval] val_mse=2.823e+00  (n=2997)
Epoch 00075: Time=   6.6s, Loss=4.74e+00, Inv=4.74e+00, For=2.37e+01, Power=6.62e-01
  [eval] val_mse=2.811e+00  (n=2997)
Epoch 00076: Time=   6.7s, Loss=4.70e+00, Inv=4.70e+00, For=2.41e+01, Power=6.60e-01
  [eval] val_mse=2.791e+00  (n=2997)
Epoch 00077: Time=   6.7s, Loss=4.66e+00, Inv=4.66e+00, For=2.43e+01, Power=6.56e-01
  [eval] val_mse=2.773e+00  (n=2997)
Epoch 00078: Time=   6.7s, Loss=4.62e+00, Inv=4.62e+00, For=2.45e+01, Power=6.53e-01
  [eval] val_mse=2.761e+00  (n=2997)
Epoch 00079: Time=   6.8s, Loss=4.58e+00, Inv=4.58e+00, For=2.51e+01, Power=6.49e-01
  [eval] val_mse=2.748e+00  (n=2997)
Epoch 00080: Time=   6.8s, Loss=4.54e+00, Inv=4.54e+00, For=2.55e+01, Power=6.47e-01
  [eval] val_mse=2.729e+00  (n=2997)
Epoch 00081: Time=   6.8s, Loss=4.51e+00, Inv=4.51e+00, For=2.58e+01, Power=6.45e-01
  [eval] val_mse=2.719e+00  (n=2997)
Epoch 00082: Time=   6.9s, Loss=4.48e+00, Inv=4.48e+00, For=2.62e+01, Power=6.42e-01
  [eval] val_mse=2.710e+00  (n=2997)
Epoch 00083: Time=   6.9s, Loss=4.45e+00, Inv=4.45e+00, For=2.64e+01, Power=6.41e-01
  [eval] val_mse=2.693e+00  (n=2997)
Epoch 00084: Time=   6.9s, Loss=4.41e+00, Inv=4.41e+00, For=2.70e+01, Power=6.38e-01
  [eval] val_mse=2.687e+00  (n=2997)
Epoch 00085: Time=   7.0s, Loss=4.38e+00, Inv=4.38e+00, For=2.74e+01, Power=6.36e-01
  [eval] val_mse=2.668e+00  (n=2997)
Epoch 00086: Time=   7.0s, Loss=4.35e+00, Inv=4.35e+00, For=2.75e+01, Power=6.34e-01
  [eval] val_mse=2.662e+00  (n=2997)
Epoch 00087: Time=   7.0s, Loss=4.33e+00, Inv=4.33e+00, For=2.81e+01, Power=6.32e-01
  [eval] val_mse=2.653e+00  (n=2997)
Epoch 00088: Time=   7.1s, Loss=4.30e+00, Inv=4.30e+00, For=2.83e+01, Power=6.30e-01
  [eval] val_mse=2.639e+00  (n=2997)
Epoch 00089: Time=   7.1s, Loss=4.27e+00, Inv=4.27e+00, For=2.88e+01, Power=6.27e-01
  [eval] val_mse=2.628e+00  (n=2997)
Epoch 00090: Time=   7.1s, Loss=4.25e+00, Inv=4.25e+00, For=2.93e+01, Power=6.26e-01
  [eval] val_mse=2.624e+00  (n=2997)
Epoch 00091: Time=   7.1s, Loss=4.22e+00, Inv=4.22e+00, For=2.92e+01, Power=6.24e-01
  [eval] val_mse=2.599e+00  (n=2997)
Epoch 00092: Time=   7.2s, Loss=4.20e+00, Inv=4.20e+00, For=3.01e+01, Power=6.23e-01
  [eval] val_mse=2.597e+00  (n=2997)
Epoch 00093: Time=   7.2s, Loss=4.17e+00, Inv=4.17e+00, For=3.00e+01, Power=6.19e-01
  [eval] val_mse=2.604e+00  (n=2997)
Epoch 00094: Time=   7.2s, Loss=4.15e+00, Inv=4.15e+00, For=3.05e+01, Power=6.18e-01
  [eval] val_mse=2.592e+00  (n=2997)
Epoch 00095: Time=   7.3s, Loss=4.13e+00, Inv=4.13e+00, For=3.07e+01, Power=6.16e-01
  [eval] val_mse=2.580e+00  (n=2997)
Epoch 00096: Time=   7.3s, Loss=4.11e+00, Inv=4.11e+00, For=3.11e+01, Power=6.17e-01
  [eval] val_mse=2.566e+00  (n=2997)
Epoch 00097: Time=   7.3s, Loss=4.10e+00, Inv=4.10e+00, For=3.15e+01, Power=6.16e-01
  [eval] val_mse=2.561e+00  (n=2997)
Epoch 00098: Time=   7.4s, Loss=4.08e+00, Inv=4.08e+00, For=3.22e+01, Power=6.15e-01
  [eval] val_mse=2.570e+00  (n=2997)
Epoch 00099: Time=   7.4s, Loss=4.06e+00, Inv=4.06e+00, For=3.21e+01, Power=6.13e-01
  [eval] val_mse=2.549e+00  (n=2997)
Epoch 00100: Time=   7.4s, Loss=4.04e+00, Inv=4.04e+00, For=3.24e+01, Power=6.12e-01
  [eval] val_mse=2.538e+00  (n=2997)
Epoch 00101: Time=   7.5s, Loss=4.02e+00, Inv=4.02e+00, For=3.33e+01, Power=6.10e-01
  [eval] val_mse=2.543e+00  (n=2997)
Epoch 00102: Time=   7.5s, Loss=4.01e+00, Inv=4.01e+00, For=3.30e+01, Power=6.09e-01
  [eval] val_mse=2.522e+00  (n=2997)
Epoch 00103: Time=   7.5s, Loss=3.99e+00, Inv=3.99e+00, For=3.38e+01, Power=6.08e-01
  [eval] val_mse=2.526e+00  (n=2997)
Epoch 00104: Time=   7.6s, Loss=3.97e+00, Inv=3.97e+00, For=3.41e+01, Power=6.08e-01
  [eval] val_mse=2.545e+00  (n=2997)
Epoch 00105: Time=   7.6s, Loss=3.96e+00, Inv=3.96e+00, For=3.41e+01, Power=6.05e-01
  [eval] val_mse=2.508e+00  (n=2997)
Epoch 00106: Time=   7.6s, Loss=3.95e+00, Inv=3.95e+00, For=3.46e+01, Power=6.05e-01
  [eval] val_mse=2.517e+00  (n=2997)
Epoch 00107: Time=   7.7s, Loss=3.93e+00, Inv=3.93e+00, For=3.52e+01, Power=6.04e-01
  [eval] val_mse=2.505e+00  (n=2997)
Epoch 00108: Time=   7.7s, Loss=3.92e+00, Inv=3.92e+00, For=3.54e+01, Power=6.05e-01
  [eval] val_mse=2.519e+00  (n=2997)
Epoch 00109: Time=   7.7s, Loss=3.90e+00, Inv=3.90e+00, For=3.59e+01, Power=6.03e-01
  [eval] val_mse=2.503e+00  (n=2997)
Epoch 00110: Time=   7.7s, Loss=3.89e+00, Inv=3.89e+00, For=3.61e+01, Power=6.02e-01
  [eval] val_mse=2.500e+00  (n=2997)
Epoch 00111: Time=   7.8s, Loss=3.88e+00, Inv=3.88e+00, For=3.63e+01, Power=6.02e-01
  [eval] val_mse=2.478e+00  (n=2997)
Epoch 00112: Time=   7.8s, Loss=3.87e+00, Inv=3.87e+00, For=3.69e+01, Power=6.01e-01
  [eval] val_mse=2.499e+00  (n=2997)
Epoch 00113: Time=   7.8s, Loss=3.86e+00, Inv=3.86e+00, For=3.70e+01, Power=6.01e-01
  [eval] val_mse=2.472e+00  (n=2997)
Epoch 00114: Time=   7.9s, Loss=3.85e+00, Inv=3.85e+00, For=3.76e+01, Power=6.00e-01
  [eval] val_mse=2.483e+00  (n=2997)
Epoch 00115: Time=   7.9s, Loss=3.84e+00, Inv=3.84e+00, For=3.82e+01, Power=6.00e-01
  [eval] val_mse=2.487e+00  (n=2997)
Epoch 00116: Time=   7.9s, Loss=3.83e+00, Inv=3.83e+00, For=3.81e+01, Power=5.99e-01
  [eval] val_mse=2.485e+00  (n=2997)
Epoch 00117: Time=   8.0s, Loss=3.82e+00, Inv=3.82e+00, For=3.83e+01, Power=5.98e-01
  [eval] val_mse=2.481e+00  (n=2997)
Epoch 00118: Time=   8.0s, Loss=3.81e+00, Inv=3.81e+00, For=3.90e+01, Power=5.96e-01
  [eval] val_mse=2.463e+00  (n=2997)
Epoch 00119: Time=   8.0s, Loss=3.80e+00, Inv=3.80e+00, For=3.93e+01, Power=5.97e-01
  [eval] val_mse=2.462e+00  (n=2997)
Epoch 00120: Time=   8.1s, Loss=3.79e+00, Inv=3.79e+00, For=3.96e+01, Power=5.96e-01
  [eval] val_mse=2.458e+00  (n=2997)
Epoch 00121: Time=   8.1s, Loss=3.78e+00, Inv=3.78e+00, For=3.96e+01, Power=5.96e-01
  [eval] val_mse=2.442e+00  (n=2997)
Epoch 00122: Time=   8.1s, Loss=3.77e+00, Inv=3.77e+00, For=4.05e+01, Power=5.95e-01
  [eval] val_mse=2.444e+00  (n=2997)
Epoch 00123: Time=   8.1s, Loss=3.77e+00, Inv=3.77e+00, For=4.12e+01, Power=5.96e-01
  [eval] val_mse=2.452e+00  (n=2997)
Epoch 00124: Time=   8.2s, Loss=3.76e+00, Inv=3.76e+00, For=4.08e+01, Power=5.95e-01
  [eval] val_mse=2.438e+00  (n=2997)
Epoch 00125: Time=   8.2s, Loss=3.75e+00, Inv=3.75e+00, For=4.13e+01, Power=5.95e-01
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00126: Time=   8.2s, Loss=3.74e+00, Inv=3.74e+00, For=4.15e+01, Power=5.94e-01
  [eval] val_mse=2.442e+00  (n=2997)
Epoch 00127: Time=   8.3s, Loss=3.73e+00, Inv=3.73e+00, For=4.24e+01, Power=5.95e-01
  [eval] val_mse=2.459e+00  (n=2997)
Epoch 00128: Time=   8.3s, Loss=3.72e+00, Inv=3.72e+00, For=4.26e+01, Power=5.93e-01
  [eval] val_mse=2.439e+00  (n=2997)
Epoch 00129: Time=   8.3s, Loss=3.72e+00, Inv=3.72e+00, For=4.23e+01, Power=5.92e-01
  [eval] val_mse=2.432e+00  (n=2997)
Epoch 00130: Time=   8.4s, Loss=3.71e+00, Inv=3.71e+00, For=4.33e+01, Power=5.94e-01
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00131: Time=   8.4s, Loss=3.70e+00, Inv=3.70e+00, For=4.33e+01, Power=5.93e-01
  [eval] val_mse=2.447e+00  (n=2997)
Epoch 00132: Time=   8.4s, Loss=3.70e+00, Inv=3.70e+00, For=4.39e+01, Power=5.92e-01
  [eval] val_mse=2.431e+00  (n=2997)
Epoch 00133: Time=   8.5s, Loss=3.69e+00, Inv=3.69e+00, For=4.42e+01, Power=5.92e-01
  [eval] val_mse=2.427e+00  (n=2997)
Epoch 00134: Time=   8.5s, Loss=3.68e+00, Inv=3.68e+00, For=4.44e+01, Power=5.91e-01
  [eval] val_mse=2.417e+00  (n=2997)
Epoch 00135: Time=   8.5s, Loss=3.68e+00, Inv=3.68e+00, For=4.48e+01, Power=5.92e-01
  [eval] val_mse=2.413e+00  (n=2997)
Epoch 00136: Time=   8.5s, Loss=3.67e+00, Inv=3.67e+00, For=4.50e+01, Power=5.91e-01
  [eval] val_mse=2.401e+00  (n=2997)
Epoch 00137: Time=   8.6s, Loss=3.67e+00, Inv=3.67e+00, For=4.53e+01, Power=5.90e-01
  [eval] val_mse=2.394e+00  (n=2997)
Epoch 00138: Time=   8.6s, Loss=3.66e+00, Inv=3.66e+00, For=4.59e+01, Power=5.90e-01
  [eval] val_mse=2.430e+00  (n=2997)
Epoch 00139: Time=   8.6s, Loss=3.65e+00, Inv=3.65e+00, For=4.62e+01, Power=5.89e-01
  [eval] val_mse=2.411e+00  (n=2997)
Epoch 00140: Time=   8.7s, Loss=3.65e+00, Inv=3.65e+00, For=4.63e+01, Power=5.90e-01
  [eval] val_mse=2.407e+00  (n=2997)
Epoch 00141: Time=   8.7s, Loss=3.64e+00, Inv=3.64e+00, For=4.70e+01, Power=5.90e-01
  [eval] val_mse=2.409e+00  (n=2997)
Epoch 00142: Time=   8.7s, Loss=3.64e+00, Inv=3.64e+00, For=4.72e+01, Power=5.90e-01
  [eval] val_mse=2.417e+00  (n=2997)
Epoch 00143: Time=   8.8s, Loss=3.63e+00, Inv=3.63e+00, For=4.72e+01, Power=5.88e-01
  [eval] val_mse=2.391e+00  (n=2997)
Epoch 00144: Time=   8.8s, Loss=3.62e+00, Inv=3.62e+00, For=4.77e+01, Power=5.88e-01
  [eval] val_mse=2.397e+00  (n=2997)
Epoch 00145: Time=   8.8s, Loss=3.62e+00, Inv=3.62e+00, For=4.82e+01, Power=5.89e-01
  [eval] val_mse=2.410e+00  (n=2997)
Epoch 00146: Time=   8.9s, Loss=3.61e+00, Inv=3.61e+00, For=4.85e+01, Power=5.88e-01
  [eval] val_mse=2.399e+00  (n=2997)
Epoch 00147: Time=   8.9s, Loss=3.61e+00, Inv=3.61e+00, For=4.87e+01, Power=5.87e-01
  [eval] val_mse=2.395e+00  (n=2997)
Epoch 00148: Time=   8.9s, Loss=3.61e+00, Inv=3.61e+00, For=4.88e+01, Power=5.88e-01
  [eval] val_mse=2.396e+00  (n=2997)
Epoch 00149: Time=   8.9s, Loss=3.60e+00, Inv=3.60e+00, For=4.94e+01, Power=5.88e-01
  [eval] val_mse=2.381e+00  (n=2997)
Epoch 00150: Time=   9.0s, Loss=3.60e+00, Inv=3.60e+00, For=4.95e+01, Power=5.87e-01
  [eval] val_mse=2.391e+00  (n=2997)
Epoch 00151: Time=   9.0s, Loss=3.59e+00, Inv=3.59e+00, For=4.97e+01, Power=5.88e-01
  [eval] val_mse=2.374e+00  (n=2997)
Epoch 00152: Time=   9.0s, Loss=3.59e+00, Inv=3.59e+00, For=5.04e+01, Power=5.88e-01
  [eval] val_mse=2.380e+00  (n=2997)
Epoch 00153: Time=   9.1s, Loss=3.58e+00, Inv=3.58e+00, For=5.08e+01, Power=5.87e-01
  [eval] val_mse=2.384e+00  (n=2997)
Epoch 00154: Time=   9.1s, Loss=3.58e+00, Inv=3.58e+00, For=5.06e+01, Power=5.87e-01
  [eval] val_mse=2.374e+00  (n=2997)
Epoch 00155: Time=   9.1s, Loss=3.58e+00, Inv=3.58e+00, For=5.15e+01, Power=5.88e-01
  [eval] val_mse=2.382e+00  (n=2997)
Epoch 00156: Time=   9.2s, Loss=3.57e+00, Inv=3.57e+00, For=5.14e+01, Power=5.86e-01
  [eval] val_mse=2.376e+00  (n=2997)
Epoch 00157: Time=   9.2s, Loss=3.57e+00, Inv=3.57e+00, For=5.17e+01, Power=5.87e-01
  [eval] val_mse=2.381e+00  (n=2997)
Epoch 00158: Time=   9.2s, Loss=3.56e+00, Inv=3.56e+00, For=5.24e+01, Power=5.86e-01
  [eval] val_mse=2.391e+00  (n=2997)
Epoch 00159: Time=   9.3s, Loss=3.56e+00, Inv=3.56e+00, For=5.19e+01, Power=5.86e-01
  [eval] val_mse=2.356e+00  (n=2997)
Epoch 00160: Time=   9.3s, Loss=3.55e+00, Inv=3.55e+00, For=5.26e+01, Power=5.86e-01
  [eval] val_mse=2.341e+00  (n=2997)
Epoch 00161: Time=   9.3s, Loss=3.55e+00, Inv=3.55e+00, For=5.29e+01, Power=5.86e-01
  [eval] val_mse=2.371e+00  (n=2997)
Epoch 00162: Time=   9.4s, Loss=3.55e+00, Inv=3.55e+00, For=5.29e+01, Power=5.85e-01
  [eval] val_mse=2.362e+00  (n=2997)
Epoch 00163: Time=   9.4s, Loss=3.54e+00, Inv=3.54e+00, For=5.37e+01, Power=5.86e-01
  [eval] val_mse=2.361e+00  (n=2997)
Epoch 00164: Time=   9.4s, Loss=3.53e+00, Inv=3.53e+00, For=5.38e+01, Power=5.83e-01
  [eval] val_mse=2.348e+00  (n=2997)
Epoch 00165: Time=   9.5s, Loss=3.53e+00, Inv=3.53e+00, For=5.38e+01, Power=5.86e-01
  [eval] val_mse=2.350e+00  (n=2997)
Epoch 00166: Time=   9.5s, Loss=3.53e+00, Inv=3.53e+00, For=5.43e+01, Power=5.86e-01
  [eval] val_mse=2.338e+00  (n=2997)
Epoch 00167: Time=   9.5s, Loss=3.52e+00, Inv=3.52e+00, For=5.44e+01, Power=5.83e-01
  [eval] val_mse=2.363e+00  (n=2997)
Epoch 00168: Time=   9.6s, Loss=3.52e+00, Inv=3.52e+00, For=5.48e+01, Power=5.85e-01
  [eval] val_mse=2.334e+00  (n=2997)
Epoch 00169: Time=   9.6s, Loss=3.52e+00, Inv=3.52e+00, For=5.48e+01, Power=5.85e-01
  [eval] val_mse=2.335e+00  (n=2997)
Epoch 00170: Time=   9.6s, Loss=3.51e+00, Inv=3.51e+00, For=5.55e+01, Power=5.84e-01
  [eval] val_mse=2.350e+00  (n=2997)
Epoch 00171: Time=   9.7s, Loss=3.51e+00, Inv=3.51e+00, For=5.52e+01, Power=5.85e-01
  [eval] val_mse=2.330e+00  (n=2997)
Epoch 00172: Time=   9.7s, Loss=3.51e+00, Inv=3.51e+00, For=5.55e+01, Power=5.84e-01
  [eval] val_mse=2.325e+00  (n=2997)
Epoch 00173: Time=   9.7s, Loss=3.51e+00, Inv=3.51e+00, For=5.64e+01, Power=5.84e-01
  [eval] val_mse=2.331e+00  (n=2997)
Epoch 00174: Time=   9.8s, Loss=3.51e+00, Inv=3.51e+00, For=5.62e+01, Power=5.84e-01
  [eval] val_mse=2.312e+00  (n=2997)
Epoch 00175: Time=   9.8s, Loss=3.50e+00, Inv=3.50e+00, For=5.64e+01, Power=5.84e-01
  [eval] val_mse=2.326e+00  (n=2997)
Epoch 00176: Time=   9.8s, Loss=3.50e+00, Inv=3.50e+00, For=5.69e+01, Power=5.84e-01
  [eval] val_mse=2.309e+00  (n=2997)
Epoch 00177: Time=   9.9s, Loss=3.49e+00, Inv=3.49e+00, For=5.69e+01, Power=5.83e-01
  [eval] val_mse=2.327e+00  (n=2997)
Epoch 00178: Time=   9.9s, Loss=3.49e+00, Inv=3.49e+00, For=5.73e+01, Power=5.83e-01
  [eval] val_mse=2.322e+00  (n=2997)
Epoch 00179: Time=   9.9s, Loss=3.49e+00, Inv=3.49e+00, For=5.73e+01, Power=5.84e-01
  [eval] val_mse=2.327e+00  (n=2997)
Epoch 00180: Time=  10.0s, Loss=3.49e+00, Inv=3.49e+00, For=5.77e+01, Power=5.83e-01
  [eval] val_mse=2.311e+00  (n=2997)
Epoch 00181: Time=  10.0s, Loss=3.48e+00, Inv=3.48e+00, For=5.77e+01, Power=5.83e-01
  [eval] val_mse=2.314e+00  (n=2997)
Epoch 00182: Time=  10.0s, Loss=3.48e+00, Inv=3.48e+00, For=5.85e+01, Power=5.82e-01
  [eval] val_mse=2.333e+00  (n=2997)
Epoch 00183: Time=  10.0s, Loss=3.48e+00, Inv=3.48e+00, For=5.81e+01, Power=5.83e-01
  [eval] val_mse=2.310e+00  (n=2997)
Epoch 00184: Time=  10.1s, Loss=3.47e+00, Inv=3.47e+00, For=5.86e+01, Power=5.83e-01
  [eval] val_mse=2.298e+00  (n=2997)
Epoch 00185: Time=  10.1s, Loss=3.47e+00, Inv=3.47e+00, For=5.86e+01, Power=5.83e-01
  [eval] val_mse=2.317e+00  (n=2997)
Epoch 00186: Time=  10.1s, Loss=3.47e+00, Inv=3.47e+00, For=5.90e+01, Power=5.81e-01
  [eval] val_mse=2.278e+00  (n=2997)
Epoch 00187: Time=  10.2s, Loss=3.47e+00, Inv=3.47e+00, For=5.92e+01, Power=5.83e-01
  [eval] val_mse=2.311e+00  (n=2997)
Epoch 00188: Time=  10.2s, Loss=3.46e+00, Inv=3.46e+00, For=5.95e+01, Power=5.82e-01
  [eval] val_mse=2.309e+00  (n=2997)
Epoch 00189: Time=  10.2s, Loss=3.46e+00, Inv=3.46e+00, For=5.94e+01, Power=5.82e-01
  [eval] val_mse=2.298e+00  (n=2997)
Epoch 00190: Time=  10.3s, Loss=3.46e+00, Inv=3.46e+00, For=6.00e+01, Power=5.82e-01
  [eval] val_mse=2.299e+00  (n=2997)
Epoch 00191: Time=  10.3s, Loss=3.46e+00, Inv=3.46e+00, For=5.99e+01, Power=5.83e-01
  [eval] val_mse=2.315e+00  (n=2997)
Epoch 00192: Time=  10.3s, Loss=3.46e+00, Inv=3.46e+00, For=6.04e+01, Power=5.83e-01
  [eval] val_mse=2.297e+00  (n=2997)
Epoch 00193: Time=  10.4s, Loss=3.45e+00, Inv=3.45e+00, For=6.04e+01, Power=5.83e-01
  [eval] val_mse=2.302e+00  (n=2997)
Epoch 00194: Time=  10.4s, Loss=3.45e+00, Inv=3.45e+00, For=6.04e+01, Power=5.82e-01
  [eval] val_mse=2.281e+00  (n=2997)
Epoch 00195: Time=  10.4s, Loss=3.45e+00, Inv=3.45e+00, For=6.08e+01, Power=5.83e-01
  [eval] val_mse=2.300e+00  (n=2997)
Epoch 00196: Time=  10.4s, Loss=3.45e+00, Inv=3.45e+00, For=6.10e+01, Power=5.83e-01
  [eval] val_mse=2.290e+00  (n=2997)
  [early_stop] stop at epoch=196 (best_epoch=186, best_val_mse=2.278e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 6.161e-01
Torque MSE  = 1.199e-01
Torque RMSE = 3.462e-01
Per-joint MSE : 1.522e-01 3.394e-01 1.070e-01 3.860e-02 4.159e-02 4.058e-02
Per-joint RMSE: 3.901e-01 5.826e-01 3.270e-01 1.965e-01 2.039e-01 2.014e-01
Comp Time per Sample = 2.210e-04s / 4524.9Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-ogijqspw because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7e1949c5e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:47:09.423006: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:47:11.062359: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   2.9s, Loss=1.57e+04, Inv=1.57e+04, For=5.86e+00, Power=1.23e+03
  [eval] val_mse=2.319e+02  (n=2997)
Epoch 00002: Time=   4.3s, Loss=3.78e+03, Inv=3.78e+03, For=5.75e+00, Power=3.70e+02
  [eval] val_mse=1.256e+02  (n=2997)
Epoch 00003: Time=   4.3s, Loss=1.67e+03, Inv=1.67e+03, For=5.66e+00, Power=2.05e+02
  [eval] val_mse=7.862e+01  (n=2997)
Epoch 00004: Time=   4.3s, Loss=9.40e+02, Inv=9.40e+02, For=5.58e+00, Power=1.27e+02
  [eval] val_mse=5.268e+01  (n=2997)
Epoch 00005: Time=   4.3s, Loss=5.87e+02, Inv=5.87e+02, For=5.49e+00, Power=8.23e+01
  [eval] val_mse=3.745e+01  (n=2997)
Epoch 00006: Time=   4.4s, Loss=3.95e+02, Inv=3.95e+02, For=5.40e+00, Power=5.60e+01
  [eval] val_mse=2.804e+01  (n=2997)
Epoch 00007: Time=   4.4s, Loss=2.82e+02, Inv=2.82e+02, For=5.32e+00, Power=3.99e+01
  [eval] val_mse=2.187e+01  (n=2997)
Epoch 00008: Time=   4.4s, Loss=2.10e+02, Inv=2.10e+02, For=5.24e+00, Power=2.95e+01
  [eval] val_mse=1.785e+01  (n=2997)
Epoch 00009: Time=   4.5s, Loss=1.63e+02, Inv=1.63e+02, For=5.17e+00, Power=2.24e+01
  [eval] val_mse=1.498e+01  (n=2997)
Epoch 00010: Time=   4.5s, Loss=1.29e+02, Inv=1.29e+02, For=5.11e+00, Power=1.75e+01
  [eval] val_mse=1.291e+01  (n=2997)
Epoch 00011: Time=   4.5s, Loss=1.05e+02, Inv=1.05e+02, For=5.04e+00, Power=1.40e+01
  [eval] val_mse=1.137e+01  (n=2997)
Epoch 00012: Time=   4.5s, Loss=8.73e+01, Inv=8.73e+01, For=5.00e+00, Power=1.14e+01
  [eval] val_mse=1.016e+01  (n=2997)
Epoch 00013: Time=   4.6s, Loss=7.36e+01, Inv=7.36e+01, For=4.95e+00, Power=9.43e+00
  [eval] val_mse=9.211e+00  (n=2997)
Epoch 00014: Time=   4.6s, Loss=6.30e+01, Inv=6.30e+01, For=4.92e+00, Power=7.91e+00
  [eval] val_mse=8.457e+00  (n=2997)
Epoch 00015: Time=   4.6s, Loss=5.46e+01, Inv=5.46e+01, For=4.90e+00, Power=6.75e+00
  [eval] val_mse=7.815e+00  (n=2997)
Epoch 00016: Time=   4.7s, Loss=4.77e+01, Inv=4.77e+01, For=4.89e+00, Power=5.80e+00
  [eval] val_mse=7.275e+00  (n=2997)
Epoch 00017: Time=   4.7s, Loss=4.21e+01, Inv=4.21e+01, For=4.88e+00, Power=5.03e+00
  [eval] val_mse=6.820e+00  (n=2997)
Epoch 00018: Time=   4.7s, Loss=3.74e+01, Inv=3.74e+01, For=4.87e+00, Power=4.42e+00
  [eval] val_mse=6.421e+00  (n=2997)
Epoch 00019: Time=   4.8s, Loss=3.35e+01, Inv=3.35e+01, For=4.88e+00, Power=3.91e+00
  [eval] val_mse=6.075e+00  (n=2997)
Epoch 00020: Time=   4.8s, Loss=3.02e+01, Inv=3.02e+01, For=4.89e+00, Power=3.49e+00
  [eval] val_mse=5.769e+00  (n=2997)
Epoch 00021: Time=   4.8s, Loss=2.74e+01, Inv=2.74e+01, For=4.91e+00, Power=3.13e+00
  [eval] val_mse=5.490e+00  (n=2997)
Epoch 00022: Time=   4.9s, Loss=2.50e+01, Inv=2.50e+01, For=4.94e+00, Power=2.83e+00
  [eval] val_mse=5.254e+00  (n=2997)
Epoch 00023: Time=   4.9s, Loss=2.29e+01, Inv=2.29e+01, For=4.97e+00, Power=2.57e+00
  [eval] val_mse=5.049e+00  (n=2997)
Epoch 00024: Time=   4.9s, Loss=2.10e+01, Inv=2.10e+01, For=5.01e+00, Power=2.35e+00
  [eval] val_mse=4.860e+00  (n=2997)
Epoch 00025: Time=   5.0s, Loss=1.95e+01, Inv=1.95e+01, For=5.07e+00, Power=2.16e+00
  [eval] val_mse=4.691e+00  (n=2997)
Epoch 00026: Time=   5.0s, Loss=1.81e+01, Inv=1.81e+01, For=5.14e+00, Power=1.99e+00
  [eval] val_mse=4.547e+00  (n=2997)
Epoch 00027: Time=   5.0s, Loss=1.69e+01, Inv=1.69e+01, For=5.22e+00, Power=1.85e+00
  [eval] val_mse=4.422e+00  (n=2997)
Epoch 00028: Time=   5.0s, Loss=1.58e+01, Inv=1.58e+01, For=5.31e+00, Power=1.72e+00
  [eval] val_mse=4.319e+00  (n=2997)
Epoch 00029: Time=   5.1s, Loss=1.48e+01, Inv=1.48e+01, For=5.41e+00, Power=1.61e+00
  [eval] val_mse=4.223e+00  (n=2997)
Epoch 00030: Time=   5.1s, Loss=1.40e+01, Inv=1.40e+01, For=5.53e+00, Power=1.51e+00
  [eval] val_mse=4.138e+00  (n=2997)
Epoch 00031: Time=   5.1s, Loss=1.33e+01, Inv=1.33e+01, For=5.66e+00, Power=1.43e+00
  [eval] val_mse=4.054e+00  (n=2997)
Epoch 00032: Time=   5.2s, Loss=1.26e+01, Inv=1.26e+01, For=5.81e+00, Power=1.35e+00
  [eval] val_mse=3.984e+00  (n=2997)
Epoch 00033: Time=   5.2s, Loss=1.20e+01, Inv=1.20e+01, For=5.97e+00, Power=1.29e+00
  [eval] val_mse=3.912e+00  (n=2997)
Epoch 00034: Time=   5.2s, Loss=1.15e+01, Inv=1.15e+01, For=6.15e+00, Power=1.23e+00
  [eval] val_mse=3.851e+00  (n=2997)
Epoch 00035: Time=   5.3s, Loss=1.10e+01, Inv=1.10e+01, For=6.35e+00, Power=1.17e+00
  [eval] val_mse=3.785e+00  (n=2997)
Epoch 00036: Time=   5.3s, Loss=1.05e+01, Inv=1.05e+01, For=6.56e+00, Power=1.13e+00
  [eval] val_mse=3.727e+00  (n=2997)
Epoch 00037: Time=   5.3s, Loss=1.01e+01, Inv=1.01e+01, For=6.76e+00, Power=1.09e+00
  [eval] val_mse=3.658e+00  (n=2997)
Epoch 00038: Time=   5.4s, Loss=9.77e+00, Inv=9.77e+00, For=6.99e+00, Power=1.05e+00
  [eval] val_mse=3.605e+00  (n=2997)
Epoch 00039: Time=   5.4s, Loss=9.44e+00, Inv=9.44e+00, For=7.23e+00, Power=1.01e+00
  [eval] val_mse=3.556e+00  (n=2997)
Epoch 00040: Time=   5.4s, Loss=9.12e+00, Inv=9.12e+00, For=7.48e+00, Power=9.80e-01
  [eval] val_mse=3.494e+00  (n=2997)
Epoch 00041: Time=   5.4s, Loss=8.83e+00, Inv=8.83e+00, For=7.72e+00, Power=9.52e-01
  [eval] val_mse=3.448e+00  (n=2997)
Epoch 00042: Time=   5.5s, Loss=8.56e+00, Inv=8.56e+00, For=7.99e+00, Power=9.26e-01
  [eval] val_mse=3.389e+00  (n=2997)
Epoch 00043: Time=   5.5s, Loss=8.31e+00, Inv=8.31e+00, For=8.28e+00, Power=9.03e-01
  [eval] val_mse=3.346e+00  (n=2997)
Epoch 00044: Time=   5.5s, Loss=8.09e+00, Inv=8.09e+00, For=8.58e+00, Power=8.82e-01
  [eval] val_mse=3.295e+00  (n=2997)
Epoch 00045: Time=   5.6s, Loss=7.87e+00, Inv=7.87e+00, For=8.85e+00, Power=8.63e-01
  [eval] val_mse=3.244e+00  (n=2997)
Epoch 00046: Time=   5.6s, Loss=7.67e+00, Inv=7.67e+00, For=9.16e+00, Power=8.46e-01
  [eval] val_mse=3.201e+00  (n=2997)
Epoch 00047: Time=   5.6s, Loss=7.48e+00, Inv=7.48e+00, For=9.46e+00, Power=8.29e-01
  [eval] val_mse=3.161e+00  (n=2997)
Epoch 00048: Time=   5.7s, Loss=7.31e+00, Inv=7.31e+00, For=9.76e+00, Power=8.14e-01
  [eval] val_mse=3.124e+00  (n=2997)
Epoch 00049: Time=   5.7s, Loss=7.14e+00, Inv=7.14e+00, For=1.01e+01, Power=8.01e-01
  [eval] val_mse=3.087e+00  (n=2997)
Epoch 00050: Time=   5.7s, Loss=6.98e+00, Inv=6.98e+00, For=1.04e+01, Power=7.88e-01
  [eval] val_mse=3.043e+00  (n=2997)
Epoch 00051: Time=   5.8s, Loss=6.84e+00, Inv=6.84e+00, For=1.07e+01, Power=7.77e-01
  [eval] val_mse=3.010e+00  (n=2997)
Epoch 00052: Time=   5.8s, Loss=6.70e+00, Inv=6.70e+00, For=1.11e+01, Power=7.65e-01
  [eval] val_mse=2.973e+00  (n=2997)
Epoch 00053: Time=   5.8s, Loss=6.57e+00, Inv=6.57e+00, For=1.14e+01, Power=7.55e-01
  [eval] val_mse=2.943e+00  (n=2997)
Epoch 00054: Time=   5.9s, Loss=6.44e+00, Inv=6.44e+00, For=1.18e+01, Power=7.46e-01
  [eval] val_mse=2.907e+00  (n=2997)
Epoch 00055: Time=   5.9s, Loss=6.33e+00, Inv=6.33e+00, For=1.21e+01, Power=7.37e-01
  [eval] val_mse=2.884e+00  (n=2997)
Epoch 00056: Time=   5.9s, Loss=6.21e+00, Inv=6.21e+00, For=1.24e+01, Power=7.29e-01
  [eval] val_mse=2.855e+00  (n=2997)
Epoch 00057: Time=   6.0s, Loss=6.11e+00, Inv=6.11e+00, For=1.27e+01, Power=7.21e-01
  [eval] val_mse=2.818e+00  (n=2997)
Epoch 00058: Time=   6.0s, Loss=6.00e+00, Inv=6.00e+00, For=1.32e+01, Power=7.14e-01
  [eval] val_mse=2.799e+00  (n=2997)
Epoch 00059: Time=   6.0s, Loss=5.92e+00, Inv=5.92e+00, For=1.35e+01, Power=7.08e-01
  [eval] val_mse=2.779e+00  (n=2997)
Epoch 00060: Time=   6.1s, Loss=5.82e+00, Inv=5.82e+00, For=1.39e+01, Power=7.01e-01
  [eval] val_mse=2.749e+00  (n=2997)
Epoch 00061: Time=   6.1s, Loss=5.74e+00, Inv=5.74e+00, For=1.42e+01, Power=6.95e-01
  [eval] val_mse=2.735e+00  (n=2997)
Epoch 00062: Time=   6.1s, Loss=5.66e+00, Inv=5.66e+00, For=1.46e+01, Power=6.90e-01
  [eval] val_mse=2.717e+00  (n=2997)
Epoch 00063: Time=   6.2s, Loss=5.58e+00, Inv=5.58e+00, For=1.50e+01, Power=6.86e-01
  [eval] val_mse=2.691e+00  (n=2997)
Epoch 00064: Time=   6.2s, Loss=5.50e+00, Inv=5.50e+00, For=1.53e+01, Power=6.80e-01
  [eval] val_mse=2.674e+00  (n=2997)
Epoch 00065: Time=   6.2s, Loss=5.43e+00, Inv=5.43e+00, For=1.57e+01, Power=6.77e-01
  [eval] val_mse=2.661e+00  (n=2997)
Epoch 00066: Time=   6.3s, Loss=5.36e+00, Inv=5.36e+00, For=1.60e+01, Power=6.72e-01
  [eval] val_mse=2.644e+00  (n=2997)
Epoch 00067: Time=   6.3s, Loss=5.30e+00, Inv=5.30e+00, For=1.63e+01, Power=6.68e-01
  [eval] val_mse=2.628e+00  (n=2997)
Epoch 00068: Time=   6.3s, Loss=5.23e+00, Inv=5.23e+00, For=1.67e+01, Power=6.63e-01
  [eval] val_mse=2.615e+00  (n=2997)
Epoch 00069: Time=   6.4s, Loss=5.17e+00, Inv=5.17e+00, For=1.71e+01, Power=6.60e-01
  [eval] val_mse=2.589e+00  (n=2997)
Epoch 00070: Time=   6.4s, Loss=5.12e+00, Inv=5.12e+00, For=1.75e+01, Power=6.57e-01
  [eval] val_mse=2.592e+00  (n=2997)
Epoch 00071: Time=   6.4s, Loss=5.06e+00, Inv=5.06e+00, For=1.79e+01, Power=6.54e-01
  [eval] val_mse=2.571e+00  (n=2997)
Epoch 00072: Time=   6.5s, Loss=5.01e+00, Inv=5.01e+00, For=1.82e+01, Power=6.50e-01
  [eval] val_mse=2.559e+00  (n=2997)
Epoch 00073: Time=   6.5s, Loss=4.96e+00, Inv=4.96e+00, For=1.85e+01, Power=6.48e-01
  [eval] val_mse=2.537e+00  (n=2997)
Epoch 00074: Time=   6.5s, Loss=4.91e+00, Inv=4.91e+00, For=1.89e+01, Power=6.44e-01
  [eval] val_mse=2.540e+00  (n=2997)
Epoch 00075: Time=   6.5s, Loss=4.86e+00, Inv=4.86e+00, For=1.94e+01, Power=6.42e-01
  [eval] val_mse=2.529e+00  (n=2997)
Epoch 00076: Time=   6.6s, Loss=4.81e+00, Inv=4.81e+00, For=1.96e+01, Power=6.39e-01
  [eval] val_mse=2.510e+00  (n=2997)
Epoch 00077: Time=   6.6s, Loss=4.77e+00, Inv=4.77e+00, For=2.00e+01, Power=6.38e-01
  [eval] val_mse=2.514e+00  (n=2997)
Epoch 00078: Time=   6.6s, Loss=4.73e+00, Inv=4.73e+00, For=2.04e+01, Power=6.35e-01
  [eval] val_mse=2.500e+00  (n=2997)
Epoch 00079: Time=   6.7s, Loss=4.69e+00, Inv=4.69e+00, For=2.08e+01, Power=6.32e-01
  [eval] val_mse=2.494e+00  (n=2997)
Epoch 00080: Time=   6.7s, Loss=4.65e+00, Inv=4.65e+00, For=2.10e+01, Power=6.31e-01
  [eval] val_mse=2.474e+00  (n=2997)
Epoch 00081: Time=   6.7s, Loss=4.62e+00, Inv=4.62e+00, For=2.14e+01, Power=6.29e-01
  [eval] val_mse=2.473e+00  (n=2997)
Epoch 00082: Time=   6.8s, Loss=4.58e+00, Inv=4.58e+00, For=2.18e+01, Power=6.27e-01
  [eval] val_mse=2.467e+00  (n=2997)
Epoch 00083: Time=   6.8s, Loss=4.54e+00, Inv=4.54e+00, For=2.22e+01, Power=6.25e-01
  [eval] val_mse=2.465e+00  (n=2997)
Epoch 00084: Time=   6.8s, Loss=4.51e+00, Inv=4.51e+00, For=2.25e+01, Power=6.23e-01
  [eval] val_mse=2.465e+00  (n=2997)
Epoch 00085: Time=   6.8s, Loss=4.48e+00, Inv=4.48e+00, For=2.29e+01, Power=6.22e-01
  [eval] val_mse=2.456e+00  (n=2997)
Epoch 00086: Time=   6.9s, Loss=4.44e+00, Inv=4.44e+00, For=2.32e+01, Power=6.20e-01
  [eval] val_mse=2.462e+00  (n=2997)
Epoch 00087: Time=   6.9s, Loss=4.42e+00, Inv=4.42e+00, For=2.36e+01, Power=6.19e-01
  [eval] val_mse=2.466e+00  (n=2997)
Epoch 00088: Time=   6.9s, Loss=4.39e+00, Inv=4.39e+00, For=2.39e+01, Power=6.17e-01
  [eval] val_mse=2.437e+00  (n=2997)
Epoch 00089: Time=   7.0s, Loss=4.36e+00, Inv=4.36e+00, For=2.43e+01, Power=6.16e-01
  [eval] val_mse=2.458e+00  (n=2997)
Epoch 00090: Time=   7.0s, Loss=4.33e+00, Inv=4.33e+00, For=2.46e+01, Power=6.15e-01
  [eval] val_mse=2.440e+00  (n=2997)
Epoch 00091: Time=   7.0s, Loss=4.31e+00, Inv=4.31e+00, For=2.50e+01, Power=6.14e-01
  [eval] val_mse=2.449e+00  (n=2997)
Epoch 00092: Time=   7.1s, Loss=4.28e+00, Inv=4.28e+00, For=2.53e+01, Power=6.13e-01
  [eval] val_mse=2.446e+00  (n=2997)
Epoch 00093: Time=   7.1s, Loss=4.25e+00, Inv=4.25e+00, For=2.58e+01, Power=6.11e-01
  [eval] val_mse=2.447e+00  (n=2997)
Epoch 00094: Time=   7.1s, Loss=4.23e+00, Inv=4.23e+00, For=2.61e+01, Power=6.11e-01
  [eval] val_mse=2.438e+00  (n=2997)
Epoch 00095: Time=   7.2s, Loss=4.21e+00, Inv=4.21e+00, For=2.64e+01, Power=6.09e-01
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00096: Time=   7.2s, Loss=4.19e+00, Inv=4.19e+00, For=2.67e+01, Power=6.09e-01
  [eval] val_mse=2.451e+00  (n=2997)
Epoch 00097: Time=   7.2s, Loss=4.17e+00, Inv=4.17e+00, For=2.71e+01, Power=6.07e-01
  [eval] val_mse=2.451e+00  (n=2997)
Epoch 00098: Time=   7.3s, Loss=4.15e+00, Inv=4.15e+00, For=2.76e+01, Power=6.06e-01
  [eval] val_mse=2.459e+00  (n=2997)
  [early_stop] stop at epoch=98 (best_epoch=88, best_val_mse=2.437e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 6.373e-01
Torque MSE  = 1.290e-01
Torque RMSE = 3.592e-01
Per-joint MSE : 1.639e-01 2.325e-01 1.472e-01 9.617e-02 6.559e-02 6.884e-02
Per-joint RMSE: 4.049e-01 4.822e-01 3.837e-01 3.101e-01 2.561e-01 2.624e-01
Comp Time per Sample = 2.304e-04s / 4340.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_128 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-ka3hzfdh because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2', 'n_width': 128, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x749ef7e1a8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
  type = structured
  hp_preset = lutter_like_128
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:47:26.115611: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:47:27.746156: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.0s, Loss=2.65e+04, Inv=2.65e+04, For=5.84e+00, Power=1.61e+03
  [eval] val_mse=2.555e+02  (n=2997)
Epoch 00002: Time=   4.2s, Loss=6.14e+03, Inv=6.14e+03, For=5.79e+00, Power=3.53e+02
  [eval] val_mse=8.565e+01  (n=2997)
Epoch 00003: Time=   4.3s, Loss=2.63e+03, Inv=2.63e+03, For=5.79e+00, Power=1.65e+02
  [eval] val_mse=4.311e+01  (n=2997)
Epoch 00004: Time=   4.3s, Loss=1.44e+03, Inv=1.44e+03, For=5.87e+00, Power=9.78e+01
  [eval] val_mse=2.649e+01  (n=2997)
Epoch 00005: Time=   4.3s, Loss=9.00e+02, Inv=9.00e+02, For=5.97e+00, Power=6.42e+01
  [eval] val_mse=1.791e+01  (n=2997)
Epoch 00006: Time=   4.4s, Loss=6.09e+02, Inv=6.09e+02, For=6.09e+00, Power=4.49e+01
  [eval] val_mse=1.322e+01  (n=2997)
Epoch 00007: Time=   4.4s, Loss=4.38e+02, Inv=4.38e+02, For=6.22e+00, Power=3.31e+01
  [eval] val_mse=1.043e+01  (n=2997)
Epoch 00008: Time=   4.4s, Loss=3.29e+02, Inv=3.29e+02, For=6.35e+00, Power=2.52e+01
  [eval] val_mse=8.549e+00  (n=2997)
Epoch 00009: Time=   4.5s, Loss=2.55e+02, Inv=2.55e+02, For=6.46e+00, Power=1.97e+01
  [eval] val_mse=7.261e+00  (n=2997)
Epoch 00010: Time=   4.5s, Loss=2.03e+02, Inv=2.03e+02, For=6.54e+00, Power=1.57e+01
  [eval] val_mse=6.372e+00  (n=2997)
Epoch 00011: Time=   4.5s, Loss=1.66e+02, Inv=1.66e+02, For=6.65e+00, Power=1.29e+01
  [eval] val_mse=5.688e+00  (n=2997)
Epoch 00012: Time=   4.6s, Loss=1.38e+02, Inv=1.38e+02, For=6.75e+00, Power=1.07e+01
  [eval] val_mse=5.176e+00  (n=2997)
Epoch 00013: Time=   4.6s, Loss=1.16e+02, Inv=1.16e+02, For=6.85e+00, Power=8.99e+00
  [eval] val_mse=4.779e+00  (n=2997)
Epoch 00014: Time=   4.6s, Loss=9.92e+01, Inv=9.92e+01, For=6.95e+00, Power=7.67e+00
  [eval] val_mse=4.466e+00  (n=2997)
Epoch 00015: Time=   4.7s, Loss=8.57e+01, Inv=8.57e+01, For=7.06e+00, Power=6.61e+00
  [eval] val_mse=4.210e+00  (n=2997)
Epoch 00016: Time=   4.7s, Loss=7.49e+01, Inv=7.49e+01, For=7.16e+00, Power=5.77e+00
  [eval] val_mse=3.993e+00  (n=2997)
Epoch 00017: Time=   4.7s, Loss=6.59e+01, Inv=6.59e+01, For=7.23e+00, Power=5.08e+00
  [eval] val_mse=3.822e+00  (n=2997)
Epoch 00018: Time=   4.8s, Loss=5.85e+01, Inv=5.85e+01, For=7.33e+00, Power=4.50e+00
  [eval] val_mse=3.671e+00  (n=2997)
Epoch 00019: Time=   4.8s, Loss=5.22e+01, Inv=5.22e+01, For=7.38e+00, Power=4.01e+00
  [eval] val_mse=3.543e+00  (n=2997)
Epoch 00020: Time=   4.8s, Loss=4.69e+01, Inv=4.69e+01, For=7.43e+00, Power=3.62e+00
  [eval] val_mse=3.427e+00  (n=2997)
Epoch 00021: Time=   4.9s, Loss=4.24e+01, Inv=4.24e+01, For=7.47e+00, Power=3.27e+00
  [eval] val_mse=3.329e+00  (n=2997)
Epoch 00022: Time=   4.9s, Loss=3.85e+01, Inv=3.85e+01, For=7.51e+00, Power=2.98e+00
  [eval] val_mse=3.243e+00  (n=2997)
Epoch 00023: Time=   4.9s, Loss=3.51e+01, Inv=3.51e+01, For=7.55e+00, Power=2.72e+00
  [eval] val_mse=3.169e+00  (n=2997)
Epoch 00024: Time=   5.0s, Loss=3.21e+01, Inv=3.21e+01, For=7.60e+00, Power=2.50e+00
  [eval] val_mse=3.104e+00  (n=2997)
Epoch 00025: Time=   5.0s, Loss=2.96e+01, Inv=2.96e+01, For=7.68e+00, Power=2.31e+00
  [eval] val_mse=3.052e+00  (n=2997)
Epoch 00026: Time=   5.0s, Loss=2.73e+01, Inv=2.73e+01, For=7.81e+00, Power=2.14e+00
  [eval] val_mse=3.002e+00  (n=2997)
Epoch 00027: Time=   5.1s, Loss=2.54e+01, Inv=2.54e+01, For=7.97e+00, Power=1.99e+00
  [eval] val_mse=2.964e+00  (n=2997)
Epoch 00028: Time=   5.1s, Loss=2.36e+01, Inv=2.36e+01, For=8.16e+00, Power=1.86e+00
  [eval] val_mse=2.942e+00  (n=2997)
Epoch 00029: Time=   5.1s, Loss=2.21e+01, Inv=2.21e+01, For=8.38e+00, Power=1.74e+00
  [eval] val_mse=2.915e+00  (n=2997)
Epoch 00030: Time=   5.2s, Loss=2.07e+01, Inv=2.07e+01, For=8.64e+00, Power=1.64e+00
  [eval] val_mse=2.891e+00  (n=2997)
Epoch 00031: Time=   5.2s, Loss=1.95e+01, Inv=1.95e+01, For=8.91e+00, Power=1.55e+00
  [eval] val_mse=2.884e+00  (n=2997)
Epoch 00032: Time=   5.2s, Loss=1.84e+01, Inv=1.84e+01, For=9.18e+00, Power=1.47e+00
  [eval] val_mse=2.866e+00  (n=2997)
Epoch 00033: Time=   5.3s, Loss=1.74e+01, Inv=1.74e+01, For=9.51e+00, Power=1.39e+00
  [eval] val_mse=2.848e+00  (n=2997)
Epoch 00034: Time=   5.3s, Loss=1.65e+01, Inv=1.65e+01, For=9.85e+00, Power=1.33e+00
  [eval] val_mse=2.834e+00  (n=2997)
Epoch 00035: Time=   5.3s, Loss=1.56e+01, Inv=1.56e+01, For=1.02e+01, Power=1.27e+00
  [eval] val_mse=2.814e+00  (n=2997)
Epoch 00036: Time=   5.3s, Loss=1.49e+01, Inv=1.49e+01, For=1.05e+01, Power=1.22e+00
  [eval] val_mse=2.794e+00  (n=2997)
Epoch 00037: Time=   5.4s, Loss=1.43e+01, Inv=1.43e+01, For=1.09e+01, Power=1.17e+00
  [eval] val_mse=2.781e+00  (n=2997)
Epoch 00038: Time=   5.4s, Loss=1.36e+01, Inv=1.36e+01, For=1.12e+01, Power=1.13e+00
  [eval] val_mse=2.755e+00  (n=2997)
Epoch 00039: Time=   5.4s, Loss=1.31e+01, Inv=1.31e+01, For=1.16e+01, Power=1.09e+00
  [eval] val_mse=2.735e+00  (n=2997)
Epoch 00040: Time=   5.5s, Loss=1.26e+01, Inv=1.26e+01, For=1.19e+01, Power=1.05e+00
  [eval] val_mse=2.720e+00  (n=2997)
Epoch 00041: Time=   5.5s, Loss=1.21e+01, Inv=1.21e+01, For=1.23e+01, Power=1.02e+00
  [eval] val_mse=2.698e+00  (n=2997)
Epoch 00042: Time=   5.5s, Loss=1.16e+01, Inv=1.16e+01, For=1.26e+01, Power=9.89e-01
  [eval] val_mse=2.668e+00  (n=2997)
Epoch 00043: Time=   5.6s, Loss=1.12e+01, Inv=1.12e+01, For=1.29e+01, Power=9.62e-01
  [eval] val_mse=2.651e+00  (n=2997)
Epoch 00044: Time=   5.6s, Loss=1.08e+01, Inv=1.08e+01, For=1.33e+01, Power=9.37e-01
  [eval] val_mse=2.617e+00  (n=2997)
Epoch 00045: Time=   5.6s, Loss=1.05e+01, Inv=1.05e+01, For=1.37e+01, Power=9.14e-01
  [eval] val_mse=2.589e+00  (n=2997)
Epoch 00046: Time=   5.7s, Loss=1.02e+01, Inv=1.02e+01, For=1.41e+01, Power=8.93e-01
  [eval] val_mse=2.565e+00  (n=2997)
Epoch 00047: Time=   5.7s, Loss=9.85e+00, Inv=9.85e+00, For=1.44e+01, Power=8.75e-01
  [eval] val_mse=2.536e+00  (n=2997)
Epoch 00048: Time=   5.7s, Loss=9.55e+00, Inv=9.55e+00, For=1.48e+01, Power=8.56e-01
  [eval] val_mse=2.515e+00  (n=2997)
Epoch 00049: Time=   5.8s, Loss=9.29e+00, Inv=9.29e+00, For=1.52e+01, Power=8.41e-01
  [eval] val_mse=2.483e+00  (n=2997)
Epoch 00050: Time=   5.8s, Loss=9.03e+00, Inv=9.03e+00, For=1.56e+01, Power=8.24e-01
  [eval] val_mse=2.467e+00  (n=2997)
Epoch 00051: Time=   5.8s, Loss=8.80e+00, Inv=8.80e+00, For=1.60e+01, Power=8.11e-01
  [eval] val_mse=2.435e+00  (n=2997)
Epoch 00052: Time=   5.9s, Loss=8.57e+00, Inv=8.57e+00, For=1.64e+01, Power=7.99e-01
  [eval] val_mse=2.411e+00  (n=2997)
Epoch 00053: Time=   5.9s, Loss=8.36e+00, Inv=8.36e+00, For=1.69e+01, Power=7.87e-01
  [eval] val_mse=2.395e+00  (n=2997)
Epoch 00054: Time=   5.9s, Loss=8.15e+00, Inv=8.15e+00, For=1.73e+01, Power=7.74e-01
  [eval] val_mse=2.355e+00  (n=2997)
Epoch 00055: Time=   5.9s, Loss=7.97e+00, Inv=7.97e+00, For=1.77e+01, Power=7.66e-01
  [eval] val_mse=2.345e+00  (n=2997)
Epoch 00056: Time=   6.0s, Loss=7.79e+00, Inv=7.79e+00, For=1.81e+01, Power=7.56e-01
  [eval] val_mse=2.320e+00  (n=2997)
Epoch 00057: Time=   6.0s, Loss=7.63e+00, Inv=7.63e+00, For=1.86e+01, Power=7.47e-01
  [eval] val_mse=2.296e+00  (n=2997)
Epoch 00058: Time=   6.0s, Loss=7.46e+00, Inv=7.46e+00, For=1.91e+01, Power=7.39e-01
  [eval] val_mse=2.276e+00  (n=2997)
Epoch 00059: Time=   6.1s, Loss=7.31e+00, Inv=7.31e+00, For=1.95e+01, Power=7.28e-01
  [eval] val_mse=2.256e+00  (n=2997)
Epoch 00060: Time=   6.1s, Loss=7.17e+00, Inv=7.17e+00, For=2.00e+01, Power=7.22e-01
  [eval] val_mse=2.240e+00  (n=2997)
Epoch 00061: Time=   6.1s, Loss=7.03e+00, Inv=7.03e+00, For=2.05e+01, Power=7.15e-01
  [eval] val_mse=2.224e+00  (n=2997)
Epoch 00062: Time=   6.2s, Loss=6.90e+00, Inv=6.90e+00, For=2.10e+01, Power=7.10e-01
  [eval] val_mse=2.204e+00  (n=2997)
Epoch 00063: Time=   6.2s, Loss=6.78e+00, Inv=6.78e+00, For=2.15e+01, Power=7.04e-01
  [eval] val_mse=2.173e+00  (n=2997)
Epoch 00064: Time=   6.2s, Loss=6.66e+00, Inv=6.66e+00, For=2.20e+01, Power=6.98e-01
  [eval] val_mse=2.173e+00  (n=2997)
Epoch 00065: Time=   6.3s, Loss=6.55e+00, Inv=6.55e+00, For=2.25e+01, Power=6.92e-01
  [eval] val_mse=2.141e+00  (n=2997)
Epoch 00066: Time=   6.3s, Loss=6.44e+00, Inv=6.44e+00, For=2.30e+01, Power=6.88e-01
  [eval] val_mse=2.138e+00  (n=2997)
Epoch 00067: Time=   6.3s, Loss=6.34e+00, Inv=6.34e+00, For=2.36e+01, Power=6.85e-01
  [eval] val_mse=2.117e+00  (n=2997)
Epoch 00068: Time=   6.4s, Loss=6.24e+00, Inv=6.24e+00, For=2.41e+01, Power=6.78e-01
  [eval] val_mse=2.105e+00  (n=2997)
Epoch 00069: Time=   6.4s, Loss=6.15e+00, Inv=6.15e+00, For=2.46e+01, Power=6.75e-01
  [eval] val_mse=2.093e+00  (n=2997)
Epoch 00070: Time=   6.4s, Loss=6.06e+00, Inv=6.06e+00, For=2.52e+01, Power=6.71e-01
  [eval] val_mse=2.077e+00  (n=2997)
Epoch 00071: Time=   6.5s, Loss=5.97e+00, Inv=5.97e+00, For=2.58e+01, Power=6.68e-01
  [eval] val_mse=2.059e+00  (n=2997)
Epoch 00072: Time=   6.5s, Loss=5.89e+00, Inv=5.89e+00, For=2.64e+01, Power=6.64e-01
  [eval] val_mse=2.056e+00  (n=2997)
Epoch 00073: Time=   6.5s, Loss=5.81e+00, Inv=5.81e+00, For=2.69e+01, Power=6.60e-01
  [eval] val_mse=2.034e+00  (n=2997)
Epoch 00074: Time=   6.5s, Loss=5.74e+00, Inv=5.74e+00, For=2.75e+01, Power=6.57e-01
  [eval] val_mse=2.026e+00  (n=2997)
Epoch 00075: Time=   6.6s, Loss=5.66e+00, Inv=5.66e+00, For=2.81e+01, Power=6.54e-01
  [eval] val_mse=2.004e+00  (n=2997)
Epoch 00076: Time=   6.6s, Loss=5.59e+00, Inv=5.59e+00, For=2.87e+01, Power=6.52e-01
  [eval] val_mse=2.000e+00  (n=2997)
Epoch 00077: Time=   6.6s, Loss=5.53e+00, Inv=5.53e+00, For=2.93e+01, Power=6.49e-01
  [eval] val_mse=1.990e+00  (n=2997)
Epoch 00078: Time=   6.7s, Loss=5.46e+00, Inv=5.46e+00, For=2.99e+01, Power=6.45e-01
  [eval] val_mse=1.976e+00  (n=2997)
Epoch 00079: Time=   6.7s, Loss=5.41e+00, Inv=5.41e+00, For=3.04e+01, Power=6.44e-01
  [eval] val_mse=1.963e+00  (n=2997)
Epoch 00080: Time=   6.7s, Loss=5.35e+00, Inv=5.35e+00, For=3.11e+01, Power=6.42e-01
  [eval] val_mse=1.949e+00  (n=2997)
Epoch 00081: Time=   6.8s, Loss=5.29e+00, Inv=5.29e+00, For=3.17e+01, Power=6.39e-01
  [eval] val_mse=1.938e+00  (n=2997)
Epoch 00082: Time=   6.8s, Loss=5.24e+00, Inv=5.24e+00, For=3.24e+01, Power=6.37e-01
  [eval] val_mse=1.931e+00  (n=2997)
Epoch 00083: Time=   6.8s, Loss=5.18e+00, Inv=5.18e+00, For=3.30e+01, Power=6.36e-01
  [eval] val_mse=1.919e+00  (n=2997)
Epoch 00084: Time=   6.8s, Loss=5.14e+00, Inv=5.14e+00, For=3.36e+01, Power=6.34e-01
  [eval] val_mse=1.913e+00  (n=2997)
Epoch 00085: Time=   6.9s, Loss=5.08e+00, Inv=5.08e+00, For=3.43e+01, Power=6.31e-01
  [eval] val_mse=1.900e+00  (n=2997)
Epoch 00086: Time=   6.9s, Loss=5.04e+00, Inv=5.04e+00, For=3.49e+01, Power=6.30e-01
  [eval] val_mse=1.886e+00  (n=2997)
Epoch 00087: Time=   6.9s, Loss=4.99e+00, Inv=4.99e+00, For=3.56e+01, Power=6.28e-01
  [eval] val_mse=1.876e+00  (n=2997)
Epoch 00088: Time=   7.0s, Loss=4.95e+00, Inv=4.95e+00, For=3.62e+01, Power=6.27e-01
  [eval] val_mse=1.872e+00  (n=2997)
Epoch 00089: Time=   7.0s, Loss=4.91e+00, Inv=4.91e+00, For=3.69e+01, Power=6.26e-01
  [eval] val_mse=1.860e+00  (n=2997)
Epoch 00090: Time=   7.0s, Loss=4.87e+00, Inv=4.87e+00, For=3.76e+01, Power=6.24e-01
  [eval] val_mse=1.850e+00  (n=2997)
Epoch 00091: Time=   7.1s, Loss=4.83e+00, Inv=4.83e+00, For=3.82e+01, Power=6.21e-01
  [eval] val_mse=1.844e+00  (n=2997)
Epoch 00092: Time=   7.1s, Loss=4.79e+00, Inv=4.79e+00, For=3.88e+01, Power=6.21e-01
  [eval] val_mse=1.833e+00  (n=2997)
Epoch 00093: Time=   7.1s, Loss=4.76e+00, Inv=4.76e+00, For=3.96e+01, Power=6.20e-01
  [eval] val_mse=1.830e+00  (n=2997)
Epoch 00094: Time=   7.2s, Loss=4.72e+00, Inv=4.72e+00, For=4.04e+01, Power=6.19e-01
  [eval] val_mse=1.816e+00  (n=2997)
Epoch 00095: Time=   7.2s, Loss=4.69e+00, Inv=4.69e+00, For=4.09e+01, Power=6.16e-01
  [eval] val_mse=1.804e+00  (n=2997)
Epoch 00096: Time=   7.2s, Loss=4.66e+00, Inv=4.66e+00, For=4.17e+01, Power=6.16e-01
  [eval] val_mse=1.798e+00  (n=2997)
Epoch 00097: Time=   7.3s, Loss=4.62e+00, Inv=4.62e+00, For=4.22e+01, Power=6.16e-01
  [eval] val_mse=1.790e+00  (n=2997)
Epoch 00098: Time=   7.3s, Loss=4.59e+00, Inv=4.59e+00, For=4.30e+01, Power=6.15e-01
  [eval] val_mse=1.781e+00  (n=2997)
Epoch 00099: Time=   7.3s, Loss=4.56e+00, Inv=4.56e+00, For=4.36e+01, Power=6.14e-01
  [eval] val_mse=1.769e+00  (n=2997)
Epoch 00100: Time=   7.4s, Loss=4.53e+00, Inv=4.53e+00, For=4.43e+01, Power=6.12e-01
  [eval] val_mse=1.767e+00  (n=2997)
Epoch 00101: Time=   7.4s, Loss=4.51e+00, Inv=4.51e+00, For=4.50e+01, Power=6.12e-01
  [eval] val_mse=1.762e+00  (n=2997)
Epoch 00102: Time=   7.4s, Loss=4.48e+00, Inv=4.48e+00, For=4.57e+01, Power=6.10e-01
  [eval] val_mse=1.743e+00  (n=2997)
Epoch 00103: Time=   7.5s, Loss=4.45e+00, Inv=4.45e+00, For=4.66e+01, Power=6.09e-01
  [eval] val_mse=1.735e+00  (n=2997)
Epoch 00104: Time=   7.5s, Loss=4.43e+00, Inv=4.43e+00, For=4.70e+01, Power=6.07e-01
  [eval] val_mse=1.728e+00  (n=2997)
Epoch 00105: Time=   7.5s, Loss=4.40e+00, Inv=4.40e+00, For=4.77e+01, Power=6.09e-01
  [eval] val_mse=1.727e+00  (n=2997)
Epoch 00106: Time=   7.5s, Loss=4.38e+00, Inv=4.38e+00, For=4.84e+01, Power=6.08e-01
  [eval] val_mse=1.713e+00  (n=2997)
Epoch 00107: Time=   7.6s, Loss=4.35e+00, Inv=4.35e+00, For=4.90e+01, Power=6.07e-01
  [eval] val_mse=1.711e+00  (n=2997)
Epoch 00108: Time=   7.6s, Loss=4.33e+00, Inv=4.33e+00, For=4.97e+01, Power=6.06e-01
  [eval] val_mse=1.704e+00  (n=2997)
Epoch 00109: Time=   7.6s, Loss=4.31e+00, Inv=4.31e+00, For=5.06e+01, Power=6.06e-01
  [eval] val_mse=1.689e+00  (n=2997)
Epoch 00110: Time=   7.7s, Loss=4.29e+00, Inv=4.29e+00, For=5.12e+01, Power=6.04e-01
  [eval] val_mse=1.686e+00  (n=2997)
Epoch 00111: Time=   7.7s, Loss=4.27e+00, Inv=4.27e+00, For=5.19e+01, Power=6.04e-01
  [eval] val_mse=1.684e+00  (n=2997)
Epoch 00112: Time=   7.7s, Loss=4.25e+00, Inv=4.25e+00, For=5.24e+01, Power=6.03e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00113: Time=   7.8s, Loss=4.23e+00, Inv=4.23e+00, For=5.30e+01, Power=6.03e-01
  [eval] val_mse=1.672e+00  (n=2997)
Epoch 00114: Time=   7.8s, Loss=4.21e+00, Inv=4.21e+00, For=5.39e+01, Power=6.02e-01
  [eval] val_mse=1.667e+00  (n=2997)
Epoch 00115: Time=   7.8s, Loss=4.20e+00, Inv=4.20e+00, For=5.46e+01, Power=6.03e-01
  [eval] val_mse=1.652e+00  (n=2997)
Epoch 00116: Time=   7.9s, Loss=4.18e+00, Inv=4.18e+00, For=5.49e+01, Power=6.02e-01
  [eval] val_mse=1.649e+00  (n=2997)
Epoch 00117: Time=   7.9s, Loss=4.16e+00, Inv=4.16e+00, For=5.61e+01, Power=6.01e-01
  [eval] val_mse=1.640e+00  (n=2997)
Epoch 00118: Time=   7.9s, Loss=4.14e+00, Inv=4.14e+00, For=5.65e+01, Power=6.01e-01
  [eval] val_mse=1.642e+00  (n=2997)
Epoch 00119: Time=   8.0s, Loss=4.13e+00, Inv=4.13e+00, For=5.70e+01, Power=6.01e-01
  [eval] val_mse=1.635e+00  (n=2997)
Epoch 00120: Time=   8.0s, Loss=4.11e+00, Inv=4.11e+00, For=5.80e+01, Power=5.99e-01
  [eval] val_mse=1.639e+00  (n=2997)
Epoch 00121: Time=   8.0s, Loss=4.10e+00, Inv=4.10e+00, For=5.85e+01, Power=5.99e-01
  [eval] val_mse=1.626e+00  (n=2997)
Epoch 00122: Time=   8.0s, Loss=4.08e+00, Inv=4.08e+00, For=5.93e+01, Power=5.99e-01
  [eval] val_mse=1.628e+00  (n=2997)
Epoch 00123: Time=   8.1s, Loss=4.07e+00, Inv=4.07e+00, For=5.95e+01, Power=5.99e-01
  [eval] val_mse=1.618e+00  (n=2997)
Epoch 00124: Time=   8.1s, Loss=4.05e+00, Inv=4.05e+00, For=5.98e+01, Power=5.98e-01
  [eval] val_mse=1.625e+00  (n=2997)
Epoch 00125: Time=   8.1s, Loss=4.04e+00, Inv=4.04e+00, For=6.14e+01, Power=5.97e-01
  [eval] val_mse=1.605e+00  (n=2997)
Epoch 00126: Time=   8.2s, Loss=4.03e+00, Inv=4.03e+00, For=6.10e+01, Power=5.97e-01
  [eval] val_mse=1.606e+00  (n=2997)
Epoch 00127: Time=   8.2s, Loss=4.01e+00, Inv=4.01e+00, For=6.23e+01, Power=5.96e-01
  [eval] val_mse=1.600e+00  (n=2997)
Epoch 00128: Time=   8.2s, Loss=4.00e+00, Inv=4.00e+00, For=6.27e+01, Power=5.96e-01
  [eval] val_mse=1.606e+00  (n=2997)
Epoch 00129: Time=   8.3s, Loss=3.99e+00, Inv=3.99e+00, For=6.39e+01, Power=5.96e-01
  [eval] val_mse=1.600e+00  (n=2997)
Epoch 00130: Time=   8.3s, Loss=3.98e+00, Inv=3.98e+00, For=6.38e+01, Power=5.97e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00131: Time=   8.3s, Loss=3.96e+00, Inv=3.96e+00, For=6.47e+01, Power=5.95e-01
  [eval] val_mse=1.584e+00  (n=2997)
Epoch 00132: Time=   8.3s, Loss=3.95e+00, Inv=3.95e+00, For=6.45e+01, Power=5.95e-01
  [eval] val_mse=1.595e+00  (n=2997)
Epoch 00133: Time=   8.4s, Loss=3.94e+00, Inv=3.94e+00, For=6.53e+01, Power=5.95e-01
  [eval] val_mse=1.586e+00  (n=2997)
Epoch 00134: Time=   8.4s, Loss=3.93e+00, Inv=3.93e+00, For=6.63e+01, Power=5.95e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00135: Time=   8.4s, Loss=3.92e+00, Inv=3.92e+00, For=6.69e+01, Power=5.93e-01
  [eval] val_mse=1.593e+00  (n=2997)
Epoch 00136: Time=   8.5s, Loss=3.91e+00, Inv=3.91e+00, For=6.73e+01, Power=5.94e-01
  [eval] val_mse=1.589e+00  (n=2997)
Epoch 00137: Time=   8.5s, Loss=3.90e+00, Inv=3.90e+00, For=6.77e+01, Power=5.95e-01
  [eval] val_mse=1.585e+00  (n=2997)
Epoch 00138: Time=   8.5s, Loss=3.88e+00, Inv=3.88e+00, For=6.82e+01, Power=5.94e-01
  [eval] val_mse=1.589e+00  (n=2997)
Epoch 00139: Time=   8.6s, Loss=3.88e+00, Inv=3.88e+00, For=6.91e+01, Power=5.93e-01
  [eval] val_mse=1.581e+00  (n=2997)
Epoch 00140: Time=   8.6s, Loss=3.87e+00, Inv=3.87e+00, For=6.94e+01, Power=5.93e-01
  [eval] val_mse=1.588e+00  (n=2997)
Epoch 00141: Time=   8.6s, Loss=3.86e+00, Inv=3.86e+00, For=7.05e+01, Power=5.92e-01
  [eval] val_mse=1.584e+00  (n=2997)
Epoch 00142: Time=   8.6s, Loss=3.85e+00, Inv=3.85e+00, For=7.02e+01, Power=5.92e-01
  [eval] val_mse=1.584e+00  (n=2997)
Epoch 00143: Time=   8.7s, Loss=3.84e+00, Inv=3.84e+00, For=7.15e+01, Power=5.93e-01
  [eval] val_mse=1.583e+00  (n=2997)
Epoch 00144: Time=   8.7s, Loss=3.83e+00, Inv=3.83e+00, For=7.10e+01, Power=5.92e-01
  [eval] val_mse=1.580e+00  (n=2997)
Epoch 00145: Time=   8.7s, Loss=3.82e+00, Inv=3.82e+00, For=7.17e+01, Power=5.92e-01
  [eval] val_mse=1.583e+00  (n=2997)
Epoch 00146: Time=   8.8s, Loss=3.81e+00, Inv=3.81e+00, For=7.23e+01, Power=5.91e-01
  [eval] val_mse=1.582e+00  (n=2997)
Epoch 00147: Time=   8.8s, Loss=3.81e+00, Inv=3.81e+00, For=7.24e+01, Power=5.92e-01
  [eval] val_mse=1.579e+00  (n=2997)
Epoch 00148: Time=   8.8s, Loss=3.80e+00, Inv=3.80e+00, For=7.33e+01, Power=5.91e-01
  [eval] val_mse=1.596e+00  (n=2997)
Epoch 00149: Time=   8.8s, Loss=3.79e+00, Inv=3.79e+00, For=7.30e+01, Power=5.91e-01
  [eval] val_mse=1.586e+00  (n=2997)
Epoch 00150: Time=   8.9s, Loss=3.78e+00, Inv=3.78e+00, For=7.48e+01, Power=5.90e-01
  [eval] val_mse=1.578e+00  (n=2997)
Epoch 00151: Time=   8.9s, Loss=3.78e+00, Inv=3.78e+00, For=7.38e+01, Power=5.91e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00152: Time=   8.9s, Loss=3.76e+00, Inv=3.76e+00, For=7.55e+01, Power=5.90e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00153: Time=   9.0s, Loss=3.76e+00, Inv=3.76e+00, For=7.41e+01, Power=5.91e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00154: Time=   9.0s, Loss=3.75e+00, Inv=3.75e+00, For=7.58e+01, Power=5.90e-01
  [eval] val_mse=1.600e+00  (n=2997)
Epoch 00155: Time=   9.0s, Loss=3.74e+00, Inv=3.74e+00, For=7.64e+01, Power=5.90e-01
  [eval] val_mse=1.608e+00  (n=2997)
Epoch 00156: Time=   9.1s, Loss=3.74e+00, Inv=3.74e+00, For=7.66e+01, Power=5.90e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00157: Time=   9.1s, Loss=3.73e+00, Inv=3.73e+00, For=7.60e+01, Power=5.89e-01
  [eval] val_mse=1.603e+00  (n=2997)
Epoch 00158: Time=   9.1s, Loss=3.72e+00, Inv=3.72e+00, For=7.73e+01, Power=5.89e-01
  [eval] val_mse=1.609e+00  (n=2997)
Epoch 00159: Time=   9.2s, Loss=3.72e+00, Inv=3.72e+00, For=7.65e+01, Power=5.90e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00160: Time=   9.2s, Loss=3.71e+00, Inv=3.71e+00, For=7.81e+01, Power=5.89e-01
  [eval] val_mse=1.620e+00  (n=2997)
  [early_stop] stop at epoch=160 (best_epoch=150, best_val_mse=1.578e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2
  [val] Torque RMSE = 5.129e-01
Torque MSE  = 1.314e-01
Torque RMSE = 3.624e-01
Per-joint MSE : 1.555e-01 3.442e-01 1.141e-01 7.000e-02 4.877e-02 5.556e-02
Per-joint RMSE: 3.944e-01 5.867e-01 3.378e-01 2.646e-01 2.208e-01 2.357e-01
Comp Time per Sample = 2.138e-04s / 4677.6Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_128_actsoftplus_b1024_lr1e-4_wd1e-5_w128_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 0 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-_24oxl0w because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x79690065e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:47:46.040235: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:47:47.836537: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=8.94e+03, Inv=8.94e+03, For=5.90e+00, Power=1.70e+03
  [eval] val_mse=1.643e+02  (n=7000)
Epoch 00002: Time=   5.4s, Loss=5.96e+02, Inv=5.96e+02, For=5.66e+00, Power=1.25e+02
  [eval] val_mse=6.998e+01  (n=7000)
Epoch 00003: Time=   5.5s, Loss=2.52e+02, Inv=2.52e+02, For=5.58e+00, Power=5.00e+01
  [eval] val_mse=4.524e+01  (n=7000)
Epoch 00004: Time=   5.5s, Loss=1.48e+02, Inv=1.48e+02, For=5.65e+00, Power=3.00e+01
  [eval] val_mse=3.257e+01  (n=7000)
Epoch 00005: Time=   5.5s, Loss=9.82e+01, Inv=9.82e+01, For=5.80e+00, Power=1.99e+01
  [eval] val_mse=2.474e+01  (n=7000)
Epoch 00006: Time=   5.6s, Loss=6.97e+01, Inv=6.97e+01, For=6.01e+00, Power=1.41e+01
  [eval] val_mse=1.952e+01  (n=7000)
Epoch 00007: Time=   5.6s, Loss=5.24e+01, Inv=5.24e+01, For=6.22e+00, Power=1.03e+01
  [eval] val_mse=1.583e+01  (n=7000)
Epoch 00008: Time=   5.6s, Loss=4.13e+01, Inv=4.13e+01, For=6.51e+00, Power=7.97e+00
  [eval] val_mse=1.320e+01  (n=7000)
Epoch 00009: Time=   5.7s, Loss=3.37e+01, Inv=3.37e+01, For=6.86e+00, Power=6.41e+00
  [eval] val_mse=1.112e+01  (n=7000)
Epoch 00010: Time=   5.7s, Loss=2.80e+01, Inv=2.80e+01, For=7.15e+00, Power=5.18e+00
  [eval] val_mse=9.543e+00  (n=7000)
Epoch 00011: Time=   5.7s, Loss=2.40e+01, Inv=2.40e+01, For=7.51e+00, Power=4.35e+00
  [eval] val_mse=8.255e+00  (n=7000)
Epoch 00012: Time=   5.8s, Loss=2.07e+01, Inv=2.07e+01, For=7.84e+00, Power=3.68e+00
  [eval] val_mse=7.212e+00  (n=7000)
Epoch 00013: Time=   5.8s, Loss=1.83e+01, Inv=1.83e+01, For=8.26e+00, Power=3.18e+00
  [eval] val_mse=6.371e+00  (n=7000)
Epoch 00014: Time=   5.8s, Loss=1.63e+01, Inv=1.63e+01, For=8.58e+00, Power=2.78e+00
  [eval] val_mse=5.658e+00  (n=7000)
Epoch 00015: Time=   5.9s, Loss=1.47e+01, Inv=1.47e+01, For=8.97e+00, Power=2.47e+00
  [eval] val_mse=5.066e+00  (n=7000)
Epoch 00016: Time=   5.9s, Loss=1.34e+01, Inv=1.34e+01, For=9.34e+00, Power=2.23e+00
  [eval] val_mse=4.551e+00  (n=7000)
Epoch 00017: Time=   5.9s, Loss=1.23e+01, Inv=1.23e+01, For=9.75e+00, Power=2.01e+00
  [eval] val_mse=4.116e+00  (n=7000)
Epoch 00018: Time=   6.0s, Loss=1.14e+01, Inv=1.14e+01, For=1.01e+01, Power=1.84e+00
  [eval] val_mse=3.749e+00  (n=7000)
Epoch 00019: Time=   6.0s, Loss=1.06e+01, Inv=1.06e+01, For=1.05e+01, Power=1.69e+00
  [eval] val_mse=3.421e+00  (n=7000)
Epoch 00020: Time=   6.0s, Loss=9.89e+00, Inv=9.89e+00, For=1.08e+01, Power=1.58e+00
  [eval] val_mse=3.147e+00  (n=7000)
Epoch 00021: Time=   6.1s, Loss=9.28e+00, Inv=9.28e+00, For=1.13e+01, Power=1.48e+00
  [eval] val_mse=2.907e+00  (n=7000)
Epoch 00022: Time=   6.1s, Loss=8.76e+00, Inv=8.76e+00, For=1.17e+01, Power=1.38e+00
  [eval] val_mse=2.690e+00  (n=7000)
Epoch 00023: Time=   6.1s, Loss=8.30e+00, Inv=8.30e+00, For=1.22e+01, Power=1.30e+00
  [eval] val_mse=2.505e+00  (n=7000)
Epoch 00024: Time=   6.2s, Loss=7.91e+00, Inv=7.91e+00, For=1.27e+01, Power=1.24e+00
  [eval] val_mse=2.336e+00  (n=7000)
Epoch 00025: Time=   6.2s, Loss=7.56e+00, Inv=7.56e+00, For=1.33e+01, Power=1.18e+00
  [eval] val_mse=2.188e+00  (n=7000)
Epoch 00026: Time=   6.2s, Loss=7.23e+00, Inv=7.23e+00, For=1.39e+01, Power=1.13e+00
  [eval] val_mse=2.058e+00  (n=7000)
Epoch 00027: Time=   6.3s, Loss=6.96e+00, Inv=6.96e+00, For=1.46e+01, Power=1.09e+00
  [eval] val_mse=1.936e+00  (n=7000)
Epoch 00028: Time=   6.3s, Loss=6.73e+00, Inv=6.73e+00, For=1.52e+01, Power=1.06e+00
  [eval] val_mse=1.830e+00  (n=7000)
Epoch 00029: Time=   6.3s, Loss=6.51e+00, Inv=6.51e+00, For=1.60e+01, Power=1.02e+00
  [eval] val_mse=1.729e+00  (n=7000)
Epoch 00030: Time=   6.4s, Loss=6.29e+00, Inv=6.29e+00, For=1.67e+01, Power=9.87e-01
  [eval] val_mse=1.643e+00  (n=7000)
Epoch 00031: Time=   6.4s, Loss=6.11e+00, Inv=6.11e+00, For=1.75e+01, Power=9.60e-01
  [eval] val_mse=1.561e+00  (n=7000)
Epoch 00032: Time=   6.4s, Loss=5.94e+00, Inv=5.94e+00, For=1.83e+01, Power=9.35e-01
  [eval] val_mse=1.489e+00  (n=7000)
Epoch 00033: Time=   6.5s, Loss=5.78e+00, Inv=5.78e+00, For=1.92e+01, Power=9.15e-01
  [eval] val_mse=1.420e+00  (n=7000)
Epoch 00034: Time=   6.5s, Loss=5.65e+00, Inv=5.65e+00, For=2.02e+01, Power=8.99e-01
  [eval] val_mse=1.356e+00  (n=7000)
Epoch 00035: Time=   6.5s, Loss=5.53e+00, Inv=5.53e+00, For=2.11e+01, Power=8.81e-01
  [eval] val_mse=1.299e+00  (n=7000)
Epoch 00036: Time=   6.6s, Loss=5.41e+00, Inv=5.41e+00, For=2.22e+01, Power=8.66e-01
  [eval] val_mse=1.245e+00  (n=7000)
Epoch 00037: Time=   6.6s, Loss=5.30e+00, Inv=5.30e+00, For=2.30e+01, Power=8.49e-01
  [eval] val_mse=1.198e+00  (n=7000)
Epoch 00038: Time=   6.6s, Loss=5.20e+00, Inv=5.20e+00, For=2.42e+01, Power=8.33e-01
  [eval] val_mse=1.152e+00  (n=7000)
Epoch 00039: Time=   6.7s, Loss=5.10e+00, Inv=5.10e+00, For=2.53e+01, Power=8.25e-01
  [eval] val_mse=1.110e+00  (n=7000)
Epoch 00040: Time=   6.7s, Loss=5.02e+00, Inv=5.02e+00, For=2.65e+01, Power=8.14e-01
  [eval] val_mse=1.072e+00  (n=7000)
Epoch 00041: Time=   6.7s, Loss=4.93e+00, Inv=4.93e+00, For=2.76e+01, Power=8.05e-01
  [eval] val_mse=1.035e+00  (n=7000)
Epoch 00042: Time=   6.8s, Loss=4.86e+00, Inv=4.86e+00, For=2.89e+01, Power=7.98e-01
  [eval] val_mse=1.002e+00  (n=7000)
Epoch 00043: Time=   6.8s, Loss=4.79e+00, Inv=4.79e+00, For=3.00e+01, Power=7.89e-01
  [eval] val_mse=9.705e-01  (n=7000)
Epoch 00044: Time=   6.8s, Loss=4.72e+00, Inv=4.72e+00, For=3.13e+01, Power=7.78e-01
  [eval] val_mse=9.421e-01  (n=7000)
Epoch 00045: Time=   6.9s, Loss=4.66e+00, Inv=4.66e+00, For=3.28e+01, Power=7.75e-01
  [eval] val_mse=9.142e-01  (n=7000)
Epoch 00046: Time=   6.9s, Loss=4.59e+00, Inv=4.59e+00, For=3.41e+01, Power=7.65e-01
  [eval] val_mse=8.894e-01  (n=7000)
Epoch 00047: Time=   6.9s, Loss=4.53e+00, Inv=4.53e+00, For=3.54e+01, Power=7.61e-01
  [eval] val_mse=8.640e-01  (n=7000)
Epoch 00048: Time=   7.0s, Loss=4.47e+00, Inv=4.47e+00, For=3.70e+01, Power=7.55e-01
  [eval] val_mse=8.428e-01  (n=7000)
Epoch 00049: Time=   7.0s, Loss=4.42e+00, Inv=4.42e+00, For=3.85e+01, Power=7.48e-01
  [eval] val_mse=8.220e-01  (n=7000)
Epoch 00050: Time=   7.0s, Loss=4.38e+00, Inv=4.38e+00, For=4.00e+01, Power=7.46e-01
  [eval] val_mse=8.023e-01  (n=7000)
Epoch 00051: Time=   7.1s, Loss=4.32e+00, Inv=4.32e+00, For=4.14e+01, Power=7.39e-01
  [eval] val_mse=7.842e-01  (n=7000)
Epoch 00052: Time=   7.1s, Loss=4.28e+00, Inv=4.28e+00, For=4.31e+01, Power=7.35e-01
  [eval] val_mse=7.660e-01  (n=7000)
Epoch 00053: Time=   7.1s, Loss=4.24e+00, Inv=4.24e+00, For=4.49e+01, Power=7.35e-01
  [eval] val_mse=7.510e-01  (n=7000)
Epoch 00054: Time=   7.2s, Loss=4.20e+00, Inv=4.20e+00, For=4.67e+01, Power=7.30e-01
  [eval] val_mse=7.358e-01  (n=7000)
Epoch 00055: Time=   7.2s, Loss=4.16e+00, Inv=4.16e+00, For=4.85e+01, Power=7.27e-01
  [eval] val_mse=7.211e-01  (n=7000)
Epoch 00056: Time=   7.2s, Loss=4.11e+00, Inv=4.11e+00, For=5.01e+01, Power=7.25e-01
  [eval] val_mse=7.074e-01  (n=7000)
Epoch 00057: Time=   7.3s, Loss=4.08e+00, Inv=4.08e+00, For=5.21e+01, Power=7.22e-01
  [eval] val_mse=6.944e-01  (n=7000)
Epoch 00058: Time=   7.3s, Loss=4.05e+00, Inv=4.05e+00, For=5.41e+01, Power=7.16e-01
  [eval] val_mse=6.820e-01  (n=7000)
Epoch 00059: Time=   7.3s, Loss=4.01e+00, Inv=4.01e+00, For=5.59e+01, Power=7.12e-01
  [eval] val_mse=6.707e-01  (n=7000)
Epoch 00060: Time=   7.4s, Loss=3.98e+00, Inv=3.98e+00, For=5.82e+01, Power=7.14e-01
  [eval] val_mse=6.597e-01  (n=7000)
Epoch 00061: Time=   7.4s, Loss=3.95e+00, Inv=3.95e+00, For=6.01e+01, Power=7.14e-01
  [eval] val_mse=6.500e-01  (n=7000)
Epoch 00062: Time=   7.4s, Loss=3.92e+00, Inv=3.92e+00, For=6.25e+01, Power=7.09e-01
  [eval] val_mse=6.397e-01  (n=7000)
Epoch 00063: Time=   7.5s, Loss=3.89e+00, Inv=3.89e+00, For=6.44e+01, Power=7.09e-01
  [eval] val_mse=6.304e-01  (n=7000)
Epoch 00064: Time=   7.5s, Loss=3.87e+00, Inv=3.87e+00, For=6.63e+01, Power=7.05e-01
  [eval] val_mse=6.213e-01  (n=7000)
Epoch 00065: Time=   7.5s, Loss=3.84e+00, Inv=3.84e+00, For=6.90e+01, Power=7.06e-01
  [eval] val_mse=6.131e-01  (n=7000)
Epoch 00066: Time=   7.6s, Loss=3.81e+00, Inv=3.81e+00, For=7.09e+01, Power=7.02e-01
  [eval] val_mse=6.046e-01  (n=7000)
Epoch 00067: Time=   7.6s, Loss=3.79e+00, Inv=3.79e+00, For=7.38e+01, Power=7.01e-01
  [eval] val_mse=5.971e-01  (n=7000)
Epoch 00068: Time=   7.6s, Loss=3.76e+00, Inv=3.76e+00, For=7.54e+01, Power=6.98e-01
  [eval] val_mse=5.888e-01  (n=7000)
Epoch 00069: Time=   7.7s, Loss=3.74e+00, Inv=3.74e+00, For=7.82e+01, Power=6.95e-01
  [eval] val_mse=5.810e-01  (n=7000)
Epoch 00070: Time=   7.7s, Loss=3.72e+00, Inv=3.72e+00, For=8.08e+01, Power=6.99e-01
  [eval] val_mse=5.753e-01  (n=7000)
Epoch 00071: Time=   7.7s, Loss=3.70e+00, Inv=3.70e+00, For=8.35e+01, Power=6.93e-01
  [eval] val_mse=5.692e-01  (n=7000)
Epoch 00072: Time=   7.8s, Loss=3.69e+00, Inv=3.69e+00, For=8.53e+01, Power=6.96e-01
  [eval] val_mse=5.628e-01  (n=7000)
Epoch 00073: Time=   7.8s, Loss=3.66e+00, Inv=3.66e+00, For=8.82e+01, Power=6.94e-01
  [eval] val_mse=5.567e-01  (n=7000)
Epoch 00074: Time=   7.8s, Loss=3.65e+00, Inv=3.65e+00, For=9.11e+01, Power=6.93e-01
  [eval] val_mse=5.508e-01  (n=7000)
Epoch 00075: Time=   7.9s, Loss=3.63e+00, Inv=3.63e+00, For=9.35e+01, Power=6.95e-01
  [eval] val_mse=5.452e-01  (n=7000)
Epoch 00076: Time=   7.9s, Loss=3.61e+00, Inv=3.61e+00, For=9.64e+01, Power=6.93e-01
  [eval] val_mse=5.403e-01  (n=7000)
Epoch 00077: Time=   7.9s, Loss=3.59e+00, Inv=3.59e+00, For=9.88e+01, Power=6.89e-01
  [eval] val_mse=5.347e-01  (n=7000)
Epoch 00078: Time=   8.0s, Loss=3.58e+00, Inv=3.58e+00, For=1.02e+02, Power=6.91e-01
  [eval] val_mse=5.297e-01  (n=7000)
Epoch 00079: Time=   8.0s, Loss=3.56e+00, Inv=3.56e+00, For=1.04e+02, Power=6.88e-01
  [eval] val_mse=5.249e-01  (n=7000)
Epoch 00080: Time=   8.0s, Loss=3.55e+00, Inv=3.55e+00, For=1.08e+02, Power=6.89e-01
  [eval] val_mse=5.197e-01  (n=7000)
Epoch 00081: Time=   8.1s, Loss=3.54e+00, Inv=3.54e+00, For=1.10e+02, Power=6.91e-01
  [eval] val_mse=5.154e-01  (n=7000)
Epoch 00082: Time=   8.1s, Loss=3.53e+00, Inv=3.53e+00, For=1.14e+02, Power=6.91e-01
  [eval] val_mse=5.111e-01  (n=7000)
Epoch 00083: Time=   8.1s, Loss=3.52e+00, Inv=3.52e+00, For=1.17e+02, Power=6.91e-01
  [eval] val_mse=5.073e-01  (n=7000)
Epoch 00084: Time=   8.2s, Loss=3.51e+00, Inv=3.51e+00, For=1.20e+02, Power=6.88e-01
  [eval] val_mse=5.028e-01  (n=7000)
Epoch 00085: Time=   8.2s, Loss=3.49e+00, Inv=3.49e+00, For=1.23e+02, Power=6.88e-01
  [eval] val_mse=4.999e-01  (n=7000)
Epoch 00086: Time=   8.2s, Loss=3.48e+00, Inv=3.48e+00, For=1.26e+02, Power=6.88e-01
  [eval] val_mse=4.956e-01  (n=7000)
Epoch 00087: Time=   8.3s, Loss=3.47e+00, Inv=3.47e+00, For=1.29e+02, Power=6.87e-01
  [eval] val_mse=4.913e-01  (n=7000)
Epoch 00088: Time=   8.3s, Loss=3.46e+00, Inv=3.46e+00, For=1.33e+02, Power=6.87e-01
  [eval] val_mse=4.878e-01  (n=7000)
Epoch 00089: Time=   8.3s, Loss=3.45e+00, Inv=3.45e+00, For=1.36e+02, Power=6.89e-01
  [eval] val_mse=4.833e-01  (n=7000)
Epoch 00090: Time=   8.4s, Loss=3.44e+00, Inv=3.44e+00, For=1.39e+02, Power=6.88e-01
  [eval] val_mse=4.807e-01  (n=7000)
Epoch 00091: Time=   8.4s, Loss=3.43e+00, Inv=3.43e+00, For=1.42e+02, Power=6.86e-01
  [eval] val_mse=4.773e-01  (n=7000)
Epoch 00092: Time=   8.4s, Loss=3.42e+00, Inv=3.42e+00, For=1.45e+02, Power=6.86e-01
  [eval] val_mse=4.743e-01  (n=7000)
Epoch 00093: Time=   8.5s, Loss=3.40e+00, Inv=3.40e+00, For=1.49e+02, Power=6.84e-01
  [eval] val_mse=4.711e-01  (n=7000)
Epoch 00094: Time=   8.5s, Loss=3.40e+00, Inv=3.40e+00, For=1.54e+02, Power=6.88e-01
  [eval] val_mse=4.675e-01  (n=7000)
Epoch 00095: Time=   8.5s, Loss=3.39e+00, Inv=3.39e+00, For=1.56e+02, Power=6.83e-01
  [eval] val_mse=4.643e-01  (n=7000)
Epoch 00096: Time=   8.6s, Loss=3.38e+00, Inv=3.38e+00, For=1.61e+02, Power=6.84e-01
  [eval] val_mse=4.616e-01  (n=7000)
Epoch 00097: Time=   8.6s, Loss=3.37e+00, Inv=3.37e+00, For=1.62e+02, Power=6.84e-01
  [eval] val_mse=4.593e-01  (n=7000)
Epoch 00098: Time=   8.6s, Loss=3.37e+00, Inv=3.37e+00, For=1.67e+02, Power=6.86e-01
  [eval] val_mse=4.554e-01  (n=7000)
Epoch 00099: Time=   8.7s, Loss=3.36e+00, Inv=3.36e+00, For=1.72e+02, Power=6.87e-01
  [eval] val_mse=4.524e-01  (n=7000)
Epoch 00100: Time=   8.7s, Loss=3.36e+00, Inv=3.36e+00, For=1.75e+02, Power=6.88e-01
  [eval] val_mse=4.500e-01  (n=7000)
Epoch 00101: Time=   8.7s, Loss=3.35e+00, Inv=3.35e+00, For=1.78e+02, Power=6.85e-01
  [eval] val_mse=4.479e-01  (n=7000)
Epoch 00102: Time=   8.8s, Loss=3.34e+00, Inv=3.34e+00, For=1.81e+02, Power=6.82e-01
  [eval] val_mse=4.449e-01  (n=7000)
Epoch 00103: Time=   8.8s, Loss=3.33e+00, Inv=3.33e+00, For=1.86e+02, Power=6.82e-01
  [eval] val_mse=4.417e-01  (n=7000)
Epoch 00104: Time=   8.8s, Loss=3.32e+00, Inv=3.32e+00, For=1.91e+02, Power=6.84e-01
  [eval] val_mse=4.394e-01  (n=7000)
Epoch 00105: Time=   8.9s, Loss=3.32e+00, Inv=3.32e+00, For=1.91e+02, Power=6.85e-01
  [eval] val_mse=4.370e-01  (n=7000)
Epoch 00106: Time=   8.9s, Loss=3.30e+00, Inv=3.30e+00, For=1.98e+02, Power=6.83e-01
  [eval] val_mse=4.342e-01  (n=7000)
Epoch 00107: Time=   8.9s, Loss=3.30e+00, Inv=3.30e+00, For=2.00e+02, Power=6.82e-01
  [eval] val_mse=4.322e-01  (n=7000)
Epoch 00108: Time=   9.0s, Loss=3.30e+00, Inv=3.30e+00, For=2.07e+02, Power=6.83e-01
  [eval] val_mse=4.297e-01  (n=7000)
Epoch 00109: Time=   9.0s, Loss=3.29e+00, Inv=3.29e+00, For=2.10e+02, Power=6.83e-01
  [eval] val_mse=4.271e-01  (n=7000)
Epoch 00110: Time=   9.0s, Loss=3.28e+00, Inv=3.28e+00, For=2.13e+02, Power=6.79e-01
  [eval] val_mse=4.256e-01  (n=7000)
Epoch 00111: Time=   9.1s, Loss=3.28e+00, Inv=3.28e+00, For=2.16e+02, Power=6.83e-01
  [eval] val_mse=4.228e-01  (n=7000)
Epoch 00112: Time=   9.1s, Loss=3.27e+00, Inv=3.27e+00, For=2.22e+02, Power=6.85e-01
  [eval] val_mse=4.215e-01  (n=7000)
Epoch 00113: Time=   9.1s, Loss=3.27e+00, Inv=3.27e+00, For=2.24e+02, Power=6.86e-01
  [eval] val_mse=4.188e-01  (n=7000)
Epoch 00114: Time=   9.2s, Loss=3.26e+00, Inv=3.26e+00, For=2.30e+02, Power=6.83e-01
  [eval] val_mse=4.167e-01  (n=7000)
Epoch 00115: Time=   9.2s, Loss=3.26e+00, Inv=3.26e+00, For=2.30e+02, Power=6.81e-01
  [eval] val_mse=4.150e-01  (n=7000)
Epoch 00116: Time=   9.2s, Loss=3.25e+00, Inv=3.25e+00, For=2.38e+02, Power=6.81e-01
  [eval] val_mse=4.129e-01  (n=7000)
Epoch 00117: Time=   9.3s, Loss=3.24e+00, Inv=3.24e+00, For=2.41e+02, Power=6.81e-01
  [eval] val_mse=4.107e-01  (n=7000)
Epoch 00118: Time=   9.3s, Loss=3.24e+00, Inv=3.24e+00, For=2.46e+02, Power=6.80e-01
  [eval] val_mse=4.086e-01  (n=7000)
Epoch 00119: Time=   9.3s, Loss=3.23e+00, Inv=3.23e+00, For=2.51e+02, Power=6.80e-01
  [eval] val_mse=4.070e-01  (n=7000)
Epoch 00120: Time=   9.4s, Loss=3.23e+00, Inv=3.23e+00, For=2.51e+02, Power=6.82e-01
  [eval] val_mse=4.061e-01  (n=7000)
Epoch 00121: Time=   9.4s, Loss=3.22e+00, Inv=3.22e+00, For=2.58e+02, Power=6.83e-01
  [eval] val_mse=4.026e-01  (n=7000)
Epoch 00122: Time=   9.4s, Loss=3.22e+00, Inv=3.22e+00, For=2.65e+02, Power=6.82e-01
  [eval] val_mse=4.016e-01  (n=7000)
Epoch 00123: Time=   9.5s, Loss=3.21e+00, Inv=3.21e+00, For=2.66e+02, Power=6.81e-01
  [eval] val_mse=4.000e-01  (n=7000)
Epoch 00124: Time=   9.5s, Loss=3.21e+00, Inv=3.21e+00, For=2.66e+02, Power=6.83e-01
  [eval] val_mse=3.977e-01  (n=7000)
Epoch 00125: Time=   9.5s, Loss=3.21e+00, Inv=3.21e+00, For=2.74e+02, Power=6.82e-01
  [eval] val_mse=3.965e-01  (n=7000)
Epoch 00126: Time=   9.6s, Loss=3.20e+00, Inv=3.20e+00, For=2.80e+02, Power=6.84e-01
  [eval] val_mse=3.947e-01  (n=7000)
Epoch 00127: Time=   9.6s, Loss=3.20e+00, Inv=3.20e+00, For=2.84e+02, Power=6.81e-01
  [eval] val_mse=3.930e-01  (n=7000)
Epoch 00128: Time=   9.6s, Loss=3.19e+00, Inv=3.19e+00, For=2.87e+02, Power=6.80e-01
  [eval] val_mse=3.918e-01  (n=7000)
Epoch 00129: Time=   9.7s, Loss=3.19e+00, Inv=3.19e+00, For=2.94e+02, Power=6.80e-01
  [eval] val_mse=3.899e-01  (n=7000)
Epoch 00130: Time=   9.7s, Loss=3.19e+00, Inv=3.19e+00, For=2.99e+02, Power=6.80e-01
  [eval] val_mse=3.895e-01  (n=7000)
Epoch 00131: Time=   9.7s, Loss=3.18e+00, Inv=3.18e+00, For=2.95e+02, Power=6.83e-01
  [eval] val_mse=3.874e-01  (n=7000)
Epoch 00132: Time=   9.8s, Loss=3.18e+00, Inv=3.18e+00, For=3.09e+02, Power=6.80e-01
  [eval] val_mse=3.860e-01  (n=7000)
Epoch 00133: Time=   9.8s, Loss=3.17e+00, Inv=3.17e+00, For=3.05e+02, Power=6.82e-01
  [eval] val_mse=3.838e-01  (n=7000)
Epoch 00134: Time=   9.8s, Loss=3.17e+00, Inv=3.17e+00, For=3.11e+02, Power=6.81e-01
  [eval] val_mse=3.825e-01  (n=7000)
Epoch 00135: Time=   9.9s, Loss=3.16e+00, Inv=3.16e+00, For=3.15e+02, Power=6.79e-01
  [eval] val_mse=3.819e-01  (n=7000)
Epoch 00136: Time=   9.9s, Loss=3.16e+00, Inv=3.16e+00, For=3.27e+02, Power=6.81e-01
  [eval] val_mse=3.804e-01  (n=7000)
Epoch 00137: Time=   9.9s, Loss=3.16e+00, Inv=3.16e+00, For=3.17e+02, Power=6.82e-01
  [eval] val_mse=3.796e-01  (n=7000)
Epoch 00138: Time=  10.0s, Loss=3.16e+00, Inv=3.16e+00, For=3.35e+02, Power=6.78e-01
  [eval] val_mse=3.770e-01  (n=7000)
Epoch 00139: Time=  10.0s, Loss=3.15e+00, Inv=3.15e+00, For=3.31e+02, Power=6.81e-01
  [eval] val_mse=3.773e-01  (n=7000)
Epoch 00140: Time=  10.0s, Loss=3.15e+00, Inv=3.15e+00, For=3.39e+02, Power=6.81e-01
  [eval] val_mse=3.750e-01  (n=7000)
Epoch 00141: Time=  10.1s, Loss=3.15e+00, Inv=3.15e+00, For=3.45e+02, Power=6.81e-01
  [eval] val_mse=3.734e-01  (n=7000)
Epoch 00142: Time=  10.1s, Loss=3.15e+00, Inv=3.15e+00, For=3.45e+02, Power=6.81e-01
  [eval] val_mse=3.722e-01  (n=7000)
Epoch 00143: Time=  10.1s, Loss=3.14e+00, Inv=3.14e+00, For=3.49e+02, Power=6.80e-01
  [eval] val_mse=3.715e-01  (n=7000)
Epoch 00144: Time=  10.2s, Loss=3.14e+00, Inv=3.14e+00, For=3.58e+02, Power=6.81e-01
  [eval] val_mse=3.706e-01  (n=7000)
Epoch 00145: Time=  10.2s, Loss=3.13e+00, Inv=3.13e+00, For=3.55e+02, Power=6.80e-01
  [eval] val_mse=3.686e-01  (n=7000)
Epoch 00146: Time=  10.2s, Loss=3.13e+00, Inv=3.13e+00, For=3.62e+02, Power=6.80e-01
  [eval] val_mse=3.677e-01  (n=7000)
Epoch 00147: Time=  10.3s, Loss=3.12e+00, Inv=3.12e+00, For=3.66e+02, Power=6.79e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00148: Time=  10.3s, Loss=3.12e+00, Inv=3.12e+00, For=3.76e+02, Power=6.80e-01
  [eval] val_mse=3.662e-01  (n=7000)
Epoch 00149: Time=  10.3s, Loss=3.12e+00, Inv=3.12e+00, For=3.77e+02, Power=6.81e-01
  [eval] val_mse=3.648e-01  (n=7000)
Epoch 00150: Time=  10.4s, Loss=3.12e+00, Inv=3.12e+00, For=3.86e+02, Power=6.82e-01
  [eval] val_mse=3.649e-01  (n=7000)
Epoch 00151: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=3.80e+02, Power=6.81e-01
  [eval] val_mse=3.625e-01  (n=7000)
Epoch 00152: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=3.95e+02, Power=6.77e-01
  [eval] val_mse=3.617e-01  (n=7000)
Epoch 00153: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=3.88e+02, Power=6.76e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00154: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=4.04e+02, Power=6.79e-01
  [eval] val_mse=3.606e-01  (n=7000)
Epoch 00155: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=4.04e+02, Power=6.80e-01
  [eval] val_mse=3.590e-01  (n=7000)
Epoch 00156: Time=  10.6s, Loss=3.10e+00, Inv=3.10e+00, For=4.09e+02, Power=6.78e-01
  [eval] val_mse=3.588e-01  (n=7000)
Epoch 00157: Time=  10.6s, Loss=3.10e+00, Inv=3.10e+00, For=4.14e+02, Power=6.80e-01
  [eval] val_mse=3.576e-01  (n=7000)
Epoch 00158: Time=  10.6s, Loss=3.10e+00, Inv=3.10e+00, For=4.15e+02, Power=6.83e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00159: Time=  10.7s, Loss=3.09e+00, Inv=3.09e+00, For=4.18e+02, Power=6.83e-01
  [eval] val_mse=3.555e-01  (n=7000)
Epoch 00160: Time=  10.7s, Loss=3.09e+00, Inv=3.09e+00, For=4.30e+02, Power=6.81e-01
  [eval] val_mse=3.542e-01  (n=7000)
Epoch 00161: Time=  10.7s, Loss=3.09e+00, Inv=3.09e+00, For=4.26e+02, Power=6.81e-01
  [eval] val_mse=3.540e-01  (n=7000)
Epoch 00162: Time=  10.8s, Loss=3.09e+00, Inv=3.09e+00, For=4.42e+02, Power=6.81e-01
  [eval] val_mse=3.548e-01  (n=7000)
Epoch 00163: Time=  10.8s, Loss=3.08e+00, Inv=3.08e+00, For=4.35e+02, Power=6.79e-01
  [eval] val_mse=3.518e-01  (n=7000)
Epoch 00164: Time=  10.8s, Loss=3.08e+00, Inv=3.08e+00, For=4.52e+02, Power=6.82e-01
  [eval] val_mse=3.516e-01  (n=7000)
Epoch 00165: Time=  10.9s, Loss=3.08e+00, Inv=3.08e+00, For=4.53e+02, Power=6.82e-01
  [eval] val_mse=3.504e-01  (n=7000)
Epoch 00166: Time=  10.9s, Loss=3.08e+00, Inv=3.08e+00, For=4.55e+02, Power=6.79e-01
  [eval] val_mse=3.503e-01  (n=7000)
Epoch 00167: Time=  10.9s, Loss=3.07e+00, Inv=3.07e+00, For=4.54e+02, Power=6.82e-01
  [eval] val_mse=3.497e-01  (n=7000)
Epoch 00168: Time=  11.0s, Loss=3.07e+00, Inv=3.07e+00, For=4.66e+02, Power=6.81e-01
  [eval] val_mse=3.481e-01  (n=7000)
Epoch 00169: Time=  11.0s, Loss=3.07e+00, Inv=3.07e+00, For=4.65e+02, Power=6.76e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00170: Time=  11.0s, Loss=3.07e+00, Inv=3.07e+00, For=4.79e+02, Power=6.80e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00171: Time=  11.1s, Loss=3.07e+00, Inv=3.07e+00, For=4.83e+02, Power=6.81e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00172: Time=  11.1s, Loss=3.07e+00, Inv=3.07e+00, For=4.89e+02, Power=6.79e-01
  [eval] val_mse=3.464e-01  (n=7000)
Epoch 00173: Time=  11.1s, Loss=3.06e+00, Inv=3.06e+00, For=4.85e+02, Power=6.76e-01
  [eval] val_mse=3.453e-01  (n=7000)
Epoch 00174: Time=  11.2s, Loss=3.06e+00, Inv=3.06e+00, For=4.94e+02, Power=6.81e-01
  [eval] val_mse=3.444e-01  (n=7000)
Epoch 00175: Time=  11.2s, Loss=3.06e+00, Inv=3.06e+00, For=5.05e+02, Power=6.83e-01
  [eval] val_mse=3.439e-01  (n=7000)
Epoch 00176: Time=  11.2s, Loss=3.06e+00, Inv=3.06e+00, For=4.99e+02, Power=6.83e-01
  [eval] val_mse=3.429e-01  (n=7000)
Epoch 00177: Time=  11.3s, Loss=3.05e+00, Inv=3.05e+00, For=5.10e+02, Power=6.80e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00178: Time=  11.3s, Loss=3.05e+00, Inv=3.05e+00, For=5.25e+02, Power=6.80e-01
  [eval] val_mse=3.422e-01  (n=7000)
Epoch 00179: Time=  11.3s, Loss=3.05e+00, Inv=3.05e+00, For=5.27e+02, Power=6.81e-01
  [eval] val_mse=3.412e-01  (n=7000)
Epoch 00180: Time=  11.4s, Loss=3.05e+00, Inv=3.05e+00, For=5.26e+02, Power=6.82e-01
  [eval] val_mse=3.406e-01  (n=7000)
Epoch 00181: Time=  11.4s, Loss=3.04e+00, Inv=3.04e+00, For=5.17e+02, Power=6.80e-01
  [eval] val_mse=3.399e-01  (n=7000)
Epoch 00182: Time=  11.4s, Loss=3.04e+00, Inv=3.04e+00, For=5.32e+02, Power=6.82e-01
  [eval] val_mse=3.399e-01  (n=7000)
Epoch 00183: Time=  11.5s, Loss=3.04e+00, Inv=3.04e+00, For=5.44e+02, Power=6.78e-01
  [eval] val_mse=3.389e-01  (n=7000)
Epoch 00184: Time=  11.5s, Loss=3.04e+00, Inv=3.04e+00, For=5.31e+02, Power=6.80e-01
  [eval] val_mse=3.385e-01  (n=7000)
Epoch 00185: Time=  11.5s, Loss=3.04e+00, Inv=3.04e+00, For=5.57e+02, Power=6.79e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00186: Time=  11.6s, Loss=3.03e+00, Inv=3.03e+00, For=5.71e+02, Power=6.81e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00187: Time=  11.6s, Loss=3.04e+00, Inv=3.04e+00, For=5.55e+02, Power=6.80e-01
  [eval] val_mse=3.377e-01  (n=7000)
Epoch 00188: Time=  11.6s, Loss=3.03e+00, Inv=3.03e+00, For=5.76e+02, Power=6.78e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00189: Time=  11.7s, Loss=3.03e+00, Inv=3.03e+00, For=5.72e+02, Power=6.77e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00190: Time=  11.7s, Loss=3.03e+00, Inv=3.03e+00, For=5.84e+02, Power=6.79e-01
  [eval] val_mse=3.355e-01  (n=7000)
Epoch 00191: Time=  11.7s, Loss=3.03e+00, Inv=3.03e+00, For=5.92e+02, Power=6.80e-01
  [eval] val_mse=3.352e-01  (n=7000)
Epoch 00192: Time=  11.7s, Loss=3.02e+00, Inv=3.02e+00, For=5.93e+02, Power=6.79e-01
  [eval] val_mse=3.354e-01  (n=7000)
Epoch 00193: Time=  11.8s, Loss=3.02e+00, Inv=3.02e+00, For=5.81e+02, Power=6.80e-01
  [eval] val_mse=3.346e-01  (n=7000)
Epoch 00194: Time=  11.8s, Loss=3.02e+00, Inv=3.02e+00, For=5.95e+02, Power=6.80e-01
  [eval] val_mse=3.343e-01  (n=7000)
Epoch 00195: Time=  11.8s, Loss=3.02e+00, Inv=3.02e+00, For=6.15e+02, Power=6.78e-01
  [eval] val_mse=3.336e-01  (n=7000)
Epoch 00196: Time=  11.9s, Loss=3.02e+00, Inv=3.02e+00, For=6.25e+02, Power=6.80e-01
  [eval] val_mse=3.328e-01  (n=7000)
Epoch 00197: Time=  11.9s, Loss=3.02e+00, Inv=3.02e+00, For=6.14e+02, Power=6.79e-01
  [eval] val_mse=3.335e-01  (n=7000)
Epoch 00198: Time=  11.9s, Loss=3.02e+00, Inv=3.02e+00, For=6.17e+02, Power=6.82e-01
  [eval] val_mse=3.317e-01  (n=7000)
Epoch 00199: Time=  12.0s, Loss=3.01e+00, Inv=3.01e+00, For=6.31e+02, Power=6.77e-01
  [eval] val_mse=3.322e-01  (n=7000)
Epoch 00200: Time=  12.0s, Loss=3.01e+00, Inv=3.01e+00, For=6.21e+02, Power=6.81e-01
  [eval] val_mse=3.315e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 2.351e-01
Torque MSE  = 6.816e-02
Torque RMSE = 2.611e-01
Per-joint MSE : 7.384e-02 1.637e-01 4.474e-02 2.096e-02 7.825e-02 2.744e-02
Per-joint RMSE: 2.717e-01 4.047e-01 2.115e-01 1.448e-01 2.797e-01 1.657e-01
Comp Time per Sample = 2.907e-04s / 3440.4Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-fugbmqab because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7310604d68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:48:07.855886: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:48:09.676832: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.8s, Loss=2.38e+03, Inv=2.38e+03, For=5.71e+00, Power=4.63e+02
  [eval] val_mse=3.623e+01  (n=7000)
Epoch 00002: Time=   5.4s, Loss=1.37e+02, Inv=1.37e+02, For=5.32e+00, Power=2.88e+01
  [eval] val_mse=1.544e+01  (n=7000)
Epoch 00003: Time=   5.4s, Loss=6.78e+01, Inv=6.78e+01, For=5.12e+00, Power=1.31e+01
  [eval] val_mse=1.086e+01  (n=7000)
Epoch 00004: Time=   5.5s, Loss=4.54e+01, Inv=4.54e+01, For=5.12e+00, Power=8.05e+00
  [eval] val_mse=8.283e+00  (n=7000)
Epoch 00005: Time=   5.5s, Loss=3.34e+01, Inv=3.34e+01, For=5.25e+00, Power=5.62e+00
  [eval] val_mse=6.539e+00  (n=7000)
Epoch 00006: Time=   5.5s, Loss=2.57e+01, Inv=2.57e+01, For=5.41e+00, Power=4.15e+00
  [eval] val_mse=5.299e+00  (n=7000)
Epoch 00007: Time=   5.6s, Loss=2.08e+01, Inv=2.08e+01, For=5.68e+00, Power=3.23e+00
  [eval] val_mse=4.382e+00  (n=7000)
Epoch 00008: Time=   5.6s, Loss=1.73e+01, Inv=1.73e+01, For=6.03e+00, Power=2.63e+00
  [eval] val_mse=3.693e+00  (n=7000)
Epoch 00009: Time=   5.6s, Loss=1.47e+01, Inv=1.47e+01, For=6.47e+00, Power=2.19e+00
  [eval] val_mse=3.174e+00  (n=7000)
Epoch 00010: Time=   5.7s, Loss=1.29e+01, Inv=1.29e+01, For=6.95e+00, Power=1.89e+00
  [eval] val_mse=2.758e+00  (n=7000)
Epoch 00011: Time=   5.7s, Loss=1.14e+01, Inv=1.14e+01, For=7.45e+00, Power=1.67e+00
  [eval] val_mse=2.430e+00  (n=7000)
Epoch 00012: Time=   5.7s, Loss=1.03e+01, Inv=1.03e+01, For=8.00e+00, Power=1.50e+00
  [eval] val_mse=2.167e+00  (n=7000)
Epoch 00013: Time=   5.8s, Loss=9.36e+00, Inv=9.36e+00, For=8.61e+00, Power=1.36e+00
  [eval] val_mse=1.956e+00  (n=7000)
Epoch 00014: Time=   5.8s, Loss=8.63e+00, Inv=8.63e+00, For=9.15e+00, Power=1.26e+00
  [eval] val_mse=1.782e+00  (n=7000)
Epoch 00015: Time=   5.8s, Loss=8.02e+00, Inv=8.02e+00, For=9.71e+00, Power=1.18e+00
  [eval] val_mse=1.639e+00  (n=7000)
Epoch 00016: Time=   5.9s, Loss=7.52e+00, Inv=7.52e+00, For=1.03e+01, Power=1.11e+00
  [eval] val_mse=1.520e+00  (n=7000)
Epoch 00017: Time=   5.9s, Loss=7.08e+00, Inv=7.08e+00, For=1.08e+01, Power=1.05e+00
  [eval] val_mse=1.418e+00  (n=7000)
Epoch 00018: Time=   5.9s, Loss=6.72e+00, Inv=6.72e+00, For=1.13e+01, Power=1.01e+00
  [eval] val_mse=1.334e+00  (n=7000)
Epoch 00019: Time=   6.0s, Loss=6.43e+00, Inv=6.43e+00, For=1.19e+01, Power=9.77e-01
  [eval] val_mse=1.261e+00  (n=7000)
Epoch 00020: Time=   6.0s, Loss=6.15e+00, Inv=6.15e+00, For=1.24e+01, Power=9.46e-01
  [eval] val_mse=1.195e+00  (n=7000)
Epoch 00021: Time=   6.0s, Loss=5.92e+00, Inv=5.92e+00, For=1.30e+01, Power=9.16e-01
  [eval] val_mse=1.139e+00  (n=7000)
Epoch 00022: Time=   6.1s, Loss=5.73e+00, Inv=5.73e+00, For=1.36e+01, Power=8.96e-01
  [eval] val_mse=1.088e+00  (n=7000)
Epoch 00023: Time=   6.1s, Loss=5.55e+00, Inv=5.55e+00, For=1.41e+01, Power=8.76e-01
  [eval] val_mse=1.042e+00  (n=7000)
Epoch 00024: Time=   6.1s, Loss=5.41e+00, Inv=5.41e+00, For=1.47e+01, Power=8.62e-01
  [eval] val_mse=9.991e-01  (n=7000)
Epoch 00025: Time=   6.2s, Loss=5.25e+00, Inv=5.25e+00, For=1.54e+01, Power=8.46e-01
  [eval] val_mse=9.638e-01  (n=7000)
Epoch 00026: Time=   6.2s, Loss=5.13e+00, Inv=5.13e+00, For=1.59e+01, Power=8.29e-01
  [eval] val_mse=9.291e-01  (n=7000)
Epoch 00027: Time=   6.3s, Loss=5.01e+00, Inv=5.01e+00, For=1.64e+01, Power=8.17e-01
  [eval] val_mse=8.991e-01  (n=7000)
Epoch 00028: Time=   6.3s, Loss=4.91e+00, Inv=4.91e+00, For=1.73e+01, Power=8.11e-01
  [eval] val_mse=8.710e-01  (n=7000)
Epoch 00029: Time=   6.3s, Loss=4.82e+00, Inv=4.82e+00, For=1.79e+01, Power=8.02e-01
  [eval] val_mse=8.432e-01  (n=7000)
Epoch 00030: Time=   6.4s, Loss=4.73e+00, Inv=4.73e+00, For=1.86e+01, Power=7.94e-01
  [eval] val_mse=8.177e-01  (n=7000)
Epoch 00031: Time=   6.4s, Loss=4.65e+00, Inv=4.65e+00, For=1.93e+01, Power=7.86e-01
  [eval] val_mse=7.979e-01  (n=7000)
Epoch 00032: Time=   6.4s, Loss=4.58e+00, Inv=4.58e+00, For=1.99e+01, Power=7.85e-01
  [eval] val_mse=7.755e-01  (n=7000)
Epoch 00033: Time=   6.5s, Loss=4.51e+00, Inv=4.51e+00, For=2.05e+01, Power=7.76e-01
  [eval] val_mse=7.558e-01  (n=7000)
Epoch 00034: Time=   6.5s, Loss=4.43e+00, Inv=4.43e+00, For=2.12e+01, Power=7.64e-01
  [eval] val_mse=7.367e-01  (n=7000)
Epoch 00035: Time=   6.5s, Loss=4.38e+00, Inv=4.38e+00, For=2.22e+01, Power=7.69e-01
  [eval] val_mse=7.201e-01  (n=7000)
Epoch 00036: Time=   6.6s, Loss=4.31e+00, Inv=4.31e+00, For=2.26e+01, Power=7.59e-01
  [eval] val_mse=7.044e-01  (n=7000)
Epoch 00037: Time=   6.6s, Loss=4.27e+00, Inv=4.27e+00, For=2.35e+01, Power=7.58e-01
  [eval] val_mse=6.904e-01  (n=7000)
Epoch 00038: Time=   6.6s, Loss=4.21e+00, Inv=4.21e+00, For=2.42e+01, Power=7.54e-01
  [eval] val_mse=6.749e-01  (n=7000)
Epoch 00039: Time=   6.7s, Loss=4.17e+00, Inv=4.17e+00, For=2.51e+01, Power=7.49e-01
  [eval] val_mse=6.624e-01  (n=7000)
Epoch 00040: Time=   6.7s, Loss=4.12e+00, Inv=4.12e+00, For=2.58e+01, Power=7.48e-01
  [eval] val_mse=6.486e-01  (n=7000)
Epoch 00041: Time=   6.7s, Loss=4.08e+00, Inv=4.08e+00, For=2.66e+01, Power=7.45e-01
  [eval] val_mse=6.385e-01  (n=7000)
Epoch 00042: Time=   6.8s, Loss=4.04e+00, Inv=4.04e+00, For=2.74e+01, Power=7.42e-01
  [eval] val_mse=6.272e-01  (n=7000)
Epoch 00043: Time=   6.8s, Loss=4.00e+00, Inv=4.00e+00, For=2.80e+01, Power=7.40e-01
  [eval] val_mse=6.152e-01  (n=7000)
Epoch 00044: Time=   6.8s, Loss=3.96e+00, Inv=3.96e+00, For=2.92e+01, Power=7.33e-01
  [eval] val_mse=6.056e-01  (n=7000)
Epoch 00045: Time=   6.9s, Loss=3.93e+00, Inv=3.93e+00, For=2.97e+01, Power=7.34e-01
  [eval] val_mse=5.968e-01  (n=7000)
Epoch 00046: Time=   6.9s, Loss=3.89e+00, Inv=3.89e+00, For=3.08e+01, Power=7.30e-01
  [eval] val_mse=5.880e-01  (n=7000)
Epoch 00047: Time=   6.9s, Loss=3.86e+00, Inv=3.86e+00, For=3.19e+01, Power=7.28e-01
  [eval] val_mse=5.791e-01  (n=7000)
Epoch 00048: Time=   7.0s, Loss=3.83e+00, Inv=3.83e+00, For=3.22e+01, Power=7.29e-01
  [eval] val_mse=5.711e-01  (n=7000)
Epoch 00049: Time=   7.0s, Loss=3.81e+00, Inv=3.81e+00, For=3.36e+01, Power=7.26e-01
  [eval] val_mse=5.630e-01  (n=7000)
Epoch 00050: Time=   7.0s, Loss=3.78e+00, Inv=3.78e+00, For=3.40e+01, Power=7.25e-01
  [eval] val_mse=5.562e-01  (n=7000)
Epoch 00051: Time=   7.1s, Loss=3.76e+00, Inv=3.76e+00, For=3.49e+01, Power=7.20e-01
  [eval] val_mse=5.479e-01  (n=7000)
Epoch 00052: Time=   7.1s, Loss=3.73e+00, Inv=3.73e+00, For=3.61e+01, Power=7.22e-01
  [eval] val_mse=5.419e-01  (n=7000)
Epoch 00053: Time=   7.1s, Loss=3.71e+00, Inv=3.71e+00, For=3.63e+01, Power=7.19e-01
  [eval] val_mse=5.346e-01  (n=7000)
Epoch 00054: Time=   7.2s, Loss=3.69e+00, Inv=3.69e+00, For=3.81e+01, Power=7.17e-01
  [eval] val_mse=5.306e-01  (n=7000)
Epoch 00055: Time=   7.2s, Loss=3.67e+00, Inv=3.67e+00, For=3.89e+01, Power=7.19e-01
  [eval] val_mse=5.226e-01  (n=7000)
Epoch 00056: Time=   7.2s, Loss=3.65e+00, Inv=3.65e+00, For=3.96e+01, Power=7.13e-01
  [eval] val_mse=5.174e-01  (n=7000)
Epoch 00057: Time=   7.3s, Loss=3.63e+00, Inv=3.63e+00, For=4.00e+01, Power=7.15e-01
  [eval] val_mse=5.106e-01  (n=7000)
Epoch 00058: Time=   7.3s, Loss=3.61e+00, Inv=3.61e+00, For=4.18e+01, Power=7.11e-01
  [eval] val_mse=5.052e-01  (n=7000)
Epoch 00059: Time=   7.3s, Loss=3.59e+00, Inv=3.59e+00, For=4.10e+01, Power=7.09e-01
  [eval] val_mse=5.002e-01  (n=7000)
Epoch 00060: Time=   7.4s, Loss=3.58e+00, Inv=3.58e+00, For=4.31e+01, Power=7.11e-01
  [eval] val_mse=4.959e-01  (n=7000)
Epoch 00061: Time=   7.4s, Loss=3.57e+00, Inv=3.57e+00, For=4.43e+01, Power=7.05e-01
  [eval] val_mse=4.896e-01  (n=7000)
Epoch 00062: Time=   7.4s, Loss=3.55e+00, Inv=3.55e+00, For=4.48e+01, Power=7.06e-01
  [eval] val_mse=4.854e-01  (n=7000)
Epoch 00063: Time=   7.5s, Loss=3.54e+00, Inv=3.54e+00, For=4.56e+01, Power=7.08e-01
  [eval] val_mse=4.808e-01  (n=7000)
Epoch 00064: Time=   7.5s, Loss=3.52e+00, Inv=3.52e+00, For=4.64e+01, Power=7.04e-01
  [eval] val_mse=4.766e-01  (n=7000)
Epoch 00065: Time=   7.5s, Loss=3.51e+00, Inv=3.51e+00, For=4.75e+01, Power=7.05e-01
  [eval] val_mse=4.722e-01  (n=7000)
Epoch 00066: Time=   7.6s, Loss=3.50e+00, Inv=3.50e+00, For=4.78e+01, Power=7.06e-01
  [eval] val_mse=4.681e-01  (n=7000)
Epoch 00067: Time=   7.6s, Loss=3.48e+00, Inv=3.48e+00, For=4.84e+01, Power=7.01e-01
  [eval] val_mse=4.631e-01  (n=7000)
Epoch 00068: Time=   7.6s, Loss=3.48e+00, Inv=3.48e+00, For=4.97e+01, Power=7.03e-01
  [eval] val_mse=4.608e-01  (n=7000)
Epoch 00069: Time=   7.7s, Loss=3.46e+00, Inv=3.46e+00, For=5.08e+01, Power=7.00e-01
  [eval] val_mse=4.569e-01  (n=7000)
Epoch 00070: Time=   7.7s, Loss=3.45e+00, Inv=3.45e+00, For=5.12e+01, Power=6.98e-01
  [eval] val_mse=4.529e-01  (n=7000)
Epoch 00071: Time=   7.7s, Loss=3.44e+00, Inv=3.44e+00, For=5.22e+01, Power=7.00e-01
  [eval] val_mse=4.496e-01  (n=7000)
Epoch 00072: Time=   7.8s, Loss=3.43e+00, Inv=3.43e+00, For=5.33e+01, Power=6.97e-01
  [eval] val_mse=4.458e-01  (n=7000)
Epoch 00073: Time=   7.8s, Loss=3.42e+00, Inv=3.42e+00, For=5.43e+01, Power=7.00e-01
  [eval] val_mse=4.422e-01  (n=7000)
Epoch 00074: Time=   7.8s, Loss=3.41e+00, Inv=3.41e+00, For=5.46e+01, Power=6.96e-01
  [eval] val_mse=4.393e-01  (n=7000)
Epoch 00075: Time=   7.9s, Loss=3.40e+00, Inv=3.40e+00, For=5.49e+01, Power=6.96e-01
  [eval] val_mse=4.363e-01  (n=7000)
Epoch 00076: Time=   7.9s, Loss=3.39e+00, Inv=3.39e+00, For=5.82e+01, Power=6.96e-01
  [eval] val_mse=4.332e-01  (n=7000)
Epoch 00077: Time=   7.9s, Loss=3.38e+00, Inv=3.38e+00, For=5.74e+01, Power=6.93e-01
  [eval] val_mse=4.302e-01  (n=7000)
Epoch 00078: Time=   8.0s, Loss=3.38e+00, Inv=3.38e+00, For=5.79e+01, Power=6.96e-01
  [eval] val_mse=4.276e-01  (n=7000)
Epoch 00079: Time=   8.0s, Loss=3.37e+00, Inv=3.37e+00, For=5.97e+01, Power=6.96e-01
  [eval] val_mse=4.256e-01  (n=7000)
Epoch 00080: Time=   8.0s, Loss=3.36e+00, Inv=3.36e+00, For=5.89e+01, Power=6.96e-01
  [eval] val_mse=4.224e-01  (n=7000)
Epoch 00081: Time=   8.1s, Loss=3.36e+00, Inv=3.36e+00, For=6.18e+01, Power=6.94e-01
  [eval] val_mse=4.201e-01  (n=7000)
Epoch 00082: Time=   8.1s, Loss=3.34e+00, Inv=3.34e+00, For=6.20e+01, Power=6.91e-01
  [eval] val_mse=4.179e-01  (n=7000)
Epoch 00083: Time=   8.1s, Loss=3.33e+00, Inv=3.33e+00, For=6.15e+01, Power=6.88e-01
  [eval] val_mse=4.147e-01  (n=7000)
Epoch 00084: Time=   8.2s, Loss=3.33e+00, Inv=3.33e+00, For=6.42e+01, Power=6.91e-01
  [eval] val_mse=4.137e-01  (n=7000)
Epoch 00085: Time=   8.2s, Loss=3.32e+00, Inv=3.32e+00, For=6.49e+01, Power=6.90e-01
  [eval] val_mse=4.111e-01  (n=7000)
Epoch 00086: Time=   8.2s, Loss=3.32e+00, Inv=3.32e+00, For=6.48e+01, Power=6.90e-01
  [eval] val_mse=4.084e-01  (n=7000)
Epoch 00087: Time=   8.3s, Loss=3.31e+00, Inv=3.31e+00, For=6.54e+01, Power=6.91e-01
  [eval] val_mse=4.065e-01  (n=7000)
Epoch 00088: Time=   8.3s, Loss=3.30e+00, Inv=3.30e+00, For=6.64e+01, Power=6.88e-01
  [eval] val_mse=4.042e-01  (n=7000)
Epoch 00089: Time=   8.3s, Loss=3.30e+00, Inv=3.30e+00, For=6.89e+01, Power=6.89e-01
  [eval] val_mse=4.029e-01  (n=7000)
Epoch 00090: Time=   8.4s, Loss=3.28e+00, Inv=3.28e+00, For=6.86e+01, Power=6.90e-01
  [eval] val_mse=4.008e-01  (n=7000)
Epoch 00091: Time=   8.4s, Loss=3.28e+00, Inv=3.28e+00, For=7.00e+01, Power=6.91e-01
  [eval] val_mse=3.988e-01  (n=7000)
Epoch 00092: Time=   8.4s, Loss=3.28e+00, Inv=3.28e+00, For=7.16e+01, Power=6.87e-01
  [eval] val_mse=3.968e-01  (n=7000)
Epoch 00093: Time=   8.5s, Loss=3.27e+00, Inv=3.27e+00, For=7.12e+01, Power=6.88e-01
  [eval] val_mse=3.962e-01  (n=7000)
Epoch 00094: Time=   8.5s, Loss=3.27e+00, Inv=3.27e+00, For=7.29e+01, Power=6.89e-01
  [eval] val_mse=3.935e-01  (n=7000)
Epoch 00095: Time=   8.5s, Loss=3.26e+00, Inv=3.26e+00, For=7.42e+01, Power=6.88e-01
  [eval] val_mse=3.934e-01  (n=7000)
Epoch 00096: Time=   8.6s, Loss=3.26e+00, Inv=3.26e+00, For=7.43e+01, Power=6.90e-01
  [eval] val_mse=3.916e-01  (n=7000)
Epoch 00097: Time=   8.6s, Loss=3.25e+00, Inv=3.25e+00, For=7.51e+01, Power=6.87e-01
  [eval] val_mse=3.894e-01  (n=7000)
Epoch 00098: Time=   8.6s, Loss=3.24e+00, Inv=3.24e+00, For=7.73e+01, Power=6.87e-01
  [eval] val_mse=3.880e-01  (n=7000)
Epoch 00099: Time=   8.7s, Loss=3.24e+00, Inv=3.24e+00, For=7.75e+01, Power=6.85e-01
  [eval] val_mse=3.868e-01  (n=7000)
Epoch 00100: Time=   8.7s, Loss=3.23e+00, Inv=3.23e+00, For=7.85e+01, Power=6.85e-01
  [eval] val_mse=3.853e-01  (n=7000)
Epoch 00101: Time=   8.7s, Loss=3.23e+00, Inv=3.23e+00, For=7.98e+01, Power=6.86e-01
  [eval] val_mse=3.841e-01  (n=7000)
Epoch 00102: Time=   8.8s, Loss=3.22e+00, Inv=3.22e+00, For=8.03e+01, Power=6.81e-01
  [eval] val_mse=3.827e-01  (n=7000)
Epoch 00103: Time=   8.8s, Loss=3.22e+00, Inv=3.22e+00, For=8.20e+01, Power=6.88e-01
  [eval] val_mse=3.816e-01  (n=7000)
Epoch 00104: Time=   8.8s, Loss=3.22e+00, Inv=3.22e+00, For=8.24e+01, Power=6.87e-01
  [eval] val_mse=3.812e-01  (n=7000)
Epoch 00105: Time=   8.9s, Loss=3.21e+00, Inv=3.21e+00, For=8.45e+01, Power=6.83e-01
  [eval] val_mse=3.795e-01  (n=7000)
Epoch 00106: Time=   8.9s, Loss=3.21e+00, Inv=3.21e+00, For=8.45e+01, Power=6.81e-01
  [eval] val_mse=3.782e-01  (n=7000)
Epoch 00107: Time=   8.9s, Loss=3.21e+00, Inv=3.21e+00, For=8.54e+01, Power=6.85e-01
  [eval] val_mse=3.775e-01  (n=7000)
Epoch 00108: Time=   9.0s, Loss=3.20e+00, Inv=3.20e+00, For=8.78e+01, Power=6.85e-01
  [eval] val_mse=3.760e-01  (n=7000)
Epoch 00109: Time=   9.0s, Loss=3.19e+00, Inv=3.19e+00, For=8.84e+01, Power=6.84e-01
  [eval] val_mse=3.750e-01  (n=7000)
Epoch 00110: Time=   9.0s, Loss=3.19e+00, Inv=3.19e+00, For=8.78e+01, Power=6.83e-01
  [eval] val_mse=3.742e-01  (n=7000)
Epoch 00111: Time=   9.1s, Loss=3.19e+00, Inv=3.19e+00, For=9.06e+01, Power=6.87e-01
  [eval] val_mse=3.732e-01  (n=7000)
Epoch 00112: Time=   9.1s, Loss=3.18e+00, Inv=3.18e+00, For=9.18e+01, Power=6.85e-01
  [eval] val_mse=3.725e-01  (n=7000)
Epoch 00113: Time=   9.1s, Loss=3.19e+00, Inv=3.19e+00, For=9.28e+01, Power=6.85e-01
  [eval] val_mse=3.718e-01  (n=7000)
Epoch 00114: Time=   9.2s, Loss=3.17e+00, Inv=3.17e+00, For=9.44e+01, Power=6.83e-01
  [eval] val_mse=3.710e-01  (n=7000)
Epoch 00115: Time=   9.2s, Loss=3.17e+00, Inv=3.17e+00, For=9.57e+01, Power=6.83e-01
  [eval] val_mse=3.705e-01  (n=7000)
Epoch 00116: Time=   9.2s, Loss=3.17e+00, Inv=3.17e+00, For=9.46e+01, Power=6.83e-01
  [eval] val_mse=3.691e-01  (n=7000)
Epoch 00117: Time=   9.3s, Loss=3.16e+00, Inv=3.16e+00, For=9.78e+01, Power=6.81e-01
  [eval] val_mse=3.685e-01  (n=7000)
Epoch 00118: Time=   9.3s, Loss=3.15e+00, Inv=3.15e+00, For=9.86e+01, Power=6.80e-01
  [eval] val_mse=3.674e-01  (n=7000)
Epoch 00119: Time=   9.3s, Loss=3.15e+00, Inv=3.15e+00, For=9.94e+01, Power=6.81e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00120: Time=   9.4s, Loss=3.15e+00, Inv=3.15e+00, For=1.00e+02, Power=6.79e-01
  [eval] val_mse=3.667e-01  (n=7000)
Epoch 00121: Time=   9.4s, Loss=3.15e+00, Inv=3.15e+00, For=1.04e+02, Power=6.81e-01
  [eval] val_mse=3.655e-01  (n=7000)
Epoch 00122: Time=   9.5s, Loss=3.15e+00, Inv=3.15e+00, For=1.03e+02, Power=6.84e-01
  [eval] val_mse=3.640e-01  (n=7000)
Epoch 00123: Time=   9.5s, Loss=3.14e+00, Inv=3.14e+00, For=1.04e+02, Power=6.84e-01
  [eval] val_mse=3.639e-01  (n=7000)
Epoch 00124: Time=   9.5s, Loss=3.14e+00, Inv=3.14e+00, For=1.06e+02, Power=6.82e-01
  [eval] val_mse=3.637e-01  (n=7000)
Epoch 00125: Time=   9.6s, Loss=3.13e+00, Inv=3.13e+00, For=1.08e+02, Power=6.83e-01
  [eval] val_mse=3.630e-01  (n=7000)
Epoch 00126: Time=   9.6s, Loss=3.13e+00, Inv=3.13e+00, For=1.08e+02, Power=6.82e-01
  [eval] val_mse=3.610e-01  (n=7000)
Epoch 00127: Time=   9.6s, Loss=3.12e+00, Inv=3.12e+00, For=1.10e+02, Power=6.80e-01
  [eval] val_mse=3.614e-01  (n=7000)
Epoch 00128: Time=   9.7s, Loss=3.12e+00, Inv=3.12e+00, For=1.12e+02, Power=6.80e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00129: Time=   9.7s, Loss=3.12e+00, Inv=3.12e+00, For=1.12e+02, Power=6.81e-01
  [eval] val_mse=3.591e-01  (n=7000)
Epoch 00130: Time=   9.7s, Loss=3.12e+00, Inv=3.12e+00, For=1.15e+02, Power=6.80e-01
  [eval] val_mse=3.591e-01  (n=7000)
Epoch 00131: Time=   9.8s, Loss=3.12e+00, Inv=3.12e+00, For=1.15e+02, Power=6.83e-01
  [eval] val_mse=3.578e-01  (n=7000)
Epoch 00132: Time=   9.8s, Loss=3.11e+00, Inv=3.11e+00, For=1.17e+02, Power=6.82e-01
  [eval] val_mse=3.573e-01  (n=7000)
Epoch 00133: Time=   9.8s, Loss=3.11e+00, Inv=3.11e+00, For=1.19e+02, Power=6.81e-01
  [eval] val_mse=3.571e-01  (n=7000)
Epoch 00134: Time=   9.9s, Loss=3.11e+00, Inv=3.11e+00, For=1.20e+02, Power=6.80e-01
  [eval] val_mse=3.569e-01  (n=7000)
Epoch 00135: Time=   9.9s, Loss=3.11e+00, Inv=3.11e+00, For=1.21e+02, Power=6.81e-01
  [eval] val_mse=3.558e-01  (n=7000)
Epoch 00136: Time=   9.9s, Loss=3.10e+00, Inv=3.10e+00, For=1.24e+02, Power=6.83e-01
  [eval] val_mse=3.556e-01  (n=7000)
Epoch 00137: Time=  10.0s, Loss=3.10e+00, Inv=3.10e+00, For=1.23e+02, Power=6.81e-01
  [eval] val_mse=3.549e-01  (n=7000)
Epoch 00138: Time=  10.0s, Loss=3.10e+00, Inv=3.10e+00, For=1.24e+02, Power=6.79e-01
  [eval] val_mse=3.538e-01  (n=7000)
Epoch 00139: Time=  10.0s, Loss=3.09e+00, Inv=3.09e+00, For=1.26e+02, Power=6.79e-01
  [eval] val_mse=3.538e-01  (n=7000)
Epoch 00140: Time=  10.1s, Loss=3.09e+00, Inv=3.09e+00, For=1.29e+02, Power=6.80e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00141: Time=  10.1s, Loss=3.09e+00, Inv=3.09e+00, For=1.29e+02, Power=6.81e-01
  [eval] val_mse=3.536e-01  (n=7000)
Epoch 00142: Time=  10.1s, Loss=3.09e+00, Inv=3.09e+00, For=1.31e+02, Power=6.83e-01
  [eval] val_mse=3.523e-01  (n=7000)
Epoch 00143: Time=  10.2s, Loss=3.08e+00, Inv=3.08e+00, For=1.31e+02, Power=6.82e-01
  [eval] val_mse=3.517e-01  (n=7000)
Epoch 00144: Time=  10.2s, Loss=3.08e+00, Inv=3.08e+00, For=1.34e+02, Power=6.82e-01
  [eval] val_mse=3.511e-01  (n=7000)
Epoch 00145: Time=  10.2s, Loss=3.08e+00, Inv=3.08e+00, For=1.34e+02, Power=6.85e-01
  [eval] val_mse=3.501e-01  (n=7000)
Epoch 00146: Time=  10.3s, Loss=3.07e+00, Inv=3.07e+00, For=1.38e+02, Power=6.78e-01
  [eval] val_mse=3.502e-01  (n=7000)
Epoch 00147: Time=  10.3s, Loss=3.07e+00, Inv=3.07e+00, For=1.38e+02, Power=6.82e-01
  [eval] val_mse=3.503e-01  (n=7000)
Epoch 00148: Time=  10.3s, Loss=3.07e+00, Inv=3.07e+00, For=1.40e+02, Power=6.81e-01
  [eval] val_mse=3.490e-01  (n=7000)
Epoch 00149: Time=  10.4s, Loss=3.08e+00, Inv=3.08e+00, For=1.40e+02, Power=6.80e-01
  [eval] val_mse=3.483e-01  (n=7000)
Epoch 00150: Time=  10.4s, Loss=3.07e+00, Inv=3.07e+00, For=1.45e+02, Power=6.80e-01
  [eval] val_mse=3.478e-01  (n=7000)
Epoch 00151: Time=  10.4s, Loss=3.07e+00, Inv=3.07e+00, For=1.44e+02, Power=6.81e-01
  [eval] val_mse=3.485e-01  (n=7000)
Epoch 00152: Time=  10.5s, Loss=3.06e+00, Inv=3.06e+00, For=1.45e+02, Power=6.80e-01
  [eval] val_mse=3.476e-01  (n=7000)
Epoch 00153: Time=  10.5s, Loss=3.06e+00, Inv=3.06e+00, For=1.44e+02, Power=6.79e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00154: Time=  10.5s, Loss=3.06e+00, Inv=3.06e+00, For=1.48e+02, Power=6.82e-01
  [eval] val_mse=3.468e-01  (n=7000)
Epoch 00155: Time=  10.6s, Loss=3.06e+00, Inv=3.06e+00, For=1.49e+02, Power=6.80e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00156: Time=  10.6s, Loss=3.05e+00, Inv=3.05e+00, For=1.49e+02, Power=6.82e-01
  [eval] val_mse=3.455e-01  (n=7000)
Epoch 00157: Time=  10.6s, Loss=3.05e+00, Inv=3.05e+00, For=1.53e+02, Power=6.80e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00158: Time=  10.7s, Loss=3.04e+00, Inv=3.04e+00, For=1.51e+02, Power=6.79e-01
  [eval] val_mse=3.449e-01  (n=7000)
Epoch 00159: Time=  10.7s, Loss=3.05e+00, Inv=3.05e+00, For=1.55e+02, Power=6.82e-01
  [eval] val_mse=3.441e-01  (n=7000)
Epoch 00160: Time=  10.7s, Loss=3.04e+00, Inv=3.04e+00, For=1.55e+02, Power=6.80e-01
  [eval] val_mse=3.436e-01  (n=7000)
Epoch 00161: Time=  10.8s, Loss=3.04e+00, Inv=3.04e+00, For=1.58e+02, Power=6.81e-01
  [eval] val_mse=3.432e-01  (n=7000)
Epoch 00162: Time=  10.8s, Loss=3.05e+00, Inv=3.05e+00, For=1.57e+02, Power=6.81e-01
  [eval] val_mse=3.439e-01  (n=7000)
Epoch 00163: Time=  10.8s, Loss=3.04e+00, Inv=3.04e+00, For=1.59e+02, Power=6.81e-01
  [eval] val_mse=3.432e-01  (n=7000)
Epoch 00164: Time=  10.9s, Loss=3.04e+00, Inv=3.04e+00, For=1.61e+02, Power=6.81e-01
  [eval] val_mse=3.423e-01  (n=7000)
Epoch 00165: Time=  10.9s, Loss=3.04e+00, Inv=3.04e+00, For=1.60e+02, Power=6.82e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00166: Time=  10.9s, Loss=3.04e+00, Inv=3.04e+00, For=1.62e+02, Power=6.80e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00167: Time=  11.0s, Loss=3.04e+00, Inv=3.04e+00, For=1.66e+02, Power=6.82e-01
  [eval] val_mse=3.407e-01  (n=7000)
Epoch 00168: Time=  11.0s, Loss=3.03e+00, Inv=3.03e+00, For=1.65e+02, Power=6.81e-01
  [eval] val_mse=3.414e-01  (n=7000)
Epoch 00169: Time=  11.0s, Loss=3.03e+00, Inv=3.03e+00, For=1.69e+02, Power=6.82e-01
  [eval] val_mse=3.404e-01  (n=7000)
Epoch 00170: Time=  11.1s, Loss=3.03e+00, Inv=3.03e+00, For=1.67e+02, Power=6.82e-01
  [eval] val_mse=3.422e-01  (n=7000)
Epoch 00171: Time=  11.1s, Loss=3.03e+00, Inv=3.03e+00, For=1.68e+02, Power=6.83e-01
  [eval] val_mse=3.404e-01  (n=7000)
Epoch 00172: Time=  11.1s, Loss=3.02e+00, Inv=3.02e+00, For=1.70e+02, Power=6.82e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00173: Time=  11.2s, Loss=3.02e+00, Inv=3.02e+00, For=1.71e+02, Power=6.81e-01
  [eval] val_mse=3.390e-01  (n=7000)
Epoch 00174: Time=  11.2s, Loss=3.03e+00, Inv=3.03e+00, For=1.72e+02, Power=6.82e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00175: Time=  11.2s, Loss=3.02e+00, Inv=3.02e+00, For=1.71e+02, Power=6.80e-01
  [eval] val_mse=3.382e-01  (n=7000)
Epoch 00176: Time=  11.3s, Loss=3.02e+00, Inv=3.02e+00, For=1.75e+02, Power=6.82e-01
  [eval] val_mse=3.387e-01  (n=7000)
Epoch 00177: Time=  11.3s, Loss=3.02e+00, Inv=3.02e+00, For=1.75e+02, Power=6.79e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00178: Time=  11.3s, Loss=3.01e+00, Inv=3.01e+00, For=1.74e+02, Power=6.82e-01
  [eval] val_mse=3.380e-01  (n=7000)
Epoch 00179: Time=  11.4s, Loss=3.01e+00, Inv=3.01e+00, For=1.76e+02, Power=6.79e-01
  [eval] val_mse=3.368e-01  (n=7000)
Epoch 00180: Time=  11.4s, Loss=3.01e+00, Inv=3.01e+00, For=1.77e+02, Power=6.79e-01
  [eval] val_mse=3.374e-01  (n=7000)
Epoch 00181: Time=  11.4s, Loss=3.01e+00, Inv=3.01e+00, For=1.77e+02, Power=6.80e-01
  [eval] val_mse=3.371e-01  (n=7000)
Epoch 00182: Time=  11.5s, Loss=3.01e+00, Inv=3.01e+00, For=1.80e+02, Power=6.77e-01
  [eval] val_mse=3.364e-01  (n=7000)
Epoch 00183: Time=  11.5s, Loss=3.01e+00, Inv=3.01e+00, For=1.80e+02, Power=6.76e-01
  [eval] val_mse=3.364e-01  (n=7000)
Epoch 00184: Time=  11.5s, Loss=3.00e+00, Inv=3.00e+00, For=1.81e+02, Power=6.78e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00185: Time=  11.6s, Loss=3.00e+00, Inv=3.00e+00, For=1.82e+02, Power=6.80e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00186: Time=  11.6s, Loss=3.01e+00, Inv=3.01e+00, For=1.85e+02, Power=6.83e-01
  [eval] val_mse=3.359e-01  (n=7000)
Epoch 00187: Time=  11.6s, Loss=3.00e+00, Inv=3.00e+00, For=1.84e+02, Power=6.80e-01
  [eval] val_mse=3.354e-01  (n=7000)
Epoch 00188: Time=  11.7s, Loss=3.00e+00, Inv=3.00e+00, For=1.84e+02, Power=6.80e-01
  [eval] val_mse=3.363e-01  (n=7000)
Epoch 00189: Time=  11.7s, Loss=2.99e+00, Inv=2.99e+00, For=1.83e+02, Power=6.79e-01
  [eval] val_mse=3.342e-01  (n=7000)
Epoch 00190: Time=  11.7s, Loss=3.00e+00, Inv=3.00e+00, For=1.83e+02, Power=6.82e-01
  [eval] val_mse=3.341e-01  (n=7000)
Epoch 00191: Time=  11.8s, Loss=2.99e+00, Inv=2.99e+00, For=1.87e+02, Power=6.81e-01
  [eval] val_mse=3.338e-01  (n=7000)
Epoch 00192: Time=  11.8s, Loss=2.99e+00, Inv=2.99e+00, For=1.83e+02, Power=6.81e-01
  [eval] val_mse=3.334e-01  (n=7000)
Epoch 00193: Time=  11.8s, Loss=3.00e+00, Inv=3.00e+00, For=1.87e+02, Power=6.80e-01
  [eval] val_mse=3.335e-01  (n=7000)
Epoch 00194: Time=  11.9s, Loss=2.99e+00, Inv=2.99e+00, For=1.90e+02, Power=6.82e-01
  [eval] val_mse=3.329e-01  (n=7000)
Epoch 00195: Time=  11.9s, Loss=2.99e+00, Inv=2.99e+00, For=1.86e+02, Power=6.83e-01
  [eval] val_mse=3.332e-01  (n=7000)
Epoch 00196: Time=  11.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.91e+02, Power=6.81e-01
  [eval] val_mse=3.324e-01  (n=7000)
Epoch 00197: Time=  12.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.92e+02, Power=6.85e-01
  [eval] val_mse=3.326e-01  (n=7000)
Epoch 00198: Time=  12.0s, Loss=2.99e+00, Inv=2.99e+00, For=1.89e+02, Power=6.83e-01
  [eval] val_mse=3.321e-01  (n=7000)
Epoch 00199: Time=  12.0s, Loss=2.98e+00, Inv=2.98e+00, For=1.88e+02, Power=6.80e-01
  [eval] val_mse=3.316e-01  (n=7000)
Epoch 00200: Time=  12.1s, Loss=2.98e+00, Inv=2.98e+00, For=1.89e+02, Power=6.79e-01
  [eval] val_mse=3.315e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 2.350e-01
Torque MSE  = 1.206e-01
Torque RMSE = 3.473e-01
Per-joint MSE : 7.763e-02 4.425e-01 4.610e-02 2.728e-02 1.101e-01 2.000e-02
Per-joint RMSE: 2.786e-01 6.652e-01 2.147e-01 1.652e-01 3.319e-01 1.414e-01
Comp Time per Sample = 2.794e-04s / 3578.6Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-_aem_yn4 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x78fc119de8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:48:29.688423: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:48:31.477729: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=5.45e+03, Inv=5.45e+03, For=5.78e+00, Power=4.93e+02
  [eval] val_mse=1.264e+02  (n=7000)
Epoch 00002: Time=   5.6s, Loss=4.03e+02, Inv=4.03e+02, For=5.50e+00, Power=4.38e+01
  [eval] val_mse=5.172e+01  (n=7000)
Epoch 00003: Time=   5.6s, Loss=1.62e+02, Inv=1.62e+02, For=5.35e+00, Power=2.07e+01
  [eval] val_mse=3.232e+01  (n=7000)
Epoch 00004: Time=   5.6s, Loss=9.62e+01, Inv=9.62e+01, For=5.33e+00, Power=1.38e+01
  [eval] val_mse=2.350e+01  (n=7000)
Epoch 00005: Time=   5.7s, Loss=6.60e+01, Inv=6.60e+01, For=5.31e+00, Power=1.00e+01
  [eval] val_mse=1.814e+01  (n=7000)
Epoch 00006: Time=   5.7s, Loss=4.88e+01, Inv=4.88e+01, For=5.31e+00, Power=7.53e+00
  [eval] val_mse=1.458e+01  (n=7000)
Epoch 00007: Time=   5.7s, Loss=3.81e+01, Inv=3.81e+01, For=5.38e+00, Power=5.90e+00
  [eval] val_mse=1.200e+01  (n=7000)
Epoch 00008: Time=   5.8s, Loss=3.08e+01, Inv=3.08e+01, For=5.46e+00, Power=4.76e+00
  [eval] val_mse=1.008e+01  (n=7000)
Epoch 00009: Time=   5.8s, Loss=2.57e+01, Inv=2.57e+01, For=5.58e+00, Power=3.94e+00
  [eval] val_mse=8.599e+00  (n=7000)
Epoch 00010: Time=   5.8s, Loss=2.20e+01, Inv=2.20e+01, For=5.74e+00, Power=3.34e+00
  [eval] val_mse=7.421e+00  (n=7000)
Epoch 00011: Time=   5.9s, Loss=1.90e+01, Inv=1.90e+01, For=5.89e+00, Power=2.85e+00
  [eval] val_mse=6.490e+00  (n=7000)
Epoch 00012: Time=   5.9s, Loss=1.68e+01, Inv=1.68e+01, For=6.06e+00, Power=2.50e+00
  [eval] val_mse=5.735e+00  (n=7000)
Epoch 00013: Time=   5.9s, Loss=1.49e+01, Inv=1.49e+01, For=6.24e+00, Power=2.20e+00
  [eval] val_mse=5.110e+00  (n=7000)
Epoch 00014: Time=   6.0s, Loss=1.35e+01, Inv=1.35e+01, For=6.45e+00, Power=1.98e+00
  [eval] val_mse=4.594e+00  (n=7000)
Epoch 00015: Time=   6.0s, Loss=1.22e+01, Inv=1.22e+01, For=6.64e+00, Power=1.79e+00
  [eval] val_mse=4.165e+00  (n=7000)
Epoch 00016: Time=   6.0s, Loss=1.12e+01, Inv=1.12e+01, For=6.85e+00, Power=1.64e+00
  [eval] val_mse=3.799e+00  (n=7000)
Epoch 00017: Time=   6.1s, Loss=1.04e+01, Inv=1.04e+01, For=7.09e+00, Power=1.52e+00
  [eval] val_mse=3.485e+00  (n=7000)
Epoch 00018: Time=   6.1s, Loss=9.69e+00, Inv=9.69e+00, For=7.35e+00, Power=1.41e+00
  [eval] val_mse=3.214e+00  (n=7000)
Epoch 00019: Time=   6.1s, Loss=9.08e+00, Inv=9.08e+00, For=7.59e+00, Power=1.32e+00
  [eval] val_mse=2.985e+00  (n=7000)
Epoch 00020: Time=   6.2s, Loss=8.53e+00, Inv=8.53e+00, For=7.86e+00, Power=1.24e+00
  [eval] val_mse=2.789e+00  (n=7000)
Epoch 00021: Time=   6.2s, Loss=8.09e+00, Inv=8.09e+00, For=8.16e+00, Power=1.18e+00
  [eval] val_mse=2.611e+00  (n=7000)
Epoch 00022: Time=   6.2s, Loss=7.69e+00, Inv=7.69e+00, For=8.48e+00, Power=1.13e+00
  [eval] val_mse=2.459e+00  (n=7000)
Epoch 00023: Time=   6.3s, Loss=7.35e+00, Inv=7.35e+00, For=8.84e+00, Power=1.08e+00
  [eval] val_mse=2.319e+00  (n=7000)
Epoch 00024: Time=   6.3s, Loss=7.04e+00, Inv=7.04e+00, For=9.20e+00, Power=1.04e+00
  [eval] val_mse=2.200e+00  (n=7000)
Epoch 00025: Time=   6.3s, Loss=6.78e+00, Inv=6.78e+00, For=9.57e+00, Power=1.00e+00
  [eval] val_mse=2.089e+00  (n=7000)
Epoch 00026: Time=   6.4s, Loss=6.56e+00, Inv=6.56e+00, For=9.97e+00, Power=9.70e-01
  [eval] val_mse=1.987e+00  (n=7000)
Epoch 00027: Time=   6.4s, Loss=6.33e+00, Inv=6.33e+00, For=1.04e+01, Power=9.48e-01
  [eval] val_mse=1.900e+00  (n=7000)
Epoch 00028: Time=   6.4s, Loss=6.15e+00, Inv=6.15e+00, For=1.08e+01, Power=9.25e-01
  [eval] val_mse=1.818e+00  (n=7000)
Epoch 00029: Time=   6.5s, Loss=5.99e+00, Inv=5.99e+00, For=1.13e+01, Power=9.02e-01
  [eval] val_mse=1.740e+00  (n=7000)
Epoch 00030: Time=   6.5s, Loss=5.84e+00, Inv=5.84e+00, For=1.17e+01, Power=8.88e-01
  [eval] val_mse=1.670e+00  (n=7000)
Epoch 00031: Time=   6.5s, Loss=5.69e+00, Inv=5.69e+00, For=1.22e+01, Power=8.72e-01
  [eval] val_mse=1.607e+00  (n=7000)
Epoch 00032: Time=   6.6s, Loss=5.56e+00, Inv=5.56e+00, For=1.27e+01, Power=8.57e-01
  [eval] val_mse=1.547e+00  (n=7000)
Epoch 00033: Time=   6.6s, Loss=5.44e+00, Inv=5.44e+00, For=1.32e+01, Power=8.41e-01
  [eval] val_mse=1.491e+00  (n=7000)
Epoch 00034: Time=   6.6s, Loss=5.34e+00, Inv=5.34e+00, For=1.37e+01, Power=8.34e-01
  [eval] val_mse=1.441e+00  (n=7000)
Epoch 00035: Time=   6.7s, Loss=5.25e+00, Inv=5.25e+00, For=1.43e+01, Power=8.23e-01
  [eval] val_mse=1.390e+00  (n=7000)
Epoch 00036: Time=   6.7s, Loss=5.15e+00, Inv=5.15e+00, For=1.47e+01, Power=8.14e-01
  [eval] val_mse=1.345e+00  (n=7000)
Epoch 00037: Time=   6.7s, Loss=5.07e+00, Inv=5.07e+00, For=1.53e+01, Power=8.05e-01
  [eval] val_mse=1.302e+00  (n=7000)
Epoch 00038: Time=   6.8s, Loss=4.98e+00, Inv=4.98e+00, For=1.58e+01, Power=8.00e-01
  [eval] val_mse=1.265e+00  (n=7000)
Epoch 00039: Time=   6.8s, Loss=4.91e+00, Inv=4.91e+00, For=1.64e+01, Power=7.93e-01
  [eval] val_mse=1.227e+00  (n=7000)
Epoch 00040: Time=   6.8s, Loss=4.84e+00, Inv=4.84e+00, For=1.69e+01, Power=7.86e-01
  [eval] val_mse=1.191e+00  (n=7000)
Epoch 00041: Time=   6.9s, Loss=4.78e+00, Inv=4.78e+00, For=1.75e+01, Power=7.82e-01
  [eval] val_mse=1.157e+00  (n=7000)
Epoch 00042: Time=   6.9s, Loss=4.72e+00, Inv=4.72e+00, For=1.80e+01, Power=7.77e-01
  [eval] val_mse=1.126e+00  (n=7000)
Epoch 00043: Time=   6.9s, Loss=4.67e+00, Inv=4.67e+00, For=1.86e+01, Power=7.76e-01
  [eval] val_mse=1.095e+00  (n=7000)
Epoch 00044: Time=   7.0s, Loss=4.61e+00, Inv=4.61e+00, For=1.92e+01, Power=7.65e-01
  [eval] val_mse=1.067e+00  (n=7000)
Epoch 00045: Time=   7.0s, Loss=4.55e+00, Inv=4.55e+00, For=1.98e+01, Power=7.63e-01
  [eval] val_mse=1.040e+00  (n=7000)
Epoch 00046: Time=   7.0s, Loss=4.50e+00, Inv=4.50e+00, For=2.04e+01, Power=7.61e-01
  [eval] val_mse=1.015e+00  (n=7000)
Epoch 00047: Time=   7.1s, Loss=4.45e+00, Inv=4.45e+00, For=2.10e+01, Power=7.54e-01
  [eval] val_mse=9.896e-01  (n=7000)
Epoch 00048: Time=   7.1s, Loss=4.40e+00, Inv=4.40e+00, For=2.15e+01, Power=7.51e-01
  [eval] val_mse=9.681e-01  (n=7000)
Epoch 00049: Time=   7.1s, Loss=4.36e+00, Inv=4.36e+00, For=2.21e+01, Power=7.49e-01
  [eval] val_mse=9.440e-01  (n=7000)
Epoch 00050: Time=   7.2s, Loss=4.32e+00, Inv=4.32e+00, For=2.27e+01, Power=7.48e-01
  [eval] val_mse=9.245e-01  (n=7000)
Epoch 00051: Time=   7.2s, Loss=4.28e+00, Inv=4.28e+00, For=2.33e+01, Power=7.41e-01
  [eval] val_mse=9.061e-01  (n=7000)
Epoch 00052: Time=   7.2s, Loss=4.24e+00, Inv=4.24e+00, For=2.39e+01, Power=7.40e-01
  [eval] val_mse=8.857e-01  (n=7000)
Epoch 00053: Time=   7.3s, Loss=4.21e+00, Inv=4.21e+00, For=2.47e+01, Power=7.40e-01
  [eval] val_mse=8.680e-01  (n=7000)
Epoch 00054: Time=   7.3s, Loss=4.17e+00, Inv=4.17e+00, For=2.51e+01, Power=7.36e-01
  [eval] val_mse=8.512e-01  (n=7000)
Epoch 00055: Time=   7.3s, Loss=4.14e+00, Inv=4.14e+00, For=2.59e+01, Power=7.37e-01
  [eval] val_mse=8.345e-01  (n=7000)
Epoch 00056: Time=   7.4s, Loss=4.09e+00, Inv=4.09e+00, For=2.64e+01, Power=7.32e-01
  [eval] val_mse=8.191e-01  (n=7000)
Epoch 00057: Time=   7.4s, Loss=4.07e+00, Inv=4.07e+00, For=2.71e+01, Power=7.32e-01
  [eval] val_mse=8.045e-01  (n=7000)
Epoch 00058: Time=   7.4s, Loss=4.03e+00, Inv=4.03e+00, For=2.78e+01, Power=7.28e-01
  [eval] val_mse=7.900e-01  (n=7000)
Epoch 00059: Time=   7.5s, Loss=4.01e+00, Inv=4.01e+00, For=2.84e+01, Power=7.30e-01
  [eval] val_mse=7.748e-01  (n=7000)
Epoch 00060: Time=   7.5s, Loss=3.98e+00, Inv=3.98e+00, For=2.92e+01, Power=7.29e-01
  [eval] val_mse=7.631e-01  (n=7000)
Epoch 00061: Time=   7.5s, Loss=3.95e+00, Inv=3.95e+00, For=2.97e+01, Power=7.27e-01
  [eval] val_mse=7.503e-01  (n=7000)
Epoch 00062: Time=   7.6s, Loss=3.92e+00, Inv=3.92e+00, For=3.04e+01, Power=7.24e-01
  [eval] val_mse=7.373e-01  (n=7000)
Epoch 00063: Time=   7.6s, Loss=3.90e+00, Inv=3.90e+00, For=3.10e+01, Power=7.21e-01
  [eval] val_mse=7.257e-01  (n=7000)
Epoch 00064: Time=   7.6s, Loss=3.87e+00, Inv=3.87e+00, For=3.16e+01, Power=7.21e-01
  [eval] val_mse=7.143e-01  (n=7000)
Epoch 00065: Time=   7.7s, Loss=3.85e+00, Inv=3.85e+00, For=3.24e+01, Power=7.20e-01
  [eval] val_mse=7.035e-01  (n=7000)
Epoch 00066: Time=   7.7s, Loss=3.82e+00, Inv=3.82e+00, For=3.30e+01, Power=7.19e-01
  [eval] val_mse=6.931e-01  (n=7000)
Epoch 00067: Time=   7.7s, Loss=3.80e+00, Inv=3.80e+00, For=3.38e+01, Power=7.20e-01
  [eval] val_mse=6.836e-01  (n=7000)
Epoch 00068: Time=   7.8s, Loss=3.77e+00, Inv=3.77e+00, For=3.43e+01, Power=7.15e-01
  [eval] val_mse=6.739e-01  (n=7000)
Epoch 00069: Time=   7.8s, Loss=3.76e+00, Inv=3.76e+00, For=3.52e+01, Power=7.14e-01
  [eval] val_mse=6.633e-01  (n=7000)
Epoch 00070: Time=   7.8s, Loss=3.74e+00, Inv=3.74e+00, For=3.57e+01, Power=7.13e-01
  [eval] val_mse=6.533e-01  (n=7000)
Epoch 00071: Time=   7.9s, Loss=3.72e+00, Inv=3.72e+00, For=3.65e+01, Power=7.15e-01
  [eval] val_mse=6.451e-01  (n=7000)
Epoch 00072: Time=   7.9s, Loss=3.70e+00, Inv=3.70e+00, For=3.72e+01, Power=7.12e-01
  [eval] val_mse=6.367e-01  (n=7000)
Epoch 00073: Time=   7.9s, Loss=3.68e+00, Inv=3.68e+00, For=3.80e+01, Power=7.12e-01
  [eval] val_mse=6.284e-01  (n=7000)
Epoch 00074: Time=   8.0s, Loss=3.66e+00, Inv=3.66e+00, For=3.87e+01, Power=7.09e-01
  [eval] val_mse=6.205e-01  (n=7000)
Epoch 00075: Time=   8.0s, Loss=3.65e+00, Inv=3.65e+00, For=3.92e+01, Power=7.09e-01
  [eval] val_mse=6.121e-01  (n=7000)
Epoch 00076: Time=   8.0s, Loss=3.63e+00, Inv=3.63e+00, For=4.00e+01, Power=7.11e-01
  [eval] val_mse=6.045e-01  (n=7000)
Epoch 00077: Time=   8.1s, Loss=3.61e+00, Inv=3.61e+00, For=4.07e+01, Power=7.09e-01
  [eval] val_mse=5.975e-01  (n=7000)
Epoch 00078: Time=   8.1s, Loss=3.60e+00, Inv=3.60e+00, For=4.16e+01, Power=7.08e-01
  [eval] val_mse=5.907e-01  (n=7000)
Epoch 00079: Time=   8.1s, Loss=3.58e+00, Inv=3.58e+00, For=4.22e+01, Power=7.03e-01
  [eval] val_mse=5.832e-01  (n=7000)
Epoch 00080: Time=   8.2s, Loss=3.57e+00, Inv=3.57e+00, For=4.27e+01, Power=7.07e-01
  [eval] val_mse=5.759e-01  (n=7000)
Epoch 00081: Time=   8.2s, Loss=3.56e+00, Inv=3.56e+00, For=4.36e+01, Power=7.06e-01
  [eval] val_mse=5.689e-01  (n=7000)
Epoch 00082: Time=   8.2s, Loss=3.55e+00, Inv=3.55e+00, For=4.45e+01, Power=7.06e-01
  [eval] val_mse=5.639e-01  (n=7000)
Epoch 00083: Time=   8.3s, Loss=3.54e+00, Inv=3.54e+00, For=4.50e+01, Power=7.05e-01
  [eval] val_mse=5.561e-01  (n=7000)
Epoch 00084: Time=   8.3s, Loss=3.53e+00, Inv=3.53e+00, For=4.57e+01, Power=7.04e-01
  [eval] val_mse=5.506e-01  (n=7000)
Epoch 00085: Time=   8.3s, Loss=3.51e+00, Inv=3.51e+00, For=4.66e+01, Power=7.01e-01
  [eval] val_mse=5.440e-01  (n=7000)
Epoch 00086: Time=   8.4s, Loss=3.50e+00, Inv=3.50e+00, For=4.74e+01, Power=7.03e-01
  [eval] val_mse=5.381e-01  (n=7000)
Epoch 00087: Time=   8.4s, Loss=3.49e+00, Inv=3.49e+00, For=4.79e+01, Power=7.03e-01
  [eval] val_mse=5.329e-01  (n=7000)
Epoch 00088: Time=   8.4s, Loss=3.48e+00, Inv=3.48e+00, For=4.86e+01, Power=7.00e-01
  [eval] val_mse=5.266e-01  (n=7000)
Epoch 00089: Time=   8.5s, Loss=3.46e+00, Inv=3.46e+00, For=4.95e+01, Power=7.02e-01
  [eval] val_mse=5.205e-01  (n=7000)
Epoch 00090: Time=   8.5s, Loss=3.45e+00, Inv=3.45e+00, For=5.03e+01, Power=6.98e-01
  [eval] val_mse=5.151e-01  (n=7000)
Epoch 00091: Time=   8.5s, Loss=3.45e+00, Inv=3.45e+00, For=5.10e+01, Power=7.02e-01
  [eval] val_mse=5.101e-01  (n=7000)
Epoch 00092: Time=   8.6s, Loss=3.44e+00, Inv=3.44e+00, For=5.17e+01, Power=7.01e-01
  [eval] val_mse=5.052e-01  (n=7000)
Epoch 00093: Time=   8.6s, Loss=3.43e+00, Inv=3.43e+00, For=5.22e+01, Power=6.98e-01
  [eval] val_mse=5.009e-01  (n=7000)
Epoch 00094: Time=   8.6s, Loss=3.42e+00, Inv=3.42e+00, For=5.32e+01, Power=6.98e-01
  [eval] val_mse=4.954e-01  (n=7000)
Epoch 00095: Time=   8.7s, Loss=3.40e+00, Inv=3.40e+00, For=5.37e+01, Power=6.95e-01
  [eval] val_mse=4.903e-01  (n=7000)
Epoch 00096: Time=   8.7s, Loss=3.39e+00, Inv=3.39e+00, For=5.47e+01, Power=6.96e-01
  [eval] val_mse=4.863e-01  (n=7000)
Epoch 00097: Time=   8.7s, Loss=3.39e+00, Inv=3.39e+00, For=5.52e+01, Power=6.98e-01
  [eval] val_mse=4.821e-01  (n=7000)
Epoch 00098: Time=   8.8s, Loss=3.38e+00, Inv=3.38e+00, For=5.62e+01, Power=6.96e-01
  [eval] val_mse=4.784e-01  (n=7000)
Epoch 00099: Time=   8.8s, Loss=3.37e+00, Inv=3.37e+00, For=5.68e+01, Power=6.96e-01
  [eval] val_mse=4.739e-01  (n=7000)
Epoch 00100: Time=   8.8s, Loss=3.36e+00, Inv=3.36e+00, For=5.76e+01, Power=6.93e-01
  [eval] val_mse=4.689e-01  (n=7000)
Epoch 00101: Time=   8.9s, Loss=3.35e+00, Inv=3.35e+00, For=5.84e+01, Power=6.93e-01
  [eval] val_mse=4.663e-01  (n=7000)
Epoch 00102: Time=   8.9s, Loss=3.34e+00, Inv=3.34e+00, For=5.89e+01, Power=6.94e-01
  [eval] val_mse=4.618e-01  (n=7000)
Epoch 00103: Time=   8.9s, Loss=3.34e+00, Inv=3.34e+00, For=5.97e+01, Power=6.91e-01
  [eval] val_mse=4.582e-01  (n=7000)
Epoch 00104: Time=   9.0s, Loss=3.33e+00, Inv=3.33e+00, For=6.06e+01, Power=6.93e-01
  [eval] val_mse=4.559e-01  (n=7000)
Epoch 00105: Time=   9.0s, Loss=3.32e+00, Inv=3.32e+00, For=6.17e+01, Power=6.93e-01
  [eval] val_mse=4.525e-01  (n=7000)
Epoch 00106: Time=   9.0s, Loss=3.31e+00, Inv=3.31e+00, For=6.22e+01, Power=6.91e-01
  [eval] val_mse=4.485e-01  (n=7000)
Epoch 00107: Time=   9.1s, Loss=3.30e+00, Inv=3.30e+00, For=6.25e+01, Power=6.91e-01
  [eval] val_mse=4.445e-01  (n=7000)
Epoch 00108: Time=   9.1s, Loss=3.29e+00, Inv=3.29e+00, For=6.38e+01, Power=6.89e-01
  [eval] val_mse=4.413e-01  (n=7000)
Epoch 00109: Time=   9.1s, Loss=3.29e+00, Inv=3.29e+00, For=6.44e+01, Power=6.90e-01
  [eval] val_mse=4.384e-01  (n=7000)
Epoch 00110: Time=   9.2s, Loss=3.28e+00, Inv=3.28e+00, For=6.50e+01, Power=6.89e-01
  [eval] val_mse=4.354e-01  (n=7000)
Epoch 00111: Time=   9.2s, Loss=3.28e+00, Inv=3.28e+00, For=6.56e+01, Power=6.92e-01
  [eval] val_mse=4.333e-01  (n=7000)
Epoch 00112: Time=   9.2s, Loss=3.27e+00, Inv=3.27e+00, For=6.69e+01, Power=6.90e-01
  [eval] val_mse=4.294e-01  (n=7000)
Epoch 00113: Time=   9.3s, Loss=3.27e+00, Inv=3.27e+00, For=6.76e+01, Power=6.89e-01
  [eval] val_mse=4.271e-01  (n=7000)
Epoch 00114: Time=   9.3s, Loss=3.26e+00, Inv=3.26e+00, For=6.80e+01, Power=6.91e-01
  [eval] val_mse=4.248e-01  (n=7000)
Epoch 00115: Time=   9.3s, Loss=3.25e+00, Inv=3.25e+00, For=6.94e+01, Power=6.90e-01
  [eval] val_mse=4.216e-01  (n=7000)
Epoch 00116: Time=   9.4s, Loss=3.24e+00, Inv=3.24e+00, For=6.98e+01, Power=6.84e-01
  [eval] val_mse=4.195e-01  (n=7000)
Epoch 00117: Time=   9.4s, Loss=3.24e+00, Inv=3.24e+00, For=7.11e+01, Power=6.88e-01
  [eval] val_mse=4.162e-01  (n=7000)
Epoch 00118: Time=   9.4s, Loss=3.23e+00, Inv=3.23e+00, For=7.14e+01, Power=6.87e-01
  [eval] val_mse=4.141e-01  (n=7000)
Epoch 00119: Time=   9.5s, Loss=3.23e+00, Inv=3.23e+00, For=7.25e+01, Power=6.88e-01
  [eval] val_mse=4.122e-01  (n=7000)
Epoch 00120: Time=   9.5s, Loss=3.22e+00, Inv=3.22e+00, For=7.31e+01, Power=6.87e-01
  [eval] val_mse=4.097e-01  (n=7000)
Epoch 00121: Time=   9.5s, Loss=3.22e+00, Inv=3.22e+00, For=7.41e+01, Power=6.86e-01
  [eval] val_mse=4.082e-01  (n=7000)
Epoch 00122: Time=   9.6s, Loss=3.21e+00, Inv=3.21e+00, For=7.55e+01, Power=6.85e-01
  [eval] val_mse=4.060e-01  (n=7000)
Epoch 00123: Time=   9.6s, Loss=3.21e+00, Inv=3.21e+00, For=7.58e+01, Power=6.84e-01
  [eval] val_mse=4.035e-01  (n=7000)
Epoch 00124: Time=   9.6s, Loss=3.20e+00, Inv=3.20e+00, For=7.68e+01, Power=6.85e-01
  [eval] val_mse=4.015e-01  (n=7000)
Epoch 00125: Time=   9.7s, Loss=3.19e+00, Inv=3.19e+00, For=7.78e+01, Power=6.84e-01
  [eval] val_mse=3.993e-01  (n=7000)
Epoch 00126: Time=   9.7s, Loss=3.19e+00, Inv=3.19e+00, For=7.82e+01, Power=6.86e-01
  [eval] val_mse=3.978e-01  (n=7000)
Epoch 00127: Time=   9.7s, Loss=3.18e+00, Inv=3.18e+00, For=7.97e+01, Power=6.86e-01
  [eval] val_mse=3.957e-01  (n=7000)
Epoch 00128: Time=   9.8s, Loss=3.18e+00, Inv=3.18e+00, For=8.01e+01, Power=6.82e-01
  [eval] val_mse=3.937e-01  (n=7000)
Epoch 00129: Time=   9.8s, Loss=3.18e+00, Inv=3.18e+00, For=8.14e+01, Power=6.86e-01
  [eval] val_mse=3.924e-01  (n=7000)
Epoch 00130: Time=   9.8s, Loss=3.17e+00, Inv=3.17e+00, For=8.17e+01, Power=6.84e-01
  [eval] val_mse=3.911e-01  (n=7000)
Epoch 00131: Time=   9.9s, Loss=3.17e+00, Inv=3.17e+00, For=8.32e+01, Power=6.87e-01
  [eval] val_mse=3.903e-01  (n=7000)
Epoch 00132: Time=   9.9s, Loss=3.16e+00, Inv=3.16e+00, For=8.43e+01, Power=6.86e-01
  [eval] val_mse=3.874e-01  (n=7000)
Epoch 00133: Time=   9.9s, Loss=3.16e+00, Inv=3.16e+00, For=8.51e+01, Power=6.85e-01
  [eval] val_mse=3.860e-01  (n=7000)
Epoch 00134: Time=  10.0s, Loss=3.15e+00, Inv=3.15e+00, For=8.58e+01, Power=6.82e-01
  [eval] val_mse=3.844e-01  (n=7000)
Epoch 00135: Time=  10.0s, Loss=3.15e+00, Inv=3.15e+00, For=8.72e+01, Power=6.83e-01
  [eval] val_mse=3.833e-01  (n=7000)
Epoch 00136: Time=  10.0s, Loss=3.14e+00, Inv=3.14e+00, For=8.76e+01, Power=6.83e-01
  [eval] val_mse=3.825e-01  (n=7000)
Epoch 00137: Time=  10.1s, Loss=3.14e+00, Inv=3.14e+00, For=8.90e+01, Power=6.82e-01
  [eval] val_mse=3.807e-01  (n=7000)
Epoch 00138: Time=  10.1s, Loss=3.14e+00, Inv=3.14e+00, For=9.03e+01, Power=6.82e-01
  [eval] val_mse=3.796e-01  (n=7000)
Epoch 00139: Time=  10.1s, Loss=3.13e+00, Inv=3.13e+00, For=9.14e+01, Power=6.81e-01
  [eval] val_mse=3.782e-01  (n=7000)
Epoch 00140: Time=  10.2s, Loss=3.13e+00, Inv=3.13e+00, For=9.13e+01, Power=6.83e-01
  [eval] val_mse=3.779e-01  (n=7000)
Epoch 00141: Time=  10.2s, Loss=3.12e+00, Inv=3.12e+00, For=9.34e+01, Power=6.81e-01
  [eval] val_mse=3.760e-01  (n=7000)
Epoch 00142: Time=  10.2s, Loss=3.12e+00, Inv=3.12e+00, For=9.37e+01, Power=6.82e-01
  [eval] val_mse=3.739e-01  (n=7000)
Epoch 00143: Time=  10.3s, Loss=3.12e+00, Inv=3.12e+00, For=9.53e+01, Power=6.84e-01
  [eval] val_mse=3.737e-01  (n=7000)
Epoch 00144: Time=  10.3s, Loss=3.11e+00, Inv=3.11e+00, For=9.59e+01, Power=6.80e-01
  [eval] val_mse=3.725e-01  (n=7000)
Epoch 00145: Time=  10.3s, Loss=3.11e+00, Inv=3.11e+00, For=9.73e+01, Power=6.82e-01
  [eval] val_mse=3.710e-01  (n=7000)
Epoch 00146: Time=  10.4s, Loss=3.11e+00, Inv=3.11e+00, For=9.86e+01, Power=6.81e-01
  [eval] val_mse=3.702e-01  (n=7000)
Epoch 00147: Time=  10.4s, Loss=3.10e+00, Inv=3.10e+00, For=1.00e+02, Power=6.81e-01
  [eval] val_mse=3.686e-01  (n=7000)
Epoch 00148: Time=  10.4s, Loss=3.10e+00, Inv=3.10e+00, For=1.01e+02, Power=6.84e-01
  [eval] val_mse=3.683e-01  (n=7000)
Epoch 00149: Time=  10.5s, Loss=3.09e+00, Inv=3.09e+00, For=1.02e+02, Power=6.81e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00150: Time=  10.5s, Loss=3.09e+00, Inv=3.09e+00, For=1.03e+02, Power=6.83e-01
  [eval] val_mse=3.659e-01  (n=7000)
Epoch 00151: Time=  10.5s, Loss=3.09e+00, Inv=3.09e+00, For=1.04e+02, Power=6.83e-01
  [eval] val_mse=3.654e-01  (n=7000)
Epoch 00152: Time=  10.6s, Loss=3.09e+00, Inv=3.09e+00, For=1.05e+02, Power=6.80e-01
  [eval] val_mse=3.642e-01  (n=7000)
Epoch 00153: Time=  10.6s, Loss=3.08e+00, Inv=3.08e+00, For=1.06e+02, Power=6.80e-01
  [eval] val_mse=3.637e-01  (n=7000)
Epoch 00154: Time=  10.6s, Loss=3.08e+00, Inv=3.08e+00, For=1.09e+02, Power=6.80e-01
  [eval] val_mse=3.627e-01  (n=7000)
Epoch 00155: Time=  10.7s, Loss=3.08e+00, Inv=3.08e+00, For=1.09e+02, Power=6.83e-01
  [eval] val_mse=3.613e-01  (n=7000)
Epoch 00156: Time=  10.7s, Loss=3.07e+00, Inv=3.07e+00, For=1.10e+02, Power=6.80e-01
  [eval] val_mse=3.607e-01  (n=7000)
Epoch 00157: Time=  10.7s, Loss=3.07e+00, Inv=3.07e+00, For=1.12e+02, Power=6.79e-01
  [eval] val_mse=3.601e-01  (n=7000)
Epoch 00158: Time=  10.8s, Loss=3.06e+00, Inv=3.06e+00, For=1.12e+02, Power=6.81e-01
  [eval] val_mse=3.591e-01  (n=7000)
Epoch 00159: Time=  10.8s, Loss=3.07e+00, Inv=3.07e+00, For=1.13e+02, Power=6.81e-01
  [eval] val_mse=3.589e-01  (n=7000)
Epoch 00160: Time=  10.8s, Loss=3.07e+00, Inv=3.07e+00, For=1.16e+02, Power=6.79e-01
  [eval] val_mse=3.576e-01  (n=7000)
Epoch 00161: Time=  10.9s, Loss=3.06e+00, Inv=3.06e+00, For=1.17e+02, Power=6.81e-01
  [eval] val_mse=3.587e-01  (n=7000)
Epoch 00162: Time=  10.9s, Loss=3.06e+00, Inv=3.06e+00, For=1.18e+02, Power=6.83e-01
  [eval] val_mse=3.570e-01  (n=7000)
Epoch 00163: Time=  10.9s, Loss=3.06e+00, Inv=3.06e+00, For=1.19e+02, Power=6.82e-01
  [eval] val_mse=3.560e-01  (n=7000)
Epoch 00164: Time=  11.0s, Loss=3.05e+00, Inv=3.05e+00, For=1.21e+02, Power=6.80e-01
  [eval] val_mse=3.551e-01  (n=7000)
Epoch 00165: Time=  11.0s, Loss=3.05e+00, Inv=3.05e+00, For=1.22e+02, Power=6.80e-01
  [eval] val_mse=3.544e-01  (n=7000)
Epoch 00166: Time=  11.0s, Loss=3.05e+00, Inv=3.05e+00, For=1.23e+02, Power=6.80e-01
  [eval] val_mse=3.538e-01  (n=7000)
Epoch 00167: Time=  11.1s, Loss=3.05e+00, Inv=3.05e+00, For=1.26e+02, Power=6.80e-01
  [eval] val_mse=3.532e-01  (n=7000)
Epoch 00168: Time=  11.1s, Loss=3.05e+00, Inv=3.05e+00, For=1.25e+02, Power=6.81e-01
  [eval] val_mse=3.532e-01  (n=7000)
Epoch 00169: Time=  11.1s, Loss=3.04e+00, Inv=3.04e+00, For=1.26e+02, Power=6.77e-01
  [eval] val_mse=3.525e-01  (n=7000)
Epoch 00170: Time=  11.2s, Loss=3.04e+00, Inv=3.04e+00, For=1.29e+02, Power=6.77e-01
  [eval] val_mse=3.506e-01  (n=7000)
Epoch 00171: Time=  11.2s, Loss=3.04e+00, Inv=3.04e+00, For=1.30e+02, Power=6.81e-01
  [eval] val_mse=3.504e-01  (n=7000)
Epoch 00172: Time=  11.2s, Loss=3.04e+00, Inv=3.04e+00, For=1.33e+02, Power=6.82e-01
  [eval] val_mse=3.508e-01  (n=7000)
Epoch 00173: Time=  11.2s, Loss=3.04e+00, Inv=3.04e+00, For=1.33e+02, Power=6.81e-01
  [eval] val_mse=3.509e-01  (n=7000)
Epoch 00174: Time=  11.3s, Loss=3.03e+00, Inv=3.03e+00, For=1.34e+02, Power=6.80e-01
  [eval] val_mse=3.490e-01  (n=7000)
Epoch 00175: Time=  11.3s, Loss=3.03e+00, Inv=3.03e+00, For=1.36e+02, Power=6.76e-01
  [eval] val_mse=3.482e-01  (n=7000)
Epoch 00176: Time=  11.3s, Loss=3.03e+00, Inv=3.03e+00, For=1.38e+02, Power=6.79e-01
  [eval] val_mse=3.474e-01  (n=7000)
Epoch 00177: Time=  11.4s, Loss=3.03e+00, Inv=3.03e+00, For=1.38e+02, Power=6.79e-01
  [eval] val_mse=3.478e-01  (n=7000)
Epoch 00178: Time=  11.4s, Loss=3.02e+00, Inv=3.02e+00, For=1.41e+02, Power=6.80e-01
  [eval] val_mse=3.473e-01  (n=7000)
Epoch 00179: Time=  11.4s, Loss=3.02e+00, Inv=3.02e+00, For=1.42e+02, Power=6.77e-01
  [eval] val_mse=3.467e-01  (n=7000)
Epoch 00180: Time=  11.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.44e+02, Power=6.81e-01
  [eval] val_mse=3.458e-01  (n=7000)
Epoch 00181: Time=  11.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.44e+02, Power=6.80e-01
  [eval] val_mse=3.455e-01  (n=7000)
Epoch 00182: Time=  11.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.47e+02, Power=6.80e-01
  [eval] val_mse=3.456e-01  (n=7000)
Epoch 00183: Time=  11.6s, Loss=3.02e+00, Inv=3.02e+00, For=1.48e+02, Power=6.79e-01
  [eval] val_mse=3.447e-01  (n=7000)
Epoch 00184: Time=  11.6s, Loss=3.01e+00, Inv=3.01e+00, For=1.50e+02, Power=6.79e-01
  [eval] val_mse=3.450e-01  (n=7000)
Epoch 00185: Time=  11.6s, Loss=3.02e+00, Inv=3.02e+00, For=1.52e+02, Power=6.81e-01
  [eval] val_mse=3.443e-01  (n=7000)
Epoch 00186: Time=  11.7s, Loss=3.01e+00, Inv=3.01e+00, For=1.53e+02, Power=6.79e-01
  [eval] val_mse=3.441e-01  (n=7000)
Epoch 00187: Time=  11.7s, Loss=3.01e+00, Inv=3.01e+00, For=1.55e+02, Power=6.78e-01
  [eval] val_mse=3.440e-01  (n=7000)
Epoch 00188: Time=  11.7s, Loss=3.01e+00, Inv=3.01e+00, For=1.57e+02, Power=6.79e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00189: Time=  11.8s, Loss=3.00e+00, Inv=3.00e+00, For=1.58e+02, Power=6.79e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00190: Time=  11.8s, Loss=3.00e+00, Inv=3.00e+00, For=1.59e+02, Power=6.77e-01
  [eval] val_mse=3.422e-01  (n=7000)
Epoch 00191: Time=  11.8s, Loss=3.01e+00, Inv=3.01e+00, For=1.63e+02, Power=6.78e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00192: Time=  11.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.63e+02, Power=6.78e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00193: Time=  11.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.64e+02, Power=6.80e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00194: Time=  11.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.66e+02, Power=6.79e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00195: Time=  12.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.67e+02, Power=6.80e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00196: Time=  12.0s, Loss=2.99e+00, Inv=2.99e+00, For=1.68e+02, Power=6.79e-01
  [eval] val_mse=3.395e-01  (n=7000)
Epoch 00197: Time=  12.0s, Loss=2.99e+00, Inv=2.99e+00, For=1.72e+02, Power=6.80e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00198: Time=  12.1s, Loss=2.99e+00, Inv=2.99e+00, For=1.71e+02, Power=6.79e-01
  [eval] val_mse=3.398e-01  (n=7000)
Epoch 00199: Time=  12.1s, Loss=2.99e+00, Inv=2.99e+00, For=1.76e+02, Power=6.79e-01
  [eval] val_mse=3.383e-01  (n=7000)
Epoch 00200: Time=  12.1s, Loss=2.99e+00, Inv=2.99e+00, For=1.76e+02, Power=6.81e-01
  [eval] val_mse=3.389e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 2.375e-01
Torque MSE  = 7.982e-02
Torque RMSE = 2.825e-01
Per-joint MSE : 7.447e-02 1.549e-01 6.316e-02 1.820e-02 1.514e-01 1.681e-02
Per-joint RMSE: 2.729e-01 3.935e-01 2.513e-01 1.349e-01 3.892e-01 1.297e-01
Comp Time per Sample = 2.827e-04s / 3537.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-wrx3vpe0 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x70f7a12068c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:48:51.595865: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:48:53.390913: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=5.15e+03, Inv=5.15e+03, For=5.77e+00, Power=8.86e+02
  [eval] val_mse=1.832e+02  (n=7000)
Epoch 00002: Time=   5.5s, Loss=4.51e+02, Inv=4.51e+02, For=5.58e+00, Power=9.04e+01
  [eval] val_mse=7.297e+01  (n=7000)
Epoch 00003: Time=   5.5s, Loss=1.89e+02, Inv=1.89e+02, For=5.48e+00, Power=4.07e+01
  [eval] val_mse=4.713e+01  (n=7000)
Epoch 00004: Time=   5.6s, Loss=1.15e+02, Inv=1.15e+02, For=5.43e+00, Power=2.45e+01
  [eval] val_mse=3.210e+01  (n=7000)
Epoch 00005: Time=   5.6s, Loss=7.87e+01, Inv=7.87e+01, For=5.41e+00, Power=1.60e+01
  [eval] val_mse=2.309e+01  (n=7000)
Epoch 00006: Time=   5.6s, Loss=5.71e+01, Inv=5.71e+01, For=5.39e+00, Power=1.12e+01
  [eval] val_mse=1.739e+01  (n=7000)
Epoch 00007: Time=   5.7s, Loss=4.34e+01, Inv=4.34e+01, For=5.40e+00, Power=8.17e+00
  [eval] val_mse=1.352e+01  (n=7000)
Epoch 00008: Time=   5.7s, Loss=3.43e+01, Inv=3.43e+01, For=5.46e+00, Power=6.23e+00
  [eval] val_mse=1.088e+01  (n=7000)
Epoch 00009: Time=   5.7s, Loss=2.80e+01, Inv=2.80e+01, For=5.56e+00, Power=4.96e+00
  [eval] val_mse=8.935e+00  (n=7000)
Epoch 00010: Time=   5.8s, Loss=2.35e+01, Inv=2.35e+01, For=5.69e+00, Power=4.05e+00
  [eval] val_mse=7.488e+00  (n=7000)
Epoch 00011: Time=   5.8s, Loss=2.00e+01, Inv=2.00e+01, For=5.82e+00, Power=3.38e+00
  [eval] val_mse=6.371e+00  (n=7000)
Epoch 00012: Time=   5.8s, Loss=1.74e+01, Inv=1.74e+01, For=5.98e+00, Power=2.86e+00
  [eval] val_mse=5.518e+00  (n=7000)
Epoch 00013: Time=   5.9s, Loss=1.54e+01, Inv=1.54e+01, For=6.17e+00, Power=2.48e+00
  [eval] val_mse=4.825e+00  (n=7000)
Epoch 00014: Time=   5.9s, Loss=1.37e+01, Inv=1.37e+01, For=6.36e+00, Power=2.19e+00
  [eval] val_mse=4.271e+00  (n=7000)
Epoch 00015: Time=   5.9s, Loss=1.24e+01, Inv=1.24e+01, For=6.58e+00, Power=1.96e+00
  [eval] val_mse=3.819e+00  (n=7000)
Epoch 00016: Time=   6.0s, Loss=1.13e+01, Inv=1.13e+01, For=6.82e+00, Power=1.77e+00
  [eval] val_mse=3.435e+00  (n=7000)
Epoch 00017: Time=   6.0s, Loss=1.05e+01, Inv=1.05e+01, For=7.12e+00, Power=1.61e+00
  [eval] val_mse=3.120e+00  (n=7000)
Epoch 00018: Time=   6.0s, Loss=9.71e+00, Inv=9.71e+00, For=7.41e+00, Power=1.48e+00
  [eval] val_mse=2.847e+00  (n=7000)
Epoch 00019: Time=   6.1s, Loss=9.07e+00, Inv=9.07e+00, For=7.70e+00, Power=1.38e+00
  [eval] val_mse=2.614e+00  (n=7000)
Epoch 00020: Time=   6.1s, Loss=8.54e+00, Inv=8.54e+00, For=8.03e+00, Power=1.30e+00
  [eval] val_mse=2.412e+00  (n=7000)
Epoch 00021: Time=   6.1s, Loss=8.09e+00, Inv=8.09e+00, For=8.42e+00, Power=1.22e+00
  [eval] val_mse=2.241e+00  (n=7000)
Epoch 00022: Time=   6.2s, Loss=7.68e+00, Inv=7.68e+00, For=8.78e+00, Power=1.17e+00
  [eval] val_mse=2.089e+00  (n=7000)
Epoch 00023: Time=   6.2s, Loss=7.33e+00, Inv=7.33e+00, For=9.23e+00, Power=1.11e+00
  [eval] val_mse=1.954e+00  (n=7000)
Epoch 00024: Time=   6.2s, Loss=7.01e+00, Inv=7.01e+00, For=9.64e+00, Power=1.07e+00
  [eval] val_mse=1.837e+00  (n=7000)
Epoch 00025: Time=   6.3s, Loss=6.75e+00, Inv=6.75e+00, For=1.01e+01, Power=1.03e+00
  [eval] val_mse=1.734e+00  (n=7000)
Epoch 00026: Time=   6.3s, Loss=6.52e+00, Inv=6.52e+00, For=1.05e+01, Power=9.95e-01
  [eval] val_mse=1.634e+00  (n=7000)
Epoch 00027: Time=   6.3s, Loss=6.30e+00, Inv=6.30e+00, For=1.10e+01, Power=9.65e-01
  [eval] val_mse=1.548e+00  (n=7000)
Epoch 00028: Time=   6.4s, Loss=6.10e+00, Inv=6.10e+00, For=1.15e+01, Power=9.42e-01
  [eval] val_mse=1.471e+00  (n=7000)
Epoch 00029: Time=   6.4s, Loss=5.92e+00, Inv=5.92e+00, For=1.21e+01, Power=9.19e-01
  [eval] val_mse=1.400e+00  (n=7000)
Epoch 00030: Time=   6.4s, Loss=5.77e+00, Inv=5.77e+00, For=1.25e+01, Power=8.97e-01
  [eval] val_mse=1.334e+00  (n=7000)
Epoch 00031: Time=   6.5s, Loss=5.62e+00, Inv=5.62e+00, For=1.30e+01, Power=8.81e-01
  [eval] val_mse=1.275e+00  (n=7000)
Epoch 00032: Time=   6.5s, Loss=5.49e+00, Inv=5.49e+00, For=1.36e+01, Power=8.67e-01
  [eval] val_mse=1.221e+00  (n=7000)
Epoch 00033: Time=   6.5s, Loss=5.36e+00, Inv=5.36e+00, For=1.39e+01, Power=8.50e-01
  [eval] val_mse=1.168e+00  (n=7000)
Epoch 00034: Time=   6.6s, Loss=5.25e+00, Inv=5.25e+00, For=1.45e+01, Power=8.37e-01
  [eval] val_mse=1.122e+00  (n=7000)
Epoch 00035: Time=   6.6s, Loss=5.14e+00, Inv=5.14e+00, For=1.50e+01, Power=8.24e-01
  [eval] val_mse=1.081e+00  (n=7000)
Epoch 00036: Time=   6.6s, Loss=5.05e+00, Inv=5.05e+00, For=1.57e+01, Power=8.16e-01
  [eval] val_mse=1.041e+00  (n=7000)
Epoch 00037: Time=   6.7s, Loss=4.95e+00, Inv=4.95e+00, For=1.61e+01, Power=8.06e-01
  [eval] val_mse=1.002e+00  (n=7000)
Epoch 00038: Time=   6.7s, Loss=4.87e+00, Inv=4.87e+00, For=1.68e+01, Power=8.02e-01
  [eval] val_mse=9.688e-01  (n=7000)
Epoch 00039: Time=   6.7s, Loss=4.79e+00, Inv=4.79e+00, For=1.71e+01, Power=7.94e-01
  [eval] val_mse=9.367e-01  (n=7000)
Epoch 00040: Time=   6.8s, Loss=4.71e+00, Inv=4.71e+00, For=1.77e+01, Power=7.85e-01
  [eval] val_mse=9.067e-01  (n=7000)
Epoch 00041: Time=   6.8s, Loss=4.64e+00, Inv=4.64e+00, For=1.82e+01, Power=7.81e-01
  [eval] val_mse=8.791e-01  (n=7000)
Epoch 00042: Time=   6.8s, Loss=4.57e+00, Inv=4.57e+00, For=1.87e+01, Power=7.73e-01
  [eval] val_mse=8.522e-01  (n=7000)
Epoch 00043: Time=   6.9s, Loss=4.51e+00, Inv=4.51e+00, For=1.93e+01, Power=7.66e-01
  [eval] val_mse=8.297e-01  (n=7000)
Epoch 00044: Time=   6.9s, Loss=4.45e+00, Inv=4.45e+00, For=1.97e+01, Power=7.61e-01
  [eval] val_mse=8.054e-01  (n=7000)
Epoch 00045: Time=   6.9s, Loss=4.39e+00, Inv=4.39e+00, For=2.02e+01, Power=7.58e-01
  [eval] val_mse=7.850e-01  (n=7000)
Epoch 00046: Time=   7.0s, Loss=4.34e+00, Inv=4.34e+00, For=2.08e+01, Power=7.52e-01
  [eval] val_mse=7.648e-01  (n=7000)
Epoch 00047: Time=   7.0s, Loss=4.29e+00, Inv=4.29e+00, For=2.13e+01, Power=7.53e-01
  [eval] val_mse=7.462e-01  (n=7000)
Epoch 00048: Time=   7.0s, Loss=4.23e+00, Inv=4.23e+00, For=2.17e+01, Power=7.43e-01
  [eval] val_mse=7.283e-01  (n=7000)
Epoch 00049: Time=   7.1s, Loss=4.19e+00, Inv=4.19e+00, For=2.23e+01, Power=7.46e-01
  [eval] val_mse=7.119e-01  (n=7000)
Epoch 00050: Time=   7.1s, Loss=4.15e+00, Inv=4.15e+00, For=2.28e+01, Power=7.42e-01
  [eval] val_mse=6.953e-01  (n=7000)
Epoch 00051: Time=   7.1s, Loss=4.11e+00, Inv=4.11e+00, For=2.32e+01, Power=7.38e-01
  [eval] val_mse=6.811e-01  (n=7000)
Epoch 00052: Time=   7.2s, Loss=4.07e+00, Inv=4.07e+00, For=2.40e+01, Power=7.36e-01
  [eval] val_mse=6.678e-01  (n=7000)
Epoch 00053: Time=   7.2s, Loss=4.03e+00, Inv=4.03e+00, For=2.43e+01, Power=7.35e-01
  [eval] val_mse=6.545e-01  (n=7000)
Epoch 00054: Time=   7.2s, Loss=3.99e+00, Inv=3.99e+00, For=2.49e+01, Power=7.29e-01
  [eval] val_mse=6.409e-01  (n=7000)
Epoch 00055: Time=   7.3s, Loss=3.96e+00, Inv=3.96e+00, For=2.52e+01, Power=7.29e-01
  [eval] val_mse=6.294e-01  (n=7000)
Epoch 00056: Time=   7.3s, Loss=3.92e+00, Inv=3.92e+00, For=2.60e+01, Power=7.22e-01
  [eval] val_mse=6.179e-01  (n=7000)
Epoch 00057: Time=   7.3s, Loss=3.90e+00, Inv=3.90e+00, For=2.66e+01, Power=7.24e-01
  [eval] val_mse=6.078e-01  (n=7000)
Epoch 00058: Time=   7.4s, Loss=3.87e+00, Inv=3.87e+00, For=2.69e+01, Power=7.25e-01
  [eval] val_mse=5.973e-01  (n=7000)
Epoch 00059: Time=   7.4s, Loss=3.84e+00, Inv=3.84e+00, For=2.76e+01, Power=7.21e-01
  [eval] val_mse=5.882e-01  (n=7000)
Epoch 00060: Time=   7.4s, Loss=3.81e+00, Inv=3.81e+00, For=2.80e+01, Power=7.21e-01
  [eval] val_mse=5.783e-01  (n=7000)
Epoch 00061: Time=   7.5s, Loss=3.78e+00, Inv=3.78e+00, For=2.87e+01, Power=7.16e-01
  [eval] val_mse=5.701e-01  (n=7000)
Epoch 00062: Time=   7.5s, Loss=3.77e+00, Inv=3.77e+00, For=2.92e+01, Power=7.16e-01
  [eval] val_mse=5.619e-01  (n=7000)
Epoch 00063: Time=   7.5s, Loss=3.74e+00, Inv=3.74e+00, For=2.99e+01, Power=7.17e-01
  [eval] val_mse=5.540e-01  (n=7000)
Epoch 00064: Time=   7.6s, Loss=3.72e+00, Inv=3.72e+00, For=3.00e+01, Power=7.15e-01
  [eval] val_mse=5.465e-01  (n=7000)
Epoch 00065: Time=   7.6s, Loss=3.70e+00, Inv=3.70e+00, For=3.10e+01, Power=7.12e-01
  [eval] val_mse=5.397e-01  (n=7000)
Epoch 00066: Time=   7.6s, Loss=3.68e+00, Inv=3.68e+00, For=3.15e+01, Power=7.14e-01
  [eval] val_mse=5.318e-01  (n=7000)
Epoch 00067: Time=   7.7s, Loss=3.66e+00, Inv=3.66e+00, For=3.17e+01, Power=7.12e-01
  [eval] val_mse=5.256e-01  (n=7000)
Epoch 00068: Time=   7.7s, Loss=3.64e+00, Inv=3.64e+00, For=3.24e+01, Power=7.09e-01
  [eval] val_mse=5.197e-01  (n=7000)
Epoch 00069: Time=   7.7s, Loss=3.62e+00, Inv=3.62e+00, For=3.30e+01, Power=7.08e-01
  [eval] val_mse=5.131e-01  (n=7000)
Epoch 00070: Time=   7.8s, Loss=3.60e+00, Inv=3.60e+00, For=3.32e+01, Power=7.08e-01
  [eval] val_mse=5.076e-01  (n=7000)
Epoch 00071: Time=   7.8s, Loss=3.59e+00, Inv=3.59e+00, For=3.43e+01, Power=7.06e-01
  [eval] val_mse=5.015e-01  (n=7000)
Epoch 00072: Time=   7.8s, Loss=3.56e+00, Inv=3.56e+00, For=3.44e+01, Power=7.01e-01
  [eval] val_mse=4.956e-01  (n=7000)
Epoch 00073: Time=   7.9s, Loss=3.55e+00, Inv=3.55e+00, For=3.52e+01, Power=7.06e-01
  [eval] val_mse=4.910e-01  (n=7000)
Epoch 00074: Time=   7.9s, Loss=3.54e+00, Inv=3.54e+00, For=3.57e+01, Power=7.02e-01
  [eval] val_mse=4.878e-01  (n=7000)
Epoch 00075: Time=   7.9s, Loss=3.53e+00, Inv=3.53e+00, For=3.63e+01, Power=7.04e-01
  [eval] val_mse=4.811e-01  (n=7000)
Epoch 00076: Time=   8.0s, Loss=3.51e+00, Inv=3.51e+00, For=3.70e+01, Power=7.05e-01
  [eval] val_mse=4.765e-01  (n=7000)
Epoch 00077: Time=   8.0s, Loss=3.49e+00, Inv=3.49e+00, For=3.73e+01, Power=6.97e-01
  [eval] val_mse=4.721e-01  (n=7000)
Epoch 00078: Time=   8.0s, Loss=3.49e+00, Inv=3.49e+00, For=3.83e+01, Power=7.03e-01
  [eval] val_mse=4.687e-01  (n=7000)
Epoch 00079: Time=   8.1s, Loss=3.47e+00, Inv=3.47e+00, For=3.79e+01, Power=7.00e-01
  [eval] val_mse=4.638e-01  (n=7000)
Epoch 00080: Time=   8.1s, Loss=3.46e+00, Inv=3.46e+00, For=3.97e+01, Power=7.01e-01
  [eval] val_mse=4.596e-01  (n=7000)
Epoch 00081: Time=   8.1s, Loss=3.45e+00, Inv=3.45e+00, For=3.97e+01, Power=6.99e-01
  [eval] val_mse=4.558e-01  (n=7000)
Epoch 00082: Time=   8.2s, Loss=3.44e+00, Inv=3.44e+00, For=4.02e+01, Power=7.00e-01
  [eval] val_mse=4.523e-01  (n=7000)
Epoch 00083: Time=   8.2s, Loss=3.43e+00, Inv=3.43e+00, For=4.11e+01, Power=7.01e-01
  [eval] val_mse=4.506e-01  (n=7000)
Epoch 00084: Time=   8.2s, Loss=3.42e+00, Inv=3.42e+00, For=4.19e+01, Power=6.99e-01
  [eval] val_mse=4.466e-01  (n=7000)
Epoch 00085: Time=   8.3s, Loss=3.41e+00, Inv=3.41e+00, For=4.20e+01, Power=6.99e-01
  [eval] val_mse=4.436e-01  (n=7000)
Epoch 00086: Time=   8.3s, Loss=3.39e+00, Inv=3.39e+00, For=4.23e+01, Power=6.98e-01
  [eval] val_mse=4.404e-01  (n=7000)
Epoch 00087: Time=   8.3s, Loss=3.39e+00, Inv=3.39e+00, For=4.39e+01, Power=6.97e-01
  [eval] val_mse=4.379e-01  (n=7000)
Epoch 00088: Time=   8.4s, Loss=3.38e+00, Inv=3.38e+00, For=4.34e+01, Power=6.97e-01
  [eval] val_mse=4.352e-01  (n=7000)
Epoch 00089: Time=   8.4s, Loss=3.37e+00, Inv=3.37e+00, For=4.50e+01, Power=6.97e-01
  [eval] val_mse=4.305e-01  (n=7000)
Epoch 00090: Time=   8.4s, Loss=3.36e+00, Inv=3.36e+00, For=4.50e+01, Power=6.97e-01
  [eval] val_mse=4.279e-01  (n=7000)
Epoch 00091: Time=   8.5s, Loss=3.35e+00, Inv=3.35e+00, For=4.54e+01, Power=6.93e-01
  [eval] val_mse=4.259e-01  (n=7000)
Epoch 00092: Time=   8.5s, Loss=3.35e+00, Inv=3.35e+00, For=4.63e+01, Power=6.96e-01
  [eval] val_mse=4.234e-01  (n=7000)
Epoch 00093: Time=   8.5s, Loss=3.33e+00, Inv=3.33e+00, For=4.72e+01, Power=6.91e-01
  [eval] val_mse=4.210e-01  (n=7000)
Epoch 00094: Time=   8.6s, Loss=3.32e+00, Inv=3.32e+00, For=4.72e+01, Power=6.92e-01
  [eval] val_mse=4.182e-01  (n=7000)
Epoch 00095: Time=   8.6s, Loss=3.32e+00, Inv=3.32e+00, For=4.80e+01, Power=6.94e-01
  [eval] val_mse=4.157e-01  (n=7000)
Epoch 00096: Time=   8.6s, Loss=3.31e+00, Inv=3.31e+00, For=4.91e+01, Power=6.94e-01
  [eval] val_mse=4.141e-01  (n=7000)
Epoch 00097: Time=   8.7s, Loss=3.30e+00, Inv=3.30e+00, For=4.94e+01, Power=6.93e-01
  [eval] val_mse=4.115e-01  (n=7000)
Epoch 00098: Time=   8.7s, Loss=3.30e+00, Inv=3.30e+00, For=5.01e+01, Power=6.95e-01
  [eval] val_mse=4.100e-01  (n=7000)
Epoch 00099: Time=   8.7s, Loss=3.29e+00, Inv=3.29e+00, For=5.06e+01, Power=6.88e-01
  [eval] val_mse=4.074e-01  (n=7000)
Epoch 00100: Time=   8.8s, Loss=3.29e+00, Inv=3.29e+00, For=5.17e+01, Power=6.93e-01
  [eval] val_mse=4.064e-01  (n=7000)
Epoch 00101: Time=   8.8s, Loss=3.28e+00, Inv=3.28e+00, For=5.14e+01, Power=6.89e-01
  [eval] val_mse=4.034e-01  (n=7000)
Epoch 00102: Time=   8.8s, Loss=3.27e+00, Inv=3.27e+00, For=5.23e+01, Power=6.93e-01
  [eval] val_mse=4.022e-01  (n=7000)
Epoch 00103: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=5.31e+01, Power=6.90e-01
  [eval] val_mse=4.006e-01  (n=7000)
Epoch 00104: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=5.38e+01, Power=6.92e-01
  [eval] val_mse=3.997e-01  (n=7000)
Epoch 00105: Time=   8.9s, Loss=3.25e+00, Inv=3.25e+00, For=5.44e+01, Power=6.90e-01
  [eval] val_mse=3.967e-01  (n=7000)
Epoch 00106: Time=   9.0s, Loss=3.25e+00, Inv=3.25e+00, For=5.49e+01, Power=6.91e-01
  [eval] val_mse=3.958e-01  (n=7000)
Epoch 00107: Time=   9.0s, Loss=3.24e+00, Inv=3.24e+00, For=5.56e+01, Power=6.89e-01
  [eval] val_mse=3.948e-01  (n=7000)
Epoch 00108: Time=   9.0s, Loss=3.24e+00, Inv=3.24e+00, For=5.63e+01, Power=6.92e-01
  [eval] val_mse=3.921e-01  (n=7000)
Epoch 00109: Time=   9.1s, Loss=3.23e+00, Inv=3.23e+00, For=5.66e+01, Power=6.90e-01
  [eval] val_mse=3.902e-01  (n=7000)
Epoch 00110: Time=   9.1s, Loss=3.22e+00, Inv=3.22e+00, For=5.78e+01, Power=6.88e-01
  [eval] val_mse=3.888e-01  (n=7000)
Epoch 00111: Time=   9.1s, Loss=3.22e+00, Inv=3.22e+00, For=5.78e+01, Power=6.91e-01
  [eval] val_mse=3.865e-01  (n=7000)
Epoch 00112: Time=   9.2s, Loss=3.21e+00, Inv=3.21e+00, For=5.90e+01, Power=6.86e-01
  [eval] val_mse=3.866e-01  (n=7000)
Epoch 00113: Time=   9.2s, Loss=3.20e+00, Inv=3.20e+00, For=5.96e+01, Power=6.88e-01
  [eval] val_mse=3.865e-01  (n=7000)
Epoch 00114: Time=   9.2s, Loss=3.21e+00, Inv=3.21e+00, For=6.01e+01, Power=6.88e-01
  [eval] val_mse=3.831e-01  (n=7000)
Epoch 00115: Time=   9.3s, Loss=3.20e+00, Inv=3.20e+00, For=6.10e+01, Power=6.88e-01
  [eval] val_mse=3.823e-01  (n=7000)
Epoch 00116: Time=   9.3s, Loss=3.20e+00, Inv=3.20e+00, For=6.13e+01, Power=6.89e-01
  [eval] val_mse=3.806e-01  (n=7000)
Epoch 00117: Time=   9.3s, Loss=3.19e+00, Inv=3.19e+00, For=6.24e+01, Power=6.89e-01
  [eval] val_mse=3.806e-01  (n=7000)
Epoch 00118: Time=   9.4s, Loss=3.18e+00, Inv=3.18e+00, For=6.17e+01, Power=6.83e-01
  [eval] val_mse=3.781e-01  (n=7000)
Epoch 00119: Time=   9.4s, Loss=3.18e+00, Inv=3.18e+00, For=6.37e+01, Power=6.87e-01
  [eval] val_mse=3.776e-01  (n=7000)
Epoch 00120: Time=   9.4s, Loss=3.17e+00, Inv=3.17e+00, For=6.42e+01, Power=6.85e-01
  [eval] val_mse=3.763e-01  (n=7000)
Epoch 00121: Time=   9.5s, Loss=3.18e+00, Inv=3.18e+00, For=6.48e+01, Power=6.87e-01
  [eval] val_mse=3.753e-01  (n=7000)
Epoch 00122: Time=   9.5s, Loss=3.17e+00, Inv=3.17e+00, For=6.58e+01, Power=6.86e-01
  [eval] val_mse=3.742e-01  (n=7000)
Epoch 00123: Time=   9.5s, Loss=3.16e+00, Inv=3.16e+00, For=6.53e+01, Power=6.84e-01
  [eval] val_mse=3.735e-01  (n=7000)
Epoch 00124: Time=   9.6s, Loss=3.16e+00, Inv=3.16e+00, For=6.70e+01, Power=6.87e-01
  [eval] val_mse=3.719e-01  (n=7000)
Epoch 00125: Time=   9.6s, Loss=3.15e+00, Inv=3.15e+00, For=6.66e+01, Power=6.85e-01
  [eval] val_mse=3.711e-01  (n=7000)
Epoch 00126: Time=   9.6s, Loss=3.15e+00, Inv=3.15e+00, For=6.83e+01, Power=6.85e-01
  [eval] val_mse=3.698e-01  (n=7000)
Epoch 00127: Time=   9.7s, Loss=3.15e+00, Inv=3.15e+00, For=6.89e+01, Power=6.85e-01
  [eval] val_mse=3.700e-01  (n=7000)
Epoch 00128: Time=   9.7s, Loss=3.14e+00, Inv=3.14e+00, For=6.89e+01, Power=6.85e-01
  [eval] val_mse=3.682e-01  (n=7000)
Epoch 00129: Time=   9.7s, Loss=3.14e+00, Inv=3.14e+00, For=6.94e+01, Power=6.86e-01
  [eval] val_mse=3.670e-01  (n=7000)
Epoch 00130: Time=   9.8s, Loss=3.13e+00, Inv=3.13e+00, For=7.10e+01, Power=6.84e-01
  [eval] val_mse=3.660e-01  (n=7000)
Epoch 00131: Time=   9.8s, Loss=3.13e+00, Inv=3.13e+00, For=7.09e+01, Power=6.85e-01
  [eval] val_mse=3.662e-01  (n=7000)
Epoch 00132: Time=   9.8s, Loss=3.13e+00, Inv=3.13e+00, For=7.19e+01, Power=6.85e-01
  [eval] val_mse=3.645e-01  (n=7000)
Epoch 00133: Time=   9.9s, Loss=3.13e+00, Inv=3.13e+00, For=7.19e+01, Power=6.86e-01
  [eval] val_mse=3.644e-01  (n=7000)
Epoch 00134: Time=   9.9s, Loss=3.13e+00, Inv=3.13e+00, For=7.29e+01, Power=6.88e-01
  [eval] val_mse=3.630e-01  (n=7000)
Epoch 00135: Time=   9.9s, Loss=3.12e+00, Inv=3.12e+00, For=7.35e+01, Power=6.85e-01
  [eval] val_mse=3.627e-01  (n=7000)
Epoch 00136: Time=  10.0s, Loss=3.12e+00, Inv=3.12e+00, For=7.41e+01, Power=6.82e-01
  [eval] val_mse=3.618e-01  (n=7000)
Epoch 00137: Time=  10.0s, Loss=3.12e+00, Inv=3.12e+00, For=7.48e+01, Power=6.86e-01
  [eval] val_mse=3.606e-01  (n=7000)
Epoch 00138: Time=  10.0s, Loss=3.11e+00, Inv=3.11e+00, For=7.59e+01, Power=6.85e-01
  [eval] val_mse=3.606e-01  (n=7000)
Epoch 00139: Time=  10.1s, Loss=3.11e+00, Inv=3.11e+00, For=7.58e+01, Power=6.84e-01
  [eval] val_mse=3.602e-01  (n=7000)
Epoch 00140: Time=  10.1s, Loss=3.10e+00, Inv=3.10e+00, For=7.69e+01, Power=6.81e-01
  [eval] val_mse=3.598e-01  (n=7000)
Epoch 00141: Time=  10.1s, Loss=3.10e+00, Inv=3.10e+00, For=7.72e+01, Power=6.84e-01
  [eval] val_mse=3.580e-01  (n=7000)
Epoch 00142: Time=  10.2s, Loss=3.10e+00, Inv=3.10e+00, For=7.79e+01, Power=6.82e-01
  [eval] val_mse=3.570e-01  (n=7000)
Epoch 00143: Time=  10.2s, Loss=3.09e+00, Inv=3.09e+00, For=7.80e+01, Power=6.81e-01
  [eval] val_mse=3.566e-01  (n=7000)
Epoch 00144: Time=  10.2s, Loss=3.09e+00, Inv=3.09e+00, For=7.99e+01, Power=6.80e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00145: Time=  10.3s, Loss=3.09e+00, Inv=3.09e+00, For=7.91e+01, Power=6.83e-01
  [eval] val_mse=3.553e-01  (n=7000)
Epoch 00146: Time=  10.3s, Loss=3.09e+00, Inv=3.09e+00, For=8.08e+01, Power=6.84e-01
  [eval] val_mse=3.555e-01  (n=7000)
Epoch 00147: Time=  10.3s, Loss=3.08e+00, Inv=3.08e+00, For=8.04e+01, Power=6.82e-01
  [eval] val_mse=3.545e-01  (n=7000)
Epoch 00148: Time=  10.3s, Loss=3.08e+00, Inv=3.08e+00, For=8.17e+01, Power=6.80e-01
  [eval] val_mse=3.546e-01  (n=7000)
Epoch 00149: Time=  10.4s, Loss=3.08e+00, Inv=3.08e+00, For=8.20e+01, Power=6.81e-01
  [eval] val_mse=3.547e-01  (n=7000)
Epoch 00150: Time=  10.4s, Loss=3.08e+00, Inv=3.08e+00, For=8.27e+01, Power=6.82e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00151: Time=  10.4s, Loss=3.08e+00, Inv=3.08e+00, For=8.30e+01, Power=6.82e-01
  [eval] val_mse=3.525e-01  (n=7000)
Epoch 00152: Time=  10.5s, Loss=3.07e+00, Inv=3.07e+00, For=8.32e+01, Power=6.82e-01
  [eval] val_mse=3.530e-01  (n=7000)
Epoch 00153: Time=  10.5s, Loss=3.07e+00, Inv=3.07e+00, For=8.43e+01, Power=6.81e-01
  [eval] val_mse=3.511e-01  (n=7000)
Epoch 00154: Time=  10.5s, Loss=3.07e+00, Inv=3.07e+00, For=8.50e+01, Power=6.83e-01
  [eval] val_mse=3.511e-01  (n=7000)
Epoch 00155: Time=  10.6s, Loss=3.06e+00, Inv=3.06e+00, For=8.56e+01, Power=6.82e-01
  [eval] val_mse=3.509e-01  (n=7000)
Epoch 00156: Time=  10.6s, Loss=3.06e+00, Inv=3.06e+00, For=8.53e+01, Power=6.82e-01
  [eval] val_mse=3.493e-01  (n=7000)
Epoch 00157: Time=  10.6s, Loss=3.06e+00, Inv=3.06e+00, For=8.65e+01, Power=6.80e-01
  [eval] val_mse=3.496e-01  (n=7000)
Epoch 00158: Time=  10.7s, Loss=3.06e+00, Inv=3.06e+00, For=8.71e+01, Power=6.80e-01
  [eval] val_mse=3.494e-01  (n=7000)
Epoch 00159: Time=  10.7s, Loss=3.06e+00, Inv=3.06e+00, For=8.75e+01, Power=6.81e-01
  [eval] val_mse=3.492e-01  (n=7000)
Epoch 00160: Time=  10.7s, Loss=3.05e+00, Inv=3.05e+00, For=8.75e+01, Power=6.80e-01
  [eval] val_mse=3.478e-01  (n=7000)
Epoch 00161: Time=  10.8s, Loss=3.05e+00, Inv=3.05e+00, For=8.79e+01, Power=6.80e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00162: Time=  10.8s, Loss=3.05e+00, Inv=3.05e+00, For=8.94e+01, Power=6.83e-01
  [eval] val_mse=3.471e-01  (n=7000)
Epoch 00163: Time=  10.8s, Loss=3.05e+00, Inv=3.05e+00, For=8.93e+01, Power=6.81e-01
  [eval] val_mse=3.476e-01  (n=7000)
Epoch 00164: Time=  10.9s, Loss=3.04e+00, Inv=3.04e+00, For=8.86e+01, Power=6.81e-01
  [eval] val_mse=3.463e-01  (n=7000)
Epoch 00165: Time=  10.9s, Loss=3.04e+00, Inv=3.04e+00, For=9.06e+01, Power=6.81e-01
  [eval] val_mse=3.456e-01  (n=7000)
Epoch 00166: Time=  10.9s, Loss=3.04e+00, Inv=3.04e+00, For=9.03e+01, Power=6.82e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00167: Time=  11.0s, Loss=3.04e+00, Inv=3.04e+00, For=9.17e+01, Power=6.81e-01
  [eval] val_mse=3.457e-01  (n=7000)
Epoch 00168: Time=  11.0s, Loss=3.04e+00, Inv=3.04e+00, For=9.18e+01, Power=6.82e-01
  [eval] val_mse=3.460e-01  (n=7000)
Epoch 00169: Time=  11.0s, Loss=3.03e+00, Inv=3.03e+00, For=9.18e+01, Power=6.82e-01
  [eval] val_mse=3.444e-01  (n=7000)
Epoch 00170: Time=  11.1s, Loss=3.03e+00, Inv=3.03e+00, For=9.20e+01, Power=6.81e-01
  [eval] val_mse=3.433e-01  (n=7000)
Epoch 00171: Time=  11.1s, Loss=3.02e+00, Inv=3.02e+00, For=9.26e+01, Power=6.78e-01
  [eval] val_mse=3.441e-01  (n=7000)
Epoch 00172: Time=  11.1s, Loss=3.03e+00, Inv=3.03e+00, For=9.36e+01, Power=6.84e-01
  [eval] val_mse=3.440e-01  (n=7000)
Epoch 00173: Time=  11.2s, Loss=3.02e+00, Inv=3.02e+00, For=9.35e+01, Power=6.79e-01
  [eval] val_mse=3.437e-01  (n=7000)
Epoch 00174: Time=  11.2s, Loss=3.03e+00, Inv=3.03e+00, For=9.42e+01, Power=6.81e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00175: Time=  11.2s, Loss=3.03e+00, Inv=3.03e+00, For=9.53e+01, Power=6.84e-01
  [eval] val_mse=3.438e-01  (n=7000)
Epoch 00176: Time=  11.3s, Loss=3.02e+00, Inv=3.02e+00, For=9.46e+01, Power=6.79e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00177: Time=  11.3s, Loss=3.01e+00, Inv=3.01e+00, For=9.49e+01, Power=6.79e-01
  [eval] val_mse=3.421e-01  (n=7000)
Epoch 00178: Time=  11.3s, Loss=3.01e+00, Inv=3.01e+00, For=9.48e+01, Power=6.79e-01
  [eval] val_mse=3.415e-01  (n=7000)
Epoch 00179: Time=  11.4s, Loss=3.01e+00, Inv=3.01e+00, For=9.68e+01, Power=6.76e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00180: Time=  11.4s, Loss=3.01e+00, Inv=3.01e+00, For=9.61e+01, Power=6.79e-01
  [eval] val_mse=3.412e-01  (n=7000)
Epoch 00181: Time=  11.4s, Loss=3.01e+00, Inv=3.01e+00, For=9.62e+01, Power=6.79e-01
  [eval] val_mse=3.407e-01  (n=7000)
Epoch 00182: Time=  11.5s, Loss=3.01e+00, Inv=3.01e+00, For=9.71e+01, Power=6.79e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00183: Time=  11.5s, Loss=3.01e+00, Inv=3.01e+00, For=9.70e+01, Power=6.78e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00184: Time=  11.5s, Loss=3.00e+00, Inv=3.00e+00, For=9.71e+01, Power=6.81e-01
  [eval] val_mse=3.404e-01  (n=7000)
Epoch 00185: Time=  11.6s, Loss=3.00e+00, Inv=3.00e+00, For=9.80e+01, Power=6.79e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00186: Time=  11.6s, Loss=3.00e+00, Inv=3.00e+00, For=9.83e+01, Power=6.80e-01
  [eval] val_mse=3.414e-01  (n=7000)
Epoch 00187: Time=  11.6s, Loss=3.00e+00, Inv=3.00e+00, For=9.77e+01, Power=6.78e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00188: Time=  11.7s, Loss=3.00e+00, Inv=3.00e+00, For=9.82e+01, Power=6.79e-01
  [eval] val_mse=3.388e-01  (n=7000)
Epoch 00189: Time=  11.7s, Loss=2.99e+00, Inv=2.99e+00, For=9.86e+01, Power=6.79e-01
  [eval] val_mse=3.384e-01  (n=7000)
Epoch 00190: Time=  11.7s, Loss=2.99e+00, Inv=2.99e+00, For=9.98e+01, Power=6.77e-01
  [eval] val_mse=3.391e-01  (n=7000)
Epoch 00191: Time=  11.8s, Loss=2.99e+00, Inv=2.99e+00, For=9.89e+01, Power=6.78e-01
  [eval] val_mse=3.383e-01  (n=7000)
Epoch 00192: Time=  11.8s, Loss=2.99e+00, Inv=2.99e+00, For=1.00e+02, Power=6.79e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00193: Time=  11.8s, Loss=2.99e+00, Inv=2.99e+00, For=9.89e+01, Power=6.79e-01
  [eval] val_mse=3.378e-01  (n=7000)
Epoch 00194: Time=  11.9s, Loss=2.99e+00, Inv=2.99e+00, For=1.00e+02, Power=6.80e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00195: Time=  11.9s, Loss=2.98e+00, Inv=2.98e+00, For=1.00e+02, Power=6.79e-01
  [eval] val_mse=3.382e-01  (n=7000)
Epoch 00196: Time=  11.9s, Loss=2.99e+00, Inv=2.99e+00, For=1.00e+02, Power=6.81e-01
  [eval] val_mse=3.374e-01  (n=7000)
Epoch 00197: Time=  12.0s, Loss=2.98e+00, Inv=2.98e+00, For=1.01e+02, Power=6.79e-01
  [eval] val_mse=3.370e-01  (n=7000)
Epoch 00198: Time=  12.0s, Loss=2.97e+00, Inv=2.97e+00, For=1.00e+02, Power=6.78e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00199: Time=  12.0s, Loss=2.98e+00, Inv=2.98e+00, For=1.00e+02, Power=6.80e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00200: Time=  12.1s, Loss=2.98e+00, Inv=2.98e+00, For=1.01e+02, Power=6.78e-01
  [eval] val_mse=3.367e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 2.367e-01
Torque MSE  = 1.083e-01
Torque RMSE = 3.292e-01
Per-joint MSE : 7.265e-02 3.515e-01 5.307e-02 2.033e-02 1.366e-01 1.588e-02
Per-joint RMSE: 2.695e-01 5.929e-01 2.304e-01 1.426e-01 3.697e-01 1.260e-01
Comp Time per Sample = 3.094e-04s / 3232.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-7dr663md because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x79a3303828c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:49:13.576331: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:49:15.383320: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.0s, Loss=1.12e+04, Inv=1.12e+04, For=5.76e+00, Power=1.01e+03
  [eval] val_mse=2.198e+02  (n=7000)
Epoch 00002: Time=   5.6s, Loss=8.23e+02, Inv=8.23e+02, For=5.64e+00, Power=7.28e+01
  [eval] val_mse=8.858e+01  (n=7000)
Epoch 00003: Time=   5.6s, Loss=3.40e+02, Inv=3.40e+02, For=5.72e+00, Power=3.22e+01
  [eval] val_mse=4.973e+01  (n=7000)
Epoch 00004: Time=   5.7s, Loss=2.03e+02, Inv=2.03e+02, For=5.80e+00, Power=1.99e+01
  [eval] val_mse=3.172e+01  (n=7000)
Epoch 00005: Time=   5.7s, Loss=1.36e+02, Inv=1.36e+02, For=5.93e+00, Power=1.34e+01
  [eval] val_mse=2.184e+01  (n=7000)
Epoch 00006: Time=   5.7s, Loss=9.71e+01, Inv=9.71e+01, For=6.06e+00, Power=9.72e+00
  [eval] val_mse=1.598e+01  (n=7000)
Epoch 00007: Time=   5.8s, Loss=7.31e+01, Inv=7.31e+01, For=6.27e+00, Power=7.32e+00
  [eval] val_mse=1.225e+01  (n=7000)
Epoch 00008: Time=   5.8s, Loss=5.73e+01, Inv=5.73e+01, For=6.53e+00, Power=5.81e+00
  [eval] val_mse=9.755e+00  (n=7000)
Epoch 00009: Time=   5.8s, Loss=4.65e+01, Inv=4.65e+01, For=6.81e+00, Power=4.70e+00
  [eval] val_mse=7.942e+00  (n=7000)
Epoch 00010: Time=   5.9s, Loss=3.84e+01, Inv=3.84e+01, For=7.08e+00, Power=3.92e+00
  [eval] val_mse=6.624e+00  (n=7000)
Epoch 00011: Time=   5.9s, Loss=3.24e+01, Inv=3.24e+01, For=7.37e+00, Power=3.34e+00
  [eval] val_mse=5.608e+00  (n=7000)
Epoch 00012: Time=   5.9s, Loss=2.78e+01, Inv=2.78e+01, For=7.59e+00, Power=2.88e+00
  [eval] val_mse=4.823e+00  (n=7000)
Epoch 00013: Time=   6.0s, Loss=2.42e+01, Inv=2.42e+01, For=7.82e+00, Power=2.54e+00
  [eval] val_mse=4.204e+00  (n=7000)
Epoch 00014: Time=   6.0s, Loss=2.13e+01, Inv=2.13e+01, For=8.01e+00, Power=2.24e+00
  [eval] val_mse=3.715e+00  (n=7000)
Epoch 00015: Time=   6.0s, Loss=1.90e+01, Inv=1.90e+01, For=8.19e+00, Power=2.03e+00
  [eval] val_mse=3.315e+00  (n=7000)
Epoch 00016: Time=   6.1s, Loss=1.72e+01, Inv=1.72e+01, For=8.38e+00, Power=1.85e+00
  [eval] val_mse=2.988e+00  (n=7000)
Epoch 00017: Time=   6.1s, Loss=1.56e+01, Inv=1.56e+01, For=8.55e+00, Power=1.71e+00
  [eval] val_mse=2.710e+00  (n=7000)
Epoch 00018: Time=   6.1s, Loss=1.43e+01, Inv=1.43e+01, For=8.72e+00, Power=1.58e+00
  [eval] val_mse=2.484e+00  (n=7000)
Epoch 00019: Time=   6.2s, Loss=1.31e+01, Inv=1.31e+01, For=8.87e+00, Power=1.48e+00
  [eval] val_mse=2.290e+00  (n=7000)
Epoch 00020: Time=   6.2s, Loss=1.22e+01, Inv=1.22e+01, For=9.11e+00, Power=1.39e+00
  [eval] val_mse=2.128e+00  (n=7000)
Epoch 00021: Time=   6.2s, Loss=1.14e+01, Inv=1.14e+01, For=9.29e+00, Power=1.30e+00
  [eval] val_mse=1.986e+00  (n=7000)
Epoch 00022: Time=   6.3s, Loss=1.07e+01, Inv=1.07e+01, For=9.56e+00, Power=1.25e+00
  [eval] val_mse=1.865e+00  (n=7000)
Epoch 00023: Time=   6.3s, Loss=1.01e+01, Inv=1.01e+01, For=9.87e+00, Power=1.19e+00
  [eval] val_mse=1.763e+00  (n=7000)
Epoch 00024: Time=   6.3s, Loss=9.51e+00, Inv=9.51e+00, For=1.02e+01, Power=1.14e+00
  [eval] val_mse=1.671e+00  (n=7000)
Epoch 00025: Time=   6.4s, Loss=9.07e+00, Inv=9.07e+00, For=1.05e+01, Power=1.10e+00
  [eval] val_mse=1.587e+00  (n=7000)
Epoch 00026: Time=   6.4s, Loss=8.62e+00, Inv=8.62e+00, For=1.09e+01, Power=1.06e+00
  [eval] val_mse=1.518e+00  (n=7000)
Epoch 00027: Time=   6.4s, Loss=8.24e+00, Inv=8.24e+00, For=1.13e+01, Power=1.03e+00
  [eval] val_mse=1.452e+00  (n=7000)
Epoch 00028: Time=   6.5s, Loss=7.90e+00, Inv=7.90e+00, For=1.17e+01, Power=9.97e-01
  [eval] val_mse=1.393e+00  (n=7000)
Epoch 00029: Time=   6.5s, Loss=7.59e+00, Inv=7.59e+00, For=1.21e+01, Power=9.72e-01
  [eval] val_mse=1.341e+00  (n=7000)
Epoch 00030: Time=   6.5s, Loss=7.34e+00, Inv=7.34e+00, For=1.26e+01, Power=9.47e-01
  [eval] val_mse=1.293e+00  (n=7000)
Epoch 00031: Time=   6.6s, Loss=7.08e+00, Inv=7.08e+00, For=1.31e+01, Power=9.27e-01
  [eval] val_mse=1.247e+00  (n=7000)
Epoch 00032: Time=   6.6s, Loss=6.86e+00, Inv=6.86e+00, For=1.36e+01, Power=9.12e-01
  [eval] val_mse=1.207e+00  (n=7000)
Epoch 00033: Time=   6.7s, Loss=6.66e+00, Inv=6.66e+00, For=1.41e+01, Power=8.91e-01
  [eval] val_mse=1.171e+00  (n=7000)
Epoch 00034: Time=   6.7s, Loss=6.47e+00, Inv=6.47e+00, For=1.46e+01, Power=8.77e-01
  [eval] val_mse=1.135e+00  (n=7000)
Epoch 00035: Time=   6.7s, Loss=6.30e+00, Inv=6.30e+00, For=1.52e+01, Power=8.66e-01
  [eval] val_mse=1.102e+00  (n=7000)
Epoch 00036: Time=   6.7s, Loss=6.14e+00, Inv=6.14e+00, For=1.57e+01, Power=8.54e-01
  [eval] val_mse=1.072e+00  (n=7000)
Epoch 00037: Time=   6.8s, Loss=5.99e+00, Inv=5.99e+00, For=1.62e+01, Power=8.42e-01
  [eval] val_mse=1.043e+00  (n=7000)
Epoch 00038: Time=   6.8s, Loss=5.86e+00, Inv=5.86e+00, For=1.67e+01, Power=8.30e-01
  [eval] val_mse=1.017e+00  (n=7000)
Epoch 00039: Time=   6.8s, Loss=5.72e+00, Inv=5.72e+00, For=1.74e+01, Power=8.23e-01
  [eval] val_mse=9.915e-01  (n=7000)
Epoch 00040: Time=   6.9s, Loss=5.61e+00, Inv=5.61e+00, For=1.79e+01, Power=8.15e-01
  [eval] val_mse=9.697e-01  (n=7000)
Epoch 00041: Time=   6.9s, Loss=5.51e+00, Inv=5.51e+00, For=1.85e+01, Power=8.04e-01
  [eval] val_mse=9.476e-01  (n=7000)
Epoch 00042: Time=   6.9s, Loss=5.40e+00, Inv=5.40e+00, For=1.91e+01, Power=7.95e-01
  [eval] val_mse=9.270e-01  (n=7000)
Epoch 00043: Time=   7.0s, Loss=5.30e+00, Inv=5.30e+00, For=1.97e+01, Power=7.91e-01
  [eval] val_mse=9.073e-01  (n=7000)
Epoch 00044: Time=   7.0s, Loss=5.21e+00, Inv=5.21e+00, For=2.04e+01, Power=7.85e-01
  [eval] val_mse=8.907e-01  (n=7000)
Epoch 00045: Time=   7.0s, Loss=5.13e+00, Inv=5.13e+00, For=2.10e+01, Power=7.79e-01
  [eval] val_mse=8.732e-01  (n=7000)
Epoch 00046: Time=   7.1s, Loss=5.05e+00, Inv=5.05e+00, For=2.17e+01, Power=7.74e-01
  [eval] val_mse=8.566e-01  (n=7000)
Epoch 00047: Time=   7.1s, Loss=4.98e+00, Inv=4.98e+00, For=2.24e+01, Power=7.67e-01
  [eval] val_mse=8.416e-01  (n=7000)
Epoch 00048: Time=   7.1s, Loss=4.91e+00, Inv=4.91e+00, For=2.31e+01, Power=7.65e-01
  [eval] val_mse=8.277e-01  (n=7000)
Epoch 00049: Time=   7.2s, Loss=4.84e+00, Inv=4.84e+00, For=2.38e+01, Power=7.59e-01
  [eval] val_mse=8.131e-01  (n=7000)
Epoch 00050: Time=   7.2s, Loss=4.77e+00, Inv=4.77e+00, For=2.44e+01, Power=7.54e-01
  [eval] val_mse=8.008e-01  (n=7000)
Epoch 00051: Time=   7.2s, Loss=4.70e+00, Inv=4.70e+00, For=2.52e+01, Power=7.51e-01
  [eval] val_mse=7.885e-01  (n=7000)
Epoch 00052: Time=   7.3s, Loss=4.64e+00, Inv=4.64e+00, For=2.60e+01, Power=7.47e-01
  [eval] val_mse=7.774e-01  (n=7000)
Epoch 00053: Time=   7.3s, Loss=4.59e+00, Inv=4.59e+00, For=2.69e+01, Power=7.42e-01
  [eval] val_mse=7.664e-01  (n=7000)
Epoch 00054: Time=   7.3s, Loss=4.53e+00, Inv=4.53e+00, For=2.75e+01, Power=7.38e-01
  [eval] val_mse=7.556e-01  (n=7000)
Epoch 00055: Time=   7.4s, Loss=4.49e+00, Inv=4.49e+00, For=2.85e+01, Power=7.37e-01
  [eval] val_mse=7.473e-01  (n=7000)
Epoch 00056: Time=   7.4s, Loss=4.44e+00, Inv=4.44e+00, For=2.92e+01, Power=7.36e-01
  [eval] val_mse=7.370e-01  (n=7000)
Epoch 00057: Time=   7.4s, Loss=4.39e+00, Inv=4.39e+00, For=3.02e+01, Power=7.33e-01
  [eval] val_mse=7.286e-01  (n=7000)
Epoch 00058: Time=   7.5s, Loss=4.35e+00, Inv=4.35e+00, For=3.10e+01, Power=7.29e-01
  [eval] val_mse=7.198e-01  (n=7000)
Epoch 00059: Time=   7.5s, Loss=4.30e+00, Inv=4.30e+00, For=3.19e+01, Power=7.29e-01
  [eval] val_mse=7.120e-01  (n=7000)
Epoch 00060: Time=   7.5s, Loss=4.27e+00, Inv=4.27e+00, For=3.27e+01, Power=7.26e-01
  [eval] val_mse=7.047e-01  (n=7000)
Epoch 00061: Time=   7.6s, Loss=4.22e+00, Inv=4.22e+00, For=3.39e+01, Power=7.22e-01
  [eval] val_mse=6.968e-01  (n=7000)
Epoch 00062: Time=   7.6s, Loss=4.19e+00, Inv=4.19e+00, For=3.48e+01, Power=7.22e-01
  [eval] val_mse=6.901e-01  (n=7000)
Epoch 00063: Time=   7.6s, Loss=4.15e+00, Inv=4.15e+00, For=3.58e+01, Power=7.15e-01
  [eval] val_mse=6.830e-01  (n=7000)
Epoch 00064: Time=   7.7s, Loss=4.12e+00, Inv=4.12e+00, For=3.66e+01, Power=7.18e-01
  [eval] val_mse=6.764e-01  (n=7000)
Epoch 00065: Time=   7.7s, Loss=4.09e+00, Inv=4.09e+00, For=3.81e+01, Power=7.15e-01
  [eval] val_mse=6.710e-01  (n=7000)
Epoch 00066: Time=   7.7s, Loss=4.06e+00, Inv=4.06e+00, For=3.91e+01, Power=7.16e-01
  [eval] val_mse=6.640e-01  (n=7000)
Epoch 00067: Time=   7.8s, Loss=4.03e+00, Inv=4.03e+00, For=4.01e+01, Power=7.12e-01
  [eval] val_mse=6.578e-01  (n=7000)
Epoch 00068: Time=   7.8s, Loss=4.00e+00, Inv=4.00e+00, For=4.13e+01, Power=7.12e-01
  [eval] val_mse=6.524e-01  (n=7000)
Epoch 00069: Time=   7.8s, Loss=3.97e+00, Inv=3.97e+00, For=4.23e+01, Power=7.08e-01
  [eval] val_mse=6.465e-01  (n=7000)
Epoch 00070: Time=   7.9s, Loss=3.94e+00, Inv=3.94e+00, For=4.35e+01, Power=7.13e-01
  [eval] val_mse=6.418e-01  (n=7000)
Epoch 00071: Time=   7.9s, Loss=3.92e+00, Inv=3.92e+00, For=4.49e+01, Power=7.10e-01
  [eval] val_mse=6.360e-01  (n=7000)
Epoch 00072: Time=   7.9s, Loss=3.89e+00, Inv=3.89e+00, For=4.62e+01, Power=7.08e-01
  [eval] val_mse=6.321e-01  (n=7000)
Epoch 00073: Time=   8.0s, Loss=3.87e+00, Inv=3.87e+00, For=4.76e+01, Power=7.09e-01
  [eval] val_mse=6.272e-01  (n=7000)
Epoch 00074: Time=   8.0s, Loss=3.85e+00, Inv=3.85e+00, For=4.85e+01, Power=7.07e-01
  [eval] val_mse=6.219e-01  (n=7000)
Epoch 00075: Time=   8.0s, Loss=3.83e+00, Inv=3.83e+00, For=5.01e+01, Power=7.08e-01
  [eval] val_mse=6.165e-01  (n=7000)
Epoch 00076: Time=   8.1s, Loss=3.81e+00, Inv=3.81e+00, For=5.14e+01, Power=7.04e-01
  [eval] val_mse=6.117e-01  (n=7000)
Epoch 00077: Time=   8.1s, Loss=3.79e+00, Inv=3.79e+00, For=5.28e+01, Power=7.06e-01
  [eval] val_mse=6.080e-01  (n=7000)
Epoch 00078: Time=   8.1s, Loss=3.77e+00, Inv=3.77e+00, For=5.44e+01, Power=7.03e-01
  [eval] val_mse=6.023e-01  (n=7000)
Epoch 00079: Time=   8.2s, Loss=3.75e+00, Inv=3.75e+00, For=5.54e+01, Power=7.03e-01
  [eval] val_mse=5.975e-01  (n=7000)
Epoch 00080: Time=   8.2s, Loss=3.73e+00, Inv=3.73e+00, For=5.69e+01, Power=7.00e-01
  [eval] val_mse=5.947e-01  (n=7000)
Epoch 00081: Time=   8.2s, Loss=3.71e+00, Inv=3.71e+00, For=5.87e+01, Power=7.04e-01
  [eval] val_mse=5.896e-01  (n=7000)
Epoch 00082: Time=   8.3s, Loss=3.69e+00, Inv=3.69e+00, For=5.99e+01, Power=7.00e-01
  [eval] val_mse=5.874e-01  (n=7000)
Epoch 00083: Time=   8.3s, Loss=3.68e+00, Inv=3.68e+00, For=6.19e+01, Power=6.98e-01
  [eval] val_mse=5.828e-01  (n=7000)
Epoch 00084: Time=   8.3s, Loss=3.66e+00, Inv=3.66e+00, For=6.29e+01, Power=6.98e-01
  [eval] val_mse=5.795e-01  (n=7000)
Epoch 00085: Time=   8.4s, Loss=3.65e+00, Inv=3.65e+00, For=6.51e+01, Power=6.98e-01
  [eval] val_mse=5.746e-01  (n=7000)
Epoch 00086: Time=   8.4s, Loss=3.63e+00, Inv=3.63e+00, For=6.62e+01, Power=6.99e-01
  [eval] val_mse=5.715e-01  (n=7000)
Epoch 00087: Time=   8.4s, Loss=3.62e+00, Inv=3.62e+00, For=6.85e+01, Power=6.94e-01
  [eval] val_mse=5.669e-01  (n=7000)
Epoch 00088: Time=   8.5s, Loss=3.60e+00, Inv=3.60e+00, For=6.98e+01, Power=6.98e-01
  [eval] val_mse=5.635e-01  (n=7000)
Epoch 00089: Time=   8.5s, Loss=3.59e+00, Inv=3.59e+00, For=7.15e+01, Power=6.96e-01
  [eval] val_mse=5.598e-01  (n=7000)
Epoch 00090: Time=   8.5s, Loss=3.58e+00, Inv=3.58e+00, For=7.32e+01, Power=6.94e-01
  [eval] val_mse=5.559e-01  (n=7000)
Epoch 00091: Time=   8.6s, Loss=3.56e+00, Inv=3.56e+00, For=7.49e+01, Power=6.96e-01
  [eval] val_mse=5.522e-01  (n=7000)
Epoch 00092: Time=   8.6s, Loss=3.55e+00, Inv=3.55e+00, For=7.65e+01, Power=6.96e-01
  [eval] val_mse=5.499e-01  (n=7000)
Epoch 00093: Time=   8.6s, Loss=3.53e+00, Inv=3.53e+00, For=7.90e+01, Power=6.93e-01
  [eval] val_mse=5.463e-01  (n=7000)
Epoch 00094: Time=   8.7s, Loss=3.52e+00, Inv=3.52e+00, For=8.01e+01, Power=6.94e-01
  [eval] val_mse=5.434e-01  (n=7000)
Epoch 00095: Time=   8.7s, Loss=3.52e+00, Inv=3.52e+00, For=8.28e+01, Power=6.96e-01
  [eval] val_mse=5.392e-01  (n=7000)
Epoch 00096: Time=   8.7s, Loss=3.50e+00, Inv=3.50e+00, For=8.41e+01, Power=6.95e-01
  [eval] val_mse=5.371e-01  (n=7000)
Epoch 00097: Time=   8.8s, Loss=3.49e+00, Inv=3.49e+00, For=8.59e+01, Power=6.92e-01
  [eval] val_mse=5.343e-01  (n=7000)
Epoch 00098: Time=   8.8s, Loss=3.48e+00, Inv=3.48e+00, For=8.83e+01, Power=6.92e-01
  [eval] val_mse=5.319e-01  (n=7000)
Epoch 00099: Time=   8.8s, Loss=3.47e+00, Inv=3.47e+00, For=9.12e+01, Power=6.93e-01
  [eval] val_mse=5.274e-01  (n=7000)
Epoch 00100: Time=   8.9s, Loss=3.46e+00, Inv=3.46e+00, For=9.20e+01, Power=6.93e-01
  [eval] val_mse=5.253e-01  (n=7000)
Epoch 00101: Time=   8.9s, Loss=3.45e+00, Inv=3.45e+00, For=9.44e+01, Power=6.92e-01
  [eval] val_mse=5.230e-01  (n=7000)
Epoch 00102: Time=   8.9s, Loss=3.44e+00, Inv=3.44e+00, For=9.62e+01, Power=6.90e-01
  [eval] val_mse=5.206e-01  (n=7000)
Epoch 00103: Time=   9.0s, Loss=3.43e+00, Inv=3.43e+00, For=9.85e+01, Power=6.91e-01
  [eval] val_mse=5.163e-01  (n=7000)
Epoch 00104: Time=   9.0s, Loss=3.42e+00, Inv=3.42e+00, For=1.01e+02, Power=6.91e-01
  [eval] val_mse=5.144e-01  (n=7000)
Epoch 00105: Time=   9.0s, Loss=3.41e+00, Inv=3.41e+00, For=1.03e+02, Power=6.91e-01
  [eval] val_mse=5.116e-01  (n=7000)
Epoch 00106: Time=   9.1s, Loss=3.40e+00, Inv=3.40e+00, For=1.05e+02, Power=6.87e-01
  [eval] val_mse=5.097e-01  (n=7000)
Epoch 00107: Time=   9.1s, Loss=3.39e+00, Inv=3.39e+00, For=1.07e+02, Power=6.89e-01
  [eval] val_mse=5.076e-01  (n=7000)
Epoch 00108: Time=   9.1s, Loss=3.38e+00, Inv=3.38e+00, For=1.09e+02, Power=6.88e-01
  [eval] val_mse=5.046e-01  (n=7000)
Epoch 00109: Time=   9.2s, Loss=3.38e+00, Inv=3.38e+00, For=1.13e+02, Power=6.90e-01
  [eval] val_mse=5.008e-01  (n=7000)
Epoch 00110: Time=   9.2s, Loss=3.36e+00, Inv=3.36e+00, For=1.13e+02, Power=6.89e-01
  [eval] val_mse=5.006e-01  (n=7000)
Epoch 00111: Time=   9.2s, Loss=3.36e+00, Inv=3.36e+00, For=1.16e+02, Power=6.89e-01
  [eval] val_mse=4.968e-01  (n=7000)
Epoch 00112: Time=   9.3s, Loss=3.35e+00, Inv=3.35e+00, For=1.19e+02, Power=6.89e-01
  [eval] val_mse=4.939e-01  (n=7000)
Epoch 00113: Time=   9.3s, Loss=3.34e+00, Inv=3.34e+00, For=1.21e+02, Power=6.88e-01
  [eval] val_mse=4.922e-01  (n=7000)
Epoch 00114: Time=   9.3s, Loss=3.34e+00, Inv=3.34e+00, For=1.23e+02, Power=6.88e-01
  [eval] val_mse=4.897e-01  (n=7000)
Epoch 00115: Time=   9.4s, Loss=3.33e+00, Inv=3.33e+00, For=1.26e+02, Power=6.87e-01
  [eval] val_mse=4.880e-01  (n=7000)
Epoch 00116: Time=   9.4s, Loss=3.32e+00, Inv=3.32e+00, For=1.28e+02, Power=6.88e-01
  [eval] val_mse=4.866e-01  (n=7000)
Epoch 00117: Time=   9.4s, Loss=3.31e+00, Inv=3.31e+00, For=1.32e+02, Power=6.85e-01
  [eval] val_mse=4.841e-01  (n=7000)
Epoch 00118: Time=   9.5s, Loss=3.30e+00, Inv=3.30e+00, For=1.33e+02, Power=6.85e-01
  [eval] val_mse=4.828e-01  (n=7000)
Epoch 00119: Time=   9.5s, Loss=3.30e+00, Inv=3.30e+00, For=1.35e+02, Power=6.86e-01
  [eval] val_mse=4.803e-01  (n=7000)
Epoch 00120: Time=   9.5s, Loss=3.29e+00, Inv=3.29e+00, For=1.37e+02, Power=6.84e-01
  [eval] val_mse=4.797e-01  (n=7000)
Epoch 00121: Time=   9.6s, Loss=3.29e+00, Inv=3.29e+00, For=1.41e+02, Power=6.88e-01
  [eval] val_mse=4.765e-01  (n=7000)
Epoch 00122: Time=   9.6s, Loss=3.28e+00, Inv=3.28e+00, For=1.42e+02, Power=6.88e-01
  [eval] val_mse=4.757e-01  (n=7000)
Epoch 00123: Time=   9.6s, Loss=3.27e+00, Inv=3.27e+00, For=1.47e+02, Power=6.86e-01
  [eval] val_mse=4.724e-01  (n=7000)
Epoch 00124: Time=   9.7s, Loss=3.27e+00, Inv=3.27e+00, For=1.49e+02, Power=6.87e-01
  [eval] val_mse=4.705e-01  (n=7000)
Epoch 00125: Time=   9.7s, Loss=3.26e+00, Inv=3.26e+00, For=1.50e+02, Power=6.84e-01
  [eval] val_mse=4.700e-01  (n=7000)
Epoch 00126: Time=   9.7s, Loss=3.26e+00, Inv=3.26e+00, For=1.54e+02, Power=6.88e-01
  [eval] val_mse=4.677e-01  (n=7000)
Epoch 00127: Time=   9.8s, Loss=3.25e+00, Inv=3.25e+00, For=1.57e+02, Power=6.86e-01
  [eval] val_mse=4.655e-01  (n=7000)
Epoch 00128: Time=   9.8s, Loss=3.24e+00, Inv=3.24e+00, For=1.59e+02, Power=6.85e-01
  [eval] val_mse=4.645e-01  (n=7000)
Epoch 00129: Time=   9.8s, Loss=3.24e+00, Inv=3.24e+00, For=1.62e+02, Power=6.85e-01
  [eval] val_mse=4.637e-01  (n=7000)
Epoch 00130: Time=   9.9s, Loss=3.24e+00, Inv=3.24e+00, For=1.66e+02, Power=6.84e-01
  [eval] val_mse=4.612e-01  (n=7000)
Epoch 00131: Time=   9.9s, Loss=3.23e+00, Inv=3.23e+00, For=1.69e+02, Power=6.84e-01
  [eval] val_mse=4.603e-01  (n=7000)
Epoch 00132: Time=   9.9s, Loss=3.22e+00, Inv=3.22e+00, For=1.69e+02, Power=6.84e-01
  [eval] val_mse=4.587e-01  (n=7000)
Epoch 00133: Time=  10.0s, Loss=3.22e+00, Inv=3.22e+00, For=1.75e+02, Power=6.84e-01
  [eval] val_mse=4.567e-01  (n=7000)
Epoch 00134: Time=  10.0s, Loss=3.21e+00, Inv=3.21e+00, For=1.76e+02, Power=6.84e-01
  [eval] val_mse=4.554e-01  (n=7000)
Epoch 00135: Time=  10.0s, Loss=3.21e+00, Inv=3.21e+00, For=1.80e+02, Power=6.84e-01
  [eval] val_mse=4.519e-01  (n=7000)
Epoch 00136: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=1.81e+02, Power=6.82e-01
  [eval] val_mse=4.534e-01  (n=7000)
Epoch 00137: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=1.86e+02, Power=6.84e-01
  [eval] val_mse=4.507e-01  (n=7000)
Epoch 00138: Time=  10.1s, Loss=3.19e+00, Inv=3.19e+00, For=1.88e+02, Power=6.84e-01
  [eval] val_mse=4.501e-01  (n=7000)
Epoch 00139: Time=  10.2s, Loss=3.19e+00, Inv=3.19e+00, For=1.91e+02, Power=6.84e-01
  [eval] val_mse=4.482e-01  (n=7000)
Epoch 00140: Time=  10.2s, Loss=3.18e+00, Inv=3.18e+00, For=1.93e+02, Power=6.80e-01
  [eval] val_mse=4.467e-01  (n=7000)
Epoch 00141: Time=  10.2s, Loss=3.18e+00, Inv=3.18e+00, For=1.96e+02, Power=6.84e-01
  [eval] val_mse=4.458e-01  (n=7000)
Epoch 00142: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=1.99e+02, Power=6.83e-01
  [eval] val_mse=4.438e-01  (n=7000)
Epoch 00143: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=2.02e+02, Power=6.85e-01
  [eval] val_mse=4.427e-01  (n=7000)
Epoch 00144: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=2.03e+02, Power=6.82e-01
  [eval] val_mse=4.421e-01  (n=7000)
Epoch 00145: Time=  10.4s, Loss=3.17e+00, Inv=3.17e+00, For=2.10e+02, Power=6.85e-01
  [eval] val_mse=4.406e-01  (n=7000)
Epoch 00146: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=2.13e+02, Power=6.84e-01
  [eval] val_mse=4.397e-01  (n=7000)
Epoch 00147: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=2.15e+02, Power=6.82e-01
  [eval] val_mse=4.385e-01  (n=7000)
Epoch 00148: Time=  10.5s, Loss=3.15e+00, Inv=3.15e+00, For=2.17e+02, Power=6.80e-01
  [eval] val_mse=4.387e-01  (n=7000)
Epoch 00149: Time=  10.5s, Loss=3.15e+00, Inv=3.15e+00, For=2.20e+02, Power=6.81e-01
  [eval] val_mse=4.358e-01  (n=7000)
Epoch 00150: Time=  10.5s, Loss=3.15e+00, Inv=3.15e+00, For=2.24e+02, Power=6.82e-01
  [eval] val_mse=4.355e-01  (n=7000)
Epoch 00151: Time=  10.6s, Loss=3.14e+00, Inv=3.14e+00, For=2.27e+02, Power=6.82e-01
  [eval] val_mse=4.331e-01  (n=7000)
Epoch 00152: Time=  10.6s, Loss=3.13e+00, Inv=3.13e+00, For=2.29e+02, Power=6.81e-01
  [eval] val_mse=4.326e-01  (n=7000)
Epoch 00153: Time=  10.6s, Loss=3.13e+00, Inv=3.13e+00, For=2.34e+02, Power=6.82e-01
  [eval] val_mse=4.303e-01  (n=7000)
Epoch 00154: Time=  10.7s, Loss=3.13e+00, Inv=3.13e+00, For=2.33e+02, Power=6.82e-01
  [eval] val_mse=4.321e-01  (n=7000)
Epoch 00155: Time=  10.7s, Loss=3.13e+00, Inv=3.13e+00, For=2.39e+02, Power=6.83e-01
  [eval] val_mse=4.305e-01  (n=7000)
Epoch 00156: Time=  10.7s, Loss=3.12e+00, Inv=3.12e+00, For=2.41e+02, Power=6.83e-01
  [eval] val_mse=4.279e-01  (n=7000)
Epoch 00157: Time=  10.8s, Loss=3.12e+00, Inv=3.12e+00, For=2.39e+02, Power=6.84e-01
  [eval] val_mse=4.277e-01  (n=7000)
Epoch 00158: Time=  10.8s, Loss=3.12e+00, Inv=3.12e+00, For=2.49e+02, Power=6.81e-01
  [eval] val_mse=4.258e-01  (n=7000)
Epoch 00159: Time=  10.8s, Loss=3.11e+00, Inv=3.11e+00, For=2.49e+02, Power=6.81e-01
  [eval] val_mse=4.245e-01  (n=7000)
Epoch 00160: Time=  10.9s, Loss=3.11e+00, Inv=3.11e+00, For=2.53e+02, Power=6.83e-01
  [eval] val_mse=4.238e-01  (n=7000)
Epoch 00161: Time=  10.9s, Loss=3.10e+00, Inv=3.10e+00, For=2.56e+02, Power=6.82e-01
  [eval] val_mse=4.228e-01  (n=7000)
Epoch 00162: Time=  10.9s, Loss=3.10e+00, Inv=3.10e+00, For=2.58e+02, Power=6.81e-01
  [eval] val_mse=4.216e-01  (n=7000)
Epoch 00163: Time=  11.0s, Loss=3.10e+00, Inv=3.10e+00, For=2.60e+02, Power=6.83e-01
  [eval] val_mse=4.209e-01  (n=7000)
Epoch 00164: Time=  11.0s, Loss=3.09e+00, Inv=3.09e+00, For=2.62e+02, Power=6.80e-01
  [eval] val_mse=4.194e-01  (n=7000)
Epoch 00165: Time=  11.0s, Loss=3.09e+00, Inv=3.09e+00, For=2.65e+02, Power=6.83e-01
  [eval] val_mse=4.196e-01  (n=7000)
Epoch 00166: Time=  11.1s, Loss=3.09e+00, Inv=3.09e+00, For=2.64e+02, Power=6.82e-01
  [eval] val_mse=4.194e-01  (n=7000)
Epoch 00167: Time=  11.1s, Loss=3.08e+00, Inv=3.08e+00, For=2.72e+02, Power=6.82e-01
  [eval] val_mse=4.179e-01  (n=7000)
Epoch 00168: Time=  11.1s, Loss=3.08e+00, Inv=3.08e+00, For=2.73e+02, Power=6.83e-01
  [eval] val_mse=4.173e-01  (n=7000)
Epoch 00169: Time=  11.2s, Loss=3.08e+00, Inv=3.08e+00, For=2.76e+02, Power=6.78e-01
  [eval] val_mse=4.168e-01  (n=7000)
Epoch 00170: Time=  11.2s, Loss=3.08e+00, Inv=3.08e+00, For=2.78e+02, Power=6.81e-01
  [eval] val_mse=4.149e-01  (n=7000)
Epoch 00171: Time=  11.2s, Loss=3.08e+00, Inv=3.08e+00, For=2.84e+02, Power=6.82e-01
  [eval] val_mse=4.140e-01  (n=7000)
Epoch 00172: Time=  11.3s, Loss=3.07e+00, Inv=3.07e+00, For=2.82e+02, Power=6.81e-01
  [eval] val_mse=4.127e-01  (n=7000)
Epoch 00173: Time=  11.3s, Loss=3.07e+00, Inv=3.07e+00, For=2.83e+02, Power=6.83e-01
  [eval] val_mse=4.125e-01  (n=7000)
Epoch 00174: Time=  11.3s, Loss=3.07e+00, Inv=3.07e+00, For=2.90e+02, Power=6.82e-01
  [eval] val_mse=4.115e-01  (n=7000)
Epoch 00175: Time=  11.4s, Loss=3.07e+00, Inv=3.07e+00, For=2.86e+02, Power=6.80e-01
  [eval] val_mse=4.131e-01  (n=7000)
Epoch 00176: Time=  11.4s, Loss=3.07e+00, Inv=3.07e+00, For=2.96e+02, Power=6.84e-01
  [eval] val_mse=4.092e-01  (n=7000)
Epoch 00177: Time=  11.4s, Loss=3.06e+00, Inv=3.06e+00, For=2.90e+02, Power=6.78e-01
  [eval] val_mse=4.094e-01  (n=7000)
Epoch 00178: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=2.96e+02, Power=6.79e-01
  [eval] val_mse=4.076e-01  (n=7000)
Epoch 00179: Time=  11.5s, Loss=3.06e+00, Inv=3.06e+00, For=2.97e+02, Power=6.83e-01
  [eval] val_mse=4.086e-01  (n=7000)
Epoch 00180: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=3.00e+02, Power=6.80e-01
  [eval] val_mse=4.069e-01  (n=7000)
Epoch 00181: Time=  11.6s, Loss=3.05e+00, Inv=3.05e+00, For=3.06e+02, Power=6.82e-01
  [eval] val_mse=4.055e-01  (n=7000)
Epoch 00182: Time=  11.6s, Loss=3.04e+00, Inv=3.04e+00, For=3.03e+02, Power=6.77e-01
  [eval] val_mse=4.057e-01  (n=7000)
Epoch 00183: Time=  11.6s, Loss=3.05e+00, Inv=3.05e+00, For=3.05e+02, Power=6.84e-01
  [eval] val_mse=4.065e-01  (n=7000)
Epoch 00184: Time=  11.7s, Loss=3.04e+00, Inv=3.04e+00, For=3.09e+02, Power=6.79e-01
  [eval] val_mse=4.045e-01  (n=7000)
Epoch 00185: Time=  11.7s, Loss=3.04e+00, Inv=3.04e+00, For=3.09e+02, Power=6.81e-01
  [eval] val_mse=4.037e-01  (n=7000)
Epoch 00186: Time=  11.7s, Loss=3.04e+00, Inv=3.04e+00, For=3.11e+02, Power=6.77e-01
  [eval] val_mse=4.017e-01  (n=7000)
Epoch 00187: Time=  11.8s, Loss=3.04e+00, Inv=3.04e+00, For=3.16e+02, Power=6.80e-01
  [eval] val_mse=4.030e-01  (n=7000)
Epoch 00188: Time=  11.8s, Loss=3.04e+00, Inv=3.04e+00, For=3.11e+02, Power=6.80e-01
  [eval] val_mse=4.017e-01  (n=7000)
Epoch 00189: Time=  11.8s, Loss=3.03e+00, Inv=3.03e+00, For=3.11e+02, Power=6.80e-01
  [eval] val_mse=4.013e-01  (n=7000)
Epoch 00190: Time=  11.9s, Loss=3.03e+00, Inv=3.03e+00, For=3.18e+02, Power=6.78e-01
  [eval] val_mse=4.023e-01  (n=7000)
Epoch 00191: Time=  11.9s, Loss=3.03e+00, Inv=3.03e+00, For=3.23e+02, Power=6.81e-01
  [eval] val_mse=3.987e-01  (n=7000)
Epoch 00192: Time=  11.9s, Loss=3.03e+00, Inv=3.03e+00, For=3.19e+02, Power=6.80e-01
  [eval] val_mse=3.994e-01  (n=7000)
Epoch 00193: Time=  12.0s, Loss=3.02e+00, Inv=3.02e+00, For=3.19e+02, Power=6.80e-01
  [eval] val_mse=3.980e-01  (n=7000)
Epoch 00194: Time=  12.0s, Loss=3.02e+00, Inv=3.02e+00, For=3.24e+02, Power=6.80e-01
  [eval] val_mse=3.980e-01  (n=7000)
Epoch 00195: Time=  12.0s, Loss=3.02e+00, Inv=3.02e+00, For=3.24e+02, Power=6.80e-01
  [eval] val_mse=3.988e-01  (n=7000)
Epoch 00196: Time=  12.1s, Loss=3.02e+00, Inv=3.02e+00, For=3.31e+02, Power=6.80e-01
  [eval] val_mse=3.969e-01  (n=7000)
Epoch 00197: Time=  12.1s, Loss=3.02e+00, Inv=3.02e+00, For=3.23e+02, Power=6.78e-01
  [eval] val_mse=3.958e-01  (n=7000)
Epoch 00198: Time=  12.1s, Loss=3.02e+00, Inv=3.02e+00, For=3.27e+02, Power=6.81e-01
  [eval] val_mse=3.944e-01  (n=7000)
Epoch 00199: Time=  12.2s, Loss=3.02e+00, Inv=3.02e+00, For=3.31e+02, Power=6.81e-01
  [eval] val_mse=3.940e-01  (n=7000)
Epoch 00200: Time=  12.2s, Loss=3.01e+00, Inv=3.01e+00, For=3.26e+02, Power=6.80e-01
  [eval] val_mse=3.947e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 2.562e-01
Torque MSE  = 8.274e-02
Torque RMSE = 2.876e-01
Per-joint MSE : 8.889e-02 1.631e-01 6.587e-02 2.087e-02 1.414e-01 1.631e-02
Per-joint RMSE: 2.981e-01 4.038e-01 2.567e-01 1.445e-01 3.761e-01 1.277e-01
Comp Time per Sample = 3.064e-04s / 3263.8Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 1 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-qzec4sjt because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7866acf868c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:49:37.102814: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:49:38.895237: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=1.16e+04, Inv=1.16e+04, For=5.81e+00, Power=1.65e+03
  [eval] val_mse=1.246e+02  (n=2997)
Epoch 00002: Time=   5.3s, Loss=7.32e+02, Inv=7.32e+02, For=5.51e+00, Power=1.10e+02
  [eval] val_mse=4.840e+01  (n=2997)
Epoch 00003: Time=   5.3s, Loss=3.17e+02, Inv=3.17e+02, For=5.32e+00, Power=5.03e+01
  [eval] val_mse=2.867e+01  (n=2997)
Epoch 00004: Time=   5.3s, Loss=1.88e+02, Inv=1.88e+02, For=5.19e+00, Power=3.08e+01
  [eval] val_mse=1.954e+01  (n=2997)
Epoch 00005: Time=   5.4s, Loss=1.25e+02, Inv=1.25e+02, For=5.11e+00, Power=2.06e+01
  [eval] val_mse=1.448e+01  (n=2997)
Epoch 00006: Time=   5.4s, Loss=8.87e+01, Inv=8.87e+01, For=5.05e+00, Power=1.46e+01
  [eval] val_mse=1.142e+01  (n=2997)
Epoch 00007: Time=   5.5s, Loss=6.61e+01, Inv=6.61e+01, For=5.04e+00, Power=1.08e+01
  [eval] val_mse=9.469e+00  (n=2997)
Epoch 00008: Time=   5.5s, Loss=5.13e+01, Inv=5.13e+01, For=5.06e+00, Power=8.27e+00
  [eval] val_mse=8.124e+00  (n=2997)
Epoch 00009: Time=   5.5s, Loss=4.11e+01, Inv=4.11e+01, For=5.11e+00, Power=6.57e+00
  [eval] val_mse=7.137e+00  (n=2997)
Epoch 00010: Time=   5.6s, Loss=3.37e+01, Inv=3.37e+01, For=5.18e+00, Power=5.32e+00
  [eval] val_mse=6.412e+00  (n=2997)
Epoch 00011: Time=   5.6s, Loss=2.83e+01, Inv=2.83e+01, For=5.28e+00, Power=4.38e+00
  [eval] val_mse=5.840e+00  (n=2997)
Epoch 00012: Time=   5.6s, Loss=2.41e+01, Inv=2.41e+01, For=5.41e+00, Power=3.69e+00
  [eval] val_mse=5.388e+00  (n=2997)
Epoch 00013: Time=   5.7s, Loss=2.09e+01, Inv=2.09e+01, For=5.57e+00, Power=3.15e+00
  [eval] val_mse=4.982e+00  (n=2997)
Epoch 00014: Time=   5.7s, Loss=1.84e+01, Inv=1.84e+01, For=5.77e+00, Power=2.73e+00
  [eval] val_mse=4.656e+00  (n=2997)
Epoch 00015: Time=   5.7s, Loss=1.63e+01, Inv=1.63e+01, For=6.01e+00, Power=2.40e+00
  [eval] val_mse=4.358e+00  (n=2997)
Epoch 00016: Time=   5.8s, Loss=1.47e+01, Inv=1.47e+01, For=6.31e+00, Power=2.13e+00
  [eval] val_mse=4.107e+00  (n=2997)
Epoch 00017: Time=   5.8s, Loss=1.33e+01, Inv=1.33e+01, For=6.63e+00, Power=1.90e+00
  [eval] val_mse=3.879e+00  (n=2997)
Epoch 00018: Time=   5.8s, Loss=1.22e+01, Inv=1.22e+01, For=7.02e+00, Power=1.72e+00
  [eval] val_mse=3.674e+00  (n=2997)
Epoch 00019: Time=   5.9s, Loss=1.12e+01, Inv=1.12e+01, For=7.45e+00, Power=1.57e+00
  [eval] val_mse=3.502e+00  (n=2997)
Epoch 00020: Time=   5.9s, Loss=1.04e+01, Inv=1.04e+01, For=7.91e+00, Power=1.44e+00
  [eval] val_mse=3.352e+00  (n=2997)
Epoch 00021: Time=   5.9s, Loss=9.77e+00, Inv=9.77e+00, For=8.47e+00, Power=1.34e+00
  [eval] val_mse=3.222e+00  (n=2997)
Epoch 00022: Time=   6.0s, Loss=9.18e+00, Inv=9.18e+00, For=9.02e+00, Power=1.25e+00
  [eval] val_mse=3.096e+00  (n=2997)
Epoch 00023: Time=   6.0s, Loss=8.69e+00, Inv=8.69e+00, For=9.62e+00, Power=1.17e+00
  [eval] val_mse=2.982e+00  (n=2997)
Epoch 00024: Time=   6.0s, Loss=8.26e+00, Inv=8.26e+00, For=1.03e+01, Power=1.10e+00
  [eval] val_mse=2.887e+00  (n=2997)
Epoch 00025: Time=   6.1s, Loss=7.88e+00, Inv=7.88e+00, For=1.09e+01, Power=1.05e+00
  [eval] val_mse=2.792e+00  (n=2997)
Epoch 00026: Time=   6.1s, Loss=7.55e+00, Inv=7.55e+00, For=1.16e+01, Power=9.99e-01
  [eval] val_mse=2.721e+00  (n=2997)
Epoch 00027: Time=   6.2s, Loss=7.25e+00, Inv=7.25e+00, For=1.24e+01, Power=9.57e-01
  [eval] val_mse=2.636e+00  (n=2997)
Epoch 00028: Time=   6.2s, Loss=7.00e+00, Inv=7.00e+00, For=1.32e+01, Power=9.22e-01
  [eval] val_mse=2.570e+00  (n=2997)
Epoch 00029: Time=   6.2s, Loss=6.76e+00, Inv=6.76e+00, For=1.40e+01, Power=8.88e-01
  [eval] val_mse=2.498e+00  (n=2997)
Epoch 00030: Time=   6.3s, Loss=6.55e+00, Inv=6.55e+00, For=1.48e+01, Power=8.58e-01
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00031: Time=   6.3s, Loss=6.36e+00, Inv=6.36e+00, For=1.57e+01, Power=8.34e-01
  [eval] val_mse=2.379e+00  (n=2997)
Epoch 00032: Time=   6.3s, Loss=6.18e+00, Inv=6.18e+00, For=1.66e+01, Power=8.12e-01
  [eval] val_mse=2.337e+00  (n=2997)
Epoch 00033: Time=   6.4s, Loss=6.02e+00, Inv=6.02e+00, For=1.75e+01, Power=7.90e-01
  [eval] val_mse=2.295e+00  (n=2997)
Epoch 00034: Time=   6.4s, Loss=5.88e+00, Inv=5.88e+00, For=1.85e+01, Power=7.73e-01
  [eval] val_mse=2.254e+00  (n=2997)
Epoch 00035: Time=   6.4s, Loss=5.75e+00, Inv=5.75e+00, For=1.94e+01, Power=7.58e-01
  [eval] val_mse=2.206e+00  (n=2997)
Epoch 00036: Time=   6.5s, Loss=5.63e+00, Inv=5.63e+00, For=2.05e+01, Power=7.43e-01
  [eval] val_mse=2.159e+00  (n=2997)
Epoch 00037: Time=   6.5s, Loss=5.51e+00, Inv=5.51e+00, For=2.15e+01, Power=7.28e-01
  [eval] val_mse=2.139e+00  (n=2997)
Epoch 00038: Time=   6.5s, Loss=5.41e+00, Inv=5.41e+00, For=2.25e+01, Power=7.18e-01
  [eval] val_mse=2.101e+00  (n=2997)
Epoch 00039: Time=   6.6s, Loss=5.31e+00, Inv=5.31e+00, For=2.37e+01, Power=7.07e-01
  [eval] val_mse=2.068e+00  (n=2997)
Epoch 00040: Time=   6.6s, Loss=5.23e+00, Inv=5.23e+00, For=2.47e+01, Power=6.98e-01
  [eval] val_mse=2.034e+00  (n=2997)
Epoch 00041: Time=   6.6s, Loss=5.14e+00, Inv=5.14e+00, For=2.59e+01, Power=6.88e-01
  [eval] val_mse=2.020e+00  (n=2997)
Epoch 00042: Time=   6.7s, Loss=5.06e+00, Inv=5.06e+00, For=2.69e+01, Power=6.78e-01
  [eval] val_mse=1.986e+00  (n=2997)
Epoch 00043: Time=   6.7s, Loss=4.99e+00, Inv=4.99e+00, For=2.82e+01, Power=6.72e-01
  [eval] val_mse=1.960e+00  (n=2997)
Epoch 00044: Time=   6.7s, Loss=4.93e+00, Inv=4.93e+00, For=2.93e+01, Power=6.66e-01
  [eval] val_mse=1.933e+00  (n=2997)
Epoch 00045: Time=   6.8s, Loss=4.86e+00, Inv=4.86e+00, For=3.05e+01, Power=6.60e-01
  [eval] val_mse=1.914e+00  (n=2997)
Epoch 00046: Time=   6.8s, Loss=4.80e+00, Inv=4.80e+00, For=3.17e+01, Power=6.55e-01
  [eval] val_mse=1.903e+00  (n=2997)
Epoch 00047: Time=   6.8s, Loss=4.74e+00, Inv=4.74e+00, For=3.28e+01, Power=6.49e-01
  [eval] val_mse=1.870e+00  (n=2997)
Epoch 00048: Time=   6.9s, Loss=4.69e+00, Inv=4.69e+00, For=3.42e+01, Power=6.44e-01
  [eval] val_mse=1.857e+00  (n=2997)
Epoch 00049: Time=   6.9s, Loss=4.64e+00, Inv=4.64e+00, For=3.53e+01, Power=6.39e-01
  [eval] val_mse=1.847e+00  (n=2997)
Epoch 00050: Time=   7.0s, Loss=4.59e+00, Inv=4.59e+00, For=3.65e+01, Power=6.35e-01
  [eval] val_mse=1.818e+00  (n=2997)
Epoch 00051: Time=   7.0s, Loss=4.55e+00, Inv=4.55e+00, For=3.79e+01, Power=6.32e-01
  [eval] val_mse=1.800e+00  (n=2997)
Epoch 00052: Time=   7.0s, Loss=4.51e+00, Inv=4.51e+00, For=3.89e+01, Power=6.29e-01
  [eval] val_mse=1.785e+00  (n=2997)
Epoch 00053: Time=   7.1s, Loss=4.47e+00, Inv=4.47e+00, For=4.03e+01, Power=6.25e-01
  [eval] val_mse=1.767e+00  (n=2997)
Epoch 00054: Time=   7.1s, Loss=4.42e+00, Inv=4.42e+00, For=4.14e+01, Power=6.22e-01
  [eval] val_mse=1.763e+00  (n=2997)
Epoch 00055: Time=   7.1s, Loss=4.39e+00, Inv=4.39e+00, For=4.28e+01, Power=6.19e-01
  [eval] val_mse=1.741e+00  (n=2997)
Epoch 00056: Time=   7.2s, Loss=4.36e+00, Inv=4.36e+00, For=4.39e+01, Power=6.17e-01
  [eval] val_mse=1.728e+00  (n=2997)
Epoch 00057: Time=   7.2s, Loss=4.32e+00, Inv=4.32e+00, For=4.52e+01, Power=6.14e-01
  [eval] val_mse=1.711e+00  (n=2997)
Epoch 00058: Time=   7.2s, Loss=4.29e+00, Inv=4.29e+00, For=4.64e+01, Power=6.12e-01
  [eval] val_mse=1.691e+00  (n=2997)
Epoch 00059: Time=   7.3s, Loss=4.26e+00, Inv=4.26e+00, For=4.74e+01, Power=6.10e-01
  [eval] val_mse=1.693e+00  (n=2997)
Epoch 00060: Time=   7.3s, Loss=4.23e+00, Inv=4.23e+00, For=4.86e+01, Power=6.08e-01
  [eval] val_mse=1.683e+00  (n=2997)
Epoch 00061: Time=   7.3s, Loss=4.20e+00, Inv=4.20e+00, For=4.97e+01, Power=6.06e-01
  [eval] val_mse=1.667e+00  (n=2997)
Epoch 00062: Time=   7.4s, Loss=4.17e+00, Inv=4.17e+00, For=5.08e+01, Power=6.05e-01
  [eval] val_mse=1.665e+00  (n=2997)
Epoch 00063: Time=   7.4s, Loss=4.15e+00, Inv=4.15e+00, For=5.21e+01, Power=6.02e-01
  [eval] val_mse=1.643e+00  (n=2997)
Epoch 00064: Time=   7.4s, Loss=4.12e+00, Inv=4.12e+00, For=5.31e+01, Power=6.01e-01
  [eval] val_mse=1.653e+00  (n=2997)
Epoch 00065: Time=   7.5s, Loss=4.10e+00, Inv=4.10e+00, For=5.42e+01, Power=6.01e-01
  [eval] val_mse=1.634e+00  (n=2997)
Epoch 00066: Time=   7.5s, Loss=4.08e+00, Inv=4.08e+00, For=5.52e+01, Power=5.98e-01
  [eval] val_mse=1.618e+00  (n=2997)
Epoch 00067: Time=   7.5s, Loss=4.06e+00, Inv=4.06e+00, For=5.63e+01, Power=5.96e-01
  [eval] val_mse=1.626e+00  (n=2997)
Epoch 00068: Time=   7.6s, Loss=4.03e+00, Inv=4.03e+00, For=5.73e+01, Power=5.97e-01
  [eval] val_mse=1.613e+00  (n=2997)
Epoch 00069: Time=   7.6s, Loss=4.01e+00, Inv=4.01e+00, For=5.84e+01, Power=5.95e-01
  [eval] val_mse=1.603e+00  (n=2997)
Epoch 00070: Time=   7.6s, Loss=3.99e+00, Inv=3.99e+00, For=5.94e+01, Power=5.94e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00071: Time=   7.7s, Loss=3.98e+00, Inv=3.98e+00, For=6.01e+01, Power=5.93e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00072: Time=   7.7s, Loss=3.96e+00, Inv=3.96e+00, For=6.11e+01, Power=5.91e-01
  [eval] val_mse=1.609e+00  (n=2997)
Epoch 00073: Time=   7.7s, Loss=3.94e+00, Inv=3.94e+00, For=6.18e+01, Power=5.91e-01
  [eval] val_mse=1.589e+00  (n=2997)
Epoch 00074: Time=   7.8s, Loss=3.92e+00, Inv=3.92e+00, For=6.26e+01, Power=5.90e-01
  [eval] val_mse=1.590e+00  (n=2997)
Epoch 00075: Time=   7.8s, Loss=3.91e+00, Inv=3.91e+00, For=6.34e+01, Power=5.90e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00076: Time=   7.8s, Loss=3.89e+00, Inv=3.89e+00, For=6.44e+01, Power=5.89e-01
  [eval] val_mse=1.587e+00  (n=2997)
Epoch 00077: Time=   7.9s, Loss=3.88e+00, Inv=3.88e+00, For=6.50e+01, Power=5.88e-01
  [eval] val_mse=1.585e+00  (n=2997)
Epoch 00078: Time=   7.9s, Loss=3.86e+00, Inv=3.86e+00, For=6.59e+01, Power=5.87e-01
  [eval] val_mse=1.582e+00  (n=2997)
Epoch 00079: Time=   7.9s, Loss=3.85e+00, Inv=3.85e+00, For=6.67e+01, Power=5.88e-01
  [eval] val_mse=1.587e+00  (n=2997)
Epoch 00080: Time=   8.0s, Loss=3.83e+00, Inv=3.83e+00, For=6.75e+01, Power=5.85e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00081: Time=   8.0s, Loss=3.82e+00, Inv=3.82e+00, For=6.82e+01, Power=5.86e-01
  [eval] val_mse=1.614e+00  (n=2997)
Epoch 00082: Time=   8.1s, Loss=3.81e+00, Inv=3.81e+00, For=6.84e+01, Power=5.86e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00083: Time=   8.1s, Loss=3.79e+00, Inv=3.79e+00, For=6.89e+01, Power=5.85e-01
  [eval] val_mse=1.605e+00  (n=2997)
Epoch 00084: Time=   8.1s, Loss=3.79e+00, Inv=3.79e+00, For=7.00e+01, Power=5.85e-01
  [eval] val_mse=1.602e+00  (n=2997)
Epoch 00085: Time=   8.2s, Loss=3.77e+00, Inv=3.77e+00, For=7.05e+01, Power=5.85e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00086: Time=   8.2s, Loss=3.76e+00, Inv=3.76e+00, For=7.06e+01, Power=5.83e-01
  [eval] val_mse=1.618e+00  (n=2997)
Epoch 00087: Time=   8.2s, Loss=3.75e+00, Inv=3.75e+00, For=7.12e+01, Power=5.84e-01
  [eval] val_mse=1.616e+00  (n=2997)
Epoch 00088: Time=   8.3s, Loss=3.74e+00, Inv=3.74e+00, For=7.17e+01, Power=5.82e-01
  [eval] val_mse=1.612e+00  (n=2997)
  [early_stop] stop at epoch=88 (best_epoch=78, best_val_mse=1.582e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 5.135e-01
Torque MSE  = 1.283e-01
Torque RMSE = 3.582e-01
Per-joint MSE : 1.702e-01 2.866e-01 1.444e-01 5.921e-02 5.355e-02 5.594e-02
Per-joint RMSE: 4.126e-01 5.353e-01 3.800e-01 2.433e-01 2.314e-01 2.365e-01
Comp Time per Sample = 2.028e-04s / 4930.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-42ttelaf because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7cc1b2eaa8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:49:55.052769: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:49:56.855507: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=3.85e+03, Inv=3.85e+03, For=5.67e+00, Power=4.92e+02
  [eval] val_mse=6.448e+01  (n=2997)
Epoch 00002: Time=   5.3s, Loss=2.43e+02, Inv=2.43e+02, For=5.29e+00, Power=4.15e+01
  [eval] val_mse=2.554e+01  (n=2997)
Epoch 00003: Time=   5.3s, Loss=1.13e+02, Inv=1.13e+02, For=5.10e+00, Power=1.86e+01
  [eval] val_mse=1.652e+01  (n=2997)
Epoch 00004: Time=   5.4s, Loss=6.96e+01, Inv=6.96e+01, For=5.02e+00, Power=1.11e+01
  [eval] val_mse=1.220e+01  (n=2997)
Epoch 00005: Time=   5.4s, Loss=4.79e+01, Inv=4.79e+01, For=5.02e+00, Power=7.40e+00
  [eval] val_mse=9.734e+00  (n=2997)
Epoch 00006: Time=   5.4s, Loss=3.55e+01, Inv=3.55e+01, For=5.12e+00, Power=5.26e+00
  [eval] val_mse=8.178e+00  (n=2997)
Epoch 00007: Time=   5.5s, Loss=2.76e+01, Inv=2.76e+01, For=5.31e+00, Power=3.97e+00
  [eval] val_mse=7.084e+00  (n=2997)
Epoch 00008: Time=   5.5s, Loss=2.24e+01, Inv=2.24e+01, For=5.58e+00, Power=3.13e+00
  [eval] val_mse=6.279e+00  (n=2997)
Epoch 00009: Time=   5.5s, Loss=1.86e+01, Inv=1.86e+01, For=5.90e+00, Power=2.55e+00
  [eval] val_mse=5.661e+00  (n=2997)
Epoch 00010: Time=   5.6s, Loss=1.59e+01, Inv=1.59e+01, For=6.25e+00, Power=2.14e+00
  [eval] val_mse=5.165e+00  (n=2997)
Epoch 00011: Time=   5.6s, Loss=1.38e+01, Inv=1.38e+01, For=6.65e+00, Power=1.85e+00
  [eval] val_mse=4.751e+00  (n=2997)
Epoch 00012: Time=   5.6s, Loss=1.22e+01, Inv=1.22e+01, For=7.08e+00, Power=1.63e+00
  [eval] val_mse=4.403e+00  (n=2997)
Epoch 00013: Time=   5.7s, Loss=1.09e+01, Inv=1.09e+01, For=7.54e+00, Power=1.46e+00
  [eval] val_mse=4.105e+00  (n=2997)
Epoch 00014: Time=   5.7s, Loss=9.91e+00, Inv=9.91e+00, For=7.99e+00, Power=1.32e+00
  [eval] val_mse=3.863e+00  (n=2997)
Epoch 00015: Time=   5.7s, Loss=9.10e+00, Inv=9.10e+00, For=8.47e+00, Power=1.21e+00
  [eval] val_mse=3.648e+00  (n=2997)
Epoch 00016: Time=   5.8s, Loss=8.42e+00, Inv=8.42e+00, For=8.95e+00, Power=1.12e+00
  [eval] val_mse=3.475e+00  (n=2997)
Epoch 00017: Time=   5.8s, Loss=7.86e+00, Inv=7.86e+00, For=9.50e+00, Power=1.05e+00
  [eval] val_mse=3.315e+00  (n=2997)
Epoch 00018: Time=   5.8s, Loss=7.40e+00, Inv=7.40e+00, For=9.91e+00, Power=9.95e-01
  [eval] val_mse=3.197e+00  (n=2997)
Epoch 00019: Time=   5.9s, Loss=7.00e+00, Inv=7.00e+00, For=1.04e+01, Power=9.43e-01
  [eval] val_mse=3.085e+00  (n=2997)
Epoch 00020: Time=   5.9s, Loss=6.68e+00, Inv=6.68e+00, For=1.09e+01, Power=9.05e-01
  [eval] val_mse=2.980e+00  (n=2997)
Epoch 00021: Time=   5.9s, Loss=6.39e+00, Inv=6.39e+00, For=1.14e+01, Power=8.72e-01
  [eval] val_mse=2.888e+00  (n=2997)
Epoch 00022: Time=   6.0s, Loss=6.15e+00, Inv=6.15e+00, For=1.19e+01, Power=8.41e-01
  [eval] val_mse=2.806e+00  (n=2997)
Epoch 00023: Time=   6.0s, Loss=5.93e+00, Inv=5.93e+00, For=1.23e+01, Power=8.16e-01
  [eval] val_mse=2.731e+00  (n=2997)
Epoch 00024: Time=   6.0s, Loss=5.75e+00, Inv=5.75e+00, For=1.27e+01, Power=7.96e-01
  [eval] val_mse=2.654e+00  (n=2997)
Epoch 00025: Time=   6.1s, Loss=5.58e+00, Inv=5.58e+00, For=1.31e+01, Power=7.77e-01
  [eval] val_mse=2.603e+00  (n=2997)
Epoch 00026: Time=   6.1s, Loss=5.43e+00, Inv=5.43e+00, For=1.35e+01, Power=7.60e-01
  [eval] val_mse=2.541e+00  (n=2997)
Epoch 00027: Time=   6.1s, Loss=5.30e+00, Inv=5.30e+00, For=1.39e+01, Power=7.45e-01
  [eval] val_mse=2.485e+00  (n=2997)
Epoch 00028: Time=   6.2s, Loss=5.18e+00, Inv=5.18e+00, For=1.42e+01, Power=7.31e-01
  [eval] val_mse=2.425e+00  (n=2997)
Epoch 00029: Time=   6.2s, Loss=5.07e+00, Inv=5.07e+00, For=1.46e+01, Power=7.22e-01
  [eval] val_mse=2.377e+00  (n=2997)
Epoch 00030: Time=   6.2s, Loss=4.98e+00, Inv=4.98e+00, For=1.51e+01, Power=7.11e-01
  [eval] val_mse=2.354e+00  (n=2997)
Epoch 00031: Time=   6.3s, Loss=4.88e+00, Inv=4.88e+00, For=1.53e+01, Power=7.02e-01
  [eval] val_mse=2.299e+00  (n=2997)
Epoch 00032: Time=   6.3s, Loss=4.80e+00, Inv=4.80e+00, For=1.59e+01, Power=6.93e-01
  [eval] val_mse=2.261e+00  (n=2997)
Epoch 00033: Time=   6.3s, Loss=4.73e+00, Inv=4.73e+00, For=1.61e+01, Power=6.87e-01
  [eval] val_mse=2.226e+00  (n=2997)
Epoch 00034: Time=   6.4s, Loss=4.66e+00, Inv=4.66e+00, For=1.65e+01, Power=6.79e-01
  [eval] val_mse=2.193e+00  (n=2997)
Epoch 00035: Time=   6.4s, Loss=4.60e+00, Inv=4.60e+00, For=1.68e+01, Power=6.73e-01
  [eval] val_mse=2.157e+00  (n=2997)
Epoch 00036: Time=   6.4s, Loss=4.54e+00, Inv=4.54e+00, For=1.72e+01, Power=6.69e-01
  [eval] val_mse=2.133e+00  (n=2997)
Epoch 00037: Time=   6.5s, Loss=4.49e+00, Inv=4.49e+00, For=1.74e+01, Power=6.63e-01
  [eval] val_mse=2.094e+00  (n=2997)
Epoch 00038: Time=   6.5s, Loss=4.44e+00, Inv=4.44e+00, For=1.79e+01, Power=6.58e-01
  [eval] val_mse=2.073e+00  (n=2997)
Epoch 00039: Time=   6.5s, Loss=4.39e+00, Inv=4.39e+00, For=1.83e+01, Power=6.53e-01
  [eval] val_mse=2.049e+00  (n=2997)
Epoch 00040: Time=   6.6s, Loss=4.35e+00, Inv=4.35e+00, For=1.84e+01, Power=6.49e-01
  [eval] val_mse=2.032e+00  (n=2997)
Epoch 00041: Time=   6.6s, Loss=4.31e+00, Inv=4.31e+00, For=1.90e+01, Power=6.46e-01
  [eval] val_mse=2.010e+00  (n=2997)
Epoch 00042: Time=   6.6s, Loss=4.27e+00, Inv=4.27e+00, For=1.92e+01, Power=6.42e-01
  [eval] val_mse=1.980e+00  (n=2997)
Epoch 00043: Time=   6.7s, Loss=4.23e+00, Inv=4.23e+00, For=1.96e+01, Power=6.39e-01
  [eval] val_mse=1.960e+00  (n=2997)
Epoch 00044: Time=   6.7s, Loss=4.20e+00, Inv=4.20e+00, For=2.01e+01, Power=6.36e-01
  [eval] val_mse=1.939e+00  (n=2997)
Epoch 00045: Time=   6.7s, Loss=4.17e+00, Inv=4.17e+00, For=2.04e+01, Power=6.33e-01
  [eval] val_mse=1.920e+00  (n=2997)
Epoch 00046: Time=   6.8s, Loss=4.14e+00, Inv=4.14e+00, For=2.08e+01, Power=6.31e-01
  [eval] val_mse=1.915e+00  (n=2997)
Epoch 00047: Time=   6.8s, Loss=4.11e+00, Inv=4.11e+00, For=2.12e+01, Power=6.28e-01
  [eval] val_mse=1.892e+00  (n=2997)
Epoch 00048: Time=   6.8s, Loss=4.08e+00, Inv=4.08e+00, For=2.17e+01, Power=6.26e-01
  [eval] val_mse=1.867e+00  (n=2997)
Epoch 00049: Time=   6.9s, Loss=4.06e+00, Inv=4.06e+00, For=2.19e+01, Power=6.23e-01
  [eval] val_mse=1.849e+00  (n=2997)
Epoch 00050: Time=   6.9s, Loss=4.03e+00, Inv=4.03e+00, For=2.24e+01, Power=6.21e-01
  [eval] val_mse=1.835e+00  (n=2997)
Epoch 00051: Time=   6.9s, Loss=4.01e+00, Inv=4.01e+00, For=2.28e+01, Power=6.19e-01
  [eval] val_mse=1.821e+00  (n=2997)
Epoch 00052: Time=   7.0s, Loss=3.99e+00, Inv=3.99e+00, For=2.32e+01, Power=6.17e-01
  [eval] val_mse=1.815e+00  (n=2997)
Epoch 00053: Time=   7.0s, Loss=3.96e+00, Inv=3.96e+00, For=2.36e+01, Power=6.15e-01
  [eval] val_mse=1.812e+00  (n=2997)
Epoch 00054: Time=   7.0s, Loss=3.94e+00, Inv=3.94e+00, For=2.42e+01, Power=6.14e-01
  [eval] val_mse=1.788e+00  (n=2997)
Epoch 00055: Time=   7.1s, Loss=3.92e+00, Inv=3.92e+00, For=2.44e+01, Power=6.11e-01
  [eval] val_mse=1.777e+00  (n=2997)
Epoch 00056: Time=   7.1s, Loss=3.91e+00, Inv=3.91e+00, For=2.49e+01, Power=6.10e-01
  [eval] val_mse=1.752e+00  (n=2997)
Epoch 00057: Time=   7.1s, Loss=3.89e+00, Inv=3.89e+00, For=2.53e+01, Power=6.10e-01
  [eval] val_mse=1.760e+00  (n=2997)
Epoch 00058: Time=   7.2s, Loss=3.87e+00, Inv=3.87e+00, For=2.57e+01, Power=6.08e-01
  [eval] val_mse=1.742e+00  (n=2997)
Epoch 00059: Time=   7.2s, Loss=3.85e+00, Inv=3.85e+00, For=2.62e+01, Power=6.05e-01
  [eval] val_mse=1.730e+00  (n=2997)
Epoch 00060: Time=   7.2s, Loss=3.83e+00, Inv=3.83e+00, For=2.65e+01, Power=6.04e-01
  [eval] val_mse=1.731e+00  (n=2997)
Epoch 00061: Time=   7.3s, Loss=3.82e+00, Inv=3.82e+00, For=2.71e+01, Power=6.04e-01
  [eval] val_mse=1.700e+00  (n=2997)
Epoch 00062: Time=   7.3s, Loss=3.81e+00, Inv=3.81e+00, For=2.76e+01, Power=6.03e-01
  [eval] val_mse=1.699e+00  (n=2997)
Epoch 00063: Time=   7.3s, Loss=3.79e+00, Inv=3.79e+00, For=2.78e+01, Power=6.01e-01
  [eval] val_mse=1.694e+00  (n=2997)
Epoch 00064: Time=   7.4s, Loss=3.78e+00, Inv=3.78e+00, For=2.83e+01, Power=6.00e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00065: Time=   7.4s, Loss=3.77e+00, Inv=3.77e+00, For=2.90e+01, Power=6.00e-01
  [eval] val_mse=1.682e+00  (n=2997)
Epoch 00066: Time=   7.4s, Loss=3.75e+00, Inv=3.75e+00, For=2.92e+01, Power=5.98e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00067: Time=   7.5s, Loss=3.74e+00, Inv=3.74e+00, For=2.96e+01, Power=5.98e-01
  [eval] val_mse=1.682e+00  (n=2997)
Epoch 00068: Time=   7.5s, Loss=3.73e+00, Inv=3.73e+00, For=3.00e+01, Power=5.96e-01
  [eval] val_mse=1.677e+00  (n=2997)
Epoch 00069: Time=   7.5s, Loss=3.71e+00, Inv=3.71e+00, For=3.07e+01, Power=5.95e-01
  [eval] val_mse=1.683e+00  (n=2997)
Epoch 00070: Time=   7.6s, Loss=3.70e+00, Inv=3.70e+00, For=3.08e+01, Power=5.95e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00071: Time=   7.6s, Loss=3.69e+00, Inv=3.69e+00, For=3.16e+01, Power=5.94e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00072: Time=   7.6s, Loss=3.68e+00, Inv=3.68e+00, For=3.18e+01, Power=5.92e-01
  [eval] val_mse=1.692e+00  (n=2997)
Epoch 00073: Time=   7.7s, Loss=3.67e+00, Inv=3.67e+00, For=3.22e+01, Power=5.93e-01
  [eval] val_mse=1.678e+00  (n=2997)
Epoch 00074: Time=   7.7s, Loss=3.66e+00, Inv=3.66e+00, For=3.29e+01, Power=5.92e-01
  [eval] val_mse=1.693e+00  (n=2997)
Epoch 00075: Time=   7.7s, Loss=3.65e+00, Inv=3.65e+00, For=3.30e+01, Power=5.91e-01
  [eval] val_mse=1.697e+00  (n=2997)
Epoch 00076: Time=   7.8s, Loss=3.64e+00, Inv=3.64e+00, For=3.37e+01, Power=5.91e-01
  [eval] val_mse=1.705e+00  (n=2997)
Epoch 00077: Time=   7.8s, Loss=3.63e+00, Inv=3.63e+00, For=3.37e+01, Power=5.90e-01
  [eval] val_mse=1.704e+00  (n=2997)
Epoch 00078: Time=   7.8s, Loss=3.62e+00, Inv=3.62e+00, For=3.44e+01, Power=5.89e-01
  [eval] val_mse=1.704e+00  (n=2997)
Epoch 00079: Time=   7.9s, Loss=3.61e+00, Inv=3.61e+00, For=3.50e+01, Power=5.88e-01
  [eval] val_mse=1.723e+00  (n=2997)
Epoch 00080: Time=   7.9s, Loss=3.61e+00, Inv=3.61e+00, For=3.53e+01, Power=5.88e-01
  [eval] val_mse=1.732e+00  (n=2997)
Epoch 00081: Time=   7.9s, Loss=3.60e+00, Inv=3.60e+00, For=3.55e+01, Power=5.86e-01
  [eval] val_mse=1.717e+00  (n=2997)
  [early_stop] stop at epoch=81 (best_epoch=71, best_val_mse=1.675e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 5.283e-01
Torque MSE  = 1.285e-01
Torque RMSE = 3.585e-01
Per-joint MSE : 1.543e-01 3.275e-01 1.303e-01 6.379e-02 4.818e-02 4.695e-02
Per-joint RMSE: 3.928e-01 5.723e-01 3.610e-01 2.526e-01 2.195e-01 2.167e-01
Comp Time per Sample = 2.118e-04s / 4722.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-78s9hexh because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x778eb8fb28c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:50:12.649509: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:50:14.447978: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=9.66e+03, Inv=9.66e+03, For=5.72e+00, Power=5.75e+02
  [eval] val_mse=8.012e+01  (n=2997)
Epoch 00002: Time=   5.4s, Loss=6.01e+02, Inv=6.01e+02, For=5.48e+00, Power=6.50e+01
  [eval] val_mse=3.317e+01  (n=2997)
Epoch 00003: Time=   5.4s, Loss=2.59e+02, Inv=2.59e+02, For=5.31e+00, Power=3.08e+01
  [eval] val_mse=2.130e+01  (n=2997)
Epoch 00004: Time=   5.5s, Loss=1.55e+02, Inv=1.55e+02, For=5.17e+00, Power=1.89e+01
  [eval] val_mse=1.527e+01  (n=2997)
Epoch 00005: Time=   5.5s, Loss=1.04e+02, Inv=1.04e+02, For=5.07e+00, Power=1.26e+01
  [eval] val_mse=1.187e+01  (n=2997)
Epoch 00006: Time=   5.6s, Loss=7.54e+01, Inv=7.54e+01, For=4.98e+00, Power=8.90e+00
  [eval] val_mse=9.759e+00  (n=2997)
Epoch 00007: Time=   5.6s, Loss=5.74e+01, Inv=5.74e+01, For=4.95e+00, Power=6.62e+00
  [eval] val_mse=8.320e+00  (n=2997)
Epoch 00008: Time=   5.6s, Loss=4.55e+01, Inv=4.55e+01, For=4.93e+00, Power=5.10e+00
  [eval] val_mse=7.308e+00  (n=2997)
Epoch 00009: Time=   5.7s, Loss=3.71e+01, Inv=3.71e+01, For=4.96e+00, Power=4.08e+00
  [eval] val_mse=6.527e+00  (n=2997)
Epoch 00010: Time=   5.7s, Loss=3.11e+01, Inv=3.11e+01, For=5.02e+00, Power=3.35e+00
  [eval] val_mse=5.928e+00  (n=2997)
Epoch 00011: Time=   5.7s, Loss=2.65e+01, Inv=2.65e+01, For=5.08e+00, Power=2.81e+00
  [eval] val_mse=5.439e+00  (n=2997)
Epoch 00012: Time=   5.8s, Loss=2.29e+01, Inv=2.29e+01, For=5.16e+00, Power=2.40e+00
  [eval] val_mse=5.028e+00  (n=2997)
Epoch 00013: Time=   5.8s, Loss=2.01e+01, Inv=2.01e+01, For=5.25e+00, Power=2.09e+00
  [eval] val_mse=4.666e+00  (n=2997)
Epoch 00014: Time=   5.8s, Loss=1.78e+01, Inv=1.78e+01, For=5.35e+00, Power=1.85e+00
  [eval] val_mse=4.354e+00  (n=2997)
Epoch 00015: Time=   5.9s, Loss=1.59e+01, Inv=1.59e+01, For=5.45e+00, Power=1.66e+00
  [eval] val_mse=4.078e+00  (n=2997)
Epoch 00016: Time=   5.9s, Loss=1.44e+01, Inv=1.44e+01, For=5.56e+00, Power=1.50e+00
  [eval] val_mse=3.836e+00  (n=2997)
Epoch 00017: Time=   5.9s, Loss=1.32e+01, Inv=1.32e+01, For=5.66e+00, Power=1.38e+00
  [eval] val_mse=3.624e+00  (n=2997)
Epoch 00018: Time=   6.0s, Loss=1.21e+01, Inv=1.21e+01, For=5.78e+00, Power=1.27e+00
  [eval] val_mse=3.441e+00  (n=2997)
Epoch 00019: Time=   6.0s, Loss=1.12e+01, Inv=1.12e+01, For=5.89e+00, Power=1.18e+00
  [eval] val_mse=3.288e+00  (n=2997)
Epoch 00020: Time=   6.0s, Loss=1.04e+01, Inv=1.04e+01, For=6.03e+00, Power=1.11e+00
  [eval] val_mse=3.157e+00  (n=2997)
Epoch 00021: Time=   6.1s, Loss=9.75e+00, Inv=9.75e+00, For=6.18e+00, Power=1.05e+00
  [eval] val_mse=3.047e+00  (n=2997)
Epoch 00022: Time=   6.1s, Loss=9.20e+00, Inv=9.20e+00, For=6.35e+00, Power=9.96e-01
  [eval] val_mse=2.945e+00  (n=2997)
Epoch 00023: Time=   6.1s, Loss=8.72e+00, Inv=8.72e+00, For=6.53e+00, Power=9.54e-01
  [eval] val_mse=2.867e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=8.30e+00, Inv=8.30e+00, For=6.74e+00, Power=9.16e-01
  [eval] val_mse=2.790e+00  (n=2997)
Epoch 00025: Time=   6.2s, Loss=7.93e+00, Inv=7.93e+00, For=6.94e+00, Power=8.84e-01
  [eval] val_mse=2.724e+00  (n=2997)
Epoch 00026: Time=   6.3s, Loss=7.61e+00, Inv=7.61e+00, For=7.19e+00, Power=8.57e-01
  [eval] val_mse=2.662e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=7.31e+00, Inv=7.31e+00, For=7.39e+00, Power=8.33e-01
  [eval] val_mse=2.607e+00  (n=2997)
Epoch 00028: Time=   6.3s, Loss=7.06e+00, Inv=7.06e+00, For=7.65e+00, Power=8.12e-01
  [eval] val_mse=2.552e+00  (n=2997)
Epoch 00029: Time=   6.4s, Loss=6.83e+00, Inv=6.83e+00, For=7.89e+00, Power=7.93e-01
  [eval] val_mse=2.492e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=6.62e+00, Inv=6.62e+00, For=8.15e+00, Power=7.78e-01
  [eval] val_mse=2.442e+00  (n=2997)
Epoch 00031: Time=   6.4s, Loss=6.43e+00, Inv=6.43e+00, For=8.42e+00, Power=7.63e-01
  [eval] val_mse=2.389e+00  (n=2997)
Epoch 00032: Time=   6.5s, Loss=6.26e+00, Inv=6.26e+00, For=8.69e+00, Power=7.51e-01
  [eval] val_mse=2.345e+00  (n=2997)
Epoch 00033: Time=   6.5s, Loss=6.10e+00, Inv=6.10e+00, For=8.97e+00, Power=7.40e-01
  [eval] val_mse=2.296e+00  (n=2997)
Epoch 00034: Time=   6.5s, Loss=5.96e+00, Inv=5.96e+00, For=9.24e+00, Power=7.29e-01
  [eval] val_mse=2.258e+00  (n=2997)
Epoch 00035: Time=   6.6s, Loss=5.83e+00, Inv=5.83e+00, For=9.53e+00, Power=7.21e-01
  [eval] val_mse=2.219e+00  (n=2997)
Epoch 00036: Time=   6.6s, Loss=5.70e+00, Inv=5.70e+00, For=9.81e+00, Power=7.13e-01
  [eval] val_mse=2.179e+00  (n=2997)
Epoch 00037: Time=   6.6s, Loss=5.59e+00, Inv=5.59e+00, For=1.01e+01, Power=7.05e-01
  [eval] val_mse=2.136e+00  (n=2997)
Epoch 00038: Time=   6.7s, Loss=5.49e+00, Inv=5.49e+00, For=1.04e+01, Power=6.98e-01
  [eval] val_mse=2.105e+00  (n=2997)
Epoch 00039: Time=   6.7s, Loss=5.38e+00, Inv=5.38e+00, For=1.07e+01, Power=6.92e-01
  [eval] val_mse=2.066e+00  (n=2997)
Epoch 00040: Time=   6.7s, Loss=5.29e+00, Inv=5.29e+00, For=1.10e+01, Power=6.86e-01
  [eval] val_mse=2.037e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=5.21e+00, Inv=5.21e+00, For=1.13e+01, Power=6.81e-01
  [eval] val_mse=2.017e+00  (n=2997)
Epoch 00042: Time=   6.8s, Loss=5.13e+00, Inv=5.13e+00, For=1.16e+01, Power=6.74e-01
  [eval] val_mse=1.979e+00  (n=2997)
Epoch 00043: Time=   6.8s, Loss=5.05e+00, Inv=5.05e+00, For=1.18e+01, Power=6.71e-01
  [eval] val_mse=1.956e+00  (n=2997)
Epoch 00044: Time=   6.9s, Loss=4.98e+00, Inv=4.98e+00, For=1.21e+01, Power=6.67e-01
  [eval] val_mse=1.933e+00  (n=2997)
Epoch 00045: Time=   6.9s, Loss=4.91e+00, Inv=4.91e+00, For=1.24e+01, Power=6.62e-01
  [eval] val_mse=1.907e+00  (n=2997)
Epoch 00046: Time=   6.9s, Loss=4.85e+00, Inv=4.85e+00, For=1.27e+01, Power=6.58e-01
  [eval] val_mse=1.876e+00  (n=2997)
Epoch 00047: Time=   7.0s, Loss=4.79e+00, Inv=4.79e+00, For=1.30e+01, Power=6.56e-01
  [eval] val_mse=1.862e+00  (n=2997)
Epoch 00048: Time=   7.0s, Loss=4.73e+00, Inv=4.73e+00, For=1.33e+01, Power=6.52e-01
  [eval] val_mse=1.841e+00  (n=2997)
Epoch 00049: Time=   7.0s, Loss=4.68e+00, Inv=4.68e+00, For=1.36e+01, Power=6.50e-01
  [eval] val_mse=1.826e+00  (n=2997)
Epoch 00050: Time=   7.1s, Loss=4.63e+00, Inv=4.63e+00, For=1.39e+01, Power=6.45e-01
  [eval] val_mse=1.798e+00  (n=2997)
Epoch 00051: Time=   7.1s, Loss=4.58e+00, Inv=4.58e+00, For=1.42e+01, Power=6.43e-01
  [eval] val_mse=1.781e+00  (n=2997)
Epoch 00052: Time=   7.1s, Loss=4.54e+00, Inv=4.54e+00, For=1.45e+01, Power=6.41e-01
  [eval] val_mse=1.769e+00  (n=2997)
Epoch 00053: Time=   7.2s, Loss=4.49e+00, Inv=4.49e+00, For=1.48e+01, Power=6.39e-01
  [eval] val_mse=1.755e+00  (n=2997)
Epoch 00054: Time=   7.2s, Loss=4.45e+00, Inv=4.45e+00, For=1.50e+01, Power=6.35e-01
  [eval] val_mse=1.743e+00  (n=2997)
Epoch 00055: Time=   7.3s, Loss=4.41e+00, Inv=4.41e+00, For=1.53e+01, Power=6.33e-01
  [eval] val_mse=1.732e+00  (n=2997)
Epoch 00056: Time=   7.3s, Loss=4.37e+00, Inv=4.37e+00, For=1.56e+01, Power=6.32e-01
  [eval] val_mse=1.714e+00  (n=2997)
Epoch 00057: Time=   7.3s, Loss=4.33e+00, Inv=4.33e+00, For=1.59e+01, Power=6.29e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00058: Time=   7.4s, Loss=4.30e+00, Inv=4.30e+00, For=1.62e+01, Power=6.28e-01
  [eval] val_mse=1.703e+00  (n=2997)
Epoch 00059: Time=   7.4s, Loss=4.26e+00, Inv=4.26e+00, For=1.65e+01, Power=6.26e-01
  [eval] val_mse=1.687e+00  (n=2997)
Epoch 00060: Time=   7.4s, Loss=4.23e+00, Inv=4.23e+00, For=1.68e+01, Power=6.24e-01
  [eval] val_mse=1.680e+00  (n=2997)
Epoch 00061: Time=   7.5s, Loss=4.20e+00, Inv=4.20e+00, For=1.70e+01, Power=6.23e-01
  [eval] val_mse=1.681e+00  (n=2997)
Epoch 00062: Time=   7.5s, Loss=4.17e+00, Inv=4.17e+00, For=1.73e+01, Power=6.21e-01
  [eval] val_mse=1.670e+00  (n=2997)
Epoch 00063: Time=   7.5s, Loss=4.14e+00, Inv=4.14e+00, For=1.76e+01, Power=6.19e-01
  [eval] val_mse=1.661e+00  (n=2997)
Epoch 00064: Time=   7.6s, Loss=4.12e+00, Inv=4.12e+00, For=1.79e+01, Power=6.18e-01
  [eval] val_mse=1.653e+00  (n=2997)
Epoch 00065: Time=   7.6s, Loss=4.09e+00, Inv=4.09e+00, For=1.82e+01, Power=6.16e-01
  [eval] val_mse=1.667e+00  (n=2997)
Epoch 00066: Time=   7.6s, Loss=4.06e+00, Inv=4.06e+00, For=1.84e+01, Power=6.14e-01
  [eval] val_mse=1.657e+00  (n=2997)
Epoch 00067: Time=   7.7s, Loss=4.04e+00, Inv=4.04e+00, For=1.87e+01, Power=6.13e-01
  [eval] val_mse=1.654e+00  (n=2997)
Epoch 00068: Time=   7.7s, Loss=4.02e+00, Inv=4.02e+00, For=1.90e+01, Power=6.12e-01
  [eval] val_mse=1.672e+00  (n=2997)
Epoch 00069: Time=   7.7s, Loss=4.00e+00, Inv=4.00e+00, For=1.93e+01, Power=6.11e-01
  [eval] val_mse=1.649e+00  (n=2997)
Epoch 00070: Time=   7.8s, Loss=3.98e+00, Inv=3.98e+00, For=1.95e+01, Power=6.10e-01
  [eval] val_mse=1.665e+00  (n=2997)
Epoch 00071: Time=   7.8s, Loss=3.95e+00, Inv=3.95e+00, For=1.98e+01, Power=6.09e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00072: Time=   7.8s, Loss=3.94e+00, Inv=3.94e+00, For=2.01e+01, Power=6.08e-01
  [eval] val_mse=1.674e+00  (n=2997)
Epoch 00073: Time=   7.9s, Loss=3.92e+00, Inv=3.92e+00, For=2.03e+01, Power=6.07e-01
  [eval] val_mse=1.680e+00  (n=2997)
Epoch 00074: Time=   7.9s, Loss=3.90e+00, Inv=3.90e+00, For=2.06e+01, Power=6.05e-01
  [eval] val_mse=1.674e+00  (n=2997)
Epoch 00075: Time=   7.9s, Loss=3.88e+00, Inv=3.88e+00, For=2.08e+01, Power=6.03e-01
  [eval] val_mse=1.696e+00  (n=2997)
Epoch 00076: Time=   8.0s, Loss=3.87e+00, Inv=3.87e+00, For=2.11e+01, Power=6.04e-01
  [eval] val_mse=1.689e+00  (n=2997)
Epoch 00077: Time=   8.0s, Loss=3.85e+00, Inv=3.85e+00, For=2.13e+01, Power=6.02e-01
  [eval] val_mse=1.697e+00  (n=2997)
Epoch 00078: Time=   8.0s, Loss=3.84e+00, Inv=3.84e+00, For=2.16e+01, Power=6.02e-01
  [eval] val_mse=1.708e+00  (n=2997)
Epoch 00079: Time=   8.1s, Loss=3.82e+00, Inv=3.82e+00, For=2.19e+01, Power=6.00e-01
  [eval] val_mse=1.706e+00  (n=2997)
  [early_stop] stop at epoch=79 (best_epoch=69, best_val_mse=1.649e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 5.243e-01
Torque MSE  = 1.269e-01
Torque RMSE = 3.563e-01
Per-joint MSE : 1.700e-01 2.706e-01 1.401e-01 7.328e-02 5.533e-02 5.215e-02
Per-joint RMSE: 4.123e-01 5.202e-01 3.743e-01 2.707e-01 2.352e-01 2.284e-01
Comp Time per Sample = 1.995e-04s / 5012.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-v_x82i_a because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x770f18ed68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:50:30.383237: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:50:32.155615: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=1.21e+04, Inv=1.21e+04, For=5.80e+00, Power=1.20e+03
  [eval] val_mse=1.756e+02  (n=2997)
Epoch 00002: Time=   5.5s, Loss=1.01e+03, Inv=1.01e+03, For=5.64e+00, Power=1.51e+02
  [eval] val_mse=5.672e+01  (n=2997)
Epoch 00003: Time=   5.5s, Loss=4.09e+02, Inv=4.09e+02, For=5.53e+00, Power=6.48e+01
  [eval] val_mse=3.048e+01  (n=2997)
Epoch 00004: Time=   5.5s, Loss=2.35e+02, Inv=2.35e+02, For=5.44e+00, Power=3.66e+01
  [eval] val_mse=1.974e+01  (n=2997)
Epoch 00005: Time=   5.6s, Loss=1.52e+02, Inv=1.52e+02, For=5.36e+00, Power=2.30e+01
  [eval] val_mse=1.415e+01  (n=2997)
Epoch 00006: Time=   5.6s, Loss=1.06e+02, Inv=1.06e+02, For=5.29e+00, Power=1.55e+01
  [eval] val_mse=1.090e+01  (n=2997)
Epoch 00007: Time=   5.6s, Loss=7.89e+01, Inv=7.89e+01, For=5.28e+00, Power=1.12e+01
  [eval] val_mse=8.821e+00  (n=2997)
Epoch 00008: Time=   5.7s, Loss=6.10e+01, Inv=6.10e+01, For=5.29e+00, Power=8.41e+00
  [eval] val_mse=7.440e+00  (n=2997)
Epoch 00009: Time=   5.7s, Loss=4.87e+01, Inv=4.87e+01, For=5.34e+00, Power=6.55e+00
  [eval] val_mse=6.453e+00  (n=2997)
Epoch 00010: Time=   5.7s, Loss=4.00e+01, Inv=4.00e+01, For=5.41e+00, Power=5.25e+00
  [eval] val_mse=5.694e+00  (n=2997)
Epoch 00011: Time=   5.8s, Loss=3.34e+01, Inv=3.34e+01, For=5.47e+00, Power=4.33e+00
  [eval] val_mse=5.102e+00  (n=2997)
Epoch 00012: Time=   5.8s, Loss=2.84e+01, Inv=2.84e+01, For=5.59e+00, Power=3.63e+00
  [eval] val_mse=4.615e+00  (n=2997)
Epoch 00013: Time=   5.8s, Loss=2.45e+01, Inv=2.45e+01, For=5.72e+00, Power=3.11e+00
  [eval] val_mse=4.229e+00  (n=2997)
Epoch 00014: Time=   5.9s, Loss=2.15e+01, Inv=2.15e+01, For=5.86e+00, Power=2.70e+00
  [eval] val_mse=3.908e+00  (n=2997)
Epoch 00015: Time=   5.9s, Loss=1.90e+01, Inv=1.90e+01, For=6.04e+00, Power=2.38e+00
  [eval] val_mse=3.643e+00  (n=2997)
Epoch 00016: Time=   5.9s, Loss=1.70e+01, Inv=1.70e+01, For=6.25e+00, Power=2.12e+00
  [eval] val_mse=3.437e+00  (n=2997)
Epoch 00017: Time=   6.0s, Loss=1.53e+01, Inv=1.53e+01, For=6.44e+00, Power=1.90e+00
  [eval] val_mse=3.258e+00  (n=2997)
Epoch 00018: Time=   6.0s, Loss=1.40e+01, Inv=1.40e+01, For=6.73e+00, Power=1.73e+00
  [eval] val_mse=3.130e+00  (n=2997)
Epoch 00019: Time=   6.0s, Loss=1.28e+01, Inv=1.28e+01, For=7.02e+00, Power=1.58e+00
  [eval] val_mse=3.024e+00  (n=2997)
Epoch 00020: Time=   6.1s, Loss=1.19e+01, Inv=1.19e+01, For=7.32e+00, Power=1.46e+00
  [eval] val_mse=2.935e+00  (n=2997)
Epoch 00021: Time=   6.1s, Loss=1.10e+01, Inv=1.10e+01, For=7.63e+00, Power=1.36e+00
  [eval] val_mse=2.863e+00  (n=2997)
Epoch 00022: Time=   6.1s, Loss=1.03e+01, Inv=1.03e+01, For=7.98e+00, Power=1.28e+00
  [eval] val_mse=2.806e+00  (n=2997)
Epoch 00023: Time=   6.2s, Loss=9.72e+00, Inv=9.72e+00, For=8.36e+00, Power=1.20e+00
  [eval] val_mse=2.754e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=9.18e+00, Inv=9.18e+00, For=8.70e+00, Power=1.14e+00
  [eval] val_mse=2.705e+00  (n=2997)
Epoch 00025: Time=   6.3s, Loss=8.72e+00, Inv=8.72e+00, For=9.11e+00, Power=1.08e+00
  [eval] val_mse=2.654e+00  (n=2997)
Epoch 00026: Time=   6.3s, Loss=8.30e+00, Inv=8.30e+00, For=9.47e+00, Power=1.04e+00
  [eval] val_mse=2.599e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=7.93e+00, Inv=7.93e+00, For=9.86e+00, Power=9.96e-01
  [eval] val_mse=2.565e+00  (n=2997)
Epoch 00028: Time=   6.4s, Loss=7.60e+00, Inv=7.60e+00, For=1.03e+01, Power=9.58e-01
  [eval] val_mse=2.526e+00  (n=2997)
Epoch 00029: Time=   6.4s, Loss=7.30e+00, Inv=7.30e+00, For=1.06e+01, Power=9.24e-01
  [eval] val_mse=2.479e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=7.04e+00, Inv=7.04e+00, For=1.11e+01, Power=8.99e-01
  [eval] val_mse=2.449e+00  (n=2997)
Epoch 00031: Time=   6.5s, Loss=6.79e+00, Inv=6.79e+00, For=1.14e+01, Power=8.71e-01
  [eval] val_mse=2.423e+00  (n=2997)
Epoch 00032: Time=   6.5s, Loss=6.57e+00, Inv=6.57e+00, For=1.19e+01, Power=8.50e-01
  [eval] val_mse=2.394e+00  (n=2997)
Epoch 00033: Time=   6.5s, Loss=6.38e+00, Inv=6.38e+00, For=1.23e+01, Power=8.29e-01
  [eval] val_mse=2.360e+00  (n=2997)
Epoch 00034: Time=   6.6s, Loss=6.19e+00, Inv=6.19e+00, For=1.27e+01, Power=8.11e-01
  [eval] val_mse=2.340e+00  (n=2997)
Epoch 00035: Time=   6.6s, Loss=6.02e+00, Inv=6.02e+00, For=1.31e+01, Power=7.94e-01
  [eval] val_mse=2.310e+00  (n=2997)
Epoch 00036: Time=   6.6s, Loss=5.87e+00, Inv=5.87e+00, For=1.35e+01, Power=7.79e-01
  [eval] val_mse=2.295e+00  (n=2997)
Epoch 00037: Time=   6.7s, Loss=5.73e+00, Inv=5.73e+00, For=1.39e+01, Power=7.65e-01
  [eval] val_mse=2.270e+00  (n=2997)
Epoch 00038: Time=   6.7s, Loss=5.60e+00, Inv=5.60e+00, For=1.44e+01, Power=7.52e-01
  [eval] val_mse=2.256e+00  (n=2997)
Epoch 00039: Time=   6.7s, Loss=5.48e+00, Inv=5.48e+00, For=1.46e+01, Power=7.42e-01
  [eval] val_mse=2.246e+00  (n=2997)
Epoch 00040: Time=   6.8s, Loss=5.36e+00, Inv=5.36e+00, For=1.52e+01, Power=7.30e-01
  [eval] val_mse=2.228e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=5.26e+00, Inv=5.26e+00, For=1.56e+01, Power=7.21e-01
  [eval] val_mse=2.212e+00  (n=2997)
Epoch 00042: Time=   6.8s, Loss=5.16e+00, Inv=5.16e+00, For=1.60e+01, Power=7.11e-01
  [eval] val_mse=2.199e+00  (n=2997)
Epoch 00043: Time=   6.9s, Loss=5.07e+00, Inv=5.07e+00, For=1.63e+01, Power=7.03e-01
  [eval] val_mse=2.196e+00  (n=2997)
Epoch 00044: Time=   6.9s, Loss=4.99e+00, Inv=4.99e+00, For=1.69e+01, Power=6.96e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00045: Time=   6.9s, Loss=4.91e+00, Inv=4.91e+00, For=1.71e+01, Power=6.89e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00046: Time=   7.0s, Loss=4.84e+00, Inv=4.84e+00, For=1.76e+01, Power=6.83e-01
  [eval] val_mse=2.166e+00  (n=2997)
Epoch 00047: Time=   7.0s, Loss=4.76e+00, Inv=4.76e+00, For=1.79e+01, Power=6.76e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00048: Time=   7.0s, Loss=4.70e+00, Inv=4.70e+00, For=1.84e+01, Power=6.71e-01
  [eval] val_mse=2.178e+00  (n=2997)
Epoch 00049: Time=   7.1s, Loss=4.64e+00, Inv=4.64e+00, For=1.86e+01, Power=6.66e-01
  [eval] val_mse=2.164e+00  (n=2997)
Epoch 00050: Time=   7.1s, Loss=4.58e+00, Inv=4.58e+00, For=1.93e+01, Power=6.60e-01
  [eval] val_mse=2.156e+00  (n=2997)
Epoch 00051: Time=   7.1s, Loss=4.53e+00, Inv=4.53e+00, For=1.96e+01, Power=6.57e-01
  [eval] val_mse=2.169e+00  (n=2997)
Epoch 00052: Time=   7.2s, Loss=4.47e+00, Inv=4.47e+00, For=1.98e+01, Power=6.52e-01
  [eval] val_mse=2.151e+00  (n=2997)
Epoch 00053: Time=   7.2s, Loss=4.43e+00, Inv=4.43e+00, For=2.04e+01, Power=6.48e-01
  [eval] val_mse=2.164e+00  (n=2997)
Epoch 00054: Time=   7.3s, Loss=4.38e+00, Inv=4.38e+00, For=2.07e+01, Power=6.45e-01
  [eval] val_mse=2.158e+00  (n=2997)
Epoch 00055: Time=   7.3s, Loss=4.34e+00, Inv=4.34e+00, For=2.08e+01, Power=6.40e-01
  [eval] val_mse=2.157e+00  (n=2997)
Epoch 00056: Time=   7.3s, Loss=4.30e+00, Inv=4.30e+00, For=2.13e+01, Power=6.38e-01
  [eval] val_mse=2.165e+00  (n=2997)
Epoch 00057: Time=   7.4s, Loss=4.25e+00, Inv=4.25e+00, For=2.16e+01, Power=6.33e-01
  [eval] val_mse=2.157e+00  (n=2997)
Epoch 00058: Time=   7.4s, Loss=4.22e+00, Inv=4.22e+00, For=2.21e+01, Power=6.31e-01
  [eval] val_mse=2.173e+00  (n=2997)
Epoch 00059: Time=   7.4s, Loss=4.19e+00, Inv=4.19e+00, For=2.23e+01, Power=6.29e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00060: Time=   7.5s, Loss=4.15e+00, Inv=4.15e+00, For=2.29e+01, Power=6.25e-01
  [eval] val_mse=2.174e+00  (n=2997)
Epoch 00061: Time=   7.5s, Loss=4.12e+00, Inv=4.12e+00, For=2.29e+01, Power=6.23e-01
  [eval] val_mse=2.178e+00  (n=2997)
Epoch 00062: Time=   7.5s, Loss=4.09e+00, Inv=4.09e+00, For=2.33e+01, Power=6.21e-01
  [eval] val_mse=2.198e+00  (n=2997)
  [early_stop] stop at epoch=62 (best_epoch=52, best_val_mse=2.151e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 5.987e-01
Torque MSE  = 1.424e-01
Torque RMSE = 3.774e-01
Per-joint MSE : 1.794e-01 2.917e-01 1.718e-01 7.717e-02 7.313e-02 6.138e-02
Per-joint RMSE: 4.235e-01 5.401e-01 4.145e-01 2.778e-01 2.704e-01 2.477e-01
Comp Time per Sample = 2.038e-04s / 4906.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-ykaf7lku because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7294d388e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:50:47.477299: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:50:49.256864: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=1.89e+04, Inv=1.89e+04, For=5.77e+00, Power=1.15e+03
  [eval] val_mse=9.676e+01  (n=2997)
Epoch 00002: Time=   5.6s, Loss=1.30e+03, Inv=1.30e+03, For=5.57e+00, Power=1.13e+02
  [eval] val_mse=4.089e+01  (n=2997)
Epoch 00003: Time=   5.7s, Loss=5.23e+02, Inv=5.23e+02, For=5.42e+00, Power=4.64e+01
  [eval] val_mse=2.549e+01  (n=2997)
Epoch 00004: Time=   5.7s, Loss=2.99e+02, Inv=2.99e+02, For=5.33e+00, Power=2.68e+01
  [eval] val_mse=1.863e+01  (n=2997)
Epoch 00005: Time=   5.7s, Loss=1.94e+02, Inv=1.94e+02, For=5.25e+00, Power=1.73e+01
  [eval] val_mse=1.463e+01  (n=2997)
Epoch 00006: Time=   5.8s, Loss=1.36e+02, Inv=1.36e+02, For=5.19e+00, Power=1.20e+01
  [eval] val_mse=1.212e+01  (n=2997)
Epoch 00007: Time=   5.8s, Loss=1.01e+02, Inv=1.01e+02, For=5.15e+00, Power=8.82e+00
  [eval] val_mse=1.035e+01  (n=2997)
Epoch 00008: Time=   5.8s, Loss=7.85e+01, Inv=7.85e+01, For=5.15e+00, Power=6.72e+00
  [eval] val_mse=9.099e+00  (n=2997)
Epoch 00009: Time=   5.9s, Loss=6.28e+01, Inv=6.28e+01, For=5.17e+00, Power=5.32e+00
  [eval] val_mse=8.145e+00  (n=2997)
Epoch 00010: Time=   5.9s, Loss=5.16e+01, Inv=5.16e+01, For=5.17e+00, Power=4.32e+00
  [eval] val_mse=7.411e+00  (n=2997)
Epoch 00011: Time=   6.0s, Loss=4.33e+01, Inv=4.33e+01, For=5.21e+00, Power=3.60e+00
  [eval] val_mse=6.790e+00  (n=2997)
Epoch 00012: Time=   6.0s, Loss=3.70e+01, Inv=3.70e+01, For=5.26e+00, Power=3.06e+00
  [eval] val_mse=6.283e+00  (n=2997)
Epoch 00013: Time=   6.0s, Loss=3.20e+01, Inv=3.20e+01, For=5.29e+00, Power=2.64e+00
  [eval] val_mse=5.848e+00  (n=2997)
Epoch 00014: Time=   6.1s, Loss=2.80e+01, Inv=2.80e+01, For=5.35e+00, Power=2.31e+00
  [eval] val_mse=5.477e+00  (n=2997)
Epoch 00015: Time=   6.1s, Loss=2.49e+01, Inv=2.49e+01, For=5.41e+00, Power=2.05e+00
  [eval] val_mse=5.153e+00  (n=2997)
Epoch 00016: Time=   6.1s, Loss=2.22e+01, Inv=2.22e+01, For=5.47e+00, Power=1.84e+00
  [eval] val_mse=4.865e+00  (n=2997)
Epoch 00017: Time=   6.2s, Loss=2.00e+01, Inv=2.00e+01, For=5.53e+00, Power=1.67e+00
  [eval] val_mse=4.618e+00  (n=2997)
Epoch 00018: Time=   6.2s, Loss=1.82e+01, Inv=1.82e+01, For=5.62e+00, Power=1.53e+00
  [eval] val_mse=4.405e+00  (n=2997)
Epoch 00019: Time=   6.3s, Loss=1.67e+01, Inv=1.67e+01, For=5.72e+00, Power=1.41e+00
  [eval] val_mse=4.214e+00  (n=2997)
Epoch 00020: Time=   6.3s, Loss=1.53e+01, Inv=1.53e+01, For=5.82e+00, Power=1.31e+00
  [eval] val_mse=4.059e+00  (n=2997)
Epoch 00021: Time=   6.3s, Loss=1.42e+01, Inv=1.42e+01, For=5.94e+00, Power=1.22e+00
  [eval] val_mse=3.922e+00  (n=2997)
Epoch 00022: Time=   6.4s, Loss=1.32e+01, Inv=1.32e+01, For=6.08e+00, Power=1.15e+00
  [eval] val_mse=3.803e+00  (n=2997)
Epoch 00023: Time=   6.4s, Loss=1.24e+01, Inv=1.24e+01, For=6.23e+00, Power=1.09e+00
  [eval] val_mse=3.697e+00  (n=2997)
Epoch 00024: Time=   6.4s, Loss=1.17e+01, Inv=1.17e+01, For=6.41e+00, Power=1.04e+00
  [eval] val_mse=3.611e+00  (n=2997)
Epoch 00025: Time=   6.5s, Loss=1.10e+01, Inv=1.10e+01, For=6.59e+00, Power=9.93e-01
  [eval] val_mse=3.529e+00  (n=2997)
Epoch 00026: Time=   6.5s, Loss=1.05e+01, Inv=1.05e+01, For=6.81e+00, Power=9.53e-01
  [eval] val_mse=3.451e+00  (n=2997)
Epoch 00027: Time=   6.5s, Loss=9.96e+00, Inv=9.96e+00, For=7.03e+00, Power=9.19e-01
  [eval] val_mse=3.375e+00  (n=2997)
Epoch 00028: Time=   6.6s, Loss=9.51e+00, Inv=9.51e+00, For=7.25e+00, Power=8.90e-01
  [eval] val_mse=3.308e+00  (n=2997)
Epoch 00029: Time=   6.6s, Loss=9.11e+00, Inv=9.11e+00, For=7.49e+00, Power=8.65e-01
  [eval] val_mse=3.241e+00  (n=2997)
Epoch 00030: Time=   6.7s, Loss=8.75e+00, Inv=8.75e+00, For=7.75e+00, Power=8.41e-01
  [eval] val_mse=3.179e+00  (n=2997)
Epoch 00031: Time=   6.7s, Loss=8.42e+00, Inv=8.42e+00, For=8.00e+00, Power=8.19e-01
  [eval] val_mse=3.118e+00  (n=2997)
Epoch 00032: Time=   6.7s, Loss=8.13e+00, Inv=8.13e+00, For=8.26e+00, Power=8.02e-01
  [eval] val_mse=3.049e+00  (n=2997)
Epoch 00033: Time=   6.8s, Loss=7.85e+00, Inv=7.85e+00, For=8.53e+00, Power=7.84e-01
  [eval] val_mse=2.989e+00  (n=2997)
Epoch 00034: Time=   6.8s, Loss=7.60e+00, Inv=7.60e+00, For=8.81e+00, Power=7.70e-01
  [eval] val_mse=2.935e+00  (n=2997)
Epoch 00035: Time=   6.8s, Loss=7.37e+00, Inv=7.37e+00, For=9.08e+00, Power=7.58e-01
  [eval] val_mse=2.883e+00  (n=2997)
Epoch 00036: Time=   6.9s, Loss=7.16e+00, Inv=7.16e+00, For=9.41e+00, Power=7.46e-01
  [eval] val_mse=2.837e+00  (n=2997)
Epoch 00037: Time=   6.9s, Loss=6.96e+00, Inv=6.96e+00, For=9.67e+00, Power=7.34e-01
  [eval] val_mse=2.791e+00  (n=2997)
Epoch 00038: Time=   6.9s, Loss=6.77e+00, Inv=6.77e+00, For=9.98e+00, Power=7.24e-01
  [eval] val_mse=2.741e+00  (n=2997)
Epoch 00039: Time=   7.0s, Loss=6.60e+00, Inv=6.60e+00, For=1.03e+01, Power=7.14e-01
  [eval] val_mse=2.698e+00  (n=2997)
Epoch 00040: Time=   7.0s, Loss=6.45e+00, Inv=6.45e+00, For=1.06e+01, Power=7.06e-01
  [eval] val_mse=2.651e+00  (n=2997)
Epoch 00041: Time=   7.0s, Loss=6.30e+00, Inv=6.30e+00, For=1.09e+01, Power=6.99e-01
  [eval] val_mse=2.629e+00  (n=2997)
Epoch 00042: Time=   7.1s, Loss=6.16e+00, Inv=6.16e+00, For=1.12e+01, Power=6.92e-01
  [eval] val_mse=2.584e+00  (n=2997)
Epoch 00043: Time=   7.1s, Loss=6.03e+00, Inv=6.03e+00, For=1.15e+01, Power=6.86e-01
  [eval] val_mse=2.565e+00  (n=2997)
Epoch 00044: Time=   7.1s, Loss=5.91e+00, Inv=5.91e+00, For=1.19e+01, Power=6.79e-01
  [eval] val_mse=2.522e+00  (n=2997)
Epoch 00045: Time=   7.2s, Loss=5.79e+00, Inv=5.79e+00, For=1.22e+01, Power=6.73e-01
  [eval] val_mse=2.503e+00  (n=2997)
Epoch 00046: Time=   7.2s, Loss=5.68e+00, Inv=5.68e+00, For=1.26e+01, Power=6.68e-01
  [eval] val_mse=2.460e+00  (n=2997)
Epoch 00047: Time=   7.2s, Loss=5.58e+00, Inv=5.58e+00, For=1.29e+01, Power=6.63e-01
  [eval] val_mse=2.432e+00  (n=2997)
Epoch 00048: Time=   7.3s, Loss=5.48e+00, Inv=5.48e+00, For=1.33e+01, Power=6.58e-01
  [eval] val_mse=2.408e+00  (n=2997)
Epoch 00049: Time=   7.3s, Loss=5.39e+00, Inv=5.39e+00, For=1.36e+01, Power=6.54e-01
  [eval] val_mse=2.378e+00  (n=2997)
Epoch 00050: Time=   7.4s, Loss=5.30e+00, Inv=5.30e+00, For=1.40e+01, Power=6.49e-01
  [eval] val_mse=2.359e+00  (n=2997)
Epoch 00051: Time=   7.4s, Loss=5.22e+00, Inv=5.22e+00, For=1.44e+01, Power=6.46e-01
  [eval] val_mse=2.340e+00  (n=2997)
Epoch 00052: Time=   7.4s, Loss=5.15e+00, Inv=5.15e+00, For=1.47e+01, Power=6.42e-01
  [eval] val_mse=2.319e+00  (n=2997)
Epoch 00053: Time=   7.5s, Loss=5.07e+00, Inv=5.07e+00, For=1.51e+01, Power=6.39e-01
  [eval] val_mse=2.295e+00  (n=2997)
Epoch 00054: Time=   7.5s, Loss=5.00e+00, Inv=5.00e+00, For=1.55e+01, Power=6.35e-01
  [eval] val_mse=2.270e+00  (n=2997)
Epoch 00055: Time=   7.5s, Loss=4.94e+00, Inv=4.94e+00, For=1.59e+01, Power=6.33e-01
  [eval] val_mse=2.257e+00  (n=2997)
Epoch 00056: Time=   7.6s, Loss=4.88e+00, Inv=4.88e+00, For=1.63e+01, Power=6.30e-01
  [eval] val_mse=2.228e+00  (n=2997)
Epoch 00057: Time=   7.6s, Loss=4.82e+00, Inv=4.82e+00, For=1.67e+01, Power=6.27e-01
  [eval] val_mse=2.226e+00  (n=2997)
Epoch 00058: Time=   7.6s, Loss=4.76e+00, Inv=4.76e+00, For=1.71e+01, Power=6.24e-01
  [eval] val_mse=2.209e+00  (n=2997)
Epoch 00059: Time=   7.7s, Loss=4.71e+00, Inv=4.71e+00, For=1.75e+01, Power=6.20e-01
  [eval] val_mse=2.187e+00  (n=2997)
Epoch 00060: Time=   7.7s, Loss=4.66e+00, Inv=4.66e+00, For=1.79e+01, Power=6.19e-01
  [eval] val_mse=2.176e+00  (n=2997)
Epoch 00061: Time=   7.7s, Loss=4.61e+00, Inv=4.61e+00, For=1.83e+01, Power=6.16e-01
  [eval] val_mse=2.153e+00  (n=2997)
Epoch 00062: Time=   7.8s, Loss=4.56e+00, Inv=4.56e+00, For=1.87e+01, Power=6.15e-01
  [eval] val_mse=2.154e+00  (n=2997)
Epoch 00063: Time=   7.8s, Loss=4.52e+00, Inv=4.52e+00, For=1.91e+01, Power=6.13e-01
  [eval] val_mse=2.129e+00  (n=2997)
Epoch 00064: Time=   7.8s, Loss=4.48e+00, Inv=4.48e+00, For=1.95e+01, Power=6.11e-01
  [eval] val_mse=2.118e+00  (n=2997)
Epoch 00065: Time=   7.9s, Loss=4.44e+00, Inv=4.44e+00, For=1.99e+01, Power=6.09e-01
  [eval] val_mse=2.103e+00  (n=2997)
Epoch 00066: Time=   7.9s, Loss=4.40e+00, Inv=4.40e+00, For=2.03e+01, Power=6.08e-01
  [eval] val_mse=2.084e+00  (n=2997)
Epoch 00067: Time=   7.9s, Loss=4.37e+00, Inv=4.37e+00, For=2.07e+01, Power=6.07e-01
  [eval] val_mse=2.086e+00  (n=2997)
Epoch 00068: Time=   8.0s, Loss=4.33e+00, Inv=4.33e+00, For=2.11e+01, Power=6.04e-01
  [eval] val_mse=2.065e+00  (n=2997)
Epoch 00069: Time=   8.0s, Loss=4.30e+00, Inv=4.30e+00, For=2.15e+01, Power=6.04e-01
  [eval] val_mse=2.064e+00  (n=2997)
Epoch 00070: Time=   8.1s, Loss=4.27e+00, Inv=4.27e+00, For=2.19e+01, Power=6.03e-01
  [eval] val_mse=2.057e+00  (n=2997)
Epoch 00071: Time=   8.1s, Loss=4.24e+00, Inv=4.24e+00, For=2.24e+01, Power=6.02e-01
  [eval] val_mse=2.033e+00  (n=2997)
Epoch 00072: Time=   8.1s, Loss=4.21e+00, Inv=4.21e+00, For=2.28e+01, Power=6.00e-01
  [eval] val_mse=2.043e+00  (n=2997)
Epoch 00073: Time=   8.2s, Loss=4.19e+00, Inv=4.19e+00, For=2.32e+01, Power=5.99e-01
  [eval] val_mse=2.009e+00  (n=2997)
Epoch 00074: Time=   8.2s, Loss=4.16e+00, Inv=4.16e+00, For=2.36e+01, Power=5.98e-01
  [eval] val_mse=2.005e+00  (n=2997)
Epoch 00075: Time=   8.2s, Loss=4.13e+00, Inv=4.13e+00, For=2.40e+01, Power=5.97e-01
  [eval] val_mse=2.000e+00  (n=2997)
Epoch 00076: Time=   8.3s, Loss=4.11e+00, Inv=4.11e+00, For=2.44e+01, Power=5.97e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00077: Time=   8.3s, Loss=4.09e+00, Inv=4.09e+00, For=2.49e+01, Power=5.95e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00078: Time=   8.3s, Loss=4.07e+00, Inv=4.07e+00, For=2.52e+01, Power=5.94e-01
  [eval] val_mse=1.979e+00  (n=2997)
Epoch 00079: Time=   8.4s, Loss=4.05e+00, Inv=4.05e+00, For=2.56e+01, Power=5.94e-01
  [eval] val_mse=1.981e+00  (n=2997)
Epoch 00080: Time=   8.4s, Loss=4.03e+00, Inv=4.03e+00, For=2.61e+01, Power=5.94e-01
  [eval] val_mse=1.974e+00  (n=2997)
Epoch 00081: Time=   8.4s, Loss=4.01e+00, Inv=4.01e+00, For=2.65e+01, Power=5.93e-01
  [eval] val_mse=1.964e+00  (n=2997)
Epoch 00082: Time=   8.5s, Loss=3.99e+00, Inv=3.99e+00, For=2.68e+01, Power=5.92e-01
  [eval] val_mse=1.958e+00  (n=2997)
Epoch 00083: Time=   8.5s, Loss=3.98e+00, Inv=3.98e+00, For=2.73e+01, Power=5.92e-01
  [eval] val_mse=1.944e+00  (n=2997)
Epoch 00084: Time=   8.5s, Loss=3.97e+00, Inv=3.97e+00, For=2.77e+01, Power=5.92e-01
  [eval] val_mse=1.950e+00  (n=2997)
Epoch 00085: Time=   8.6s, Loss=3.95e+00, Inv=3.95e+00, For=2.81e+01, Power=5.91e-01
  [eval] val_mse=1.938e+00  (n=2997)
Epoch 00086: Time=   8.6s, Loss=3.93e+00, Inv=3.93e+00, For=2.86e+01, Power=5.91e-01
  [eval] val_mse=1.941e+00  (n=2997)
Epoch 00087: Time=   8.6s, Loss=3.92e+00, Inv=3.92e+00, For=2.90e+01, Power=5.90e-01
  [eval] val_mse=1.934e+00  (n=2997)
Epoch 00088: Time=   8.7s, Loss=3.90e+00, Inv=3.90e+00, For=2.94e+01, Power=5.90e-01
  [eval] val_mse=1.936e+00  (n=2997)
Epoch 00089: Time=   8.7s, Loss=3.89e+00, Inv=3.89e+00, For=2.98e+01, Power=5.90e-01
  [eval] val_mse=1.935e+00  (n=2997)
Epoch 00090: Time=   8.7s, Loss=3.88e+00, Inv=3.88e+00, For=3.04e+01, Power=5.89e-01
  [eval] val_mse=1.935e+00  (n=2997)
Epoch 00091: Time=   8.8s, Loss=3.87e+00, Inv=3.87e+00, For=3.06e+01, Power=5.88e-01
  [eval] val_mse=1.930e+00  (n=2997)
Epoch 00092: Time=   8.8s, Loss=3.85e+00, Inv=3.85e+00, For=3.11e+01, Power=5.88e-01
  [eval] val_mse=1.939e+00  (n=2997)
Epoch 00093: Time=   8.8s, Loss=3.85e+00, Inv=3.85e+00, For=3.16e+01, Power=5.89e-01
  [eval] val_mse=1.925e+00  (n=2997)
Epoch 00094: Time=   8.9s, Loss=3.83e+00, Inv=3.83e+00, For=3.21e+01, Power=5.89e-01
  [eval] val_mse=1.925e+00  (n=2997)
Epoch 00095: Time=   8.9s, Loss=3.82e+00, Inv=3.82e+00, For=3.23e+01, Power=5.87e-01
  [eval] val_mse=1.927e+00  (n=2997)
Epoch 00096: Time=   8.9s, Loss=3.81e+00, Inv=3.81e+00, For=3.29e+01, Power=5.88e-01
  [eval] val_mse=1.926e+00  (n=2997)
Epoch 00097: Time=   9.0s, Loss=3.80e+00, Inv=3.80e+00, For=3.34e+01, Power=5.87e-01
  [eval] val_mse=1.921e+00  (n=2997)
Epoch 00098: Time=   9.0s, Loss=3.79e+00, Inv=3.79e+00, For=3.36e+01, Power=5.88e-01
  [eval] val_mse=1.928e+00  (n=2997)
Epoch 00099: Time=   9.0s, Loss=3.78e+00, Inv=3.78e+00, For=3.42e+01, Power=5.87e-01
  [eval] val_mse=1.917e+00  (n=2997)
Epoch 00100: Time=   9.1s, Loss=3.77e+00, Inv=3.77e+00, For=3.46e+01, Power=5.86e-01
  [eval] val_mse=1.927e+00  (n=2997)
Epoch 00101: Time=   9.1s, Loss=3.76e+00, Inv=3.76e+00, For=3.50e+01, Power=5.87e-01
  [eval] val_mse=1.936e+00  (n=2997)
Epoch 00102: Time=   9.1s, Loss=3.75e+00, Inv=3.75e+00, For=3.54e+01, Power=5.86e-01
  [eval] val_mse=1.931e+00  (n=2997)
Epoch 00103: Time=   9.2s, Loss=3.74e+00, Inv=3.74e+00, For=3.59e+01, Power=5.85e-01
  [eval] val_mse=1.932e+00  (n=2997)
Epoch 00104: Time=   9.2s, Loss=3.73e+00, Inv=3.73e+00, For=3.64e+01, Power=5.85e-01
  [eval] val_mse=1.934e+00  (n=2997)
Epoch 00105: Time=   9.2s, Loss=3.72e+00, Inv=3.72e+00, For=3.67e+01, Power=5.86e-01
  [eval] val_mse=1.915e+00  (n=2997)
Epoch 00106: Time=   9.3s, Loss=3.71e+00, Inv=3.71e+00, For=3.72e+01, Power=5.86e-01
  [eval] val_mse=1.938e+00  (n=2997)
Epoch 00107: Time=   9.3s, Loss=3.70e+00, Inv=3.70e+00, For=3.76e+01, Power=5.85e-01
  [eval] val_mse=1.939e+00  (n=2997)
Epoch 00108: Time=   9.3s, Loss=3.70e+00, Inv=3.70e+00, For=3.81e+01, Power=5.86e-01
  [eval] val_mse=1.942e+00  (n=2997)
Epoch 00109: Time=   9.4s, Loss=3.69e+00, Inv=3.69e+00, For=3.86e+01, Power=5.85e-01
  [eval] val_mse=1.949e+00  (n=2997)
Epoch 00110: Time=   9.4s, Loss=3.69e+00, Inv=3.69e+00, For=3.89e+01, Power=5.86e-01
  [eval] val_mse=1.939e+00  (n=2997)
Epoch 00111: Time=   9.4s, Loss=3.67e+00, Inv=3.67e+00, For=3.95e+01, Power=5.85e-01
  [eval] val_mse=1.948e+00  (n=2997)
Epoch 00112: Time=   9.5s, Loss=3.67e+00, Inv=3.67e+00, For=3.98e+01, Power=5.85e-01
  [eval] val_mse=1.947e+00  (n=2997)
Epoch 00113: Time=   9.5s, Loss=3.66e+00, Inv=3.66e+00, For=4.02e+01, Power=5.85e-01
  [eval] val_mse=1.954e+00  (n=2997)
Epoch 00114: Time=   9.5s, Loss=3.66e+00, Inv=3.66e+00, For=4.07e+01, Power=5.85e-01
  [eval] val_mse=1.964e+00  (n=2997)
Epoch 00115: Time=   9.6s, Loss=3.65e+00, Inv=3.65e+00, For=4.11e+01, Power=5.86e-01
  [eval] val_mse=1.964e+00  (n=2997)
  [early_stop] stop at epoch=115 (best_epoch=105, best_val_mse=1.915e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2
  [val] Torque RMSE = 5.650e-01
Torque MSE  = 1.228e-01
Torque RMSE = 3.504e-01
Per-joint MSE : 1.702e-01 2.795e-01 1.353e-01 5.894e-02 4.494e-02 4.785e-02
Per-joint RMSE: 4.126e-01 5.286e-01 3.678e-01 2.428e-01 2.120e-01 2.187e-01
Comp Time per Sample = 2.052e-04s / 4873.3Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 0 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-4xgsjt1x because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7e99d4b668c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:51:08.195686: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:51:10.070454: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.3s, Loss=5.91e+03, Inv=5.91e+03, For=5.76e+00, Power=5.91e+02
  [eval] val_mse=9.472e+01  (n=7000)
Epoch 00002: Time=   6.0s, Loss=2.92e+02, Inv=2.92e+02, For=5.45e+00, Power=5.36e+01
  [eval] val_mse=3.479e+01  (n=7000)
Epoch 00003: Time=   6.0s, Loss=1.15e+02, Inv=1.15e+02, For=5.29e+00, Power=1.88e+01
  [eval] val_mse=1.817e+01  (n=7000)
Epoch 00004: Time=   6.1s, Loss=6.62e+01, Inv=6.62e+01, For=5.25e+00, Power=1.03e+01
  [eval] val_mse=1.133e+01  (n=7000)
Epoch 00005: Time=   6.1s, Loss=4.37e+01, Inv=4.37e+01, For=5.26e+00, Power=6.56e+00
  [eval] val_mse=7.640e+00  (n=7000)
Epoch 00006: Time=   6.2s, Loss=3.10e+01, Inv=3.10e+01, For=5.29e+00, Power=4.59e+00
  [eval] val_mse=5.508e+00  (n=7000)
Epoch 00007: Time=   6.2s, Loss=2.34e+01, Inv=2.34e+01, For=5.28e+00, Power=3.41e+00
  [eval] val_mse=4.132e+00  (n=7000)
Epoch 00008: Time=   6.3s, Loss=1.85e+01, Inv=1.85e+01, For=5.28e+00, Power=2.67e+00
  [eval] val_mse=3.236e+00  (n=7000)
Epoch 00009: Time=   6.3s, Loss=1.52e+01, Inv=1.52e+01, For=5.29e+00, Power=2.19e+00
  [eval] val_mse=2.607e+00  (n=7000)
Epoch 00010: Time=   6.4s, Loss=1.27e+01, Inv=1.27e+01, For=5.26e+00, Power=1.84e+00
  [eval] val_mse=2.183e+00  (n=7000)
Epoch 00011: Time=   6.4s, Loss=1.10e+01, Inv=1.10e+01, For=5.34e+00, Power=1.60e+00
  [eval] val_mse=1.867e+00  (n=7000)
Epoch 00012: Time=   6.5s, Loss=9.75e+00, Inv=9.75e+00, For=5.44e+00, Power=1.42e+00
  [eval] val_mse=1.640e+00  (n=7000)
Epoch 00013: Time=   6.5s, Loss=8.76e+00, Inv=8.76e+00, For=5.62e+00, Power=1.28e+00
  [eval] val_mse=1.464e+00  (n=7000)
Epoch 00014: Time=   6.6s, Loss=7.98e+00, Inv=7.98e+00, For=5.80e+00, Power=1.18e+00
  [eval] val_mse=1.325e+00  (n=7000)
Epoch 00015: Time=   6.6s, Loss=7.38e+00, Inv=7.38e+00, For=6.03e+00, Power=1.09e+00
  [eval] val_mse=1.211e+00  (n=7000)
Epoch 00016: Time=   6.7s, Loss=6.88e+00, Inv=6.88e+00, For=6.28e+00, Power=1.03e+00
  [eval] val_mse=1.117e+00  (n=7000)
Epoch 00017: Time=   6.7s, Loss=6.47e+00, Inv=6.47e+00, For=6.58e+00, Power=9.78e-01
  [eval] val_mse=1.040e+00  (n=7000)
Epoch 00018: Time=   6.8s, Loss=6.12e+00, Inv=6.12e+00, For=6.82e+00, Power=9.33e-01
  [eval] val_mse=9.738e-01  (n=7000)
Epoch 00019: Time=   6.8s, Loss=5.83e+00, Inv=5.83e+00, For=7.14e+00, Power=8.97e-01
  [eval] val_mse=9.172e-01  (n=7000)
Epoch 00020: Time=   6.9s, Loss=5.56e+00, Inv=5.56e+00, For=7.45e+00, Power=8.74e-01
  [eval] val_mse=8.724e-01  (n=7000)
Epoch 00021: Time=   6.9s, Loss=5.35e+00, Inv=5.35e+00, For=7.75e+00, Power=8.54e-01
  [eval] val_mse=8.325e-01  (n=7000)
Epoch 00022: Time=   7.0s, Loss=5.15e+00, Inv=5.15e+00, For=8.05e+00, Power=8.29e-01
  [eval] val_mse=7.979e-01  (n=7000)
Epoch 00023: Time=   7.0s, Loss=4.98e+00, Inv=4.98e+00, For=8.43e+00, Power=8.11e-01
  [eval] val_mse=7.655e-01  (n=7000)
Epoch 00024: Time=   7.1s, Loss=4.84e+00, Inv=4.84e+00, For=8.70e+00, Power=7.99e-01
  [eval] val_mse=7.398e-01  (n=7000)
Epoch 00025: Time=   7.1s, Loss=4.70e+00, Inv=4.70e+00, For=9.11e+00, Power=7.86e-01
  [eval] val_mse=7.172e-01  (n=7000)
Epoch 00026: Time=   7.2s, Loss=4.58e+00, Inv=4.58e+00, For=9.41e+00, Power=7.76e-01
  [eval] val_mse=6.974e-01  (n=7000)
Epoch 00027: Time=   7.2s, Loss=4.48e+00, Inv=4.48e+00, For=9.83e+00, Power=7.69e-01
  [eval] val_mse=6.782e-01  (n=7000)
Epoch 00028: Time=   7.3s, Loss=4.39e+00, Inv=4.39e+00, For=1.02e+01, Power=7.63e-01
  [eval] val_mse=6.623e-01  (n=7000)
Epoch 00029: Time=   7.3s, Loss=4.31e+00, Inv=4.31e+00, For=1.05e+01, Power=7.53e-01
  [eval] val_mse=6.468e-01  (n=7000)
Epoch 00030: Time=   7.4s, Loss=4.23e+00, Inv=4.23e+00, For=1.09e+01, Power=7.47e-01
  [eval] val_mse=6.315e-01  (n=7000)
Epoch 00031: Time=   7.4s, Loss=4.16e+00, Inv=4.16e+00, For=1.12e+01, Power=7.40e-01
  [eval] val_mse=6.205e-01  (n=7000)
Epoch 00032: Time=   7.5s, Loss=4.11e+00, Inv=4.11e+00, For=1.17e+01, Power=7.34e-01
  [eval] val_mse=6.088e-01  (n=7000)
Epoch 00033: Time=   7.5s, Loss=4.05e+00, Inv=4.05e+00, For=1.20e+01, Power=7.33e-01
  [eval] val_mse=5.965e-01  (n=7000)
Epoch 00034: Time=   7.6s, Loss=4.01e+00, Inv=4.01e+00, For=1.24e+01, Power=7.32e-01
  [eval] val_mse=5.850e-01  (n=7000)
Epoch 00035: Time=   7.6s, Loss=3.96e+00, Inv=3.96e+00, For=1.27e+01, Power=7.27e-01
  [eval] val_mse=5.767e-01  (n=7000)
Epoch 00036: Time=   7.7s, Loss=3.92e+00, Inv=3.92e+00, For=1.31e+01, Power=7.24e-01
  [eval] val_mse=5.682e-01  (n=7000)
Epoch 00037: Time=   7.7s, Loss=3.88e+00, Inv=3.88e+00, For=1.35e+01, Power=7.21e-01
  [eval] val_mse=5.569e-01  (n=7000)
Epoch 00038: Time=   7.8s, Loss=3.84e+00, Inv=3.84e+00, For=1.38e+01, Power=7.18e-01
  [eval] val_mse=5.497e-01  (n=7000)
Epoch 00039: Time=   7.8s, Loss=3.81e+00, Inv=3.81e+00, For=1.43e+01, Power=7.16e-01
  [eval] val_mse=5.427e-01  (n=7000)
Epoch 00040: Time=   7.9s, Loss=3.78e+00, Inv=3.78e+00, For=1.47e+01, Power=7.17e-01
  [eval] val_mse=5.353e-01  (n=7000)
Epoch 00041: Time=   7.9s, Loss=3.75e+00, Inv=3.75e+00, For=1.50e+01, Power=7.13e-01
  [eval] val_mse=5.266e-01  (n=7000)
Epoch 00042: Time=   8.0s, Loss=3.72e+00, Inv=3.72e+00, For=1.53e+01, Power=7.13e-01
  [eval] val_mse=5.216e-01  (n=7000)
Epoch 00043: Time=   8.0s, Loss=3.70e+00, Inv=3.70e+00, For=1.57e+01, Power=7.11e-01
  [eval] val_mse=5.157e-01  (n=7000)
Epoch 00044: Time=   8.1s, Loss=3.67e+00, Inv=3.67e+00, For=1.60e+01, Power=7.07e-01
  [eval] val_mse=5.094e-01  (n=7000)
Epoch 00045: Time=   8.1s, Loss=3.65e+00, Inv=3.65e+00, For=1.65e+01, Power=7.08e-01
  [eval] val_mse=5.039e-01  (n=7000)
Epoch 00046: Time=   8.2s, Loss=3.63e+00, Inv=3.63e+00, For=1.68e+01, Power=7.05e-01
  [eval] val_mse=4.995e-01  (n=7000)
Epoch 00047: Time=   8.2s, Loss=3.61e+00, Inv=3.61e+00, For=1.71e+01, Power=7.05e-01
  [eval] val_mse=4.934e-01  (n=7000)
Epoch 00048: Time=   8.3s, Loss=3.59e+00, Inv=3.59e+00, For=1.76e+01, Power=7.04e-01
  [eval] val_mse=4.891e-01  (n=7000)
Epoch 00049: Time=   8.3s, Loss=3.57e+00, Inv=3.57e+00, For=1.77e+01, Power=7.02e-01
  [eval] val_mse=4.840e-01  (n=7000)
Epoch 00050: Time=   8.4s, Loss=3.56e+00, Inv=3.56e+00, For=1.83e+01, Power=7.02e-01
  [eval] val_mse=4.810e-01  (n=7000)
Epoch 00051: Time=   8.4s, Loss=3.53e+00, Inv=3.53e+00, For=1.86e+01, Power=6.99e-01
  [eval] val_mse=4.749e-01  (n=7000)
Epoch 00052: Time=   8.5s, Loss=3.51e+00, Inv=3.51e+00, For=1.90e+01, Power=6.98e-01
  [eval] val_mse=4.709e-01  (n=7000)
Epoch 00053: Time=   8.5s, Loss=3.50e+00, Inv=3.50e+00, For=1.94e+01, Power=7.00e-01
  [eval] val_mse=4.684e-01  (n=7000)
Epoch 00054: Time=   8.6s, Loss=3.49e+00, Inv=3.49e+00, For=1.97e+01, Power=6.98e-01
  [eval] val_mse=4.645e-01  (n=7000)
Epoch 00055: Time=   8.6s, Loss=3.47e+00, Inv=3.47e+00, For=2.02e+01, Power=6.98e-01
  [eval] val_mse=4.596e-01  (n=7000)
Epoch 00056: Time=   8.7s, Loss=3.46e+00, Inv=3.46e+00, For=2.06e+01, Power=6.99e-01
  [eval] val_mse=4.572e-01  (n=7000)
Epoch 00057: Time=   8.7s, Loss=3.45e+00, Inv=3.45e+00, For=2.08e+01, Power=6.98e-01
  [eval] val_mse=4.545e-01  (n=7000)
Epoch 00058: Time=   8.8s, Loss=3.44e+00, Inv=3.44e+00, For=2.12e+01, Power=6.95e-01
  [eval] val_mse=4.505e-01  (n=7000)
Epoch 00059: Time=   8.8s, Loss=3.42e+00, Inv=3.42e+00, For=2.17e+01, Power=6.92e-01
  [eval] val_mse=4.471e-01  (n=7000)
Epoch 00060: Time=   8.9s, Loss=3.41e+00, Inv=3.41e+00, For=2.21e+01, Power=6.96e-01
  [eval] val_mse=4.452e-01  (n=7000)
Epoch 00061: Time=   8.9s, Loss=3.41e+00, Inv=3.41e+00, For=2.24e+01, Power=6.97e-01
  [eval] val_mse=4.423e-01  (n=7000)
Epoch 00062: Time=   9.0s, Loss=3.39e+00, Inv=3.39e+00, For=2.30e+01, Power=6.94e-01
  [eval] val_mse=4.382e-01  (n=7000)
Epoch 00063: Time=   9.0s, Loss=3.38e+00, Inv=3.38e+00, For=2.34e+01, Power=6.96e-01
  [eval] val_mse=4.345e-01  (n=7000)
Epoch 00064: Time=   9.1s, Loss=3.37e+00, Inv=3.37e+00, For=2.36e+01, Power=6.92e-01
  [eval] val_mse=4.329e-01  (n=7000)
Epoch 00065: Time=   9.1s, Loss=3.36e+00, Inv=3.36e+00, For=2.41e+01, Power=6.94e-01
  [eval] val_mse=4.308e-01  (n=7000)
Epoch 00066: Time=   9.2s, Loss=3.35e+00, Inv=3.35e+00, For=2.46e+01, Power=6.91e-01
  [eval] val_mse=4.279e-01  (n=7000)
Epoch 00067: Time=   9.2s, Loss=3.34e+00, Inv=3.34e+00, For=2.51e+01, Power=6.92e-01
  [eval] val_mse=4.250e-01  (n=7000)
Epoch 00068: Time=   9.3s, Loss=3.33e+00, Inv=3.33e+00, For=2.50e+01, Power=6.91e-01
  [eval] val_mse=4.234e-01  (n=7000)
Epoch 00069: Time=   9.3s, Loss=3.32e+00, Inv=3.32e+00, For=2.56e+01, Power=6.88e-01
  [eval] val_mse=4.208e-01  (n=7000)
Epoch 00070: Time=   9.4s, Loss=3.32e+00, Inv=3.32e+00, For=2.63e+01, Power=6.93e-01
  [eval] val_mse=4.192e-01  (n=7000)
Epoch 00071: Time=   9.4s, Loss=3.31e+00, Inv=3.31e+00, For=2.66e+01, Power=6.88e-01
  [eval] val_mse=4.191e-01  (n=7000)
Epoch 00072: Time=   9.5s, Loss=3.31e+00, Inv=3.31e+00, For=2.71e+01, Power=6.90e-01
  [eval] val_mse=4.143e-01  (n=7000)
Epoch 00073: Time=   9.5s, Loss=3.30e+00, Inv=3.30e+00, For=2.73e+01, Power=6.89e-01
  [eval] val_mse=4.133e-01  (n=7000)
Epoch 00074: Time=   9.6s, Loss=3.30e+00, Inv=3.30e+00, For=2.80e+01, Power=6.89e-01
  [eval] val_mse=4.098e-01  (n=7000)
Epoch 00075: Time=   9.6s, Loss=3.28e+00, Inv=3.28e+00, For=2.84e+01, Power=6.91e-01
  [eval] val_mse=4.087e-01  (n=7000)
Epoch 00076: Time=   9.7s, Loss=3.28e+00, Inv=3.28e+00, For=2.88e+01, Power=6.90e-01
  [eval] val_mse=4.064e-01  (n=7000)
Epoch 00077: Time=   9.7s, Loss=3.27e+00, Inv=3.27e+00, For=2.92e+01, Power=6.86e-01
  [eval] val_mse=4.053e-01  (n=7000)
Epoch 00078: Time=   9.8s, Loss=3.27e+00, Inv=3.27e+00, For=2.96e+01, Power=6.88e-01
  [eval] val_mse=4.036e-01  (n=7000)
Epoch 00079: Time=   9.8s, Loss=3.25e+00, Inv=3.25e+00, For=3.02e+01, Power=6.86e-01
  [eval] val_mse=4.023e-01  (n=7000)
Epoch 00080: Time=   9.9s, Loss=3.25e+00, Inv=3.25e+00, For=3.03e+01, Power=6.87e-01
  [eval] val_mse=4.007e-01  (n=7000)
Epoch 00081: Time=   9.9s, Loss=3.24e+00, Inv=3.24e+00, For=3.12e+01, Power=6.89e-01
  [eval] val_mse=3.986e-01  (n=7000)
Epoch 00082: Time=  10.0s, Loss=3.25e+00, Inv=3.25e+00, For=3.14e+01, Power=6.90e-01
  [eval] val_mse=3.976e-01  (n=7000)
Epoch 00083: Time=  10.0s, Loss=3.24e+00, Inv=3.24e+00, For=3.19e+01, Power=6.90e-01
  [eval] val_mse=3.967e-01  (n=7000)
Epoch 00084: Time=  10.1s, Loss=3.24e+00, Inv=3.24e+00, For=3.25e+01, Power=6.86e-01
  [eval] val_mse=3.946e-01  (n=7000)
Epoch 00085: Time=  10.1s, Loss=3.23e+00, Inv=3.23e+00, For=3.27e+01, Power=6.88e-01
  [eval] val_mse=3.934e-01  (n=7000)
Epoch 00086: Time=  10.2s, Loss=3.22e+00, Inv=3.22e+00, For=3.34e+01, Power=6.87e-01
  [eval] val_mse=3.934e-01  (n=7000)
Epoch 00087: Time=  10.2s, Loss=3.22e+00, Inv=3.22e+00, For=3.35e+01, Power=6.86e-01
  [eval] val_mse=3.911e-01  (n=7000)
Epoch 00088: Time=  10.3s, Loss=3.22e+00, Inv=3.22e+00, For=3.40e+01, Power=6.87e-01
  [eval] val_mse=3.894e-01  (n=7000)
Epoch 00089: Time=  10.3s, Loss=3.21e+00, Inv=3.21e+00, For=3.47e+01, Power=6.88e-01
  [eval] val_mse=3.888e-01  (n=7000)
Epoch 00090: Time=  10.4s, Loss=3.20e+00, Inv=3.20e+00, For=3.53e+01, Power=6.88e-01
  [eval] val_mse=3.865e-01  (n=7000)
Epoch 00091: Time=  10.4s, Loss=3.20e+00, Inv=3.20e+00, For=3.53e+01, Power=6.86e-01
  [eval] val_mse=3.858e-01  (n=7000)
Epoch 00092: Time=  10.5s, Loss=3.20e+00, Inv=3.20e+00, For=3.60e+01, Power=6.86e-01
  [eval] val_mse=3.850e-01  (n=7000)
Epoch 00093: Time=  10.5s, Loss=3.18e+00, Inv=3.18e+00, For=3.67e+01, Power=6.84e-01
  [eval] val_mse=3.834e-01  (n=7000)
Epoch 00094: Time=  10.6s, Loss=3.18e+00, Inv=3.18e+00, For=3.67e+01, Power=6.88e-01
  [eval] val_mse=3.824e-01  (n=7000)
Epoch 00095: Time=  10.6s, Loss=3.18e+00, Inv=3.18e+00, For=3.73e+01, Power=6.83e-01
  [eval] val_mse=3.815e-01  (n=7000)
Epoch 00096: Time=  10.7s, Loss=3.18e+00, Inv=3.18e+00, For=3.79e+01, Power=6.84e-01
  [eval] val_mse=3.800e-01  (n=7000)
Epoch 00097: Time=  10.7s, Loss=3.17e+00, Inv=3.17e+00, For=3.83e+01, Power=6.84e-01
  [eval] val_mse=3.803e-01  (n=7000)
Epoch 00098: Time=  10.8s, Loss=3.17e+00, Inv=3.17e+00, For=3.88e+01, Power=6.86e-01
  [eval] val_mse=3.781e-01  (n=7000)
Epoch 00099: Time=  10.8s, Loss=3.17e+00, Inv=3.17e+00, For=3.91e+01, Power=6.88e-01
  [eval] val_mse=3.776e-01  (n=7000)
Epoch 00100: Time=  10.9s, Loss=3.17e+00, Inv=3.17e+00, For=3.96e+01, Power=6.88e-01
  [eval] val_mse=3.762e-01  (n=7000)
Epoch 00101: Time=  10.9s, Loss=3.16e+00, Inv=3.16e+00, For=4.01e+01, Power=6.86e-01
  [eval] val_mse=3.761e-01  (n=7000)
Epoch 00102: Time=  11.0s, Loss=3.15e+00, Inv=3.15e+00, For=4.05e+01, Power=6.83e-01
  [eval] val_mse=3.745e-01  (n=7000)
Epoch 00103: Time=  11.0s, Loss=3.15e+00, Inv=3.15e+00, For=4.12e+01, Power=6.84e-01
  [eval] val_mse=3.750e-01  (n=7000)
Epoch 00104: Time=  11.1s, Loss=3.15e+00, Inv=3.15e+00, For=4.17e+01, Power=6.84e-01
  [eval] val_mse=3.728e-01  (n=7000)
Epoch 00105: Time=  11.1s, Loss=3.15e+00, Inv=3.15e+00, For=4.18e+01, Power=6.87e-01
  [eval] val_mse=3.719e-01  (n=7000)
Epoch 00106: Time=  11.2s, Loss=3.14e+00, Inv=3.14e+00, For=4.24e+01, Power=6.84e-01
  [eval] val_mse=3.712e-01  (n=7000)
Epoch 00107: Time=  11.2s, Loss=3.13e+00, Inv=3.13e+00, For=4.30e+01, Power=6.83e-01
  [eval] val_mse=3.710e-01  (n=7000)
Epoch 00108: Time=  11.3s, Loss=3.14e+00, Inv=3.14e+00, For=4.33e+01, Power=6.84e-01
  [eval] val_mse=3.700e-01  (n=7000)
Epoch 00109: Time=  11.3s, Loss=3.13e+00, Inv=3.13e+00, For=4.36e+01, Power=6.84e-01
  [eval] val_mse=3.690e-01  (n=7000)
Epoch 00110: Time=  11.4s, Loss=3.13e+00, Inv=3.13e+00, For=4.46e+01, Power=6.81e-01
  [eval] val_mse=3.689e-01  (n=7000)
Epoch 00111: Time=  11.4s, Loss=3.13e+00, Inv=3.13e+00, For=4.50e+01, Power=6.84e-01
  [eval] val_mse=3.673e-01  (n=7000)
Epoch 00112: Time=  11.5s, Loss=3.12e+00, Inv=3.12e+00, For=4.53e+01, Power=6.86e-01
  [eval] val_mse=3.681e-01  (n=7000)
Epoch 00113: Time=  11.5s, Loss=3.12e+00, Inv=3.12e+00, For=4.60e+01, Power=6.87e-01
  [eval] val_mse=3.660e-01  (n=7000)
Epoch 00114: Time=  11.6s, Loss=3.12e+00, Inv=3.12e+00, For=4.61e+01, Power=6.84e-01
  [eval] val_mse=3.648e-01  (n=7000)
Epoch 00115: Time=  11.6s, Loss=3.11e+00, Inv=3.11e+00, For=4.62e+01, Power=6.82e-01
  [eval] val_mse=3.670e-01  (n=7000)
Epoch 00116: Time=  11.7s, Loss=3.11e+00, Inv=3.11e+00, For=4.76e+01, Power=6.83e-01
  [eval] val_mse=3.642e-01  (n=7000)
Epoch 00117: Time=  11.7s, Loss=3.11e+00, Inv=3.11e+00, For=4.77e+01, Power=6.82e-01
  [eval] val_mse=3.647e-01  (n=7000)
Epoch 00118: Time=  11.8s, Loss=3.11e+00, Inv=3.11e+00, For=4.86e+01, Power=6.81e-01
  [eval] val_mse=3.632e-01  (n=7000)
Epoch 00119: Time=  11.8s, Loss=3.10e+00, Inv=3.10e+00, For=4.89e+01, Power=6.81e-01
  [eval] val_mse=3.623e-01  (n=7000)
Epoch 00120: Time=  11.9s, Loss=3.10e+00, Inv=3.10e+00, For=4.92e+01, Power=6.83e-01
  [eval] val_mse=3.626e-01  (n=7000)
Epoch 00121: Time=  11.9s, Loss=3.10e+00, Inv=3.10e+00, For=4.97e+01, Power=6.85e-01
  [eval] val_mse=3.609e-01  (n=7000)
Epoch 00122: Time=  12.0s, Loss=3.09e+00, Inv=3.09e+00, For=5.00e+01, Power=6.83e-01
  [eval] val_mse=3.611e-01  (n=7000)
Epoch 00123: Time=  12.0s, Loss=3.09e+00, Inv=3.09e+00, For=5.07e+01, Power=6.82e-01
  [eval] val_mse=3.607e-01  (n=7000)
Epoch 00124: Time=  12.0s, Loss=3.09e+00, Inv=3.09e+00, For=5.13e+01, Power=6.85e-01
  [eval] val_mse=3.600e-01  (n=7000)
Epoch 00125: Time=  12.1s, Loss=3.09e+00, Inv=3.09e+00, For=5.19e+01, Power=6.84e-01
  [eval] val_mse=3.594e-01  (n=7000)
Epoch 00126: Time=  12.1s, Loss=3.09e+00, Inv=3.09e+00, For=5.19e+01, Power=6.84e-01
  [eval] val_mse=3.587e-01  (n=7000)
Epoch 00127: Time=  12.2s, Loss=3.08e+00, Inv=3.08e+00, For=5.27e+01, Power=6.82e-01
  [eval] val_mse=3.575e-01  (n=7000)
Epoch 00128: Time=  12.2s, Loss=3.08e+00, Inv=3.08e+00, For=5.30e+01, Power=6.81e-01
  [eval] val_mse=3.584e-01  (n=7000)
Epoch 00129: Time=  12.3s, Loss=3.07e+00, Inv=3.07e+00, For=5.39e+01, Power=6.81e-01
  [eval] val_mse=3.577e-01  (n=7000)
Epoch 00130: Time=  12.3s, Loss=3.08e+00, Inv=3.08e+00, For=5.45e+01, Power=6.81e-01
  [eval] val_mse=3.571e-01  (n=7000)
Epoch 00131: Time=  12.4s, Loss=3.07e+00, Inv=3.07e+00, For=5.46e+01, Power=6.84e-01
  [eval] val_mse=3.559e-01  (n=7000)
Epoch 00132: Time=  12.4s, Loss=3.07e+00, Inv=3.07e+00, For=5.50e+01, Power=6.82e-01
  [eval] val_mse=3.556e-01  (n=7000)
Epoch 00133: Time=  12.5s, Loss=3.07e+00, Inv=3.07e+00, For=5.63e+01, Power=6.84e-01
  [eval] val_mse=3.555e-01  (n=7000)
Epoch 00134: Time=  12.6s, Loss=3.07e+00, Inv=3.07e+00, For=5.62e+01, Power=6.82e-01
  [eval] val_mse=3.558e-01  (n=7000)
Epoch 00135: Time=  12.6s, Loss=3.07e+00, Inv=3.07e+00, For=5.65e+01, Power=6.81e-01
  [eval] val_mse=3.551e-01  (n=7000)
Epoch 00136: Time=  12.7s, Loss=3.06e+00, Inv=3.06e+00, For=5.78e+01, Power=6.83e-01
  [eval] val_mse=3.562e-01  (n=7000)
Epoch 00137: Time=  12.7s, Loss=3.06e+00, Inv=3.06e+00, For=5.72e+01, Power=6.83e-01
  [eval] val_mse=3.554e-01  (n=7000)
Epoch 00138: Time=  12.7s, Loss=3.06e+00, Inv=3.06e+00, For=5.81e+01, Power=6.79e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00139: Time=  12.8s, Loss=3.06e+00, Inv=3.06e+00, For=5.91e+01, Power=6.82e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00140: Time=  12.8s, Loss=3.05e+00, Inv=3.05e+00, For=5.95e+01, Power=6.83e-01
  [eval] val_mse=3.509e-01  (n=7000)
Epoch 00141: Time=  12.9s, Loss=3.05e+00, Inv=3.05e+00, For=5.99e+01, Power=6.83e-01
  [eval] val_mse=3.514e-01  (n=7000)
Epoch 00142: Time=  12.9s, Loss=3.06e+00, Inv=3.06e+00, For=6.03e+01, Power=6.83e-01
  [eval] val_mse=3.521e-01  (n=7000)
Epoch 00143: Time=  13.0s, Loss=3.05e+00, Inv=3.05e+00, For=6.10e+01, Power=6.81e-01
  [eval] val_mse=3.509e-01  (n=7000)
Epoch 00144: Time=  13.0s, Loss=3.05e+00, Inv=3.05e+00, For=6.14e+01, Power=6.83e-01
  [eval] val_mse=3.507e-01  (n=7000)
Epoch 00145: Time=  13.1s, Loss=3.04e+00, Inv=3.04e+00, For=6.20e+01, Power=6.81e-01
  [eval] val_mse=3.490e-01  (n=7000)
Epoch 00146: Time=  13.1s, Loss=3.04e+00, Inv=3.04e+00, For=6.24e+01, Power=6.81e-01
  [eval] val_mse=3.493e-01  (n=7000)
Epoch 00147: Time=  13.2s, Loss=3.05e+00, Inv=3.05e+00, For=6.32e+01, Power=6.80e-01
  [eval] val_mse=3.509e-01  (n=7000)
Epoch 00148: Time=  13.2s, Loss=3.04e+00, Inv=3.04e+00, For=6.37e+01, Power=6.81e-01
  [eval] val_mse=3.494e-01  (n=7000)
Epoch 00149: Time=  13.3s, Loss=3.04e+00, Inv=3.04e+00, For=6.45e+01, Power=6.82e-01
  [eval] val_mse=3.487e-01  (n=7000)
Epoch 00150: Time=  13.3s, Loss=3.05e+00, Inv=3.05e+00, For=6.49e+01, Power=6.83e-01
  [eval] val_mse=3.487e-01  (n=7000)
Epoch 00151: Time=  13.4s, Loss=3.04e+00, Inv=3.04e+00, For=6.51e+01, Power=6.82e-01
  [eval] val_mse=3.483e-01  (n=7000)
Epoch 00152: Time=  13.4s, Loss=3.03e+00, Inv=3.03e+00, For=6.63e+01, Power=6.78e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00153: Time=  13.5s, Loss=3.03e+00, Inv=3.03e+00, For=6.71e+01, Power=6.78e-01
  [eval] val_mse=3.459e-01  (n=7000)
Epoch 00154: Time=  13.5s, Loss=3.03e+00, Inv=3.03e+00, For=6.66e+01, Power=6.80e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00155: Time=  13.6s, Loss=3.03e+00, Inv=3.03e+00, For=6.74e+01, Power=6.81e-01
  [eval] val_mse=3.458e-01  (n=7000)
Epoch 00156: Time=  13.6s, Loss=3.02e+00, Inv=3.02e+00, For=6.84e+01, Power=6.79e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00157: Time=  13.7s, Loss=3.03e+00, Inv=3.03e+00, For=6.87e+01, Power=6.80e-01
  [eval] val_mse=3.458e-01  (n=7000)
Epoch 00158: Time=  13.7s, Loss=3.03e+00, Inv=3.03e+00, For=6.96e+01, Power=6.84e-01
  [eval] val_mse=3.463e-01  (n=7000)
Epoch 00159: Time=  13.8s, Loss=3.02e+00, Inv=3.02e+00, For=6.93e+01, Power=6.84e-01
  [eval] val_mse=3.449e-01  (n=7000)
Epoch 00160: Time=  13.8s, Loss=3.02e+00, Inv=3.02e+00, For=7.09e+01, Power=6.82e-01
  [eval] val_mse=3.445e-01  (n=7000)
Epoch 00161: Time=  13.9s, Loss=3.02e+00, Inv=3.02e+00, For=7.03e+01, Power=6.82e-01
  [eval] val_mse=3.445e-01  (n=7000)
Epoch 00162: Time=  13.9s, Loss=3.03e+00, Inv=3.03e+00, For=7.28e+01, Power=6.81e-01
  [eval] val_mse=3.456e-01  (n=7000)
Epoch 00163: Time=  14.0s, Loss=3.02e+00, Inv=3.02e+00, For=7.21e+01, Power=6.79e-01
  [eval] val_mse=3.435e-01  (n=7000)
Epoch 00164: Time=  14.0s, Loss=3.02e+00, Inv=3.02e+00, For=7.25e+01, Power=6.83e-01
  [eval] val_mse=3.433e-01  (n=7000)
Epoch 00165: Time=  14.1s, Loss=3.02e+00, Inv=3.02e+00, For=7.36e+01, Power=6.83e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00166: Time=  14.1s, Loss=3.01e+00, Inv=3.01e+00, For=7.34e+01, Power=6.80e-01
  [eval] val_mse=3.437e-01  (n=7000)
Epoch 00167: Time=  14.2s, Loss=3.01e+00, Inv=3.01e+00, For=7.52e+01, Power=6.83e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00168: Time=  14.2s, Loss=3.01e+00, Inv=3.01e+00, For=7.48e+01, Power=6.82e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00169: Time=  14.3s, Loss=3.01e+00, Inv=3.01e+00, For=7.57e+01, Power=6.78e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00170: Time=  14.3s, Loss=3.01e+00, Inv=3.01e+00, For=7.61e+01, Power=6.81e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00171: Time=  14.4s, Loss=3.01e+00, Inv=3.01e+00, For=7.70e+01, Power=6.82e-01
  [eval] val_mse=3.414e-01  (n=7000)
Epoch 00172: Time=  14.4s, Loss=3.01e+00, Inv=3.01e+00, For=7.76e+01, Power=6.80e-01
  [eval] val_mse=3.407e-01  (n=7000)
Epoch 00173: Time=  14.5s, Loss=3.01e+00, Inv=3.01e+00, For=7.80e+01, Power=6.76e-01
  [eval] val_mse=3.412e-01  (n=7000)
Epoch 00174: Time=  14.5s, Loss=3.01e+00, Inv=3.01e+00, For=7.80e+01, Power=6.82e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00175: Time=  14.6s, Loss=3.01e+00, Inv=3.01e+00, For=7.89e+01, Power=6.83e-01
  [eval] val_mse=3.401e-01  (n=7000)
Epoch 00176: Time=  14.6s, Loss=3.01e+00, Inv=3.01e+00, For=8.03e+01, Power=6.83e-01
  [eval] val_mse=3.392e-01  (n=7000)
Epoch 00177: Time=  14.7s, Loss=3.01e+00, Inv=3.01e+00, For=8.00e+01, Power=6.80e-01
  [eval] val_mse=3.395e-01  (n=7000)
Epoch 00178: Time=  14.7s, Loss=3.00e+00, Inv=3.00e+00, For=8.10e+01, Power=6.79e-01
  [eval] val_mse=3.404e-01  (n=7000)
Epoch 00179: Time=  14.8s, Loss=3.00e+00, Inv=3.00e+00, For=8.19e+01, Power=6.80e-01
  [eval] val_mse=3.392e-01  (n=7000)
Epoch 00180: Time=  14.8s, Loss=3.00e+00, Inv=3.00e+00, For=8.24e+01, Power=6.82e-01
  [eval] val_mse=3.391e-01  (n=7000)
Epoch 00181: Time=  14.9s, Loss=3.01e+00, Inv=3.01e+00, For=8.32e+01, Power=6.80e-01
  [eval] val_mse=3.386e-01  (n=7000)
Epoch 00182: Time=  14.9s, Loss=3.00e+00, Inv=3.00e+00, For=8.31e+01, Power=6.83e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00183: Time=  14.9s, Loss=2.99e+00, Inv=2.99e+00, For=8.40e+01, Power=6.78e-01
  [eval] val_mse=3.384e-01  (n=7000)
Epoch 00184: Time=  15.0s, Loss=2.99e+00, Inv=2.99e+00, For=8.44e+01, Power=6.80e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00185: Time=  15.0s, Loss=2.99e+00, Inv=2.99e+00, For=8.41e+01, Power=6.80e-01
  [eval] val_mse=3.388e-01  (n=7000)
Epoch 00186: Time=  15.1s, Loss=3.00e+00, Inv=3.00e+00, For=8.77e+01, Power=6.81e-01
  [eval] val_mse=3.390e-01  (n=7000)
Epoch 00187: Time=  15.1s, Loss=3.00e+00, Inv=3.00e+00, For=8.69e+01, Power=6.80e-01
  [eval] val_mse=3.371e-01  (n=7000)
Epoch 00188: Time=  15.2s, Loss=2.99e+00, Inv=2.99e+00, For=8.65e+01, Power=6.79e-01
  [eval] val_mse=3.389e-01  (n=7000)
Epoch 00189: Time=  15.2s, Loss=2.99e+00, Inv=2.99e+00, For=8.84e+01, Power=6.78e-01
  [eval] val_mse=3.365e-01  (n=7000)
Epoch 00190: Time=  15.3s, Loss=2.98e+00, Inv=2.98e+00, For=8.87e+01, Power=6.80e-01
  [eval] val_mse=3.356e-01  (n=7000)
Epoch 00191: Time=  15.3s, Loss=2.99e+00, Inv=2.99e+00, For=8.86e+01, Power=6.81e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00192: Time=  15.4s, Loss=2.98e+00, Inv=2.98e+00, For=9.01e+01, Power=6.79e-01
  [eval] val_mse=3.380e-01  (n=7000)
Epoch 00193: Time=  15.4s, Loss=2.98e+00, Inv=2.98e+00, For=9.00e+01, Power=6.80e-01
  [eval] val_mse=3.368e-01  (n=7000)
Epoch 00194: Time=  15.5s, Loss=2.99e+00, Inv=2.99e+00, For=9.18e+01, Power=6.81e-01
  [eval] val_mse=3.366e-01  (n=7000)
Epoch 00195: Time=  15.5s, Loss=2.98e+00, Inv=2.98e+00, For=9.22e+01, Power=6.79e-01
  [eval] val_mse=3.352e-01  (n=7000)
Epoch 00196: Time=  15.6s, Loss=2.98e+00, Inv=2.98e+00, For=9.21e+01, Power=6.79e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00197: Time=  15.6s, Loss=2.98e+00, Inv=2.98e+00, For=9.39e+01, Power=6.78e-01
  [eval] val_mse=3.348e-01  (n=7000)
Epoch 00198: Time=  15.7s, Loss=2.98e+00, Inv=2.98e+00, For=9.32e+01, Power=6.82e-01
  [eval] val_mse=3.337e-01  (n=7000)
Epoch 00199: Time=  15.7s, Loss=2.98e+00, Inv=2.98e+00, For=9.43e+01, Power=6.77e-01
  [eval] val_mse=3.348e-01  (n=7000)
Epoch 00200: Time=  15.8s, Loss=2.98e+00, Inv=2.98e+00, For=9.54e+01, Power=6.81e-01
  [eval] val_mse=3.340e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 2.358e-01
Torque MSE  = 6.435e-02
Torque RMSE = 2.537e-01
Per-joint MSE : 7.539e-02 1.478e-01 4.848e-02 1.966e-02 7.975e-02 1.504e-02
Per-joint RMSE: 2.746e-01 3.844e-01 2.202e-01 1.402e-01 2.824e-01 1.226e-01
Comp Time per Sample = 3.142e-04s / 3182.8Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-h037n4r5 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7f24e639e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:51:34.207283: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:51:36.103402: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=5.38e+03, Inv=5.38e+03, For=5.79e+00, Power=5.52e+02
  [eval] val_mse=8.109e+01  (n=7000)
Epoch 00002: Time=   5.8s, Loss=2.77e+02, Inv=2.77e+02, For=5.44e+00, Power=5.14e+01
  [eval] val_mse=2.377e+01  (n=7000)
Epoch 00003: Time=   5.8s, Loss=1.05e+02, Inv=1.05e+02, For=5.25e+00, Power=2.23e+01
  [eval] val_mse=1.280e+01  (n=7000)
Epoch 00004: Time=   5.9s, Loss=6.24e+01, Inv=6.24e+01, For=5.18e+00, Power=1.30e+01
  [eval] val_mse=8.181e+00  (n=7000)
Epoch 00005: Time=   5.9s, Loss=4.22e+01, Inv=4.22e+01, For=5.17e+00, Power=8.56e+00
  [eval] val_mse=5.774e+00  (n=7000)
Epoch 00006: Time=   6.0s, Loss=3.05e+01, Inv=3.05e+01, For=5.12e+00, Power=5.99e+00
  [eval] val_mse=4.263e+00  (n=7000)
Epoch 00007: Time=   6.0s, Loss=2.34e+01, Inv=2.34e+01, For=5.14e+00, Power=4.48e+00
  [eval] val_mse=3.274e+00  (n=7000)
Epoch 00008: Time=   6.1s, Loss=1.87e+01, Inv=1.87e+01, For=5.17e+00, Power=3.49e+00
  [eval] val_mse=2.585e+00  (n=7000)
Epoch 00009: Time=   6.1s, Loss=1.54e+01, Inv=1.54e+01, For=5.21e+00, Power=2.82e+00
  [eval] val_mse=2.119e+00  (n=7000)
Epoch 00010: Time=   6.2s, Loss=1.31e+01, Inv=1.31e+01, For=5.29e+00, Power=2.35e+00
  [eval] val_mse=1.791e+00  (n=7000)
Epoch 00011: Time=   6.2s, Loss=1.13e+01, Inv=1.13e+01, For=5.37e+00, Power=2.01e+00
  [eval] val_mse=1.547e+00  (n=7000)
Epoch 00012: Time=   6.3s, Loss=9.99e+00, Inv=9.99e+00, For=5.52e+00, Power=1.76e+00
  [eval] val_mse=1.363e+00  (n=7000)
Epoch 00013: Time=   6.3s, Loss=8.95e+00, Inv=8.95e+00, For=5.68e+00, Power=1.55e+00
  [eval] val_mse=1.222e+00  (n=7000)
Epoch 00014: Time=   6.4s, Loss=8.17e+00, Inv=8.17e+00, For=5.89e+00, Power=1.40e+00
  [eval] val_mse=1.108e+00  (n=7000)
Epoch 00015: Time=   6.4s, Loss=7.54e+00, Inv=7.54e+00, For=6.14e+00, Power=1.29e+00
  [eval] val_mse=1.009e+00  (n=7000)
Epoch 00016: Time=   6.5s, Loss=7.01e+00, Inv=7.01e+00, For=6.38e+00, Power=1.20e+00
  [eval] val_mse=9.307e-01  (n=7000)
Epoch 00017: Time=   6.5s, Loss=6.56e+00, Inv=6.56e+00, For=6.63e+00, Power=1.12e+00
  [eval] val_mse=8.628e-01  (n=7000)
Epoch 00018: Time=   6.6s, Loss=6.20e+00, Inv=6.20e+00, For=6.93e+00, Power=1.06e+00
  [eval] val_mse=8.088e-01  (n=7000)
Epoch 00019: Time=   6.6s, Loss=5.89e+00, Inv=5.89e+00, For=7.22e+00, Power=1.01e+00
  [eval] val_mse=7.566e-01  (n=7000)
Epoch 00020: Time=   6.7s, Loss=5.60e+00, Inv=5.60e+00, For=7.50e+00, Power=9.62e-01
  [eval] val_mse=7.173e-01  (n=7000)
Epoch 00021: Time=   6.7s, Loss=5.36e+00, Inv=5.36e+00, For=7.81e+00, Power=9.24e-01
  [eval] val_mse=6.840e-01  (n=7000)
Epoch 00022: Time=   6.8s, Loss=5.14e+00, Inv=5.14e+00, For=8.10e+00, Power=8.93e-01
  [eval] val_mse=6.554e-01  (n=7000)
Epoch 00023: Time=   6.8s, Loss=4.96e+00, Inv=4.96e+00, For=8.45e+00, Power=8.72e-01
  [eval] val_mse=6.312e-01  (n=7000)
Epoch 00024: Time=   6.9s, Loss=4.81e+00, Inv=4.81e+00, For=8.82e+00, Power=8.53e-01
  [eval] val_mse=6.105e-01  (n=7000)
Epoch 00025: Time=   6.9s, Loss=4.65e+00, Inv=4.65e+00, For=9.14e+00, Power=8.31e-01
  [eval] val_mse=5.937e-01  (n=7000)
Epoch 00026: Time=   7.0s, Loss=4.52e+00, Inv=4.52e+00, For=9.46e+00, Power=8.10e-01
  [eval] val_mse=5.792e-01  (n=7000)
Epoch 00027: Time=   7.0s, Loss=4.41e+00, Inv=4.41e+00, For=9.80e+00, Power=8.00e-01
  [eval] val_mse=5.670e-01  (n=7000)
Epoch 00028: Time=   7.1s, Loss=4.32e+00, Inv=4.32e+00, For=1.02e+01, Power=7.89e-01
  [eval] val_mse=5.530e-01  (n=7000)
Epoch 00029: Time=   7.1s, Loss=4.24e+00, Inv=4.24e+00, For=1.06e+01, Power=7.80e-01
  [eval] val_mse=5.436e-01  (n=7000)
Epoch 00030: Time=   7.2s, Loss=4.16e+00, Inv=4.16e+00, For=1.10e+01, Power=7.70e-01
  [eval] val_mse=5.331e-01  (n=7000)
Epoch 00031: Time=   7.2s, Loss=4.09e+00, Inv=4.09e+00, For=1.14e+01, Power=7.61e-01
  [eval] val_mse=5.257e-01  (n=7000)
Epoch 00032: Time=   7.3s, Loss=4.04e+00, Inv=4.04e+00, For=1.18e+01, Power=7.60e-01
  [eval] val_mse=5.166e-01  (n=7000)
Epoch 00033: Time=   7.3s, Loss=3.97e+00, Inv=3.97e+00, For=1.21e+01, Power=7.50e-01
  [eval] val_mse=5.096e-01  (n=7000)
Epoch 00034: Time=   7.4s, Loss=3.92e+00, Inv=3.92e+00, For=1.25e+01, Power=7.40e-01
  [eval] val_mse=5.007e-01  (n=7000)
Epoch 00035: Time=   7.4s, Loss=3.88e+00, Inv=3.88e+00, For=1.29e+01, Power=7.42e-01
  [eval] val_mse=4.953e-01  (n=7000)
Epoch 00036: Time=   7.5s, Loss=3.83e+00, Inv=3.83e+00, For=1.33e+01, Power=7.34e-01
  [eval] val_mse=4.867e-01  (n=7000)
Epoch 00037: Time=   7.5s, Loss=3.80e+00, Inv=3.80e+00, For=1.38e+01, Power=7.33e-01
  [eval] val_mse=4.815e-01  (n=7000)
Epoch 00038: Time=   7.6s, Loss=3.75e+00, Inv=3.75e+00, For=1.40e+01, Power=7.29e-01
  [eval] val_mse=4.750e-01  (n=7000)
Epoch 00039: Time=   7.6s, Loss=3.72e+00, Inv=3.72e+00, For=1.45e+01, Power=7.25e-01
  [eval] val_mse=4.699e-01  (n=7000)
Epoch 00040: Time=   7.7s, Loss=3.69e+00, Inv=3.69e+00, For=1.49e+01, Power=7.23e-01
  [eval] val_mse=4.645e-01  (n=7000)
Epoch 00041: Time=   7.7s, Loss=3.66e+00, Inv=3.66e+00, For=1.53e+01, Power=7.22e-01
  [eval] val_mse=4.610e-01  (n=7000)
Epoch 00042: Time=   7.8s, Loss=3.64e+00, Inv=3.64e+00, For=1.57e+01, Power=7.18e-01
  [eval] val_mse=4.558e-01  (n=7000)
Epoch 00043: Time=   7.8s, Loss=3.61e+00, Inv=3.61e+00, For=1.61e+01, Power=7.18e-01
  [eval] val_mse=4.503e-01  (n=7000)
Epoch 00044: Time=   7.9s, Loss=3.59e+00, Inv=3.59e+00, For=1.66e+01, Power=7.11e-01
  [eval] val_mse=4.459e-01  (n=7000)
Epoch 00045: Time=   7.9s, Loss=3.57e+00, Inv=3.57e+00, For=1.69e+01, Power=7.13e-01
  [eval] val_mse=4.418e-01  (n=7000)
Epoch 00046: Time=   8.0s, Loss=3.54e+00, Inv=3.54e+00, For=1.74e+01, Power=7.09e-01
  [eval] val_mse=4.396e-01  (n=7000)
Epoch 00047: Time=   8.0s, Loss=3.52e+00, Inv=3.52e+00, For=1.78e+01, Power=7.08e-01
  [eval] val_mse=4.350e-01  (n=7000)
Epoch 00048: Time=   8.1s, Loss=3.50e+00, Inv=3.50e+00, For=1.81e+01, Power=7.08e-01
  [eval] val_mse=4.304e-01  (n=7000)
Epoch 00049: Time=   8.1s, Loss=3.49e+00, Inv=3.49e+00, For=1.86e+01, Power=7.07e-01
  [eval] val_mse=4.276e-01  (n=7000)
Epoch 00050: Time=   8.2s, Loss=3.47e+00, Inv=3.47e+00, For=1.90e+01, Power=7.06e-01
  [eval] val_mse=4.252e-01  (n=7000)
Epoch 00051: Time=   8.2s, Loss=3.46e+00, Inv=3.46e+00, For=1.95e+01, Power=7.02e-01
  [eval] val_mse=4.214e-01  (n=7000)
Epoch 00052: Time=   8.3s, Loss=3.44e+00, Inv=3.44e+00, For=1.99e+01, Power=7.04e-01
  [eval] val_mse=4.192e-01  (n=7000)
Epoch 00053: Time=   8.3s, Loss=3.43e+00, Inv=3.43e+00, For=2.03e+01, Power=7.03e-01
  [eval] val_mse=4.160e-01  (n=7000)
Epoch 00054: Time=   8.4s, Loss=3.41e+00, Inv=3.41e+00, For=2.08e+01, Power=7.01e-01
  [eval] val_mse=4.150e-01  (n=7000)
Epoch 00055: Time=   8.4s, Loss=3.40e+00, Inv=3.40e+00, For=2.13e+01, Power=7.02e-01
  [eval] val_mse=4.118e-01  (n=7000)
Epoch 00056: Time=   8.5s, Loss=3.39e+00, Inv=3.39e+00, For=2.16e+01, Power=6.97e-01
  [eval] val_mse=4.091e-01  (n=7000)
Epoch 00057: Time=   8.5s, Loss=3.38e+00, Inv=3.38e+00, For=2.20e+01, Power=7.00e-01
  [eval] val_mse=4.059e-01  (n=7000)
Epoch 00058: Time=   8.6s, Loss=3.36e+00, Inv=3.36e+00, For=2.25e+01, Power=6.96e-01
  [eval] val_mse=4.039e-01  (n=7000)
Epoch 00059: Time=   8.6s, Loss=3.35e+00, Inv=3.35e+00, For=2.28e+01, Power=6.95e-01
  [eval] val_mse=4.018e-01  (n=7000)
Epoch 00060: Time=   8.7s, Loss=3.35e+00, Inv=3.35e+00, For=2.34e+01, Power=6.98e-01
  [eval] val_mse=4.003e-01  (n=7000)
Epoch 00061: Time=   8.7s, Loss=3.33e+00, Inv=3.33e+00, For=2.40e+01, Power=6.91e-01
  [eval] val_mse=3.988e-01  (n=7000)
Epoch 00062: Time=   8.7s, Loss=3.33e+00, Inv=3.33e+00, For=2.42e+01, Power=6.94e-01
  [eval] val_mse=3.956e-01  (n=7000)
Epoch 00063: Time=   8.8s, Loss=3.32e+00, Inv=3.32e+00, For=2.47e+01, Power=6.95e-01
  [eval] val_mse=3.937e-01  (n=7000)
Epoch 00064: Time=   8.8s, Loss=3.31e+00, Inv=3.31e+00, For=2.52e+01, Power=6.92e-01
  [eval] val_mse=3.929e-01  (n=7000)
Epoch 00065: Time=   8.9s, Loss=3.30e+00, Inv=3.30e+00, For=2.56e+01, Power=6.95e-01
  [eval] val_mse=3.915e-01  (n=7000)
Epoch 00066: Time=   8.9s, Loss=3.29e+00, Inv=3.29e+00, For=2.62e+01, Power=6.96e-01
  [eval] val_mse=3.892e-01  (n=7000)
Epoch 00067: Time=   9.0s, Loss=3.28e+00, Inv=3.28e+00, For=2.66e+01, Power=6.91e-01
  [eval] val_mse=3.872e-01  (n=7000)
Epoch 00068: Time=   9.0s, Loss=3.28e+00, Inv=3.28e+00, For=2.71e+01, Power=6.93e-01
  [eval] val_mse=3.874e-01  (n=7000)
Epoch 00069: Time=   9.1s, Loss=3.26e+00, Inv=3.26e+00, For=2.77e+01, Power=6.92e-01
  [eval] val_mse=3.850e-01  (n=7000)
Epoch 00070: Time=   9.1s, Loss=3.26e+00, Inv=3.26e+00, For=2.80e+01, Power=6.90e-01
  [eval] val_mse=3.828e-01  (n=7000)
Epoch 00071: Time=   9.2s, Loss=3.26e+00, Inv=3.26e+00, For=2.84e+01, Power=6.92e-01
  [eval] val_mse=3.825e-01  (n=7000)
Epoch 00072: Time=   9.2s, Loss=3.25e+00, Inv=3.25e+00, For=2.91e+01, Power=6.89e-01
  [eval] val_mse=3.795e-01  (n=7000)
Epoch 00073: Time=   9.3s, Loss=3.24e+00, Inv=3.24e+00, For=2.94e+01, Power=6.92e-01
  [eval] val_mse=3.783e-01  (n=7000)
Epoch 00074: Time=   9.3s, Loss=3.24e+00, Inv=3.24e+00, For=3.00e+01, Power=6.89e-01
  [eval] val_mse=3.768e-01  (n=7000)
Epoch 00075: Time=   9.4s, Loss=3.23e+00, Inv=3.23e+00, For=3.05e+01, Power=6.89e-01
  [eval] val_mse=3.756e-01  (n=7000)
Epoch 00076: Time=   9.4s, Loss=3.22e+00, Inv=3.22e+00, For=3.13e+01, Power=6.90e-01
  [eval] val_mse=3.747e-01  (n=7000)
Epoch 00077: Time=   9.5s, Loss=3.22e+00, Inv=3.22e+00, For=3.17e+01, Power=6.87e-01
  [eval] val_mse=3.735e-01  (n=7000)
Epoch 00078: Time=   9.5s, Loss=3.21e+00, Inv=3.21e+00, For=3.21e+01, Power=6.90e-01
  [eval] val_mse=3.726e-01  (n=7000)
Epoch 00079: Time=   9.6s, Loss=3.21e+00, Inv=3.21e+00, For=3.29e+01, Power=6.90e-01
  [eval] val_mse=3.712e-01  (n=7000)
Epoch 00080: Time=   9.6s, Loss=3.21e+00, Inv=3.21e+00, For=3.30e+01, Power=6.91e-01
  [eval] val_mse=3.705e-01  (n=7000)
Epoch 00081: Time=   9.7s, Loss=3.20e+00, Inv=3.20e+00, For=3.39e+01, Power=6.89e-01
  [eval] val_mse=3.693e-01  (n=7000)
Epoch 00082: Time=   9.7s, Loss=3.19e+00, Inv=3.19e+00, For=3.44e+01, Power=6.86e-01
  [eval] val_mse=3.683e-01  (n=7000)
Epoch 00083: Time=   9.8s, Loss=3.18e+00, Inv=3.18e+00, For=3.45e+01, Power=6.84e-01
  [eval] val_mse=3.667e-01  (n=7000)
Epoch 00084: Time=   9.8s, Loss=3.18e+00, Inv=3.18e+00, For=3.56e+01, Power=6.86e-01
  [eval] val_mse=3.662e-01  (n=7000)
Epoch 00085: Time=   9.9s, Loss=3.18e+00, Inv=3.18e+00, For=3.60e+01, Power=6.87e-01
  [eval] val_mse=3.651e-01  (n=7000)
Epoch 00086: Time=   9.9s, Loss=3.18e+00, Inv=3.18e+00, For=3.65e+01, Power=6.86e-01
  [eval] val_mse=3.638e-01  (n=7000)
Epoch 00087: Time=  10.0s, Loss=3.17e+00, Inv=3.17e+00, For=3.69e+01, Power=6.88e-01
  [eval] val_mse=3.644e-01  (n=7000)
Epoch 00088: Time=  10.0s, Loss=3.17e+00, Inv=3.17e+00, For=3.75e+01, Power=6.85e-01
  [eval] val_mse=3.617e-01  (n=7000)
Epoch 00089: Time=  10.1s, Loss=3.16e+00, Inv=3.16e+00, For=3.83e+01, Power=6.86e-01
  [eval] val_mse=3.611e-01  (n=7000)
Epoch 00090: Time=  10.1s, Loss=3.15e+00, Inv=3.15e+00, For=3.90e+01, Power=6.86e-01
  [eval] val_mse=3.610e-01  (n=7000)
Epoch 00091: Time=  10.2s, Loss=3.16e+00, Inv=3.16e+00, For=3.97e+01, Power=6.88e-01
  [eval] val_mse=3.599e-01  (n=7000)
Epoch 00092: Time=  10.2s, Loss=3.15e+00, Inv=3.15e+00, For=3.99e+01, Power=6.84e-01
  [eval] val_mse=3.592e-01  (n=7000)
Epoch 00093: Time=  10.3s, Loss=3.15e+00, Inv=3.15e+00, For=4.05e+01, Power=6.86e-01
  [eval] val_mse=3.589e-01  (n=7000)
Epoch 00094: Time=  10.3s, Loss=3.15e+00, Inv=3.15e+00, For=4.14e+01, Power=6.87e-01
  [eval] val_mse=3.573e-01  (n=7000)
Epoch 00095: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=4.22e+01, Power=6.85e-01
  [eval] val_mse=3.572e-01  (n=7000)
Epoch 00096: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=4.26e+01, Power=6.88e-01
  [eval] val_mse=3.565e-01  (n=7000)
Epoch 00097: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=4.33e+01, Power=6.86e-01
  [eval] val_mse=3.559e-01  (n=7000)
Epoch 00098: Time=  10.5s, Loss=3.13e+00, Inv=3.13e+00, For=4.42e+01, Power=6.85e-01
  [eval] val_mse=3.548e-01  (n=7000)
Epoch 00099: Time=  10.6s, Loss=3.13e+00, Inv=3.13e+00, For=4.42e+01, Power=6.84e-01
  [eval] val_mse=3.549e-01  (n=7000)
Epoch 00100: Time=  10.6s, Loss=3.12e+00, Inv=3.12e+00, For=4.50e+01, Power=6.83e-01
  [eval] val_mse=3.537e-01  (n=7000)
Epoch 00101: Time=  10.7s, Loss=3.12e+00, Inv=3.12e+00, For=4.59e+01, Power=6.85e-01
  [eval] val_mse=3.539e-01  (n=7000)
Epoch 00102: Time=  10.7s, Loss=3.11e+00, Inv=3.11e+00, For=4.64e+01, Power=6.81e-01
  [eval] val_mse=3.520e-01  (n=7000)
Epoch 00103: Time=  10.8s, Loss=3.12e+00, Inv=3.12e+00, For=4.72e+01, Power=6.87e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00104: Time=  10.8s, Loss=3.11e+00, Inv=3.11e+00, For=4.78e+01, Power=6.86e-01
  [eval] val_mse=3.514e-01  (n=7000)
Epoch 00105: Time=  10.9s, Loss=3.11e+00, Inv=3.11e+00, For=4.85e+01, Power=6.82e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00106: Time=  10.9s, Loss=3.11e+00, Inv=3.11e+00, For=4.90e+01, Power=6.80e-01
  [eval] val_mse=3.500e-01  (n=7000)
Epoch 00107: Time=  11.0s, Loss=3.11e+00, Inv=3.11e+00, For=5.00e+01, Power=6.84e-01
  [eval] val_mse=3.489e-01  (n=7000)
Epoch 00108: Time=  11.0s, Loss=3.11e+00, Inv=3.11e+00, For=5.07e+01, Power=6.84e-01
  [eval] val_mse=3.480e-01  (n=7000)
Epoch 00109: Time=  11.1s, Loss=3.10e+00, Inv=3.10e+00, For=5.11e+01, Power=6.83e-01
  [eval] val_mse=3.478e-01  (n=7000)
Epoch 00110: Time=  11.1s, Loss=3.10e+00, Inv=3.10e+00, For=5.14e+01, Power=6.83e-01
  [eval] val_mse=3.481e-01  (n=7000)
Epoch 00111: Time=  11.1s, Loss=3.10e+00, Inv=3.10e+00, For=5.32e+01, Power=6.86e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00112: Time=  11.2s, Loss=3.10e+00, Inv=3.10e+00, For=5.34e+01, Power=6.85e-01
  [eval] val_mse=3.466e-01  (n=7000)
Epoch 00113: Time=  11.2s, Loss=3.09e+00, Inv=3.09e+00, For=5.48e+01, Power=6.84e-01
  [eval] val_mse=3.459e-01  (n=7000)
Epoch 00114: Time=  11.3s, Loss=3.08e+00, Inv=3.08e+00, For=5.44e+01, Power=6.83e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00115: Time=  11.3s, Loss=3.08e+00, Inv=3.08e+00, For=5.58e+01, Power=6.83e-01
  [eval] val_mse=3.453e-01  (n=7000)
Epoch 00116: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=5.56e+01, Power=6.84e-01
  [eval] val_mse=3.449e-01  (n=7000)
Epoch 00117: Time=  11.4s, Loss=3.07e+00, Inv=3.07e+00, For=5.75e+01, Power=6.81e-01
  [eval] val_mse=3.448e-01  (n=7000)
Epoch 00118: Time=  11.5s, Loss=3.07e+00, Inv=3.07e+00, For=5.76e+01, Power=6.80e-01
  [eval] val_mse=3.440e-01  (n=7000)
Epoch 00119: Time=  11.5s, Loss=3.08e+00, Inv=3.08e+00, For=5.81e+01, Power=6.81e-01
  [eval] val_mse=3.443e-01  (n=7000)
Epoch 00120: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=5.93e+01, Power=6.80e-01
  [eval] val_mse=3.447e-01  (n=7000)
Epoch 00121: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=6.05e+01, Power=6.81e-01
  [eval] val_mse=3.453e-01  (n=7000)
Epoch 00122: Time=  11.7s, Loss=3.07e+00, Inv=3.07e+00, For=6.11e+01, Power=6.84e-01
  [eval] val_mse=3.420e-01  (n=7000)
Epoch 00123: Time=  11.7s, Loss=3.06e+00, Inv=3.06e+00, For=6.15e+01, Power=6.84e-01
  [eval] val_mse=3.416e-01  (n=7000)
Epoch 00124: Time=  11.8s, Loss=3.06e+00, Inv=3.06e+00, For=6.24e+01, Power=6.82e-01
  [eval] val_mse=3.428e-01  (n=7000)
Epoch 00125: Time=  11.8s, Loss=3.07e+00, Inv=3.07e+00, For=6.38e+01, Power=6.84e-01
  [eval] val_mse=3.409e-01  (n=7000)
Epoch 00126: Time=  11.9s, Loss=3.06e+00, Inv=3.06e+00, For=6.42e+01, Power=6.83e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00127: Time=  11.9s, Loss=3.05e+00, Inv=3.05e+00, For=6.45e+01, Power=6.81e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00128: Time=  12.0s, Loss=3.05e+00, Inv=3.05e+00, For=6.60e+01, Power=6.81e-01
  [eval] val_mse=3.403e-01  (n=7000)
Epoch 00129: Time=  12.0s, Loss=3.05e+00, Inv=3.05e+00, For=6.60e+01, Power=6.82e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00130: Time=  12.1s, Loss=3.05e+00, Inv=3.05e+00, For=6.74e+01, Power=6.80e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00131: Time=  12.1s, Loss=3.05e+00, Inv=3.05e+00, For=6.87e+01, Power=6.83e-01
  [eval] val_mse=3.386e-01  (n=7000)
Epoch 00132: Time=  12.2s, Loss=3.04e+00, Inv=3.04e+00, For=6.90e+01, Power=6.82e-01
  [eval] val_mse=3.383e-01  (n=7000)
Epoch 00133: Time=  12.2s, Loss=3.05e+00, Inv=3.05e+00, For=6.90e+01, Power=6.81e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00134: Time=  12.3s, Loss=3.05e+00, Inv=3.05e+00, For=7.11e+01, Power=6.80e-01
  [eval] val_mse=3.368e-01  (n=7000)
Epoch 00135: Time=  12.3s, Loss=3.04e+00, Inv=3.04e+00, For=7.17e+01, Power=6.81e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00136: Time=  12.4s, Loss=3.04e+00, Inv=3.04e+00, For=7.21e+01, Power=6.83e-01
  [eval] val_mse=3.376e-01  (n=7000)
Epoch 00137: Time=  12.4s, Loss=3.03e+00, Inv=3.03e+00, For=7.30e+01, Power=6.81e-01
  [eval] val_mse=3.369e-01  (n=7000)
Epoch 00138: Time=  12.5s, Loss=3.03e+00, Inv=3.03e+00, For=7.40e+01, Power=6.79e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00139: Time=  12.5s, Loss=3.03e+00, Inv=3.03e+00, For=7.45e+01, Power=6.78e-01
  [eval] val_mse=3.354e-01  (n=7000)
Epoch 00140: Time=  12.6s, Loss=3.03e+00, Inv=3.03e+00, For=7.60e+01, Power=6.80e-01
  [eval] val_mse=3.366e-01  (n=7000)
Epoch 00141: Time=  12.6s, Loss=3.03e+00, Inv=3.03e+00, For=7.64e+01, Power=6.81e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00142: Time=  12.7s, Loss=3.03e+00, Inv=3.03e+00, For=7.72e+01, Power=6.82e-01
  [eval] val_mse=3.344e-01  (n=7000)
Epoch 00143: Time=  12.7s, Loss=3.03e+00, Inv=3.03e+00, For=7.84e+01, Power=6.82e-01
  [eval] val_mse=3.358e-01  (n=7000)
Epoch 00144: Time=  12.8s, Loss=3.03e+00, Inv=3.03e+00, For=7.90e+01, Power=6.83e-01
  [eval] val_mse=3.342e-01  (n=7000)
Epoch 00145: Time=  12.8s, Loss=3.03e+00, Inv=3.03e+00, For=8.00e+01, Power=6.85e-01
  [eval] val_mse=3.341e-01  (n=7000)
Epoch 00146: Time=  12.9s, Loss=3.02e+00, Inv=3.02e+00, For=8.08e+01, Power=6.78e-01
  [eval] val_mse=3.348e-01  (n=7000)
Epoch 00147: Time=  12.9s, Loss=3.02e+00, Inv=3.02e+00, For=8.21e+01, Power=6.82e-01
  [eval] val_mse=3.347e-01  (n=7000)
Epoch 00148: Time=  13.0s, Loss=3.02e+00, Inv=3.02e+00, For=8.28e+01, Power=6.81e-01
  [eval] val_mse=3.338e-01  (n=7000)
Epoch 00149: Time=  13.0s, Loss=3.03e+00, Inv=3.03e+00, For=8.37e+01, Power=6.80e-01
  [eval] val_mse=3.334e-01  (n=7000)
Epoch 00150: Time=  13.1s, Loss=3.03e+00, Inv=3.03e+00, For=8.48e+01, Power=6.81e-01
  [eval] val_mse=3.331e-01  (n=7000)
Epoch 00151: Time=  13.1s, Loss=3.02e+00, Inv=3.02e+00, For=8.51e+01, Power=6.82e-01
  [eval] val_mse=3.325e-01  (n=7000)
Epoch 00152: Time=  13.2s, Loss=3.02e+00, Inv=3.02e+00, For=8.77e+01, Power=6.80e-01
  [eval] val_mse=3.325e-01  (n=7000)
Epoch 00153: Time=  13.2s, Loss=3.01e+00, Inv=3.01e+00, For=8.56e+01, Power=6.79e-01
  [eval] val_mse=3.318e-01  (n=7000)
Epoch 00154: Time=  13.3s, Loss=3.02e+00, Inv=3.02e+00, For=8.90e+01, Power=6.83e-01
  [eval] val_mse=3.321e-01  (n=7000)
Epoch 00155: Time=  13.3s, Loss=3.01e+00, Inv=3.01e+00, For=8.98e+01, Power=6.81e-01
  [eval] val_mse=3.311e-01  (n=7000)
Epoch 00156: Time=  13.4s, Loss=3.01e+00, Inv=3.01e+00, For=9.04e+01, Power=6.82e-01
  [eval] val_mse=3.326e-01  (n=7000)
Epoch 00157: Time=  13.4s, Loss=3.00e+00, Inv=3.00e+00, For=9.11e+01, Power=6.80e-01
  [eval] val_mse=3.327e-01  (n=7000)
Epoch 00158: Time=  13.4s, Loss=3.00e+00, Inv=3.00e+00, For=9.15e+01, Power=6.79e-01
  [eval] val_mse=3.307e-01  (n=7000)
Epoch 00159: Time=  13.5s, Loss=3.01e+00, Inv=3.01e+00, For=9.27e+01, Power=6.81e-01
  [eval] val_mse=3.310e-01  (n=7000)
Epoch 00160: Time=  13.5s, Loss=3.01e+00, Inv=3.01e+00, For=9.44e+01, Power=6.80e-01
  [eval] val_mse=3.301e-01  (n=7000)
Epoch 00161: Time=  13.6s, Loss=3.00e+00, Inv=3.00e+00, For=9.38e+01, Power=6.81e-01
  [eval] val_mse=3.298e-01  (n=7000)
Epoch 00162: Time=  13.6s, Loss=3.00e+00, Inv=3.00e+00, For=9.57e+01, Power=6.81e-01
  [eval] val_mse=3.299e-01  (n=7000)
Epoch 00163: Time=  13.7s, Loss=3.00e+00, Inv=3.00e+00, For=9.74e+01, Power=6.81e-01
  [eval] val_mse=3.297e-01  (n=7000)
Epoch 00164: Time=  13.7s, Loss=3.00e+00, Inv=3.00e+00, For=9.97e+01, Power=6.81e-01
  [eval] val_mse=3.292e-01  (n=7000)
Epoch 00165: Time=  13.8s, Loss=3.00e+00, Inv=3.00e+00, For=9.73e+01, Power=6.82e-01
  [eval] val_mse=3.286e-01  (n=7000)
Epoch 00166: Time=  13.8s, Loss=3.00e+00, Inv=3.00e+00, For=1.00e+02, Power=6.80e-01
  [eval] val_mse=3.297e-01  (n=7000)
Epoch 00167: Time=  13.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.01e+02, Power=6.82e-01
  [eval] val_mse=3.295e-01  (n=7000)
Epoch 00168: Time=  13.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.02e+02, Power=6.82e-01
  [eval] val_mse=3.292e-01  (n=7000)
Epoch 00169: Time=  14.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.03e+02, Power=6.81e-01
  [eval] val_mse=3.284e-01  (n=7000)
Epoch 00170: Time=  14.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.04e+02, Power=6.82e-01
  [eval] val_mse=3.295e-01  (n=7000)
Epoch 00171: Time=  14.1s, Loss=3.00e+00, Inv=3.00e+00, For=1.04e+02, Power=6.83e-01
  [eval] val_mse=3.285e-01  (n=7000)
Epoch 00172: Time=  14.1s, Loss=2.98e+00, Inv=2.98e+00, For=1.07e+02, Power=6.81e-01
  [eval] val_mse=3.277e-01  (n=7000)
Epoch 00173: Time=  14.2s, Loss=2.99e+00, Inv=2.99e+00, For=1.07e+02, Power=6.81e-01
  [eval] val_mse=3.277e-01  (n=7000)
Epoch 00174: Time=  14.2s, Loss=2.99e+00, Inv=2.99e+00, For=1.08e+02, Power=6.82e-01
  [eval] val_mse=3.294e-01  (n=7000)
Epoch 00175: Time=  14.3s, Loss=2.99e+00, Inv=2.99e+00, For=1.10e+02, Power=6.80e-01
  [eval] val_mse=3.268e-01  (n=7000)
Epoch 00176: Time=  14.3s, Loss=2.99e+00, Inv=2.99e+00, For=1.10e+02, Power=6.81e-01
  [eval] val_mse=3.287e-01  (n=7000)
Epoch 00177: Time=  14.4s, Loss=2.99e+00, Inv=2.99e+00, For=1.12e+02, Power=6.79e-01
  [eval] val_mse=3.268e-01  (n=7000)
Epoch 00178: Time=  14.4s, Loss=2.99e+00, Inv=2.99e+00, For=1.11e+02, Power=6.81e-01
  [eval] val_mse=3.264e-01  (n=7000)
Epoch 00179: Time=  14.5s, Loss=2.98e+00, Inv=2.98e+00, For=1.12e+02, Power=6.78e-01
  [eval] val_mse=3.257e-01  (n=7000)
Epoch 00180: Time=  14.5s, Loss=2.98e+00, Inv=2.98e+00, For=1.15e+02, Power=6.78e-01
  [eval] val_mse=3.260e-01  (n=7000)
Epoch 00181: Time=  14.6s, Loss=2.98e+00, Inv=2.98e+00, For=1.16e+02, Power=6.79e-01
  [eval] val_mse=3.276e-01  (n=7000)
Epoch 00182: Time=  14.6s, Loss=2.98e+00, Inv=2.98e+00, For=1.18e+02, Power=6.77e-01
  [eval] val_mse=3.273e-01  (n=7000)
Epoch 00183: Time=  14.7s, Loss=2.98e+00, Inv=2.98e+00, For=1.16e+02, Power=6.75e-01
  [eval] val_mse=3.265e-01  (n=7000)
Epoch 00184: Time=  14.7s, Loss=2.98e+00, Inv=2.98e+00, For=1.19e+02, Power=6.78e-01
  [eval] val_mse=3.272e-01  (n=7000)
Epoch 00185: Time=  14.8s, Loss=2.99e+00, Inv=2.99e+00, For=1.21e+02, Power=6.80e-01
  [eval] val_mse=3.254e-01  (n=7000)
Epoch 00186: Time=  14.8s, Loss=2.98e+00, Inv=2.98e+00, For=1.23e+02, Power=6.83e-01
  [eval] val_mse=3.260e-01  (n=7000)
Epoch 00187: Time=  14.9s, Loss=2.98e+00, Inv=2.98e+00, For=1.22e+02, Power=6.78e-01
  [eval] val_mse=3.251e-01  (n=7000)
Epoch 00188: Time=  14.9s, Loss=2.98e+00, Inv=2.98e+00, For=1.26e+02, Power=6.80e-01
  [eval] val_mse=3.278e-01  (n=7000)
Epoch 00189: Time=  15.0s, Loss=2.98e+00, Inv=2.98e+00, For=1.22e+02, Power=6.78e-01
  [eval] val_mse=3.248e-01  (n=7000)
Epoch 00190: Time=  15.0s, Loss=2.98e+00, Inv=2.98e+00, For=1.25e+02, Power=6.82e-01
  [eval] val_mse=3.252e-01  (n=7000)
Epoch 00191: Time=  15.1s, Loss=2.97e+00, Inv=2.97e+00, For=1.28e+02, Power=6.81e-01
  [eval] val_mse=3.248e-01  (n=7000)
Epoch 00192: Time=  15.1s, Loss=2.97e+00, Inv=2.97e+00, For=1.28e+02, Power=6.80e-01
  [eval] val_mse=3.258e-01  (n=7000)
Epoch 00193: Time=  15.2s, Loss=2.98e+00, Inv=2.98e+00, For=1.27e+02, Power=6.79e-01
  [eval] val_mse=3.252e-01  (n=7000)
Epoch 00194: Time=  15.2s, Loss=2.97e+00, Inv=2.97e+00, For=1.32e+02, Power=6.81e-01
  [eval] val_mse=3.232e-01  (n=7000)
Epoch 00195: Time=  15.2s, Loss=2.97e+00, Inv=2.97e+00, For=1.31e+02, Power=6.82e-01
  [eval] val_mse=3.245e-01  (n=7000)
Epoch 00196: Time=  15.3s, Loss=2.97e+00, Inv=2.97e+00, For=1.34e+02, Power=6.80e-01
  [eval] val_mse=3.247e-01  (n=7000)
Epoch 00197: Time=  15.3s, Loss=2.98e+00, Inv=2.98e+00, For=1.37e+02, Power=6.83e-01
  [eval] val_mse=3.242e-01  (n=7000)
Epoch 00198: Time=  15.4s, Loss=2.97e+00, Inv=2.97e+00, For=1.35e+02, Power=6.82e-01
  [eval] val_mse=3.252e-01  (n=7000)
Epoch 00199: Time=  15.4s, Loss=2.96e+00, Inv=2.96e+00, For=1.37e+02, Power=6.79e-01
  [eval] val_mse=3.238e-01  (n=7000)
Epoch 00200: Time=  15.5s, Loss=2.96e+00, Inv=2.96e+00, For=1.38e+02, Power=6.78e-01
  [eval] val_mse=3.230e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 2.320e-01
Torque MSE  = 6.533e-02
Torque RMSE = 2.556e-01
Per-joint MSE : 7.296e-02 1.500e-01 4.747e-02 2.139e-02 8.305e-02 1.710e-02
Per-joint RMSE: 2.701e-01 3.873e-01 2.179e-01 1.463e-01 2.882e-01 1.308e-01
Comp Time per Sample = 3.188e-04s / 3136.6Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-l594twlm because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x740904a3a8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:51:59.909874: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:52:01.848564: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=1.52e+03, Inv=1.52e+03, For=5.57e+00, Power=2.88e+02
  [eval] val_mse=2.165e+01  (n=7000)
Epoch 00002: Time=   5.7s, Loss=6.99e+01, Inv=6.99e+01, For=5.46e+00, Power=1.33e+01
  [eval] val_mse=9.182e+00  (n=7000)
Epoch 00003: Time=   5.8s, Loss=3.06e+01, Inv=3.06e+01, For=5.63e+00, Power=5.60e+00
  [eval] val_mse=5.164e+00  (n=7000)
Epoch 00004: Time=   5.8s, Loss=2.00e+01, Inv=2.00e+01, For=5.93e+00, Power=3.44e+00
  [eval] val_mse=3.279e+00  (n=7000)
Epoch 00005: Time=   5.9s, Loss=1.46e+01, Inv=1.46e+01, For=6.27e+00, Power=2.45e+00
  [eval] val_mse=2.254e+00  (n=7000)
Epoch 00006: Time=   5.9s, Loss=1.14e+01, Inv=1.14e+01, For=6.64e+00, Power=1.88e+00
  [eval] val_mse=1.652e+00  (n=7000)
Epoch 00007: Time=   6.0s, Loss=9.33e+00, Inv=9.33e+00, For=7.09e+00, Power=1.53e+00
  [eval] val_mse=1.308e+00  (n=7000)
Epoch 00008: Time=   6.0s, Loss=7.98e+00, Inv=7.98e+00, For=7.57e+00, Power=1.32e+00
  [eval] val_mse=1.089e+00  (n=7000)
Epoch 00009: Time=   6.1s, Loss=7.07e+00, Inv=7.07e+00, For=8.20e+00, Power=1.16e+00
  [eval] val_mse=9.425e-01  (n=7000)
Epoch 00010: Time=   6.1s, Loss=6.40e+00, Inv=6.40e+00, For=8.90e+00, Power=1.05e+00
  [eval] val_mse=8.339e-01  (n=7000)
Epoch 00011: Time=   6.2s, Loss=5.90e+00, Inv=5.90e+00, For=9.63e+00, Power=9.75e-01
  [eval] val_mse=7.538e-01  (n=7000)
Epoch 00012: Time=   6.2s, Loss=5.53e+00, Inv=5.53e+00, For=1.05e+01, Power=9.19e-01
  [eval] val_mse=6.916e-01  (n=7000)
Epoch 00013: Time=   6.3s, Loss=5.22e+00, Inv=5.22e+00, For=1.13e+01, Power=8.74e-01
  [eval] val_mse=6.430e-01  (n=7000)
Epoch 00014: Time=   6.3s, Loss=4.98e+00, Inv=4.98e+00, For=1.22e+01, Power=8.46e-01
  [eval] val_mse=6.027e-01  (n=7000)
Epoch 00015: Time=   6.4s, Loss=4.78e+00, Inv=4.78e+00, For=1.31e+01, Power=8.19e-01
  [eval] val_mse=5.709e-01  (n=7000)
Epoch 00016: Time=   6.4s, Loss=4.62e+00, Inv=4.62e+00, For=1.42e+01, Power=7.99e-01
  [eval] val_mse=5.442e-01  (n=7000)
Epoch 00017: Time=   6.5s, Loss=4.48e+00, Inv=4.48e+00, For=1.50e+01, Power=7.85e-01
  [eval] val_mse=5.233e-01  (n=7000)
Epoch 00018: Time=   6.5s, Loss=4.35e+00, Inv=4.35e+00, For=1.61e+01, Power=7.71e-01
  [eval] val_mse=5.074e-01  (n=7000)
Epoch 00019: Time=   6.6s, Loss=4.25e+00, Inv=4.25e+00, For=1.69e+01, Power=7.60e-01
  [eval] val_mse=4.920e-01  (n=7000)
Epoch 00020: Time=   6.6s, Loss=4.15e+00, Inv=4.15e+00, For=1.79e+01, Power=7.51e-01
  [eval] val_mse=4.806e-01  (n=7000)
Epoch 00021: Time=   6.7s, Loss=4.07e+00, Inv=4.07e+00, For=1.89e+01, Power=7.46e-01
  [eval] val_mse=4.707e-01  (n=7000)
Epoch 00022: Time=   6.7s, Loss=3.98e+00, Inv=3.98e+00, For=2.01e+01, Power=7.39e-01
  [eval] val_mse=4.638e-01  (n=7000)
Epoch 00023: Time=   6.8s, Loss=3.92e+00, Inv=3.92e+00, For=2.10e+01, Power=7.31e-01
  [eval] val_mse=4.578e-01  (n=7000)
Epoch 00024: Time=   6.8s, Loss=3.86e+00, Inv=3.86e+00, For=2.18e+01, Power=7.29e-01
  [eval] val_mse=4.515e-01  (n=7000)
Epoch 00025: Time=   6.9s, Loss=3.81e+00, Inv=3.81e+00, For=2.31e+01, Power=7.24e-01
  [eval] val_mse=4.470e-01  (n=7000)
Epoch 00026: Time=   6.9s, Loss=3.76e+00, Inv=3.76e+00, For=2.41e+01, Power=7.20e-01
  [eval] val_mse=4.408e-01  (n=7000)
Epoch 00027: Time=   7.0s, Loss=3.72e+00, Inv=3.72e+00, For=2.54e+01, Power=7.18e-01
  [eval] val_mse=4.387e-01  (n=7000)
Epoch 00028: Time=   7.0s, Loss=3.67e+00, Inv=3.67e+00, For=2.59e+01, Power=7.15e-01
  [eval] val_mse=4.346e-01  (n=7000)
Epoch 00029: Time=   7.1s, Loss=3.64e+00, Inv=3.64e+00, For=2.75e+01, Power=7.12e-01
  [eval] val_mse=4.296e-01  (n=7000)
Epoch 00030: Time=   7.1s, Loss=3.61e+00, Inv=3.61e+00, For=2.80e+01, Power=7.12e-01
  [eval] val_mse=4.263e-01  (n=7000)
Epoch 00031: Time=   7.2s, Loss=3.58e+00, Inv=3.58e+00, For=3.00e+01, Power=7.12e-01
  [eval] val_mse=4.237e-01  (n=7000)
Epoch 00032: Time=   7.2s, Loss=3.55e+00, Inv=3.55e+00, For=3.05e+01, Power=7.08e-01
  [eval] val_mse=4.183e-01  (n=7000)
Epoch 00033: Time=   7.3s, Loss=3.52e+00, Inv=3.52e+00, For=3.17e+01, Power=7.06e-01
  [eval] val_mse=4.140e-01  (n=7000)
Epoch 00034: Time=   7.3s, Loss=3.51e+00, Inv=3.51e+00, For=3.27e+01, Power=7.08e-01
  [eval] val_mse=4.127e-01  (n=7000)
Epoch 00035: Time=   7.4s, Loss=3.50e+00, Inv=3.50e+00, For=3.39e+01, Power=7.05e-01
  [eval] val_mse=4.081e-01  (n=7000)
Epoch 00036: Time=   7.4s, Loss=3.47e+00, Inv=3.47e+00, For=3.48e+01, Power=7.04e-01
  [eval] val_mse=4.043e-01  (n=7000)
Epoch 00037: Time=   7.5s, Loss=3.46e+00, Inv=3.46e+00, For=3.59e+01, Power=7.02e-01
  [eval] val_mse=4.016e-01  (n=7000)
Epoch 00038: Time=   7.5s, Loss=3.43e+00, Inv=3.43e+00, For=3.75e+01, Power=7.04e-01
  [eval] val_mse=3.982e-01  (n=7000)
Epoch 00039: Time=   7.6s, Loss=3.41e+00, Inv=3.41e+00, For=3.77e+01, Power=7.01e-01
  [eval] val_mse=3.946e-01  (n=7000)
Epoch 00040: Time=   7.6s, Loss=3.41e+00, Inv=3.41e+00, For=3.93e+01, Power=7.02e-01
  [eval] val_mse=3.942e-01  (n=7000)
Epoch 00041: Time=   7.7s, Loss=3.39e+00, Inv=3.39e+00, For=4.05e+01, Power=7.02e-01
  [eval] val_mse=3.894e-01  (n=7000)
Epoch 00042: Time=   7.7s, Loss=3.38e+00, Inv=3.38e+00, For=4.12e+01, Power=7.01e-01
  [eval] val_mse=3.882e-01  (n=7000)
Epoch 00043: Time=   7.8s, Loss=3.38e+00, Inv=3.38e+00, For=4.26e+01, Power=7.03e-01
  [eval] val_mse=3.850e-01  (n=7000)
Epoch 00044: Time=   7.8s, Loss=3.35e+00, Inv=3.35e+00, For=4.30e+01, Power=6.96e-01
  [eval] val_mse=3.834e-01  (n=7000)
Epoch 00045: Time=   7.9s, Loss=3.35e+00, Inv=3.35e+00, For=4.55e+01, Power=6.99e-01
  [eval] val_mse=3.816e-01  (n=7000)
Epoch 00046: Time=   7.9s, Loss=3.34e+00, Inv=3.34e+00, For=4.58e+01, Power=6.98e-01
  [eval] val_mse=3.788e-01  (n=7000)
Epoch 00047: Time=   8.0s, Loss=3.33e+00, Inv=3.33e+00, For=4.67e+01, Power=6.94e-01
  [eval] val_mse=3.767e-01  (n=7000)
Epoch 00048: Time=   8.0s, Loss=3.31e+00, Inv=3.31e+00, For=4.86e+01, Power=6.95e-01
  [eval] val_mse=3.756e-01  (n=7000)
Epoch 00049: Time=   8.1s, Loss=3.31e+00, Inv=3.31e+00, For=4.84e+01, Power=6.95e-01
  [eval] val_mse=3.728e-01  (n=7000)
Epoch 00050: Time=   8.1s, Loss=3.31e+00, Inv=3.31e+00, For=5.04e+01, Power=6.96e-01
  [eval] val_mse=3.719e-01  (n=7000)
Epoch 00051: Time=   8.2s, Loss=3.29e+00, Inv=3.29e+00, For=5.16e+01, Power=6.90e-01
  [eval] val_mse=3.718e-01  (n=7000)
Epoch 00052: Time=   8.2s, Loss=3.29e+00, Inv=3.29e+00, For=5.21e+01, Power=6.92e-01
  [eval] val_mse=3.684e-01  (n=7000)
Epoch 00053: Time=   8.3s, Loss=3.28e+00, Inv=3.28e+00, For=5.36e+01, Power=6.93e-01
  [eval] val_mse=3.667e-01  (n=7000)
Epoch 00054: Time=   8.3s, Loss=3.27e+00, Inv=3.27e+00, For=5.34e+01, Power=6.91e-01
  [eval] val_mse=3.654e-01  (n=7000)
Epoch 00055: Time=   8.4s, Loss=3.28e+00, Inv=3.28e+00, For=5.67e+01, Power=6.92e-01
  [eval] val_mse=3.641e-01  (n=7000)
Epoch 00056: Time=   8.4s, Loss=3.26e+00, Inv=3.26e+00, For=5.60e+01, Power=6.90e-01
  [eval] val_mse=3.632e-01  (n=7000)
Epoch 00057: Time=   8.5s, Loss=3.25e+00, Inv=3.25e+00, For=5.82e+01, Power=6.92e-01
  [eval] val_mse=3.622e-01  (n=7000)
Epoch 00058: Time=   8.5s, Loss=3.24e+00, Inv=3.24e+00, For=5.88e+01, Power=6.89e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00059: Time=   8.6s, Loss=3.25e+00, Inv=3.25e+00, For=5.85e+01, Power=6.92e-01
  [eval] val_mse=3.601e-01  (n=7000)
Epoch 00060: Time=   8.6s, Loss=3.24e+00, Inv=3.24e+00, For=6.22e+01, Power=6.92e-01
  [eval] val_mse=3.581e-01  (n=7000)
Epoch 00061: Time=   8.7s, Loss=3.23e+00, Inv=3.23e+00, For=6.16e+01, Power=6.91e-01
  [eval] val_mse=3.590e-01  (n=7000)
Epoch 00062: Time=   8.7s, Loss=3.23e+00, Inv=3.23e+00, For=6.28e+01, Power=6.89e-01
  [eval] val_mse=3.564e-01  (n=7000)
Epoch 00063: Time=   8.8s, Loss=3.22e+00, Inv=3.22e+00, For=6.30e+01, Power=6.87e-01
  [eval] val_mse=3.559e-01  (n=7000)
Epoch 00064: Time=   8.8s, Loss=3.22e+00, Inv=3.22e+00, For=6.47e+01, Power=6.88e-01
  [eval] val_mse=3.544e-01  (n=7000)
Epoch 00065: Time=   8.9s, Loss=3.21e+00, Inv=3.21e+00, For=6.62e+01, Power=6.88e-01
  [eval] val_mse=3.541e-01  (n=7000)
Epoch 00066: Time=   8.9s, Loss=3.21e+00, Inv=3.21e+00, For=6.62e+01, Power=6.88e-01
  [eval] val_mse=3.535e-01  (n=7000)
Epoch 00067: Time=   9.0s, Loss=3.21e+00, Inv=3.21e+00, For=6.91e+01, Power=6.91e-01
  [eval] val_mse=3.536e-01  (n=7000)
Epoch 00068: Time=   9.0s, Loss=3.20e+00, Inv=3.20e+00, For=6.78e+01, Power=6.86e-01
  [eval] val_mse=3.518e-01  (n=7000)
Epoch 00069: Time=   9.1s, Loss=3.19e+00, Inv=3.19e+00, For=7.08e+01, Power=6.84e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00070: Time=   9.1s, Loss=3.19e+00, Inv=3.19e+00, For=6.95e+01, Power=6.85e-01
  [eval] val_mse=3.490e-01  (n=7000)
Epoch 00071: Time=   9.2s, Loss=3.19e+00, Inv=3.19e+00, For=7.14e+01, Power=6.89e-01
  [eval] val_mse=3.501e-01  (n=7000)
Epoch 00072: Time=   9.2s, Loss=3.18e+00, Inv=3.18e+00, For=7.32e+01, Power=6.86e-01
  [eval] val_mse=3.488e-01  (n=7000)
Epoch 00073: Time=   9.3s, Loss=3.18e+00, Inv=3.18e+00, For=7.27e+01, Power=6.86e-01
  [eval] val_mse=3.482e-01  (n=7000)
Epoch 00074: Time=   9.3s, Loss=3.17e+00, Inv=3.17e+00, For=7.55e+01, Power=6.84e-01
  [eval] val_mse=3.472e-01  (n=7000)
Epoch 00075: Time=   9.4s, Loss=3.17e+00, Inv=3.17e+00, For=7.49e+01, Power=6.84e-01
  [eval] val_mse=3.466e-01  (n=7000)
Epoch 00076: Time=   9.4s, Loss=3.17e+00, Inv=3.17e+00, For=7.56e+01, Power=6.86e-01
  [eval] val_mse=3.452e-01  (n=7000)
Epoch 00077: Time=   9.5s, Loss=3.16e+00, Inv=3.16e+00, For=7.65e+01, Power=6.87e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00078: Time=   9.5s, Loss=3.16e+00, Inv=3.16e+00, For=7.78e+01, Power=6.84e-01
  [eval] val_mse=3.448e-01  (n=7000)
Epoch 00079: Time=   9.6s, Loss=3.15e+00, Inv=3.15e+00, For=7.97e+01, Power=6.81e-01
  [eval] val_mse=3.457e-01  (n=7000)
Epoch 00080: Time=   9.6s, Loss=3.15e+00, Inv=3.15e+00, For=7.88e+01, Power=6.85e-01
  [eval] val_mse=3.427e-01  (n=7000)
Epoch 00081: Time=   9.7s, Loss=3.15e+00, Inv=3.15e+00, For=8.04e+01, Power=6.85e-01
  [eval] val_mse=3.438e-01  (n=7000)
Epoch 00082: Time=   9.7s, Loss=3.15e+00, Inv=3.15e+00, For=8.14e+01, Power=6.85e-01
  [eval] val_mse=3.428e-01  (n=7000)
Epoch 00083: Time=   9.8s, Loss=3.14e+00, Inv=3.14e+00, For=8.21e+01, Power=6.84e-01
  [eval] val_mse=3.415e-01  (n=7000)
Epoch 00084: Time=   9.8s, Loss=3.15e+00, Inv=3.15e+00, For=8.25e+01, Power=6.85e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00085: Time=   9.9s, Loss=3.14e+00, Inv=3.14e+00, For=8.31e+01, Power=6.82e-01
  [eval] val_mse=3.425e-01  (n=7000)
Epoch 00086: Time=   9.9s, Loss=3.13e+00, Inv=3.13e+00, For=8.51e+01, Power=6.83e-01
  [eval] val_mse=3.395e-01  (n=7000)
Epoch 00087: Time=  10.0s, Loss=3.13e+00, Inv=3.13e+00, For=8.32e+01, Power=6.84e-01
  [eval] val_mse=3.415e-01  (n=7000)
Epoch 00088: Time=  10.0s, Loss=3.13e+00, Inv=3.13e+00, For=8.59e+01, Power=6.84e-01
  [eval] val_mse=3.388e-01  (n=7000)
Epoch 00089: Time=  10.1s, Loss=3.12e+00, Inv=3.12e+00, For=8.67e+01, Power=6.84e-01
  [eval] val_mse=3.399e-01  (n=7000)
Epoch 00090: Time=  10.1s, Loss=3.12e+00, Inv=3.12e+00, For=8.74e+01, Power=6.80e-01
  [eval] val_mse=3.382e-01  (n=7000)
Epoch 00091: Time=  10.2s, Loss=3.12e+00, Inv=3.12e+00, For=8.78e+01, Power=6.85e-01
  [eval] val_mse=3.391e-01  (n=7000)
Epoch 00092: Time=  10.2s, Loss=3.12e+00, Inv=3.12e+00, For=8.74e+01, Power=6.85e-01
  [eval] val_mse=3.380e-01  (n=7000)
Epoch 00093: Time=  10.3s, Loss=3.11e+00, Inv=3.11e+00, For=8.85e+01, Power=6.83e-01
  [eval] val_mse=3.377e-01  (n=7000)
Epoch 00094: Time=  10.3s, Loss=3.11e+00, Inv=3.11e+00, For=9.00e+01, Power=6.84e-01
  [eval] val_mse=3.367e-01  (n=7000)
Epoch 00095: Time=  10.4s, Loss=3.10e+00, Inv=3.10e+00, For=8.93e+01, Power=6.81e-01
  [eval] val_mse=3.366e-01  (n=7000)
Epoch 00096: Time=  10.4s, Loss=3.10e+00, Inv=3.10e+00, For=9.19e+01, Power=6.83e-01
  [eval] val_mse=3.356e-01  (n=7000)
Epoch 00097: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=9.02e+01, Power=6.85e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00098: Time=  10.5s, Loss=3.10e+00, Inv=3.10e+00, For=9.34e+01, Power=6.84e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00099: Time=  10.6s, Loss=3.10e+00, Inv=3.10e+00, For=9.18e+01, Power=6.84e-01
  [eval] val_mse=3.355e-01  (n=7000)
Epoch 00100: Time=  10.6s, Loss=3.09e+00, Inv=3.09e+00, For=9.15e+01, Power=6.81e-01
  [eval] val_mse=3.353e-01  (n=7000)
Epoch 00101: Time=  10.6s, Loss=3.10e+00, Inv=3.10e+00, For=9.55e+01, Power=6.81e-01
  [eval] val_mse=3.343e-01  (n=7000)
Epoch 00102: Time=  10.7s, Loss=3.09e+00, Inv=3.09e+00, For=9.26e+01, Power=6.83e-01
  [eval] val_mse=3.353e-01  (n=7000)
Epoch 00103: Time=  10.7s, Loss=3.09e+00, Inv=3.09e+00, For=9.55e+01, Power=6.81e-01
  [eval] val_mse=3.346e-01  (n=7000)
Epoch 00104: Time=  10.8s, Loss=3.09e+00, Inv=3.09e+00, For=9.45e+01, Power=6.82e-01
  [eval] val_mse=3.339e-01  (n=7000)
Epoch 00105: Time=  10.8s, Loss=3.08e+00, Inv=3.08e+00, For=9.58e+01, Power=6.83e-01
  [eval] val_mse=3.329e-01  (n=7000)
Epoch 00106: Time=  10.9s, Loss=3.08e+00, Inv=3.08e+00, For=9.57e+01, Power=6.81e-01
  [eval] val_mse=3.333e-01  (n=7000)
Epoch 00107: Time=  10.9s, Loss=3.08e+00, Inv=3.08e+00, For=9.49e+01, Power=6.82e-01
  [eval] val_mse=3.317e-01  (n=7000)
Epoch 00108: Time=  11.0s, Loss=3.07e+00, Inv=3.07e+00, For=9.56e+01, Power=6.81e-01
  [eval] val_mse=3.320e-01  (n=7000)
Epoch 00109: Time=  11.0s, Loss=3.07e+00, Inv=3.07e+00, For=9.75e+01, Power=6.82e-01
  [eval] val_mse=3.330e-01  (n=7000)
Epoch 00110: Time=  11.1s, Loss=3.07e+00, Inv=3.07e+00, For=9.72e+01, Power=6.81e-01
  [eval] val_mse=3.314e-01  (n=7000)
Epoch 00111: Time=  11.1s, Loss=3.07e+00, Inv=3.07e+00, For=9.78e+01, Power=6.84e-01
  [eval] val_mse=3.308e-01  (n=7000)
Epoch 00112: Time=  11.2s, Loss=3.06e+00, Inv=3.06e+00, For=9.83e+01, Power=6.82e-01
  [eval] val_mse=3.309e-01  (n=7000)
Epoch 00113: Time=  11.2s, Loss=3.07e+00, Inv=3.07e+00, For=9.84e+01, Power=6.82e-01
  [eval] val_mse=3.306e-01  (n=7000)
Epoch 00114: Time=  11.3s, Loss=3.06e+00, Inv=3.06e+00, For=9.94e+01, Power=6.85e-01
  [eval] val_mse=3.308e-01  (n=7000)
Epoch 00115: Time=  11.3s, Loss=3.06e+00, Inv=3.06e+00, For=9.88e+01, Power=6.84e-01
  [eval] val_mse=3.289e-01  (n=7000)
Epoch 00116: Time=  11.4s, Loss=3.05e+00, Inv=3.05e+00, For=1.01e+02, Power=6.78e-01
  [eval] val_mse=3.287e-01  (n=7000)
Epoch 00117: Time=  11.4s, Loss=3.06e+00, Inv=3.06e+00, For=9.82e+01, Power=6.83e-01
  [eval] val_mse=3.293e-01  (n=7000)
Epoch 00118: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=1.01e+02, Power=6.81e-01
  [eval] val_mse=3.289e-01  (n=7000)
Epoch 00119: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=1.00e+02, Power=6.83e-01
  [eval] val_mse=3.281e-01  (n=7000)
Epoch 00120: Time=  11.6s, Loss=3.05e+00, Inv=3.05e+00, For=1.00e+02, Power=6.83e-01
  [eval] val_mse=3.281e-01  (n=7000)
Epoch 00121: Time=  11.6s, Loss=3.05e+00, Inv=3.05e+00, For=1.02e+02, Power=6.81e-01
  [eval] val_mse=3.286e-01  (n=7000)
Epoch 00122: Time=  11.7s, Loss=3.05e+00, Inv=3.05e+00, For=1.01e+02, Power=6.79e-01
  [eval] val_mse=3.280e-01  (n=7000)
Epoch 00123: Time=  11.7s, Loss=3.05e+00, Inv=3.05e+00, For=1.03e+02, Power=6.79e-01
  [eval] val_mse=3.276e-01  (n=7000)
Epoch 00124: Time=  11.8s, Loss=3.04e+00, Inv=3.04e+00, For=1.02e+02, Power=6.80e-01
  [eval] val_mse=3.279e-01  (n=7000)
Epoch 00125: Time=  11.8s, Loss=3.04e+00, Inv=3.04e+00, For=1.02e+02, Power=6.80e-01
  [eval] val_mse=3.259e-01  (n=7000)
Epoch 00126: Time=  11.9s, Loss=3.04e+00, Inv=3.04e+00, For=1.06e+02, Power=6.83e-01
  [eval] val_mse=3.276e-01  (n=7000)
Epoch 00127: Time=  11.9s, Loss=3.04e+00, Inv=3.04e+00, For=1.03e+02, Power=6.82e-01
  [eval] val_mse=3.274e-01  (n=7000)
Epoch 00128: Time=  12.0s, Loss=3.03e+00, Inv=3.03e+00, For=1.03e+02, Power=6.79e-01
  [eval] val_mse=3.262e-01  (n=7000)
Epoch 00129: Time=  12.0s, Loss=3.04e+00, Inv=3.04e+00, For=1.06e+02, Power=6.82e-01
  [eval] val_mse=3.258e-01  (n=7000)
Epoch 00130: Time=  12.1s, Loss=3.03e+00, Inv=3.03e+00, For=1.03e+02, Power=6.81e-01
  [eval] val_mse=3.262e-01  (n=7000)
Epoch 00131: Time=  12.1s, Loss=3.03e+00, Inv=3.03e+00, For=1.06e+02, Power=6.85e-01
  [eval] val_mse=3.265e-01  (n=7000)
Epoch 00132: Time=  12.2s, Loss=3.03e+00, Inv=3.03e+00, For=1.03e+02, Power=6.84e-01
  [eval] val_mse=3.247e-01  (n=7000)
Epoch 00133: Time=  12.2s, Loss=3.03e+00, Inv=3.03e+00, For=1.08e+02, Power=6.83e-01
  [eval] val_mse=3.247e-01  (n=7000)
Epoch 00134: Time=  12.3s, Loss=3.03e+00, Inv=3.03e+00, For=1.06e+02, Power=6.80e-01
  [eval] val_mse=3.242e-01  (n=7000)
Epoch 00135: Time=  12.3s, Loss=3.03e+00, Inv=3.03e+00, For=1.06e+02, Power=6.81e-01
  [eval] val_mse=3.242e-01  (n=7000)
Epoch 00136: Time=  12.4s, Loss=3.02e+00, Inv=3.02e+00, For=1.05e+02, Power=6.82e-01
  [eval] val_mse=3.245e-01  (n=7000)
Epoch 00137: Time=  12.4s, Loss=3.02e+00, Inv=3.02e+00, For=1.06e+02, Power=6.80e-01
  [eval] val_mse=3.234e-01  (n=7000)
Epoch 00138: Time=  12.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.06e+02, Power=6.82e-01
  [eval] val_mse=3.235e-01  (n=7000)
Epoch 00139: Time=  12.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.08e+02, Power=6.81e-01
  [eval] val_mse=3.245e-01  (n=7000)
Epoch 00140: Time=  12.6s, Loss=3.02e+00, Inv=3.02e+00, For=1.09e+02, Power=6.81e-01
  [eval] val_mse=3.254e-01  (n=7000)
Epoch 00141: Time=  12.6s, Loss=3.01e+00, Inv=3.01e+00, For=1.08e+02, Power=6.81e-01
  [eval] val_mse=3.244e-01  (n=7000)
Epoch 00142: Time=  12.7s, Loss=3.03e+00, Inv=3.03e+00, For=1.10e+02, Power=6.83e-01
  [eval] val_mse=3.234e-01  (n=7000)
Epoch 00143: Time=  12.7s, Loss=3.01e+00, Inv=3.01e+00, For=1.10e+02, Power=6.84e-01
  [eval] val_mse=3.229e-01  (n=7000)
Epoch 00144: Time=  12.8s, Loss=3.01e+00, Inv=3.01e+00, For=1.08e+02, Power=6.78e-01
  [eval] val_mse=3.222e-01  (n=7000)
Epoch 00145: Time=  12.8s, Loss=3.00e+00, Inv=3.00e+00, For=1.09e+02, Power=6.81e-01
  [eval] val_mse=3.215e-01  (n=7000)
Epoch 00146: Time=  12.9s, Loss=3.01e+00, Inv=3.01e+00, For=1.09e+02, Power=6.81e-01
  [eval] val_mse=3.214e-01  (n=7000)
Epoch 00147: Time=  12.9s, Loss=3.01e+00, Inv=3.01e+00, For=1.10e+02, Power=6.79e-01
  [eval] val_mse=3.224e-01  (n=7000)
Epoch 00148: Time=  13.0s, Loss=3.01e+00, Inv=3.01e+00, For=1.11e+02, Power=6.85e-01
  [eval] val_mse=3.228e-01  (n=7000)
Epoch 00149: Time=  13.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.12e+02, Power=6.80e-01
  [eval] val_mse=3.229e-01  (n=7000)
Epoch 00150: Time=  13.1s, Loss=3.01e+00, Inv=3.01e+00, For=1.11e+02, Power=6.83e-01
  [eval] val_mse=3.211e-01  (n=7000)
Epoch 00151: Time=  13.1s, Loss=3.00e+00, Inv=3.00e+00, For=1.11e+02, Power=6.82e-01
  [eval] val_mse=3.210e-01  (n=7000)
Epoch 00152: Time=  13.2s, Loss=3.00e+00, Inv=3.00e+00, For=1.11e+02, Power=6.80e-01
  [eval] val_mse=3.209e-01  (n=7000)
Epoch 00153: Time=  13.2s, Loss=3.00e+00, Inv=3.00e+00, For=1.11e+02, Power=6.80e-01
  [eval] val_mse=3.212e-01  (n=7000)
Epoch 00154: Time=  13.3s, Loss=3.00e+00, Inv=3.00e+00, For=1.14e+02, Power=6.80e-01
  [eval] val_mse=3.214e-01  (n=7000)
Epoch 00155: Time=  13.3s, Loss=3.00e+00, Inv=3.00e+00, For=1.12e+02, Power=6.82e-01
  [eval] val_mse=3.207e-01  (n=7000)
Epoch 00156: Time=  13.4s, Loss=2.99e+00, Inv=2.99e+00, For=1.13e+02, Power=6.80e-01
  [eval] val_mse=3.203e-01  (n=7000)
Epoch 00157: Time=  13.4s, Loss=2.99e+00, Inv=2.99e+00, For=1.14e+02, Power=6.80e-01
  [eval] val_mse=3.194e-01  (n=7000)
Epoch 00158: Time=  13.5s, Loss=2.98e+00, Inv=2.98e+00, For=1.15e+02, Power=6.81e-01
  [eval] val_mse=3.198e-01  (n=7000)
Epoch 00159: Time=  13.5s, Loss=3.00e+00, Inv=3.00e+00, For=1.16e+02, Power=6.82e-01
  [eval] val_mse=3.193e-01  (n=7000)
Epoch 00160: Time=  13.6s, Loss=2.99e+00, Inv=2.99e+00, For=1.15e+02, Power=6.80e-01
  [eval] val_mse=3.207e-01  (n=7000)
Epoch 00161: Time=  13.6s, Loss=2.99e+00, Inv=2.99e+00, For=1.16e+02, Power=6.81e-01
  [eval] val_mse=3.197e-01  (n=7000)
Epoch 00162: Time=  13.7s, Loss=2.99e+00, Inv=2.99e+00, For=1.18e+02, Power=6.83e-01
  [eval] val_mse=3.216e-01  (n=7000)
Epoch 00163: Time=  13.7s, Loss=2.99e+00, Inv=2.99e+00, For=1.18e+02, Power=6.82e-01
  [eval] val_mse=3.186e-01  (n=7000)
Epoch 00164: Time=  13.7s, Loss=2.99e+00, Inv=2.99e+00, For=1.19e+02, Power=6.81e-01
  [eval] val_mse=3.188e-01  (n=7000)
Epoch 00165: Time=  13.8s, Loss=2.98e+00, Inv=2.98e+00, For=1.17e+02, Power=6.80e-01
  [eval] val_mse=3.190e-01  (n=7000)
Epoch 00166: Time=  13.8s, Loss=2.98e+00, Inv=2.98e+00, For=1.19e+02, Power=6.79e-01
  [eval] val_mse=3.195e-01  (n=7000)
Epoch 00167: Time=  13.9s, Loss=2.97e+00, Inv=2.97e+00, For=1.17e+02, Power=6.80e-01
  [eval] val_mse=3.181e-01  (n=7000)
Epoch 00168: Time=  13.9s, Loss=2.97e+00, Inv=2.97e+00, For=1.21e+02, Power=6.82e-01
  [eval] val_mse=3.197e-01  (n=7000)
Epoch 00169: Time=  14.0s, Loss=2.97e+00, Inv=2.97e+00, For=1.19e+02, Power=6.78e-01
  [eval] val_mse=3.189e-01  (n=7000)
Epoch 00170: Time=  14.0s, Loss=2.97e+00, Inv=2.97e+00, For=1.21e+02, Power=6.78e-01
  [eval] val_mse=3.175e-01  (n=7000)
Epoch 00171: Time=  14.1s, Loss=2.98e+00, Inv=2.98e+00, For=1.23e+02, Power=6.81e-01
  [eval] val_mse=3.185e-01  (n=7000)
Epoch 00172: Time=  14.1s, Loss=2.98e+00, Inv=2.98e+00, For=1.24e+02, Power=6.82e-01
  [eval] val_mse=3.197e-01  (n=7000)
Epoch 00173: Time=  14.2s, Loss=2.98e+00, Inv=2.98e+00, For=1.25e+02, Power=6.82e-01
  [eval] val_mse=3.190e-01  (n=7000)
Epoch 00174: Time=  14.2s, Loss=2.97e+00, Inv=2.97e+00, For=1.24e+02, Power=6.81e-01
  [eval] val_mse=3.178e-01  (n=7000)
Epoch 00175: Time=  14.3s, Loss=2.96e+00, Inv=2.96e+00, For=1.24e+02, Power=6.77e-01
  [eval] val_mse=3.179e-01  (n=7000)
Epoch 00176: Time=  14.3s, Loss=2.96e+00, Inv=2.96e+00, For=1.25e+02, Power=6.79e-01
  [eval] val_mse=3.180e-01  (n=7000)
Epoch 00177: Time=  14.4s, Loss=2.96e+00, Inv=2.96e+00, For=1.28e+02, Power=6.79e-01
  [eval] val_mse=3.179e-01  (n=7000)
Epoch 00178: Time=  14.4s, Loss=2.96e+00, Inv=2.96e+00, For=1.26e+02, Power=6.80e-01
  [eval] val_mse=3.173e-01  (n=7000)
Epoch 00179: Time=  14.5s, Loss=2.96e+00, Inv=2.96e+00, For=1.29e+02, Power=6.78e-01
  [eval] val_mse=3.184e-01  (n=7000)
Epoch 00180: Time=  14.5s, Loss=2.96e+00, Inv=2.96e+00, For=1.30e+02, Power=6.81e-01
  [eval] val_mse=3.172e-01  (n=7000)
Epoch 00181: Time=  14.6s, Loss=2.97e+00, Inv=2.97e+00, For=1.33e+02, Power=6.83e-01
  [eval] val_mse=3.179e-01  (n=7000)
Epoch 00182: Time=  14.6s, Loss=2.97e+00, Inv=2.97e+00, For=1.32e+02, Power=6.81e-01
  [eval] val_mse=3.179e-01  (n=7000)
Epoch 00183: Time=  14.7s, Loss=2.97e+00, Inv=2.97e+00, For=1.31e+02, Power=6.80e-01
  [eval] val_mse=3.178e-01  (n=7000)
Epoch 00184: Time=  14.7s, Loss=2.97e+00, Inv=2.97e+00, For=1.35e+02, Power=6.80e-01
  [eval] val_mse=3.161e-01  (n=7000)
Epoch 00185: Time=  14.8s, Loss=2.97e+00, Inv=2.97e+00, For=1.32e+02, Power=6.83e-01
  [eval] val_mse=3.168e-01  (n=7000)
Epoch 00186: Time=  14.8s, Loss=2.96e+00, Inv=2.96e+00, For=1.34e+02, Power=6.80e-01
  [eval] val_mse=3.163e-01  (n=7000)
Epoch 00187: Time=  14.9s, Loss=2.95e+00, Inv=2.95e+00, For=1.32e+02, Power=6.78e-01
  [eval] val_mse=3.170e-01  (n=7000)
Epoch 00188: Time=  14.9s, Loss=2.96e+00, Inv=2.96e+00, For=1.35e+02, Power=6.80e-01
  [eval] val_mse=3.173e-01  (n=7000)
Epoch 00189: Time=  15.0s, Loss=2.96e+00, Inv=2.96e+00, For=1.35e+02, Power=6.80e-01
  [eval] val_mse=3.162e-01  (n=7000)
Epoch 00190: Time=  15.0s, Loss=2.96e+00, Inv=2.96e+00, For=1.37e+02, Power=6.79e-01
  [eval] val_mse=3.155e-01  (n=7000)
Epoch 00191: Time=  15.1s, Loss=2.96e+00, Inv=2.96e+00, For=1.42e+02, Power=6.77e-01
  [eval] val_mse=3.175e-01  (n=7000)
Epoch 00192: Time=  15.1s, Loss=2.96e+00, Inv=2.96e+00, For=1.39e+02, Power=6.79e-01
  [eval] val_mse=3.163e-01  (n=7000)
Epoch 00193: Time=  15.2s, Loss=2.96e+00, Inv=2.96e+00, For=1.42e+02, Power=6.81e-01
  [eval] val_mse=3.173e-01  (n=7000)
Epoch 00194: Time=  15.2s, Loss=2.96e+00, Inv=2.96e+00, For=1.41e+02, Power=6.80e-01
  [eval] val_mse=3.159e-01  (n=7000)
Epoch 00195: Time=  15.2s, Loss=2.96e+00, Inv=2.96e+00, For=1.46e+02, Power=6.82e-01
  [eval] val_mse=3.161e-01  (n=7000)
Epoch 00196: Time=  15.3s, Loss=2.95e+00, Inv=2.95e+00, For=1.42e+02, Power=6.81e-01
  [eval] val_mse=3.159e-01  (n=7000)
Epoch 00197: Time=  15.3s, Loss=2.95e+00, Inv=2.95e+00, For=1.44e+02, Power=6.80e-01
  [eval] val_mse=3.157e-01  (n=7000)
Epoch 00198: Time=  15.4s, Loss=2.96e+00, Inv=2.96e+00, For=1.47e+02, Power=6.80e-01
  [eval] val_mse=3.218e-01  (n=7000)
Epoch 00199: Time=  15.4s, Loss=2.96e+00, Inv=2.96e+00, For=1.48e+02, Power=6.82e-01
  [eval] val_mse=3.156e-01  (n=7000)
Epoch 00200: Time=  15.5s, Loss=2.95e+00, Inv=2.95e+00, For=1.45e+02, Power=6.82e-01
  [eval] val_mse=3.182e-01  (n=7000)
  [early_stop] stop at epoch=200 (best_epoch=190, best_val_mse=3.155e-01)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 2.293e-01
Torque MSE  = 7.277e-02
Torque RMSE = 2.698e-01
Per-joint MSE : 7.312e-02 2.030e-01 4.344e-02 2.318e-02 7.645e-02 1.746e-02
Per-joint RMSE: 2.704e-01 4.505e-01 2.084e-01 1.523e-01 2.765e-01 1.321e-01
Comp Time per Sample = 2.936e-04s / 3405.8Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-yy06c_bi because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7b018ac5e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:52:25.682293: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:52:27.610931: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.4s, Loss=3.12e+03, Inv=3.12e+03, For=5.71e+00, Power=5.68e+02
  [eval] val_mse=9.397e+01  (n=7000)
Epoch 00002: Time=   6.0s, Loss=1.93e+02, Inv=1.93e+02, For=5.32e+00, Power=3.42e+01
  [eval] val_mse=2.967e+01  (n=7000)
Epoch 00003: Time=   6.1s, Loss=7.19e+01, Inv=7.19e+01, For=5.23e+00, Power=1.28e+01
  [eval] val_mse=1.353e+01  (n=7000)
Epoch 00004: Time=   6.1s, Loss=4.08e+01, Inv=4.08e+01, For=5.15e+00, Power=6.91e+00
  [eval] val_mse=7.817e+00  (n=7000)
Epoch 00005: Time=   6.2s, Loss=2.68e+01, Inv=2.68e+01, For=5.08e+00, Power=4.37e+00
  [eval] val_mse=4.998e+00  (n=7000)
Epoch 00006: Time=   6.3s, Loss=1.93e+01, Inv=1.93e+01, For=5.00e+00, Power=3.03e+00
  [eval] val_mse=3.469e+00  (n=7000)
Epoch 00007: Time=   6.3s, Loss=1.49e+01, Inv=1.49e+01, For=4.93e+00, Power=2.29e+00
  [eval] val_mse=2.576e+00  (n=7000)
Epoch 00008: Time=   6.4s, Loss=1.20e+01, Inv=1.20e+01, For=4.93e+00, Power=1.82e+00
  [eval] val_mse=2.017e+00  (n=7000)
Epoch 00009: Time=   6.4s, Loss=1.02e+01, Inv=1.02e+01, For=5.02e+00, Power=1.53e+00
  [eval] val_mse=1.664e+00  (n=7000)
Epoch 00010: Time=   6.5s, Loss=8.92e+00, Inv=8.92e+00, For=5.20e+00, Power=1.33e+00
  [eval] val_mse=1.412e+00  (n=7000)
Epoch 00011: Time=   6.5s, Loss=7.97e+00, Inv=7.97e+00, For=5.41e+00, Power=1.19e+00
  [eval] val_mse=1.234e+00  (n=7000)
Epoch 00012: Time=   6.6s, Loss=7.26e+00, Inv=7.26e+00, For=5.69e+00, Power=1.09e+00
  [eval] val_mse=1.097e+00  (n=7000)
Epoch 00013: Time=   6.6s, Loss=6.73e+00, Inv=6.73e+00, For=6.02e+00, Power=1.02e+00
  [eval] val_mse=9.938e-01  (n=7000)
Epoch 00014: Time=   6.7s, Loss=6.30e+00, Inv=6.30e+00, For=6.34e+00, Power=9.64e-01
  [eval] val_mse=9.097e-01  (n=7000)
Epoch 00015: Time=   6.7s, Loss=5.96e+00, Inv=5.96e+00, For=6.73e+00, Power=9.21e-01
  [eval] val_mse=8.414e-01  (n=7000)
Epoch 00016: Time=   6.8s, Loss=5.66e+00, Inv=5.66e+00, For=7.04e+00, Power=8.84e-01
  [eval] val_mse=7.840e-01  (n=7000)
Epoch 00017: Time=   6.8s, Loss=5.43e+00, Inv=5.43e+00, For=7.49e+00, Power=8.58e-01
  [eval] val_mse=7.358e-01  (n=7000)
Epoch 00018: Time=   6.9s, Loss=5.20e+00, Inv=5.20e+00, For=7.85e+00, Power=8.33e-01
  [eval] val_mse=6.962e-01  (n=7000)
Epoch 00019: Time=   6.9s, Loss=5.02e+00, Inv=5.02e+00, For=8.19e+00, Power=8.15e-01
  [eval] val_mse=6.650e-01  (n=7000)
Epoch 00020: Time=   7.0s, Loss=4.86e+00, Inv=4.86e+00, For=8.57e+00, Power=8.02e-01
  [eval] val_mse=6.343e-01  (n=7000)
Epoch 00021: Time=   7.0s, Loss=4.71e+00, Inv=4.71e+00, For=9.06e+00, Power=7.84e-01
  [eval] val_mse=6.072e-01  (n=7000)
Epoch 00022: Time=   7.0s, Loss=4.58e+00, Inv=4.58e+00, For=9.32e+00, Power=7.78e-01
  [eval] val_mse=5.867e-01  (n=7000)
Epoch 00023: Time=   7.1s, Loss=4.45e+00, Inv=4.45e+00, For=9.82e+00, Power=7.65e-01
  [eval] val_mse=5.670e-01  (n=7000)
Epoch 00024: Time=   7.1s, Loss=4.35e+00, Inv=4.35e+00, For=1.01e+01, Power=7.58e-01
  [eval] val_mse=5.518e-01  (n=7000)
Epoch 00025: Time=   7.2s, Loss=4.25e+00, Inv=4.25e+00, For=1.06e+01, Power=7.50e-01
  [eval] val_mse=5.363e-01  (n=7000)
Epoch 00026: Time=   7.2s, Loss=4.16e+00, Inv=4.16e+00, For=1.09e+01, Power=7.42e-01
  [eval] val_mse=5.236e-01  (n=7000)
Epoch 00027: Time=   7.3s, Loss=4.09e+00, Inv=4.09e+00, For=1.15e+01, Power=7.38e-01
  [eval] val_mse=5.121e-01  (n=7000)
Epoch 00028: Time=   7.3s, Loss=4.02e+00, Inv=4.02e+00, For=1.16e+01, Power=7.33e-01
  [eval] val_mse=5.049e-01  (n=7000)
Epoch 00029: Time=   7.4s, Loss=3.95e+00, Inv=3.95e+00, For=1.23e+01, Power=7.31e-01
  [eval] val_mse=4.941e-01  (n=7000)
Epoch 00030: Time=   7.4s, Loss=3.90e+00, Inv=3.90e+00, For=1.26e+01, Power=7.24e-01
  [eval] val_mse=4.867e-01  (n=7000)
Epoch 00031: Time=   7.5s, Loss=3.84e+00, Inv=3.84e+00, For=1.29e+01, Power=7.22e-01
  [eval] val_mse=4.812e-01  (n=7000)
Epoch 00032: Time=   7.5s, Loss=3.81e+00, Inv=3.81e+00, For=1.35e+01, Power=7.22e-01
  [eval] val_mse=4.719e-01  (n=7000)
Epoch 00033: Time=   7.6s, Loss=3.76e+00, Inv=3.76e+00, For=1.35e+01, Power=7.16e-01
  [eval] val_mse=4.655e-01  (n=7000)
Epoch 00034: Time=   7.6s, Loss=3.73e+00, Inv=3.73e+00, For=1.41e+01, Power=7.14e-01
  [eval] val_mse=4.608e-01  (n=7000)
Epoch 00035: Time=   7.7s, Loss=3.70e+00, Inv=3.70e+00, For=1.43e+01, Power=7.09e-01
  [eval] val_mse=4.549e-01  (n=7000)
Epoch 00036: Time=   7.7s, Loss=3.67e+00, Inv=3.67e+00, For=1.49e+01, Power=7.11e-01
  [eval] val_mse=4.478e-01  (n=7000)
Epoch 00037: Time=   7.8s, Loss=3.63e+00, Inv=3.63e+00, For=1.49e+01, Power=7.08e-01
  [eval] val_mse=4.430e-01  (n=7000)
Epoch 00038: Time=   7.8s, Loss=3.61e+00, Inv=3.61e+00, For=1.56e+01, Power=7.11e-01
  [eval] val_mse=4.379e-01  (n=7000)
Epoch 00039: Time=   7.9s, Loss=3.59e+00, Inv=3.59e+00, For=1.55e+01, Power=7.08e-01
  [eval] val_mse=4.332e-01  (n=7000)
Epoch 00040: Time=   7.9s, Loss=3.57e+00, Inv=3.57e+00, For=1.61e+01, Power=7.06e-01
  [eval] val_mse=4.289e-01  (n=7000)
Epoch 00041: Time=   8.0s, Loss=3.55e+00, Inv=3.55e+00, For=1.64e+01, Power=7.06e-01
  [eval] val_mse=4.242e-01  (n=7000)
Epoch 00042: Time=   8.0s, Loss=3.53e+00, Inv=3.53e+00, For=1.65e+01, Power=7.03e-01
  [eval] val_mse=4.208e-01  (n=7000)
Epoch 00043: Time=   8.1s, Loss=3.51e+00, Inv=3.51e+00, For=1.71e+01, Power=7.01e-01
  [eval] val_mse=4.161e-01  (n=7000)
Epoch 00044: Time=   8.1s, Loss=3.50e+00, Inv=3.50e+00, For=1.72e+01, Power=6.99e-01
  [eval] val_mse=4.127e-01  (n=7000)
Epoch 00045: Time=   8.2s, Loss=3.48e+00, Inv=3.48e+00, For=1.75e+01, Power=7.01e-01
  [eval] val_mse=4.094e-01  (n=7000)
Epoch 00046: Time=   8.2s, Loss=3.46e+00, Inv=3.46e+00, For=1.76e+01, Power=6.98e-01
  [eval] val_mse=4.057e-01  (n=7000)
Epoch 00047: Time=   8.3s, Loss=3.45e+00, Inv=3.45e+00, For=1.84e+01, Power=7.02e-01
  [eval] val_mse=4.029e-01  (n=7000)
Epoch 00048: Time=   8.3s, Loss=3.43e+00, Inv=3.43e+00, For=1.82e+01, Power=6.95e-01
  [eval] val_mse=3.985e-01  (n=7000)
Epoch 00049: Time=   8.4s, Loss=3.42e+00, Inv=3.42e+00, For=1.87e+01, Power=7.00e-01
  [eval] val_mse=3.956e-01  (n=7000)
Epoch 00050: Time=   8.4s, Loss=3.41e+00, Inv=3.41e+00, For=1.90e+01, Power=6.98e-01
  [eval] val_mse=3.949e-01  (n=7000)
Epoch 00051: Time=   8.5s, Loss=3.41e+00, Inv=3.41e+00, For=1.92e+01, Power=6.96e-01
  [eval] val_mse=3.908e-01  (n=7000)
Epoch 00052: Time=   8.5s, Loss=3.39e+00, Inv=3.39e+00, For=1.97e+01, Power=6.97e-01
  [eval] val_mse=3.878e-01  (n=7000)
Epoch 00053: Time=   8.6s, Loss=3.37e+00, Inv=3.37e+00, For=2.00e+01, Power=6.97e-01
  [eval] val_mse=3.863e-01  (n=7000)
Epoch 00054: Time=   8.6s, Loss=3.37e+00, Inv=3.37e+00, For=2.01e+01, Power=6.93e-01
  [eval] val_mse=3.841e-01  (n=7000)
Epoch 00055: Time=   8.7s, Loss=3.36e+00, Inv=3.36e+00, For=2.03e+01, Power=6.94e-01
  [eval] val_mse=3.824e-01  (n=7000)
Epoch 00056: Time=   8.7s, Loss=3.34e+00, Inv=3.34e+00, For=2.11e+01, Power=6.90e-01
  [eval] val_mse=3.815e-01  (n=7000)
Epoch 00057: Time=   8.7s, Loss=3.34e+00, Inv=3.34e+00, For=2.12e+01, Power=6.92e-01
  [eval] val_mse=3.772e-01  (n=7000)
Epoch 00058: Time=   8.8s, Loss=3.33e+00, Inv=3.33e+00, For=2.13e+01, Power=6.94e-01
  [eval] val_mse=3.759e-01  (n=7000)
Epoch 00059: Time=   8.8s, Loss=3.32e+00, Inv=3.32e+00, For=2.18e+01, Power=6.91e-01
  [eval] val_mse=3.738e-01  (n=7000)
Epoch 00060: Time=   8.9s, Loss=3.31e+00, Inv=3.31e+00, For=2.21e+01, Power=6.92e-01
  [eval] val_mse=3.724e-01  (n=7000)
Epoch 00061: Time=   8.9s, Loss=3.31e+00, Inv=3.31e+00, For=2.24e+01, Power=6.89e-01
  [eval] val_mse=3.707e-01  (n=7000)
Epoch 00062: Time=   9.0s, Loss=3.30e+00, Inv=3.30e+00, For=2.29e+01, Power=6.89e-01
  [eval] val_mse=3.696e-01  (n=7000)
Epoch 00063: Time=   9.0s, Loss=3.30e+00, Inv=3.30e+00, For=2.31e+01, Power=6.92e-01
  [eval] val_mse=3.671e-01  (n=7000)
Epoch 00064: Time=   9.1s, Loss=3.29e+00, Inv=3.29e+00, For=2.34e+01, Power=6.90e-01
  [eval] val_mse=3.667e-01  (n=7000)
Epoch 00065: Time=   9.1s, Loss=3.28e+00, Inv=3.28e+00, For=2.37e+01, Power=6.89e-01
  [eval] val_mse=3.656e-01  (n=7000)
Epoch 00066: Time=   9.2s, Loss=3.28e+00, Inv=3.28e+00, For=2.41e+01, Power=6.91e-01
  [eval] val_mse=3.627e-01  (n=7000)
Epoch 00067: Time=   9.2s, Loss=3.27e+00, Inv=3.27e+00, For=2.43e+01, Power=6.89e-01
  [eval] val_mse=3.624e-01  (n=7000)
Epoch 00068: Time=   9.3s, Loss=3.26e+00, Inv=3.26e+00, For=2.46e+01, Power=6.87e-01
  [eval] val_mse=3.615e-01  (n=7000)
Epoch 00069: Time=   9.3s, Loss=3.25e+00, Inv=3.25e+00, For=2.52e+01, Power=6.86e-01
  [eval] val_mse=3.590e-01  (n=7000)
Epoch 00070: Time=   9.4s, Loss=3.25e+00, Inv=3.25e+00, For=2.53e+01, Power=6.88e-01
  [eval] val_mse=3.592e-01  (n=7000)
Epoch 00071: Time=   9.4s, Loss=3.24e+00, Inv=3.24e+00, For=2.58e+01, Power=6.86e-01
  [eval] val_mse=3.574e-01  (n=7000)
Epoch 00072: Time=   9.5s, Loss=3.23e+00, Inv=3.23e+00, For=2.58e+01, Power=6.83e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00073: Time=   9.5s, Loss=3.23e+00, Inv=3.23e+00, For=2.64e+01, Power=6.87e-01
  [eval] val_mse=3.554e-01  (n=7000)
Epoch 00074: Time=   9.6s, Loss=3.22e+00, Inv=3.22e+00, For=2.69e+01, Power=6.84e-01
  [eval] val_mse=3.556e-01  (n=7000)
Epoch 00075: Time=   9.6s, Loss=3.22e+00, Inv=3.22e+00, For=2.70e+01, Power=6.86e-01
  [eval] val_mse=3.546e-01  (n=7000)
Epoch 00076: Time=   9.7s, Loss=3.21e+00, Inv=3.21e+00, For=2.74e+01, Power=6.87e-01
  [eval] val_mse=3.528e-01  (n=7000)
Epoch 00077: Time=   9.7s, Loss=3.21e+00, Inv=3.21e+00, For=2.78e+01, Power=6.80e-01
  [eval] val_mse=3.523e-01  (n=7000)
Epoch 00078: Time=   9.8s, Loss=3.21e+00, Inv=3.21e+00, For=2.82e+01, Power=6.87e-01
  [eval] val_mse=3.516e-01  (n=7000)
Epoch 00079: Time=   9.8s, Loss=3.20e+00, Inv=3.20e+00, For=2.82e+01, Power=6.84e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00080: Time=   9.9s, Loss=3.19e+00, Inv=3.19e+00, For=2.90e+01, Power=6.85e-01
  [eval] val_mse=3.507e-01  (n=7000)
Epoch 00081: Time=   9.9s, Loss=3.19e+00, Inv=3.19e+00, For=2.91e+01, Power=6.84e-01
  [eval] val_mse=3.484e-01  (n=7000)
Epoch 00082: Time=  10.0s, Loss=3.19e+00, Inv=3.19e+00, For=2.98e+01, Power=6.84e-01
  [eval] val_mse=3.489e-01  (n=7000)
Epoch 00083: Time=  10.0s, Loss=3.18e+00, Inv=3.18e+00, For=2.98e+01, Power=6.87e-01
  [eval] val_mse=3.478e-01  (n=7000)
Epoch 00084: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=3.03e+01, Power=6.85e-01
  [eval] val_mse=3.468e-01  (n=7000)
Epoch 00085: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=3.07e+01, Power=6.85e-01
  [eval] val_mse=3.467e-01  (n=7000)
Epoch 00086: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=3.08e+01, Power=6.84e-01
  [eval] val_mse=3.466e-01  (n=7000)
Epoch 00087: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=3.18e+01, Power=6.84e-01
  [eval] val_mse=3.468e-01  (n=7000)
Epoch 00088: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=3.14e+01, Power=6.83e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00089: Time=  10.3s, Loss=3.16e+00, Inv=3.16e+00, For=3.25e+01, Power=6.85e-01
  [eval] val_mse=3.442e-01  (n=7000)
Epoch 00090: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=3.24e+01, Power=6.85e-01
  [eval] val_mse=3.436e-01  (n=7000)
Epoch 00091: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=3.28e+01, Power=6.82e-01
  [eval] val_mse=3.452e-01  (n=7000)
Epoch 00092: Time=  10.4s, Loss=3.15e+00, Inv=3.15e+00, For=3.32e+01, Power=6.84e-01
  [eval] val_mse=3.444e-01  (n=7000)
Epoch 00093: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=3.36e+01, Power=6.80e-01
  [eval] val_mse=3.433e-01  (n=7000)
Epoch 00094: Time=  10.5s, Loss=3.14e+00, Inv=3.14e+00, For=3.40e+01, Power=6.81e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00095: Time=  10.6s, Loss=3.14e+00, Inv=3.14e+00, For=3.40e+01, Power=6.83e-01
  [eval] val_mse=3.418e-01  (n=7000)
Epoch 00096: Time=  10.6s, Loss=3.14e+00, Inv=3.14e+00, For=3.48e+01, Power=6.83e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00097: Time=  10.7s, Loss=3.14e+00, Inv=3.14e+00, For=3.53e+01, Power=6.83e-01
  [eval] val_mse=3.408e-01  (n=7000)
Epoch 00098: Time=  10.7s, Loss=3.13e+00, Inv=3.13e+00, For=3.57e+01, Power=6.85e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00099: Time=  10.8s, Loss=3.12e+00, Inv=3.12e+00, For=3.58e+01, Power=6.78e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00100: Time=  10.8s, Loss=3.13e+00, Inv=3.13e+00, For=3.60e+01, Power=6.85e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00101: Time=  10.9s, Loss=3.13e+00, Inv=3.13e+00, For=3.66e+01, Power=6.80e-01
  [eval] val_mse=3.398e-01  (n=7000)
Epoch 00102: Time=  10.9s, Loss=3.13e+00, Inv=3.13e+00, For=3.68e+01, Power=6.85e-01
  [eval] val_mse=3.397e-01  (n=7000)
Epoch 00103: Time=  11.0s, Loss=3.12e+00, Inv=3.12e+00, For=3.78e+01, Power=6.82e-01
  [eval] val_mse=3.403e-01  (n=7000)
Epoch 00104: Time=  11.0s, Loss=3.11e+00, Inv=3.11e+00, For=3.72e+01, Power=6.84e-01
  [eval] val_mse=3.391e-01  (n=7000)
Epoch 00105: Time=  11.1s, Loss=3.11e+00, Inv=3.11e+00, For=3.81e+01, Power=6.82e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00106: Time=  11.1s, Loss=3.11e+00, Inv=3.11e+00, For=3.81e+01, Power=6.83e-01
  [eval] val_mse=3.384e-01  (n=7000)
Epoch 00107: Time=  11.2s, Loss=3.11e+00, Inv=3.11e+00, For=3.84e+01, Power=6.81e-01
  [eval] val_mse=3.380e-01  (n=7000)
Epoch 00108: Time=  11.2s, Loss=3.10e+00, Inv=3.10e+00, For=3.92e+01, Power=6.84e-01
  [eval] val_mse=3.369e-01  (n=7000)
Epoch 00109: Time=  11.3s, Loss=3.10e+00, Inv=3.10e+00, For=3.91e+01, Power=6.82e-01
  [eval] val_mse=3.376e-01  (n=7000)
Epoch 00110: Time=  11.3s, Loss=3.10e+00, Inv=3.10e+00, For=3.96e+01, Power=6.81e-01
  [eval] val_mse=3.360e-01  (n=7000)
Epoch 00111: Time=  11.4s, Loss=3.10e+00, Inv=3.10e+00, For=3.99e+01, Power=6.84e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00112: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=4.03e+01, Power=6.80e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00113: Time=  11.5s, Loss=3.09e+00, Inv=3.09e+00, For=4.09e+01, Power=6.82e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00114: Time=  11.5s, Loss=3.09e+00, Inv=3.09e+00, For=4.14e+01, Power=6.81e-01
  [eval] val_mse=3.365e-01  (n=7000)
Epoch 00115: Time=  11.6s, Loss=3.08e+00, Inv=3.08e+00, For=4.17e+01, Power=6.82e-01
  [eval] val_mse=3.360e-01  (n=7000)
Epoch 00116: Time=  11.6s, Loss=3.08e+00, Inv=3.08e+00, For=4.18e+01, Power=6.83e-01
  [eval] val_mse=3.345e-01  (n=7000)
Epoch 00117: Time=  11.7s, Loss=3.08e+00, Inv=3.08e+00, For=4.22e+01, Power=6.83e-01
  [eval] val_mse=3.347e-01  (n=7000)
Epoch 00118: Time=  11.7s, Loss=3.07e+00, Inv=3.07e+00, For=4.20e+01, Power=6.78e-01
  [eval] val_mse=3.346e-01  (n=7000)
Epoch 00119: Time=  11.8s, Loss=3.07e+00, Inv=3.07e+00, For=4.30e+01, Power=6.82e-01
  [eval] val_mse=3.351e-01  (n=7000)
Epoch 00120: Time=  11.8s, Loss=3.07e+00, Inv=3.07e+00, For=4.37e+01, Power=6.80e-01
  [eval] val_mse=3.343e-01  (n=7000)
Epoch 00121: Time=  11.9s, Loss=3.08e+00, Inv=3.08e+00, For=4.35e+01, Power=6.82e-01
  [eval] val_mse=3.338e-01  (n=7000)
Epoch 00122: Time=  11.9s, Loss=3.07e+00, Inv=3.07e+00, For=4.42e+01, Power=6.82e-01
  [eval] val_mse=3.336e-01  (n=7000)
Epoch 00123: Time=  12.0s, Loss=3.06e+00, Inv=3.06e+00, For=4.44e+01, Power=6.80e-01
  [eval] val_mse=3.348e-01  (n=7000)
Epoch 00124: Time=  12.0s, Loss=3.06e+00, Inv=3.06e+00, For=4.47e+01, Power=6.82e-01
  [eval] val_mse=3.335e-01  (n=7000)
Epoch 00125: Time=  12.1s, Loss=3.06e+00, Inv=3.06e+00, For=4.49e+01, Power=6.81e-01
  [eval] val_mse=3.333e-01  (n=7000)
Epoch 00126: Time=  12.1s, Loss=3.06e+00, Inv=3.06e+00, For=4.58e+01, Power=6.81e-01
  [eval] val_mse=3.333e-01  (n=7000)
Epoch 00127: Time=  12.1s, Loss=3.06e+00, Inv=3.06e+00, For=4.61e+01, Power=6.82e-01
  [eval] val_mse=3.334e-01  (n=7000)
Epoch 00128: Time=  12.2s, Loss=3.06e+00, Inv=3.06e+00, For=4.63e+01, Power=6.81e-01
  [eval] val_mse=3.327e-01  (n=7000)
Epoch 00129: Time=  12.2s, Loss=3.05e+00, Inv=3.05e+00, For=4.63e+01, Power=6.83e-01
  [eval] val_mse=3.333e-01  (n=7000)
Epoch 00130: Time=  12.3s, Loss=3.05e+00, Inv=3.05e+00, For=4.69e+01, Power=6.81e-01
  [eval] val_mse=3.346e-01  (n=7000)
Epoch 00131: Time=  12.3s, Loss=3.05e+00, Inv=3.05e+00, For=4.72e+01, Power=6.81e-01
  [eval] val_mse=3.324e-01  (n=7000)
Epoch 00132: Time=  12.4s, Loss=3.05e+00, Inv=3.05e+00, For=4.75e+01, Power=6.81e-01
  [eval] val_mse=3.316e-01  (n=7000)
Epoch 00133: Time=  12.4s, Loss=3.05e+00, Inv=3.05e+00, For=4.77e+01, Power=6.82e-01
  [eval] val_mse=3.320e-01  (n=7000)
Epoch 00134: Time=  12.5s, Loss=3.05e+00, Inv=3.05e+00, For=4.86e+01, Power=6.85e-01
  [eval] val_mse=3.326e-01  (n=7000)
Epoch 00135: Time=  12.5s, Loss=3.05e+00, Inv=3.05e+00, For=4.89e+01, Power=6.82e-01
  [eval] val_mse=3.310e-01  (n=7000)
Epoch 00136: Time=  12.6s, Loss=3.04e+00, Inv=3.04e+00, For=4.90e+01, Power=6.79e-01
  [eval] val_mse=3.314e-01  (n=7000)
Epoch 00137: Time=  12.6s, Loss=3.04e+00, Inv=3.04e+00, For=4.93e+01, Power=6.83e-01
  [eval] val_mse=3.309e-01  (n=7000)
Epoch 00138: Time=  12.7s, Loss=3.04e+00, Inv=3.04e+00, For=4.98e+01, Power=6.83e-01
  [eval] val_mse=3.324e-01  (n=7000)
Epoch 00139: Time=  12.7s, Loss=3.04e+00, Inv=3.04e+00, For=5.04e+01, Power=6.82e-01
  [eval] val_mse=3.315e-01  (n=7000)
Epoch 00140: Time=  12.8s, Loss=3.03e+00, Inv=3.03e+00, For=5.06e+01, Power=6.79e-01
  [eval] val_mse=3.300e-01  (n=7000)
Epoch 00141: Time=  12.8s, Loss=3.03e+00, Inv=3.03e+00, For=5.06e+01, Power=6.82e-01
  [eval] val_mse=3.301e-01  (n=7000)
Epoch 00142: Time=  12.9s, Loss=3.03e+00, Inv=3.03e+00, For=5.14e+01, Power=6.80e-01
  [eval] val_mse=3.296e-01  (n=7000)
Epoch 00143: Time=  12.9s, Loss=3.02e+00, Inv=3.02e+00, For=5.14e+01, Power=6.79e-01
  [eval] val_mse=3.297e-01  (n=7000)
Epoch 00144: Time=  13.0s, Loss=3.03e+00, Inv=3.03e+00, For=5.20e+01, Power=6.78e-01
  [eval] val_mse=3.299e-01  (n=7000)
Epoch 00145: Time=  13.0s, Loss=3.03e+00, Inv=3.03e+00, For=5.31e+01, Power=6.81e-01
  [eval] val_mse=3.289e-01  (n=7000)
Epoch 00146: Time=  13.1s, Loss=3.03e+00, Inv=3.03e+00, For=5.28e+01, Power=6.82e-01
  [eval] val_mse=3.302e-01  (n=7000)
Epoch 00147: Time=  13.1s, Loss=3.02e+00, Inv=3.02e+00, For=5.31e+01, Power=6.81e-01
  [eval] val_mse=3.282e-01  (n=7000)
Epoch 00148: Time=  13.2s, Loss=3.02e+00, Inv=3.02e+00, For=5.37e+01, Power=6.78e-01
  [eval] val_mse=3.304e-01  (n=7000)
Epoch 00149: Time=  13.2s, Loss=3.02e+00, Inv=3.02e+00, For=5.48e+01, Power=6.80e-01
  [eval] val_mse=3.310e-01  (n=7000)
Epoch 00150: Time=  13.3s, Loss=3.01e+00, Inv=3.01e+00, For=5.44e+01, Power=6.80e-01
  [eval] val_mse=3.292e-01  (n=7000)
Epoch 00151: Time=  13.3s, Loss=3.02e+00, Inv=3.02e+00, For=5.51e+01, Power=6.81e-01
  [eval] val_mse=3.297e-01  (n=7000)
Epoch 00152: Time=  13.4s, Loss=3.02e+00, Inv=3.02e+00, For=5.53e+01, Power=6.81e-01
  [eval] val_mse=3.292e-01  (n=7000)
Epoch 00153: Time=  13.4s, Loss=3.01e+00, Inv=3.01e+00, For=5.49e+01, Power=6.80e-01
  [eval] val_mse=3.282e-01  (n=7000)
Epoch 00154: Time=  13.5s, Loss=3.01e+00, Inv=3.01e+00, For=5.64e+01, Power=6.83e-01
  [eval] val_mse=3.287e-01  (n=7000)
Epoch 00155: Time=  13.5s, Loss=3.01e+00, Inv=3.01e+00, For=5.67e+01, Power=6.81e-01
  [eval] val_mse=3.299e-01  (n=7000)
Epoch 00156: Time=  13.6s, Loss=3.01e+00, Inv=3.01e+00, For=5.67e+01, Power=6.81e-01
  [eval] val_mse=3.284e-01  (n=7000)
Epoch 00157: Time=  13.6s, Loss=3.01e+00, Inv=3.01e+00, For=5.76e+01, Power=6.79e-01
  [eval] val_mse=3.276e-01  (n=7000)
Epoch 00158: Time=  13.7s, Loss=3.01e+00, Inv=3.01e+00, For=5.73e+01, Power=6.79e-01
  [eval] val_mse=3.278e-01  (n=7000)
Epoch 00159: Time=  13.7s, Loss=3.01e+00, Inv=3.01e+00, For=5.94e+01, Power=6.80e-01
  [eval] val_mse=3.289e-01  (n=7000)
Epoch 00160: Time=  13.7s, Loss=3.00e+00, Inv=3.00e+00, For=5.95e+01, Power=6.79e-01
  [eval] val_mse=3.269e-01  (n=7000)
Epoch 00161: Time=  13.8s, Loss=3.01e+00, Inv=3.01e+00, For=5.87e+01, Power=6.80e-01
  [eval] val_mse=3.280e-01  (n=7000)
Epoch 00162: Time=  13.8s, Loss=3.00e+00, Inv=3.00e+00, For=5.93e+01, Power=6.83e-01
  [eval] val_mse=3.264e-01  (n=7000)
Epoch 00163: Time=  13.9s, Loss=3.00e+00, Inv=3.00e+00, For=5.99e+01, Power=6.81e-01
  [eval] val_mse=3.260e-01  (n=7000)
Epoch 00164: Time=  13.9s, Loss=3.00e+00, Inv=3.00e+00, For=6.11e+01, Power=6.81e-01
  [eval] val_mse=3.258e-01  (n=7000)
Epoch 00165: Time=  14.0s, Loss=3.00e+00, Inv=3.00e+00, For=6.00e+01, Power=6.81e-01
  [eval] val_mse=3.267e-01  (n=7000)
Epoch 00166: Time=  14.0s, Loss=2.99e+00, Inv=2.99e+00, For=6.15e+01, Power=6.82e-01
  [eval] val_mse=3.259e-01  (n=7000)
Epoch 00167: Time=  14.1s, Loss=2.99e+00, Inv=2.99e+00, For=6.14e+01, Power=6.81e-01
  [eval] val_mse=3.271e-01  (n=7000)
Epoch 00168: Time=  14.1s, Loss=3.00e+00, Inv=3.00e+00, For=6.19e+01, Power=6.82e-01
  [eval] val_mse=3.275e-01  (n=7000)
Epoch 00169: Time=  14.2s, Loss=2.99e+00, Inv=2.99e+00, For=6.30e+01, Power=6.82e-01
  [eval] val_mse=3.269e-01  (n=7000)
Epoch 00170: Time=  14.2s, Loss=2.99e+00, Inv=2.99e+00, For=6.29e+01, Power=6.81e-01
  [eval] val_mse=3.250e-01  (n=7000)
Epoch 00171: Time=  14.3s, Loss=2.98e+00, Inv=2.98e+00, For=6.32e+01, Power=6.78e-01
  [eval] val_mse=3.249e-01  (n=7000)
Epoch 00172: Time=  14.3s, Loss=3.00e+00, Inv=3.00e+00, For=6.46e+01, Power=6.84e-01
  [eval] val_mse=3.265e-01  (n=7000)
Epoch 00173: Time=  14.4s, Loss=2.99e+00, Inv=2.99e+00, For=6.48e+01, Power=6.79e-01
  [eval] val_mse=3.273e-01  (n=7000)
Epoch 00174: Time=  14.4s, Loss=2.99e+00, Inv=2.99e+00, For=6.56e+01, Power=6.80e-01
  [eval] val_mse=3.267e-01  (n=7000)
Epoch 00175: Time=  14.5s, Loss=2.99e+00, Inv=2.99e+00, For=6.60e+01, Power=6.84e-01
  [eval] val_mse=3.288e-01  (n=7000)
Epoch 00176: Time=  14.5s, Loss=2.99e+00, Inv=2.99e+00, For=6.70e+01, Power=6.79e-01
  [eval] val_mse=3.259e-01  (n=7000)
Epoch 00177: Time=  14.6s, Loss=2.98e+00, Inv=2.98e+00, For=6.59e+01, Power=6.80e-01
  [eval] val_mse=3.255e-01  (n=7000)
Epoch 00178: Time=  14.6s, Loss=2.98e+00, Inv=2.98e+00, For=6.72e+01, Power=6.80e-01
  [eval] val_mse=3.246e-01  (n=7000)
Epoch 00179: Time=  14.7s, Loss=2.98e+00, Inv=2.98e+00, For=6.77e+01, Power=6.77e-01
  [eval] val_mse=3.241e-01  (n=7000)
Epoch 00180: Time=  14.7s, Loss=2.98e+00, Inv=2.98e+00, For=6.79e+01, Power=6.80e-01
  [eval] val_mse=3.250e-01  (n=7000)
Epoch 00181: Time=  14.8s, Loss=2.98e+00, Inv=2.98e+00, For=6.83e+01, Power=6.80e-01
  [eval] val_mse=3.267e-01  (n=7000)
Epoch 00182: Time=  14.8s, Loss=2.98e+00, Inv=2.98e+00, For=6.93e+01, Power=6.80e-01
  [eval] val_mse=3.240e-01  (n=7000)
Epoch 00183: Time=  14.9s, Loss=2.97e+00, Inv=2.97e+00, For=6.92e+01, Power=6.79e-01
  [eval] val_mse=3.241e-01  (n=7000)
Epoch 00184: Time=  14.9s, Loss=2.97e+00, Inv=2.97e+00, For=7.02e+01, Power=6.82e-01
  [eval] val_mse=3.241e-01  (n=7000)
Epoch 00185: Time=  15.0s, Loss=2.97e+00, Inv=2.97e+00, For=7.08e+01, Power=6.79e-01
  [eval] val_mse=3.242e-01  (n=7000)
Epoch 00186: Time=  15.0s, Loss=2.98e+00, Inv=2.98e+00, For=7.18e+01, Power=6.80e-01
  [eval] val_mse=3.247e-01  (n=7000)
Epoch 00187: Time=  15.1s, Loss=2.98e+00, Inv=2.98e+00, For=7.20e+01, Power=6.80e-01
  [eval] val_mse=3.241e-01  (n=7000)
Epoch 00188: Time=  15.1s, Loss=2.97e+00, Inv=2.97e+00, For=7.32e+01, Power=6.80e-01
  [eval] val_mse=3.235e-01  (n=7000)
Epoch 00189: Time=  15.2s, Loss=2.97e+00, Inv=2.97e+00, For=7.33e+01, Power=6.80e-01
  [eval] val_mse=3.225e-01  (n=7000)
Epoch 00190: Time=  15.2s, Loss=2.97e+00, Inv=2.97e+00, For=7.47e+01, Power=6.79e-01
  [eval] val_mse=3.229e-01  (n=7000)
Epoch 00191: Time=  15.3s, Loss=2.96e+00, Inv=2.96e+00, For=7.36e+01, Power=6.79e-01
  [eval] val_mse=3.235e-01  (n=7000)
Epoch 00192: Time=  15.3s, Loss=2.96e+00, Inv=2.96e+00, For=7.45e+01, Power=6.79e-01
  [eval] val_mse=3.233e-01  (n=7000)
Epoch 00193: Time=  15.3s, Loss=2.96e+00, Inv=2.96e+00, For=7.51e+01, Power=6.79e-01
  [eval] val_mse=3.244e-01  (n=7000)
Epoch 00194: Time=  15.4s, Loss=2.97e+00, Inv=2.97e+00, For=7.68e+01, Power=6.82e-01
  [eval] val_mse=3.221e-01  (n=7000)
Epoch 00195: Time=  15.4s, Loss=2.96e+00, Inv=2.96e+00, For=7.66e+01, Power=6.80e-01
  [eval] val_mse=3.233e-01  (n=7000)
Epoch 00196: Time=  15.5s, Loss=2.96e+00, Inv=2.96e+00, For=7.75e+01, Power=6.81e-01
  [eval] val_mse=3.255e-01  (n=7000)
Epoch 00197: Time=  15.5s, Loss=2.97e+00, Inv=2.97e+00, For=7.80e+01, Power=6.80e-01
  [eval] val_mse=3.231e-01  (n=7000)
Epoch 00198: Time=  15.6s, Loss=2.96e+00, Inv=2.96e+00, For=7.91e+01, Power=6.78e-01
  [eval] val_mse=3.243e-01  (n=7000)
Epoch 00199: Time=  15.6s, Loss=2.97e+00, Inv=2.97e+00, For=8.04e+01, Power=6.80e-01
  [eval] val_mse=3.226e-01  (n=7000)
Epoch 00200: Time=  15.7s, Loss=2.97e+00, Inv=2.97e+00, For=8.23e+01, Power=6.79e-01
  [eval] val_mse=3.225e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 2.317e-01
Torque MSE  = 6.612e-02
Torque RMSE = 2.571e-01
Per-joint MSE : 7.256e-02 1.598e-01 4.684e-02 1.978e-02 7.825e-02 1.942e-02
Per-joint RMSE: 2.694e-01 3.998e-01 2.164e-01 1.406e-01 2.797e-01 1.394e-01
Comp Time per Sample = 3.176e-04s / 3148.7Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-kn7658ol because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7c44804828c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:52:51.698509: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:52:53.618516: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=3.74e+03, Inv=3.74e+03, For=5.70e+00, Power=9.16e+02
  [eval] val_mse=1.989e+02  (n=7000)
Epoch 00002: Time=   5.8s, Loss=2.36e+02, Inv=2.36e+02, For=5.32e+00, Power=4.54e+01
  [eval] val_mse=4.574e+01  (n=7000)
Epoch 00003: Time=   5.9s, Loss=8.12e+01, Inv=8.12e+01, For=5.16e+00, Power=1.66e+01
  [eval] val_mse=2.062e+01  (n=7000)
Epoch 00004: Time=   5.9s, Loss=4.53e+01, Inv=4.53e+01, For=5.07e+00, Power=9.21e+00
  [eval] val_mse=1.174e+01  (n=7000)
Epoch 00005: Time=   6.0s, Loss=2.98e+01, Inv=2.98e+01, For=5.01e+00, Power=5.75e+00
  [eval] val_mse=7.501e+00  (n=7000)
Epoch 00006: Time=   6.0s, Loss=2.14e+01, Inv=2.14e+01, For=4.95e+00, Power=3.96e+00
  [eval] val_mse=5.169e+00  (n=7000)
Epoch 00007: Time=   6.1s, Loss=1.64e+01, Inv=1.64e+01, For=4.92e+00, Power=2.94e+00
  [eval] val_mse=3.810e+00  (n=7000)
Epoch 00008: Time=   6.1s, Loss=1.33e+01, Inv=1.33e+01, For=4.94e+00, Power=2.32e+00
  [eval] val_mse=2.960e+00  (n=7000)
Epoch 00009: Time=   6.2s, Loss=1.13e+01, Inv=1.13e+01, For=5.03e+00, Power=1.89e+00
  [eval] val_mse=2.389e+00  (n=7000)
Epoch 00010: Time=   6.2s, Loss=9.73e+00, Inv=9.73e+00, For=5.16e+00, Power=1.60e+00
  [eval] val_mse=1.995e+00  (n=7000)
Epoch 00011: Time=   6.3s, Loss=8.65e+00, Inv=8.65e+00, For=5.34e+00, Power=1.41e+00
  [eval] val_mse=1.699e+00  (n=7000)
Epoch 00012: Time=   6.3s, Loss=7.79e+00, Inv=7.79e+00, For=5.53e+00, Power=1.26e+00
  [eval] val_mse=1.478e+00  (n=7000)
Epoch 00013: Time=   6.4s, Loss=7.15e+00, Inv=7.15e+00, For=5.78e+00, Power=1.15e+00
  [eval] val_mse=1.312e+00  (n=7000)
Epoch 00014: Time=   6.4s, Loss=6.61e+00, Inv=6.61e+00, For=6.03e+00, Power=1.06e+00
  [eval] val_mse=1.182e+00  (n=7000)
Epoch 00015: Time=   6.5s, Loss=6.19e+00, Inv=6.19e+00, For=6.31e+00, Power=1.00e+00
  [eval] val_mse=1.075e+00  (n=7000)
Epoch 00016: Time=   6.5s, Loss=5.88e+00, Inv=5.88e+00, For=6.65e+00, Power=9.54e-01
  [eval] val_mse=9.871e-01  (n=7000)
Epoch 00017: Time=   6.6s, Loss=5.60e+00, Inv=5.60e+00, For=7.03e+00, Power=9.15e-01
  [eval] val_mse=9.207e-01  (n=7000)
Epoch 00018: Time=   6.6s, Loss=5.36e+00, Inv=5.36e+00, For=7.35e+00, Power=8.83e-01
  [eval] val_mse=8.579e-01  (n=7000)
Epoch 00019: Time=   6.7s, Loss=5.15e+00, Inv=5.15e+00, For=7.73e+00, Power=8.57e-01
  [eval] val_mse=8.108e-01  (n=7000)
Epoch 00020: Time=   6.7s, Loss=4.98e+00, Inv=4.98e+00, For=8.13e+00, Power=8.36e-01
  [eval] val_mse=7.689e-01  (n=7000)
Epoch 00021: Time=   6.8s, Loss=4.83e+00, Inv=4.83e+00, For=8.48e+00, Power=8.10e-01
  [eval] val_mse=7.328e-01  (n=7000)
Epoch 00022: Time=   6.8s, Loss=4.69e+00, Inv=4.69e+00, For=8.89e+00, Power=8.03e-01
  [eval] val_mse=7.025e-01  (n=7000)
Epoch 00023: Time=   6.9s, Loss=4.58e+00, Inv=4.58e+00, For=9.33e+00, Power=7.91e-01
  [eval] val_mse=6.773e-01  (n=7000)
Epoch 00024: Time=   6.9s, Loss=4.46e+00, Inv=4.46e+00, For=9.67e+00, Power=7.79e-01
  [eval] val_mse=6.511e-01  (n=7000)
Epoch 00025: Time=   6.9s, Loss=4.37e+00, Inv=4.37e+00, For=1.01e+01, Power=7.69e-01
  [eval] val_mse=6.327e-01  (n=7000)
Epoch 00026: Time=   7.0s, Loss=4.28e+00, Inv=4.28e+00, For=1.05e+01, Power=7.63e-01
  [eval] val_mse=6.131e-01  (n=7000)
Epoch 00027: Time=   7.0s, Loss=4.20e+00, Inv=4.20e+00, For=1.09e+01, Power=7.54e-01
  [eval] val_mse=5.991e-01  (n=7000)
Epoch 00028: Time=   7.1s, Loss=4.13e+00, Inv=4.13e+00, For=1.13e+01, Power=7.49e-01
  [eval] val_mse=5.845e-01  (n=7000)
Epoch 00029: Time=   7.1s, Loss=4.07e+00, Inv=4.07e+00, For=1.17e+01, Power=7.44e-01
  [eval] val_mse=5.705e-01  (n=7000)
Epoch 00030: Time=   7.2s, Loss=4.02e+00, Inv=4.02e+00, For=1.22e+01, Power=7.39e-01
  [eval] val_mse=5.599e-01  (n=7000)
Epoch 00031: Time=   7.2s, Loss=3.95e+00, Inv=3.95e+00, For=1.24e+01, Power=7.33e-01
  [eval] val_mse=5.492e-01  (n=7000)
Epoch 00032: Time=   7.3s, Loss=3.91e+00, Inv=3.91e+00, For=1.30e+01, Power=7.36e-01
  [eval] val_mse=5.403e-01  (n=7000)
Epoch 00033: Time=   7.3s, Loss=3.87e+00, Inv=3.87e+00, For=1.34e+01, Power=7.29e-01
  [eval] val_mse=5.328e-01  (n=7000)
Epoch 00034: Time=   7.4s, Loss=3.82e+00, Inv=3.82e+00, For=1.37e+01, Power=7.28e-01
  [eval] val_mse=5.216e-01  (n=7000)
Epoch 00035: Time=   7.4s, Loss=3.80e+00, Inv=3.80e+00, For=1.42e+01, Power=7.30e-01
  [eval] val_mse=5.146e-01  (n=7000)
Epoch 00036: Time=   7.5s, Loss=3.76e+00, Inv=3.76e+00, For=1.46e+01, Power=7.26e-01
  [eval] val_mse=5.069e-01  (n=7000)
Epoch 00037: Time=   7.5s, Loss=3.73e+00, Inv=3.73e+00, For=1.50e+01, Power=7.22e-01
  [eval] val_mse=5.018e-01  (n=7000)
Epoch 00038: Time=   7.6s, Loss=3.70e+00, Inv=3.70e+00, For=1.52e+01, Power=7.21e-01
  [eval] val_mse=4.955e-01  (n=7000)
Epoch 00039: Time=   7.6s, Loss=3.68e+00, Inv=3.68e+00, For=1.58e+01, Power=7.21e-01
  [eval] val_mse=4.891e-01  (n=7000)
Epoch 00040: Time=   7.7s, Loss=3.65e+00, Inv=3.65e+00, For=1.62e+01, Power=7.19e-01
  [eval] val_mse=4.840e-01  (n=7000)
Epoch 00041: Time=   7.7s, Loss=3.62e+00, Inv=3.62e+00, For=1.65e+01, Power=7.17e-01
  [eval] val_mse=4.788e-01  (n=7000)
Epoch 00042: Time=   7.8s, Loss=3.60e+00, Inv=3.60e+00, For=1.67e+01, Power=7.15e-01
  [eval] val_mse=4.722e-01  (n=7000)
Epoch 00043: Time=   7.8s, Loss=3.58e+00, Inv=3.58e+00, For=1.73e+01, Power=7.15e-01
  [eval] val_mse=4.696e-01  (n=7000)
Epoch 00044: Time=   7.9s, Loss=3.56e+00, Inv=3.56e+00, For=1.75e+01, Power=7.12e-01
  [eval] val_mse=4.625e-01  (n=7000)
Epoch 00045: Time=   7.9s, Loss=3.54e+00, Inv=3.54e+00, For=1.79e+01, Power=7.13e-01
  [eval] val_mse=4.589e-01  (n=7000)
Epoch 00046: Time=   8.0s, Loss=3.53e+00, Inv=3.53e+00, For=1.84e+01, Power=7.13e-01
  [eval] val_mse=4.541e-01  (n=7000)
Epoch 00047: Time=   8.0s, Loss=3.51e+00, Inv=3.51e+00, For=1.87e+01, Power=7.09e-01
  [eval] val_mse=4.510e-01  (n=7000)
Epoch 00048: Time=   8.1s, Loss=3.50e+00, Inv=3.50e+00, For=1.91e+01, Power=7.12e-01
  [eval] val_mse=4.451e-01  (n=7000)
Epoch 00049: Time=   8.1s, Loss=3.49e+00, Inv=3.49e+00, For=1.95e+01, Power=7.12e-01
  [eval] val_mse=4.433e-01  (n=7000)
Epoch 00050: Time=   8.2s, Loss=3.47e+00, Inv=3.47e+00, For=1.96e+01, Power=7.08e-01
  [eval] val_mse=4.393e-01  (n=7000)
Epoch 00051: Time=   8.2s, Loss=3.45e+00, Inv=3.45e+00, For=2.00e+01, Power=7.08e-01
  [eval] val_mse=4.356e-01  (n=7000)
Epoch 00052: Time=   8.3s, Loss=3.44e+00, Inv=3.44e+00, For=2.03e+01, Power=7.07e-01
  [eval] val_mse=4.317e-01  (n=7000)
Epoch 00053: Time=   8.3s, Loss=3.43e+00, Inv=3.43e+00, For=2.09e+01, Power=7.04e-01
  [eval] val_mse=4.306e-01  (n=7000)
Epoch 00054: Time=   8.4s, Loss=3.41e+00, Inv=3.41e+00, For=2.09e+01, Power=7.03e-01
  [eval] val_mse=4.269e-01  (n=7000)
Epoch 00055: Time=   8.4s, Loss=3.41e+00, Inv=3.41e+00, For=2.16e+01, Power=7.04e-01
  [eval] val_mse=4.233e-01  (n=7000)
Epoch 00056: Time=   8.5s, Loss=3.39e+00, Inv=3.39e+00, For=2.17e+01, Power=7.05e-01
  [eval] val_mse=4.218e-01  (n=7000)
Epoch 00057: Time=   8.5s, Loss=3.39e+00, Inv=3.39e+00, For=2.23e+01, Power=7.05e-01
  [eval] val_mse=4.188e-01  (n=7000)
Epoch 00058: Time=   8.6s, Loss=3.38e+00, Inv=3.38e+00, For=2.23e+01, Power=7.02e-01
  [eval] val_mse=4.163e-01  (n=7000)
Epoch 00059: Time=   8.6s, Loss=3.37e+00, Inv=3.37e+00, For=2.28e+01, Power=7.03e-01
  [eval] val_mse=4.129e-01  (n=7000)
Epoch 00060: Time=   8.7s, Loss=3.36e+00, Inv=3.36e+00, For=2.31e+01, Power=7.02e-01
  [eval] val_mse=4.124e-01  (n=7000)
Epoch 00061: Time=   8.7s, Loss=3.35e+00, Inv=3.35e+00, For=2.37e+01, Power=7.00e-01
  [eval] val_mse=4.081e-01  (n=7000)
Epoch 00062: Time=   8.8s, Loss=3.34e+00, Inv=3.34e+00, For=2.38e+01, Power=7.01e-01
  [eval] val_mse=4.070e-01  (n=7000)
Epoch 00063: Time=   8.8s, Loss=3.33e+00, Inv=3.33e+00, For=2.41e+01, Power=6.96e-01
  [eval] val_mse=4.043e-01  (n=7000)
Epoch 00064: Time=   8.9s, Loss=3.33e+00, Inv=3.33e+00, For=2.43e+01, Power=6.98e-01
  [eval] val_mse=4.016e-01  (n=7000)
Epoch 00065: Time=   8.9s, Loss=3.32e+00, Inv=3.32e+00, For=2.52e+01, Power=6.97e-01
  [eval] val_mse=3.996e-01  (n=7000)
Epoch 00066: Time=   9.0s, Loss=3.31e+00, Inv=3.31e+00, For=2.54e+01, Power=6.99e-01
  [eval] val_mse=3.978e-01  (n=7000)
Epoch 00067: Time=   9.0s, Loss=3.31e+00, Inv=3.31e+00, For=2.56e+01, Power=6.96e-01
  [eval] val_mse=3.961e-01  (n=7000)
Epoch 00068: Time=   9.1s, Loss=3.30e+00, Inv=3.30e+00, For=2.61e+01, Power=6.97e-01
  [eval] val_mse=3.937e-01  (n=7000)
Epoch 00069: Time=   9.1s, Loss=3.29e+00, Inv=3.29e+00, For=2.65e+01, Power=6.94e-01
  [eval] val_mse=3.932e-01  (n=7000)
Epoch 00070: Time=   9.2s, Loss=3.28e+00, Inv=3.28e+00, For=2.65e+01, Power=6.99e-01
  [eval] val_mse=3.897e-01  (n=7000)
Epoch 00071: Time=   9.2s, Loss=3.28e+00, Inv=3.28e+00, For=2.72e+01, Power=6.97e-01
  [eval] val_mse=3.891e-01  (n=7000)
Epoch 00072: Time=   9.3s, Loss=3.27e+00, Inv=3.27e+00, For=2.76e+01, Power=6.96e-01
  [eval] val_mse=3.885e-01  (n=7000)
Epoch 00073: Time=   9.3s, Loss=3.27e+00, Inv=3.27e+00, For=2.82e+01, Power=6.98e-01
  [eval] val_mse=3.864e-01  (n=7000)
Epoch 00074: Time=   9.4s, Loss=3.27e+00, Inv=3.27e+00, For=2.82e+01, Power=6.96e-01
  [eval] val_mse=3.853e-01  (n=7000)
Epoch 00075: Time=   9.4s, Loss=3.26e+00, Inv=3.26e+00, For=2.87e+01, Power=6.97e-01
  [eval] val_mse=3.823e-01  (n=7000)
Epoch 00076: Time=   9.5s, Loss=3.25e+00, Inv=3.25e+00, For=2.91e+01, Power=6.93e-01
  [eval] val_mse=3.819e-01  (n=7000)
Epoch 00077: Time=   9.5s, Loss=3.25e+00, Inv=3.25e+00, For=2.94e+01, Power=6.96e-01
  [eval] val_mse=3.799e-01  (n=7000)
Epoch 00078: Time=   9.6s, Loss=3.25e+00, Inv=3.25e+00, For=3.01e+01, Power=6.94e-01
  [eval] val_mse=3.785e-01  (n=7000)
Epoch 00079: Time=   9.6s, Loss=3.24e+00, Inv=3.24e+00, For=3.02e+01, Power=6.95e-01
  [eval] val_mse=3.773e-01  (n=7000)
Epoch 00080: Time=   9.6s, Loss=3.23e+00, Inv=3.23e+00, For=3.05e+01, Power=6.92e-01
  [eval] val_mse=3.754e-01  (n=7000)
Epoch 00081: Time=   9.7s, Loss=3.23e+00, Inv=3.23e+00, For=3.12e+01, Power=6.96e-01
  [eval] val_mse=3.748e-01  (n=7000)
Epoch 00082: Time=   9.7s, Loss=3.22e+00, Inv=3.22e+00, For=3.15e+01, Power=6.93e-01
  [eval] val_mse=3.734e-01  (n=7000)
Epoch 00083: Time=   9.8s, Loss=3.22e+00, Inv=3.22e+00, For=3.19e+01, Power=6.92e-01
  [eval] val_mse=3.720e-01  (n=7000)
Epoch 00084: Time=   9.8s, Loss=3.21e+00, Inv=3.21e+00, For=3.21e+01, Power=6.92e-01
  [eval] val_mse=3.724e-01  (n=7000)
Epoch 00085: Time=   9.9s, Loss=3.21e+00, Inv=3.21e+00, For=3.28e+01, Power=6.92e-01
  [eval] val_mse=3.707e-01  (n=7000)
Epoch 00086: Time=   9.9s, Loss=3.21e+00, Inv=3.21e+00, For=3.30e+01, Power=6.94e-01
  [eval] val_mse=3.697e-01  (n=7000)
Epoch 00087: Time=  10.0s, Loss=3.21e+00, Inv=3.21e+00, For=3.37e+01, Power=6.89e-01
  [eval] val_mse=3.679e-01  (n=7000)
Epoch 00088: Time=  10.0s, Loss=3.20e+00, Inv=3.20e+00, For=3.40e+01, Power=6.93e-01
  [eval] val_mse=3.687e-01  (n=7000)
Epoch 00089: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=3.41e+01, Power=6.90e-01
  [eval] val_mse=3.674e-01  (n=7000)
Epoch 00090: Time=  10.1s, Loss=3.19e+00, Inv=3.19e+00, For=3.45e+01, Power=6.89e-01
  [eval] val_mse=3.649e-01  (n=7000)
Epoch 00091: Time=  10.2s, Loss=3.19e+00, Inv=3.19e+00, For=3.51e+01, Power=6.92e-01
  [eval] val_mse=3.646e-01  (n=7000)
Epoch 00092: Time=  10.2s, Loss=3.19e+00, Inv=3.19e+00, For=3.56e+01, Power=6.92e-01
  [eval] val_mse=3.643e-01  (n=7000)
Epoch 00093: Time=  10.3s, Loss=3.18e+00, Inv=3.18e+00, For=3.61e+01, Power=6.89e-01
  [eval] val_mse=3.638e-01  (n=7000)
Epoch 00094: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=3.62e+01, Power=6.90e-01
  [eval] val_mse=3.625e-01  (n=7000)
Epoch 00095: Time=  10.4s, Loss=3.18e+00, Inv=3.18e+00, For=3.71e+01, Power=6.93e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00096: Time=  10.4s, Loss=3.17e+00, Inv=3.17e+00, For=3.68e+01, Power=6.92e-01
  [eval] val_mse=3.602e-01  (n=7000)
Epoch 00097: Time=  10.5s, Loss=3.16e+00, Inv=3.16e+00, For=3.75e+01, Power=6.88e-01
  [eval] val_mse=3.603e-01  (n=7000)
Epoch 00098: Time=  10.5s, Loss=3.17e+00, Inv=3.17e+00, For=3.82e+01, Power=6.89e-01
  [eval] val_mse=3.593e-01  (n=7000)
Epoch 00099: Time=  10.6s, Loss=3.16e+00, Inv=3.16e+00, For=3.86e+01, Power=6.90e-01
  [eval] val_mse=3.575e-01  (n=7000)
Epoch 00100: Time=  10.6s, Loss=3.15e+00, Inv=3.15e+00, For=3.89e+01, Power=6.90e-01
  [eval] val_mse=3.572e-01  (n=7000)
Epoch 00101: Time=  10.7s, Loss=3.15e+00, Inv=3.15e+00, For=3.96e+01, Power=6.90e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00102: Time=  10.7s, Loss=3.15e+00, Inv=3.15e+00, For=4.00e+01, Power=6.88e-01
  [eval] val_mse=3.558e-01  (n=7000)
Epoch 00103: Time=  10.8s, Loss=3.15e+00, Inv=3.15e+00, For=3.98e+01, Power=6.88e-01
  [eval] val_mse=3.550e-01  (n=7000)
Epoch 00104: Time=  10.8s, Loss=3.14e+00, Inv=3.14e+00, For=4.06e+01, Power=6.88e-01
  [eval] val_mse=3.535e-01  (n=7000)
Epoch 00105: Time=  10.9s, Loss=3.14e+00, Inv=3.14e+00, For=4.09e+01, Power=6.89e-01
  [eval] val_mse=3.540e-01  (n=7000)
Epoch 00106: Time=  10.9s, Loss=3.14e+00, Inv=3.14e+00, For=4.12e+01, Power=6.85e-01
  [eval] val_mse=3.534e-01  (n=7000)
Epoch 00107: Time=  11.0s, Loss=3.13e+00, Inv=3.13e+00, For=4.16e+01, Power=6.88e-01
  [eval] val_mse=3.529e-01  (n=7000)
Epoch 00108: Time=  11.0s, Loss=3.13e+00, Inv=3.13e+00, For=4.25e+01, Power=6.87e-01
  [eval] val_mse=3.510e-01  (n=7000)
Epoch 00109: Time=  11.1s, Loss=3.14e+00, Inv=3.14e+00, For=4.29e+01, Power=6.88e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00110: Time=  11.1s, Loss=3.12e+00, Inv=3.12e+00, For=4.33e+01, Power=6.87e-01
  [eval] val_mse=3.513e-01  (n=7000)
Epoch 00111: Time=  11.2s, Loss=3.12e+00, Inv=3.12e+00, For=4.32e+01, Power=6.88e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00112: Time=  11.2s, Loss=3.13e+00, Inv=3.13e+00, For=4.43e+01, Power=6.88e-01
  [eval] val_mse=3.487e-01  (n=7000)
Epoch 00113: Time=  11.3s, Loss=3.12e+00, Inv=3.12e+00, For=4.41e+01, Power=6.87e-01
  [eval] val_mse=3.484e-01  (n=7000)
Epoch 00114: Time=  11.3s, Loss=3.11e+00, Inv=3.11e+00, For=4.42e+01, Power=6.87e-01
  [eval] val_mse=3.474e-01  (n=7000)
Epoch 00115: Time=  11.4s, Loss=3.11e+00, Inv=3.11e+00, For=4.55e+01, Power=6.86e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00116: Time=  11.4s, Loss=3.11e+00, Inv=3.11e+00, For=4.54e+01, Power=6.87e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00117: Time=  11.5s, Loss=3.10e+00, Inv=3.10e+00, For=4.62e+01, Power=6.84e-01
  [eval] val_mse=3.463e-01  (n=7000)
Epoch 00118: Time=  11.5s, Loss=3.10e+00, Inv=3.10e+00, For=4.61e+01, Power=6.84e-01
  [eval] val_mse=3.458e-01  (n=7000)
Epoch 00119: Time=  11.6s, Loss=3.10e+00, Inv=3.10e+00, For=4.66e+01, Power=6.85e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00120: Time=  11.6s, Loss=3.10e+00, Inv=3.10e+00, For=4.68e+01, Power=6.84e-01
  [eval] val_mse=3.452e-01  (n=7000)
Epoch 00121: Time=  11.7s, Loss=3.10e+00, Inv=3.10e+00, For=4.79e+01, Power=6.88e-01
  [eval] val_mse=3.459e-01  (n=7000)
Epoch 00122: Time=  11.7s, Loss=3.10e+00, Inv=3.10e+00, For=4.77e+01, Power=6.88e-01
  [eval] val_mse=3.454e-01  (n=7000)
Epoch 00123: Time=  11.8s, Loss=3.09e+00, Inv=3.09e+00, For=4.84e+01, Power=6.86e-01
  [eval] val_mse=3.436e-01  (n=7000)
Epoch 00124: Time=  11.8s, Loss=3.10e+00, Inv=3.10e+00, For=4.86e+01, Power=6.86e-01
  [eval] val_mse=3.440e-01  (n=7000)
Epoch 00125: Time=  11.9s, Loss=3.09e+00, Inv=3.09e+00, For=4.92e+01, Power=6.84e-01
  [eval] val_mse=3.430e-01  (n=7000)
Epoch 00126: Time=  11.9s, Loss=3.08e+00, Inv=3.08e+00, For=4.93e+01, Power=6.88e-01
  [eval] val_mse=3.428e-01  (n=7000)
Epoch 00127: Time=  12.0s, Loss=3.08e+00, Inv=3.08e+00, For=4.97e+01, Power=6.86e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00128: Time=  12.0s, Loss=3.08e+00, Inv=3.08e+00, For=5.01e+01, Power=6.85e-01
  [eval] val_mse=3.434e-01  (n=7000)
Epoch 00129: Time=  12.1s, Loss=3.08e+00, Inv=3.08e+00, For=5.05e+01, Power=6.86e-01
  [eval] val_mse=3.410e-01  (n=7000)
Epoch 00130: Time=  12.1s, Loss=3.08e+00, Inv=3.08e+00, For=5.11e+01, Power=6.85e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00131: Time=  12.2s, Loss=3.07e+00, Inv=3.07e+00, For=5.17e+01, Power=6.84e-01
  [eval] val_mse=3.415e-01  (n=7000)
Epoch 00132: Time=  12.2s, Loss=3.07e+00, Inv=3.07e+00, For=5.11e+01, Power=6.84e-01
  [eval] val_mse=3.406e-01  (n=7000)
Epoch 00133: Time=  12.3s, Loss=3.07e+00, Inv=3.07e+00, For=5.26e+01, Power=6.83e-01
  [eval] val_mse=3.412e-01  (n=7000)
Epoch 00134: Time=  12.3s, Loss=3.07e+00, Inv=3.07e+00, For=5.23e+01, Power=6.83e-01
  [eval] val_mse=3.398e-01  (n=7000)
Epoch 00135: Time=  12.4s, Loss=3.06e+00, Inv=3.06e+00, For=5.29e+01, Power=6.84e-01
  [eval] val_mse=3.397e-01  (n=7000)
Epoch 00136: Time=  12.4s, Loss=3.07e+00, Inv=3.07e+00, For=5.28e+01, Power=6.82e-01
  [eval] val_mse=3.392e-01  (n=7000)
Epoch 00137: Time=  12.5s, Loss=3.06e+00, Inv=3.06e+00, For=5.39e+01, Power=6.86e-01
  [eval] val_mse=3.382e-01  (n=7000)
Epoch 00138: Time=  12.5s, Loss=3.07e+00, Inv=3.07e+00, For=5.41e+01, Power=6.84e-01
  [eval] val_mse=3.389e-01  (n=7000)
Epoch 00139: Time=  12.6s, Loss=3.06e+00, Inv=3.06e+00, For=5.49e+01, Power=6.84e-01
  [eval] val_mse=3.377e-01  (n=7000)
Epoch 00140: Time=  12.6s, Loss=3.05e+00, Inv=3.05e+00, For=5.50e+01, Power=6.81e-01
  [eval] val_mse=3.387e-01  (n=7000)
Epoch 00141: Time=  12.7s, Loss=3.06e+00, Inv=3.06e+00, For=5.53e+01, Power=6.85e-01
  [eval] val_mse=3.388e-01  (n=7000)
Epoch 00142: Time=  12.7s, Loss=3.05e+00, Inv=3.05e+00, For=5.55e+01, Power=6.84e-01
  [eval] val_mse=3.373e-01  (n=7000)
Epoch 00143: Time=  12.8s, Loss=3.05e+00, Inv=3.05e+00, For=5.59e+01, Power=6.86e-01
  [eval] val_mse=3.377e-01  (n=7000)
Epoch 00144: Time=  12.8s, Loss=3.05e+00, Inv=3.05e+00, For=5.63e+01, Power=6.83e-01
  [eval] val_mse=3.369e-01  (n=7000)
Epoch 00145: Time=  12.9s, Loss=3.06e+00, Inv=3.06e+00, For=5.76e+01, Power=6.85e-01
  [eval] val_mse=3.372e-01  (n=7000)
Epoch 00146: Time=  12.9s, Loss=3.06e+00, Inv=3.06e+00, For=5.77e+01, Power=6.85e-01
  [eval] val_mse=3.360e-01  (n=7000)
Epoch 00147: Time=  13.0s, Loss=3.05e+00, Inv=3.05e+00, For=5.74e+01, Power=6.82e-01
  [eval] val_mse=3.360e-01  (n=7000)
Epoch 00148: Time=  13.0s, Loss=3.04e+00, Inv=3.04e+00, For=5.83e+01, Power=6.81e-01
  [eval] val_mse=3.354e-01  (n=7000)
Epoch 00149: Time=  13.0s, Loss=3.04e+00, Inv=3.04e+00, For=5.85e+01, Power=6.82e-01
  [eval] val_mse=3.364e-01  (n=7000)
Epoch 00150: Time=  13.1s, Loss=3.04e+00, Inv=3.04e+00, For=5.88e+01, Power=6.83e-01
  [eval] val_mse=3.353e-01  (n=7000)
Epoch 00151: Time=  13.1s, Loss=3.04e+00, Inv=3.04e+00, For=5.91e+01, Power=6.83e-01
  [eval] val_mse=3.355e-01  (n=7000)
Epoch 00152: Time=  13.2s, Loss=3.03e+00, Inv=3.03e+00, For=5.88e+01, Power=6.82e-01
  [eval] val_mse=3.351e-01  (n=7000)
Epoch 00153: Time=  13.2s, Loss=3.03e+00, Inv=3.03e+00, For=6.07e+01, Power=6.82e-01
  [eval] val_mse=3.339e-01  (n=7000)
Epoch 00154: Time=  13.3s, Loss=3.04e+00, Inv=3.04e+00, For=6.02e+01, Power=6.83e-01
  [eval] val_mse=3.351e-01  (n=7000)
Epoch 00155: Time=  13.3s, Loss=3.03e+00, Inv=3.03e+00, For=6.06e+01, Power=6.84e-01
  [eval] val_mse=3.338e-01  (n=7000)
Epoch 00156: Time=  13.4s, Loss=3.03e+00, Inv=3.03e+00, For=6.08e+01, Power=6.85e-01
  [eval] val_mse=3.337e-01  (n=7000)
Epoch 00157: Time=  13.4s, Loss=3.03e+00, Inv=3.03e+00, For=6.08e+01, Power=6.86e-01
  [eval] val_mse=3.329e-01  (n=7000)
Epoch 00158: Time=  13.5s, Loss=3.03e+00, Inv=3.03e+00, For=6.21e+01, Power=6.82e-01
  [eval] val_mse=3.336e-01  (n=7000)
Epoch 00159: Time=  13.5s, Loss=3.03e+00, Inv=3.03e+00, For=6.17e+01, Power=6.81e-01
  [eval] val_mse=3.329e-01  (n=7000)
Epoch 00160: Time=  13.6s, Loss=3.03e+00, Inv=3.03e+00, For=6.25e+01, Power=6.83e-01
  [eval] val_mse=3.319e-01  (n=7000)
Epoch 00161: Time=  13.6s, Loss=3.02e+00, Inv=3.02e+00, For=6.25e+01, Power=6.83e-01
  [eval] val_mse=3.328e-01  (n=7000)
Epoch 00162: Time=  13.7s, Loss=3.02e+00, Inv=3.02e+00, For=6.39e+01, Power=6.82e-01
  [eval] val_mse=3.321e-01  (n=7000)
Epoch 00163: Time=  13.7s, Loss=3.02e+00, Inv=3.02e+00, For=6.29e+01, Power=6.84e-01
  [eval] val_mse=3.318e-01  (n=7000)
Epoch 00164: Time=  13.8s, Loss=3.02e+00, Inv=3.02e+00, For=6.46e+01, Power=6.81e-01
  [eval] val_mse=3.317e-01  (n=7000)
Epoch 00165: Time=  13.8s, Loss=3.02e+00, Inv=3.02e+00, For=6.41e+01, Power=6.83e-01
  [eval] val_mse=3.323e-01  (n=7000)
Epoch 00166: Time=  13.9s, Loss=3.01e+00, Inv=3.01e+00, For=6.33e+01, Power=6.83e-01
  [eval] val_mse=3.320e-01  (n=7000)
Epoch 00167: Time=  13.9s, Loss=3.01e+00, Inv=3.01e+00, For=6.64e+01, Power=6.82e-01
  [eval] val_mse=3.309e-01  (n=7000)
Epoch 00168: Time=  14.0s, Loss=3.01e+00, Inv=3.01e+00, For=6.48e+01, Power=6.84e-01
  [eval] val_mse=3.309e-01  (n=7000)
Epoch 00169: Time=  14.0s, Loss=3.01e+00, Inv=3.01e+00, For=6.59e+01, Power=6.79e-01
  [eval] val_mse=3.305e-01  (n=7000)
Epoch 00170: Time=  14.1s, Loss=3.01e+00, Inv=3.01e+00, For=6.59e+01, Power=6.82e-01
  [eval] val_mse=3.306e-01  (n=7000)
Epoch 00171: Time=  14.1s, Loss=3.02e+00, Inv=3.02e+00, For=6.75e+01, Power=6.83e-01
  [eval] val_mse=3.304e-01  (n=7000)
Epoch 00172: Time=  14.2s, Loss=3.01e+00, Inv=3.01e+00, For=6.69e+01, Power=6.81e-01
  [eval] val_mse=3.308e-01  (n=7000)
Epoch 00173: Time=  14.2s, Loss=3.01e+00, Inv=3.01e+00, For=6.77e+01, Power=6.84e-01
  [eval] val_mse=3.301e-01  (n=7000)
Epoch 00174: Time=  14.3s, Loss=3.01e+00, Inv=3.01e+00, For=6.80e+01, Power=6.84e-01
  [eval] val_mse=3.311e-01  (n=7000)
Epoch 00175: Time=  14.3s, Loss=3.01e+00, Inv=3.01e+00, For=6.90e+01, Power=6.81e-01
  [eval] val_mse=3.318e-01  (n=7000)
Epoch 00176: Time=  14.4s, Loss=3.01e+00, Inv=3.01e+00, For=6.95e+01, Power=6.84e-01
  [eval] val_mse=3.295e-01  (n=7000)
Epoch 00177: Time=  14.4s, Loss=3.00e+00, Inv=3.00e+00, For=6.87e+01, Power=6.79e-01
  [eval] val_mse=3.300e-01  (n=7000)
Epoch 00178: Time=  14.5s, Loss=2.99e+00, Inv=2.99e+00, For=6.93e+01, Power=6.81e-01
  [eval] val_mse=3.290e-01  (n=7000)
Epoch 00179: Time=  14.5s, Loss=3.00e+00, Inv=3.00e+00, For=7.06e+01, Power=6.84e-01
  [eval] val_mse=3.286e-01  (n=7000)
Epoch 00180: Time=  14.6s, Loss=3.00e+00, Inv=3.00e+00, For=7.03e+01, Power=6.81e-01
  [eval] val_mse=3.293e-01  (n=7000)
Epoch 00181: Time=  14.6s, Loss=3.00e+00, Inv=3.00e+00, For=7.04e+01, Power=6.82e-01
  [eval] val_mse=3.296e-01  (n=7000)
Epoch 00182: Time=  14.7s, Loss=2.99e+00, Inv=2.99e+00, For=7.02e+01, Power=6.77e-01
  [eval] val_mse=3.283e-01  (n=7000)
Epoch 00183: Time=  14.7s, Loss=3.00e+00, Inv=3.00e+00, For=7.16e+01, Power=6.85e-01
  [eval] val_mse=3.288e-01  (n=7000)
Epoch 00184: Time=  14.8s, Loss=2.99e+00, Inv=2.99e+00, For=7.22e+01, Power=6.80e-01
  [eval] val_mse=3.280e-01  (n=7000)
Epoch 00185: Time=  14.8s, Loss=2.99e+00, Inv=2.99e+00, For=7.23e+01, Power=6.81e-01
  [eval] val_mse=3.287e-01  (n=7000)
Epoch 00186: Time=  14.9s, Loss=2.99e+00, Inv=2.99e+00, For=7.22e+01, Power=6.79e-01
  [eval] val_mse=3.284e-01  (n=7000)
Epoch 00187: Time=  14.9s, Loss=2.99e+00, Inv=2.99e+00, For=7.40e+01, Power=6.80e-01
  [eval] val_mse=3.295e-01  (n=7000)
Epoch 00188: Time=  15.0s, Loss=2.99e+00, Inv=2.99e+00, For=7.43e+01, Power=6.81e-01
  [eval] val_mse=3.288e-01  (n=7000)
Epoch 00189: Time=  15.0s, Loss=2.99e+00, Inv=2.99e+00, For=7.37e+01, Power=6.80e-01
  [eval] val_mse=3.276e-01  (n=7000)
Epoch 00190: Time=  15.1s, Loss=2.99e+00, Inv=2.99e+00, For=7.57e+01, Power=6.79e-01
  [eval] val_mse=3.284e-01  (n=7000)
Epoch 00191: Time=  15.1s, Loss=2.99e+00, Inv=2.99e+00, For=7.39e+01, Power=6.82e-01
  [eval] val_mse=3.266e-01  (n=7000)
Epoch 00192: Time=  15.2s, Loss=2.98e+00, Inv=2.98e+00, For=7.54e+01, Power=6.82e-01
  [eval] val_mse=3.263e-01  (n=7000)
Epoch 00193: Time=  15.2s, Loss=2.98e+00, Inv=2.98e+00, For=7.55e+01, Power=6.80e-01
  [eval] val_mse=3.272e-01  (n=7000)
Epoch 00194: Time=  15.3s, Loss=2.98e+00, Inv=2.98e+00, For=7.62e+01, Power=6.80e-01
  [eval] val_mse=3.282e-01  (n=7000)
Epoch 00195: Time=  15.3s, Loss=2.99e+00, Inv=2.99e+00, For=7.70e+01, Power=6.80e-01
  [eval] val_mse=3.256e-01  (n=7000)
Epoch 00196: Time=  15.4s, Loss=2.98e+00, Inv=2.98e+00, For=7.69e+01, Power=6.80e-01
  [eval] val_mse=3.273e-01  (n=7000)
Epoch 00197: Time=  15.4s, Loss=2.98e+00, Inv=2.98e+00, For=7.97e+01, Power=6.79e-01
  [eval] val_mse=3.290e-01  (n=7000)
Epoch 00198: Time=  15.5s, Loss=2.98e+00, Inv=2.98e+00, For=7.73e+01, Power=6.82e-01
  [eval] val_mse=3.253e-01  (n=7000)
Epoch 00199: Time=  15.5s, Loss=2.98e+00, Inv=2.98e+00, For=7.83e+01, Power=6.81e-01
  [eval] val_mse=3.274e-01  (n=7000)
Epoch 00200: Time=  15.6s, Loss=2.97e+00, Inv=2.97e+00, For=7.78e+01, Power=6.81e-01
  [eval] val_mse=3.279e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 2.328e-01
Torque MSE  = 6.837e-02
Torque RMSE = 2.615e-01
Per-joint MSE : 7.408e-02 1.772e-01 4.534e-02 1.941e-02 7.767e-02 1.647e-02
Per-joint RMSE: 2.722e-01 4.210e-01 2.129e-01 1.393e-01 2.787e-01 1.284e-01
Comp Time per Sample = 3.041e-04s / 3288.5Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 1 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-tg1hgli9 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x77b8ddcaa8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:53:18.959401: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:53:20.917298: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.0s, Loss=8.20e+03, Inv=8.20e+03, For=5.73e+00, Power=6.34e+02
  [eval] val_mse=7.534e+01  (n=2997)
Epoch 00002: Time=   5.6s, Loss=3.58e+02, Inv=3.58e+02, For=5.39e+00, Power=5.35e+01
  [eval] val_mse=1.729e+01  (n=2997)
Epoch 00003: Time=   5.6s, Loss=1.28e+02, Inv=1.28e+02, For=5.15e+00, Power=1.62e+01
  [eval] val_mse=9.126e+00  (n=2997)
Epoch 00004: Time=   5.7s, Loss=7.16e+01, Inv=7.16e+01, For=4.98e+00, Power=8.56e+00
  [eval] val_mse=6.331e+00  (n=2997)
Epoch 00005: Time=   5.7s, Loss=4.63e+01, Inv=4.63e+01, For=4.88e+00, Power=5.34e+00
  [eval] val_mse=4.992e+00  (n=2997)
Epoch 00006: Time=   5.8s, Loss=3.27e+01, Inv=3.27e+01, For=4.82e+00, Power=3.70e+00
  [eval] val_mse=4.212e+00  (n=2997)
Epoch 00007: Time=   5.8s, Loss=2.44e+01, Inv=2.44e+01, For=4.79e+00, Power=2.74e+00
  [eval] val_mse=3.625e+00  (n=2997)
Epoch 00008: Time=   5.9s, Loss=1.91e+01, Inv=1.91e+01, For=4.75e+00, Power=2.15e+00
  [eval] val_mse=3.135e+00  (n=2997)
Epoch 00009: Time=   5.9s, Loss=1.55e+01, Inv=1.55e+01, For=4.71e+00, Power=1.74e+00
  [eval] val_mse=2.761e+00  (n=2997)
Epoch 00010: Time=   6.0s, Loss=1.29e+01, Inv=1.29e+01, For=4.69e+00, Power=1.47e+00
  [eval] val_mse=2.542e+00  (n=2997)
Epoch 00011: Time=   6.0s, Loss=1.11e+01, Inv=1.11e+01, For=4.76e+00, Power=1.27e+00
  [eval] val_mse=2.446e+00  (n=2997)
Epoch 00012: Time=   6.1s, Loss=9.79e+00, Inv=9.79e+00, For=4.86e+00, Power=1.13e+00
  [eval] val_mse=2.384e+00  (n=2997)
Epoch 00013: Time=   6.1s, Loss=8.83e+00, Inv=8.83e+00, For=5.03e+00, Power=1.02e+00
  [eval] val_mse=2.341e+00  (n=2997)
Epoch 00014: Time=   6.2s, Loss=8.10e+00, Inv=8.10e+00, For=5.21e+00, Power=9.45e-01
  [eval] val_mse=2.253e+00  (n=2997)
Epoch 00015: Time=   6.3s, Loss=7.49e+00, Inv=7.49e+00, For=5.39e+00, Power=8.85e-01
  [eval] val_mse=2.176e+00  (n=2997)
Epoch 00016: Time=   6.3s, Loss=7.00e+00, Inv=7.00e+00, For=5.61e+00, Power=8.38e-01
  [eval] val_mse=2.132e+00  (n=2997)
Epoch 00017: Time=   6.4s, Loss=6.60e+00, Inv=6.60e+00, For=5.82e+00, Power=8.00e-01
  [eval] val_mse=2.050e+00  (n=2997)
Epoch 00018: Time=   6.4s, Loss=6.25e+00, Inv=6.25e+00, For=6.02e+00, Power=7.71e-01
  [eval] val_mse=2.011e+00  (n=2997)
Epoch 00019: Time=   6.5s, Loss=5.96e+00, Inv=5.96e+00, For=6.24e+00, Power=7.44e-01
  [eval] val_mse=1.971e+00  (n=2997)
Epoch 00020: Time=   6.5s, Loss=5.71e+00, Inv=5.71e+00, For=6.44e+00, Power=7.22e-01
  [eval] val_mse=1.914e+00  (n=2997)
Epoch 00021: Time=   6.6s, Loss=5.49e+00, Inv=5.49e+00, For=6.70e+00, Power=7.06e-01
  [eval] val_mse=1.905e+00  (n=2997)
Epoch 00022: Time=   6.6s, Loss=5.29e+00, Inv=5.29e+00, For=6.91e+00, Power=6.90e-01
  [eval] val_mse=1.870e+00  (n=2997)
Epoch 00023: Time=   6.7s, Loss=5.12e+00, Inv=5.12e+00, For=7.12e+00, Power=6.77e-01
  [eval] val_mse=1.859e+00  (n=2997)
Epoch 00024: Time=   6.7s, Loss=4.97e+00, Inv=4.97e+00, For=7.38e+00, Power=6.66e-01
  [eval] val_mse=1.857e+00  (n=2997)
Epoch 00025: Time=   6.8s, Loss=4.84e+00, Inv=4.84e+00, For=7.59e+00, Power=6.56e-01
  [eval] val_mse=1.838e+00  (n=2997)
Epoch 00026: Time=   6.8s, Loss=4.72e+00, Inv=4.72e+00, For=7.79e+00, Power=6.47e-01
  [eval] val_mse=1.830e+00  (n=2997)
Epoch 00027: Time=   6.9s, Loss=4.60e+00, Inv=4.60e+00, For=8.01e+00, Power=6.40e-01
  [eval] val_mse=1.863e+00  (n=2997)
Epoch 00028: Time=   6.9s, Loss=4.52e+00, Inv=4.52e+00, For=8.29e+00, Power=6.34e-01
  [eval] val_mse=1.853e+00  (n=2997)
Epoch 00029: Time=   7.0s, Loss=4.43e+00, Inv=4.43e+00, For=8.49e+00, Power=6.28e-01
  [eval] val_mse=1.865e+00  (n=2997)
Epoch 00030: Time=   7.0s, Loss=4.35e+00, Inv=4.35e+00, For=8.70e+00, Power=6.22e-01
  [eval] val_mse=1.890e+00  (n=2997)
Epoch 00031: Time=   7.1s, Loss=4.28e+00, Inv=4.28e+00, For=8.96e+00, Power=6.19e-01
  [eval] val_mse=1.877e+00  (n=2997)
Epoch 00032: Time=   7.1s, Loss=4.22e+00, Inv=4.22e+00, For=9.19e+00, Power=6.15e-01
  [eval] val_mse=1.906e+00  (n=2997)
Epoch 00033: Time=   7.2s, Loss=4.17e+00, Inv=4.17e+00, For=9.42e+00, Power=6.11e-01
  [eval] val_mse=1.971e+00  (n=2997)
Epoch 00034: Time=   7.2s, Loss=4.13e+00, Inv=4.13e+00, For=9.62e+00, Power=6.09e-01
  [eval] val_mse=1.958e+00  (n=2997)
Epoch 00035: Time=   7.3s, Loss=4.08e+00, Inv=4.08e+00, For=9.87e+00, Power=6.07e-01
  [eval] val_mse=1.979e+00  (n=2997)
Epoch 00036: Time=   7.3s, Loss=4.04e+00, Inv=4.04e+00, For=1.02e+01, Power=6.04e-01
  [eval] val_mse=2.001e+00  (n=2997)
  [early_stop] stop at epoch=36 (best_epoch=26, best_val_mse=1.830e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 5.522e-01
Torque MSE  = 1.323e-01
Torque RMSE = 3.638e-01
Per-joint MSE : 1.766e-01 2.158e-01 1.679e-01 9.751e-02 6.564e-02 7.041e-02
Per-joint RMSE: 4.203e-01 4.645e-01 4.098e-01 3.123e-01 2.562e-01 2.653e-01
Comp Time per Sample = 2.431e-04s / 4114.0Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-w3h87k3j because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x72ae79c2a8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:53:36.567780: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:53:38.462301: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=6.92e+03, Inv=6.92e+03, For=5.67e+00, Power=6.17e+02
  [eval] val_mse=9.047e+01  (n=2997)
Epoch 00002: Time=   5.3s, Loss=3.55e+02, Inv=3.55e+02, For=5.35e+00, Power=6.88e+01
  [eval] val_mse=2.516e+01  (n=2997)
Epoch 00003: Time=   5.4s, Loss=1.32e+02, Inv=1.32e+02, For=5.15e+00, Power=2.44e+01
  [eval] val_mse=1.314e+01  (n=2997)
Epoch 00004: Time=   5.4s, Loss=7.40e+01, Inv=7.40e+01, For=4.97e+00, Power=1.29e+01
  [eval] val_mse=8.689e+00  (n=2997)
Epoch 00005: Time=   5.5s, Loss=4.77e+01, Inv=4.77e+01, For=4.85e+00, Power=7.90e+00
  [eval] val_mse=6.585e+00  (n=2997)
Epoch 00006: Time=   5.5s, Loss=3.35e+01, Inv=3.35e+01, For=4.76e+00, Power=5.31e+00
  [eval] val_mse=5.382e+00  (n=2997)
Epoch 00007: Time=   5.6s, Loss=2.49e+01, Inv=2.49e+01, For=4.70e+00, Power=3.84e+00
  [eval] val_mse=4.522e+00  (n=2997)
Epoch 00008: Time=   5.6s, Loss=1.94e+01, Inv=1.94e+01, For=4.69e+00, Power=2.91e+00
  [eval] val_mse=3.924e+00  (n=2997)
Epoch 00009: Time=   5.7s, Loss=1.57e+01, Inv=1.57e+01, For=4.72e+00, Power=2.30e+00
  [eval] val_mse=3.542e+00  (n=2997)
Epoch 00010: Time=   5.7s, Loss=1.32e+01, Inv=1.32e+01, For=4.80e+00, Power=1.89e+00
  [eval] val_mse=3.287e+00  (n=2997)
Epoch 00011: Time=   5.8s, Loss=1.14e+01, Inv=1.14e+01, For=4.95e+00, Power=1.61e+00
  [eval] val_mse=3.070e+00  (n=2997)
Epoch 00012: Time=   5.8s, Loss=1.00e+01, Inv=1.00e+01, For=5.14e+00, Power=1.40e+00
  [eval] val_mse=2.900e+00  (n=2997)
Epoch 00013: Time=   5.9s, Loss=9.01e+00, Inv=9.01e+00, For=5.35e+00, Power=1.24e+00
  [eval] val_mse=2.740e+00  (n=2997)
Epoch 00014: Time=   5.9s, Loss=8.20e+00, Inv=8.20e+00, For=5.57e+00, Power=1.12e+00
  [eval] val_mse=2.608e+00  (n=2997)
Epoch 00015: Time=   6.0s, Loss=7.56e+00, Inv=7.56e+00, For=5.82e+00, Power=1.03e+00
  [eval] val_mse=2.535e+00  (n=2997)
Epoch 00016: Time=   6.0s, Loss=7.03e+00, Inv=7.03e+00, For=6.07e+00, Power=9.58e-01
  [eval] val_mse=2.452e+00  (n=2997)
Epoch 00017: Time=   6.1s, Loss=6.59e+00, Inv=6.59e+00, For=6.34e+00, Power=8.97e-01
  [eval] val_mse=2.344e+00  (n=2997)
Epoch 00018: Time=   6.1s, Loss=6.23e+00, Inv=6.23e+00, For=6.61e+00, Power=8.54e-01
  [eval] val_mse=2.305e+00  (n=2997)
Epoch 00019: Time=   6.2s, Loss=5.90e+00, Inv=5.90e+00, For=6.88e+00, Power=8.12e-01
  [eval] val_mse=2.300e+00  (n=2997)
Epoch 00020: Time=   6.2s, Loss=5.63e+00, Inv=5.63e+00, For=7.17e+00, Power=7.81e-01
  [eval] val_mse=2.259e+00  (n=2997)
Epoch 00021: Time=   6.3s, Loss=5.40e+00, Inv=5.40e+00, For=7.44e+00, Power=7.55e-01
  [eval] val_mse=2.272e+00  (n=2997)
Epoch 00022: Time=   6.3s, Loss=5.19e+00, Inv=5.19e+00, For=7.74e+00, Power=7.30e-01
  [eval] val_mse=2.280e+00  (n=2997)
Epoch 00023: Time=   6.4s, Loss=5.01e+00, Inv=5.01e+00, For=7.99e+00, Power=7.10e-01
  [eval] val_mse=2.296e+00  (n=2997)
Epoch 00024: Time=   6.4s, Loss=4.86e+00, Inv=4.86e+00, For=8.30e+00, Power=6.94e-01
  [eval] val_mse=2.348e+00  (n=2997)
Epoch 00025: Time=   6.5s, Loss=4.72e+00, Inv=4.72e+00, For=8.59e+00, Power=6.80e-01
  [eval] val_mse=2.384e+00  (n=2997)
Epoch 00026: Time=   6.5s, Loss=4.59e+00, Inv=4.59e+00, For=8.85e+00, Power=6.68e-01
  [eval] val_mse=2.437e+00  (n=2997)
Epoch 00027: Time=   6.6s, Loss=4.48e+00, Inv=4.48e+00, For=9.16e+00, Power=6.57e-01
  [eval] val_mse=2.521e+00  (n=2997)
Epoch 00028: Time=   6.6s, Loss=4.39e+00, Inv=4.39e+00, For=9.42e+00, Power=6.45e-01
  [eval] val_mse=2.595e+00  (n=2997)
Epoch 00029: Time=   6.7s, Loss=4.30e+00, Inv=4.30e+00, For=9.75e+00, Power=6.40e-01
  [eval] val_mse=2.669e+00  (n=2997)
Epoch 00030: Time=   6.7s, Loss=4.24e+00, Inv=4.24e+00, For=1.01e+01, Power=6.33e-01
  [eval] val_mse=2.750e+00  (n=2997)
  [early_stop] stop at epoch=30 (best_epoch=20, best_val_mse=2.259e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 6.137e-01
Torque MSE  = 1.621e-01
Torque RMSE = 4.026e-01
Per-joint MSE : 1.861e-01 3.348e-01 2.038e-01 1.093e-01 7.074e-02 6.784e-02
Per-joint RMSE: 4.314e-01 5.786e-01 4.515e-01 3.306e-01 2.660e-01 2.605e-01
Comp Time per Sample = 2.285e-04s / 4375.8Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-97241ydk because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7017b39828c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:53:53.315010: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:53:55.221555: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.0s, Loss=2.11e+03, Inv=2.11e+03, For=5.57e+00, Power=2.86e+02
  [eval] val_mse=2.366e+01  (n=2997)
Epoch 00002: Time=   5.7s, Loss=8.98e+01, Inv=8.98e+01, For=5.26e+00, Power=1.51e+01
  [eval] val_mse=7.211e+00  (n=2997)
Epoch 00003: Time=   5.7s, Loss=3.72e+01, Inv=3.72e+01, For=5.22e+00, Power=5.88e+00
  [eval] val_mse=5.076e+00  (n=2997)
Epoch 00004: Time=   5.8s, Loss=2.33e+01, Inv=2.33e+01, For=5.31e+00, Power=3.48e+00
  [eval] val_mse=4.017e+00  (n=2997)
Epoch 00005: Time=   5.8s, Loss=1.65e+01, Inv=1.65e+01, For=5.50e+00, Power=2.37e+00
  [eval] val_mse=3.334e+00  (n=2997)
Epoch 00006: Time=   5.9s, Loss=1.25e+01, Inv=1.25e+01, For=5.75e+00, Power=1.76e+00
  [eval] val_mse=2.778e+00  (n=2997)
Epoch 00007: Time=   5.9s, Loss=1.01e+01, Inv=1.01e+01, For=6.08e+00, Power=1.41e+00
  [eval] val_mse=2.358e+00  (n=2997)
Epoch 00008: Time=   6.0s, Loss=8.44e+00, Inv=8.44e+00, For=6.44e+00, Power=1.18e+00
  [eval] val_mse=2.108e+00  (n=2997)
Epoch 00009: Time=   6.0s, Loss=7.38e+00, Inv=7.38e+00, For=6.95e+00, Power=1.03e+00
  [eval] val_mse=1.977e+00  (n=2997)
Epoch 00010: Time=   6.1s, Loss=6.66e+00, Inv=6.66e+00, For=7.52e+00, Power=9.24e-01
  [eval] val_mse=1.891e+00  (n=2997)
Epoch 00011: Time=   6.1s, Loss=6.13e+00, Inv=6.13e+00, For=8.11e+00, Power=8.52e-01
  [eval] val_mse=1.830e+00  (n=2997)
Epoch 00012: Time=   6.2s, Loss=5.74e+00, Inv=5.74e+00, For=8.73e+00, Power=7.98e-01
  [eval] val_mse=1.752e+00  (n=2997)
Epoch 00013: Time=   6.2s, Loss=5.43e+00, Inv=5.43e+00, For=9.38e+00, Power=7.60e-01
  [eval] val_mse=1.701e+00  (n=2997)
Epoch 00014: Time=   6.3s, Loss=5.19e+00, Inv=5.19e+00, For=1.00e+01, Power=7.31e-01
  [eval] val_mse=1.643e+00  (n=2997)
Epoch 00015: Time=   6.3s, Loss=4.99e+00, Inv=4.99e+00, For=1.07e+01, Power=7.08e-01
  [eval] val_mse=1.602e+00  (n=2997)
Epoch 00016: Time=   6.4s, Loss=4.83e+00, Inv=4.83e+00, For=1.13e+01, Power=6.91e-01
  [eval] val_mse=1.558e+00  (n=2997)
Epoch 00017: Time=   6.4s, Loss=4.69e+00, Inv=4.69e+00, For=1.19e+01, Power=6.77e-01
  [eval] val_mse=1.520e+00  (n=2997)
Epoch 00018: Time=   6.5s, Loss=4.58e+00, Inv=4.58e+00, For=1.27e+01, Power=6.66e-01
  [eval] val_mse=1.492e+00  (n=2997)
Epoch 00019: Time=   6.5s, Loss=4.48e+00, Inv=4.48e+00, For=1.32e+01, Power=6.56e-01
  [eval] val_mse=1.458e+00  (n=2997)
Epoch 00020: Time=   6.6s, Loss=4.38e+00, Inv=4.38e+00, For=1.38e+01, Power=6.46e-01
  [eval] val_mse=1.425e+00  (n=2997)
Epoch 00021: Time=   6.6s, Loss=4.31e+00, Inv=4.31e+00, For=1.45e+01, Power=6.42e-01
  [eval] val_mse=1.403e+00  (n=2997)
Epoch 00022: Time=   6.7s, Loss=4.24e+00, Inv=4.24e+00, For=1.51e+01, Power=6.34e-01
  [eval] val_mse=1.377e+00  (n=2997)
Epoch 00023: Time=   6.7s, Loss=4.18e+00, Inv=4.18e+00, For=1.56e+01, Power=6.31e-01
  [eval] val_mse=1.349e+00  (n=2997)
Epoch 00024: Time=   6.8s, Loss=4.12e+00, Inv=4.12e+00, For=1.63e+01, Power=6.26e-01
  [eval] val_mse=1.338e+00  (n=2997)
Epoch 00025: Time=   6.8s, Loss=4.07e+00, Inv=4.07e+00, For=1.67e+01, Power=6.22e-01
  [eval] val_mse=1.320e+00  (n=2997)
Epoch 00026: Time=   6.9s, Loss=4.02e+00, Inv=4.02e+00, For=1.74e+01, Power=6.19e-01
  [eval] val_mse=1.306e+00  (n=2997)
Epoch 00027: Time=   6.9s, Loss=3.98e+00, Inv=3.98e+00, For=1.78e+01, Power=6.15e-01
  [eval] val_mse=1.294e+00  (n=2997)
Epoch 00028: Time=   7.0s, Loss=3.94e+00, Inv=3.94e+00, For=1.84e+01, Power=6.13e-01
  [eval] val_mse=1.290e+00  (n=2997)
Epoch 00029: Time=   7.0s, Loss=3.91e+00, Inv=3.91e+00, For=1.87e+01, Power=6.09e-01
  [eval] val_mse=1.296e+00  (n=2997)
Epoch 00030: Time=   7.1s, Loss=3.87e+00, Inv=3.87e+00, For=1.94e+01, Power=6.09e-01
  [eval] val_mse=1.288e+00  (n=2997)
Epoch 00031: Time=   7.1s, Loss=3.84e+00, Inv=3.84e+00, For=1.97e+01, Power=6.06e-01
  [eval] val_mse=1.286e+00  (n=2997)
Epoch 00032: Time=   7.2s, Loss=3.82e+00, Inv=3.82e+00, For=2.02e+01, Power=6.04e-01
  [eval] val_mse=1.307e+00  (n=2997)
Epoch 00033: Time=   7.2s, Loss=3.80e+00, Inv=3.80e+00, For=2.07e+01, Power=6.03e-01
  [eval] val_mse=1.294e+00  (n=2997)
Epoch 00034: Time=   7.3s, Loss=3.76e+00, Inv=3.76e+00, For=2.09e+01, Power=6.00e-01
  [eval] val_mse=1.312e+00  (n=2997)
Epoch 00035: Time=   7.3s, Loss=3.74e+00, Inv=3.74e+00, For=2.15e+01, Power=6.01e-01
  [eval] val_mse=1.318e+00  (n=2997)
Epoch 00036: Time=   7.4s, Loss=3.73e+00, Inv=3.73e+00, For=2.18e+01, Power=5.99e-01
  [eval] val_mse=1.325e+00  (n=2997)
Epoch 00037: Time=   7.4s, Loss=3.71e+00, Inv=3.71e+00, For=2.21e+01, Power=5.98e-01
  [eval] val_mse=1.358e+00  (n=2997)
Epoch 00038: Time=   7.5s, Loss=3.69e+00, Inv=3.69e+00, For=2.25e+01, Power=5.96e-01
  [eval] val_mse=1.387e+00  (n=2997)
Epoch 00039: Time=   7.5s, Loss=3.67e+00, Inv=3.67e+00, For=2.29e+01, Power=5.96e-01
  [eval] val_mse=1.381e+00  (n=2997)
Epoch 00040: Time=   7.6s, Loss=3.65e+00, Inv=3.65e+00, For=2.32e+01, Power=5.94e-01
  [eval] val_mse=1.403e+00  (n=2997)
Epoch 00041: Time=   7.6s, Loss=3.65e+00, Inv=3.65e+00, For=2.34e+01, Power=5.93e-01
  [eval] val_mse=1.442e+00  (n=2997)
  [early_stop] stop at epoch=41 (best_epoch=31, best_val_mse=1.286e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 4.630e-01
Torque MSE  = 1.241e-01
Torque RMSE = 3.522e-01
Per-joint MSE : 1.678e-01 2.625e-01 1.450e-01 6.853e-02 5.014e-02 5.033e-02
Per-joint RMSE: 4.097e-01 5.124e-01 3.808e-01 2.618e-01 2.239e-01 2.243e-01
Comp Time per Sample = 2.171e-04s / 4606.7Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-2bkfnjrj because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x78de3e57e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:54:10.945336: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:54:12.842615: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=5.52e+03, Inv=5.52e+03, For=5.68e+00, Power=6.18e+02
  [eval] val_mse=5.818e+01  (n=2997)
Epoch 00002: Time=   5.4s, Loss=2.40e+02, Inv=2.40e+02, For=5.25e+00, Power=3.75e+01
  [eval] val_mse=1.468e+01  (n=2997)
Epoch 00003: Time=   5.4s, Loss=8.97e+01, Inv=8.97e+01, For=5.01e+00, Power=1.24e+01
  [eval] val_mse=7.777e+00  (n=2997)
Epoch 00004: Time=   5.5s, Loss=5.15e+01, Inv=5.15e+01, For=4.83e+00, Power=6.58e+00
  [eval] val_mse=5.381e+00  (n=2997)
Epoch 00005: Time=   5.5s, Loss=3.41e+01, Inv=3.41e+01, For=4.70e+00, Power=4.20e+00
  [eval] val_mse=4.245e+00  (n=2997)
Epoch 00006: Time=   5.6s, Loss=2.46e+01, Inv=2.46e+01, For=4.61e+00, Power=2.96e+00
  [eval] val_mse=3.503e+00  (n=2997)
Epoch 00007: Time=   5.6s, Loss=1.88e+01, Inv=1.88e+01, For=4.57e+00, Power=2.26e+00
  [eval] val_mse=2.970e+00  (n=2997)
Epoch 00008: Time=   5.7s, Loss=1.50e+01, Inv=1.50e+01, For=4.56e+00, Power=1.82e+00
  [eval] val_mse=2.626e+00  (n=2997)
Epoch 00009: Time=   5.7s, Loss=1.24e+01, Inv=1.24e+01, For=4.60e+00, Power=1.51e+00
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00010: Time=   5.8s, Loss=1.07e+01, Inv=1.07e+01, For=4.72e+00, Power=1.30e+00
  [eval] val_mse=2.364e+00  (n=2997)
Epoch 00011: Time=   5.8s, Loss=9.45e+00, Inv=9.45e+00, For=4.87e+00, Power=1.15e+00
  [eval] val_mse=2.279e+00  (n=2997)
Epoch 00012: Time=   5.9s, Loss=8.51e+00, Inv=8.51e+00, For=5.09e+00, Power=1.04e+00
  [eval] val_mse=2.225e+00  (n=2997)
Epoch 00013: Time=   5.9s, Loss=7.78e+00, Inv=7.78e+00, For=5.31e+00, Power=9.61e-01
  [eval] val_mse=2.156e+00  (n=2997)
Epoch 00014: Time=   6.0s, Loss=7.20e+00, Inv=7.20e+00, For=5.55e+00, Power=8.96e-01
  [eval] val_mse=2.106e+00  (n=2997)
Epoch 00015: Time=   6.0s, Loss=6.73e+00, Inv=6.73e+00, For=5.81e+00, Power=8.48e-01
  [eval] val_mse=2.055e+00  (n=2997)
Epoch 00016: Time=   6.1s, Loss=6.33e+00, Inv=6.33e+00, For=6.06e+00, Power=8.10e-01
  [eval] val_mse=2.015e+00  (n=2997)
Epoch 00017: Time=   6.1s, Loss=6.01e+00, Inv=6.01e+00, For=6.28e+00, Power=7.77e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00018: Time=   6.2s, Loss=5.73e+00, Inv=5.73e+00, For=6.60e+00, Power=7.50e-01
  [eval] val_mse=1.975e+00  (n=2997)
Epoch 00019: Time=   6.2s, Loss=5.50e+00, Inv=5.50e+00, For=6.85e+00, Power=7.29e-01
  [eval] val_mse=1.937e+00  (n=2997)
Epoch 00020: Time=   6.3s, Loss=5.29e+00, Inv=5.29e+00, For=7.12e+00, Power=7.10e-01
  [eval] val_mse=1.917e+00  (n=2997)
Epoch 00021: Time=   6.3s, Loss=5.12e+00, Inv=5.12e+00, For=7.36e+00, Power=6.95e-01
  [eval] val_mse=1.890e+00  (n=2997)
Epoch 00022: Time=   6.4s, Loss=4.96e+00, Inv=4.96e+00, For=7.59e+00, Power=6.82e-01
  [eval] val_mse=1.858e+00  (n=2997)
Epoch 00023: Time=   6.4s, Loss=4.83e+00, Inv=4.83e+00, For=7.89e+00, Power=6.70e-01
  [eval] val_mse=1.870e+00  (n=2997)
Epoch 00024: Time=   6.5s, Loss=4.71e+00, Inv=4.71e+00, For=8.12e+00, Power=6.61e-01
  [eval] val_mse=1.836e+00  (n=2997)
Epoch 00025: Time=   6.5s, Loss=4.60e+00, Inv=4.60e+00, For=8.36e+00, Power=6.52e-01
  [eval] val_mse=1.824e+00  (n=2997)
Epoch 00026: Time=   6.6s, Loss=4.50e+00, Inv=4.50e+00, For=8.61e+00, Power=6.43e-01
  [eval] val_mse=1.819e+00  (n=2997)
Epoch 00027: Time=   6.6s, Loss=4.42e+00, Inv=4.42e+00, For=8.85e+00, Power=6.38e-01
  [eval] val_mse=1.817e+00  (n=2997)
Epoch 00028: Time=   6.7s, Loss=4.35e+00, Inv=4.35e+00, For=9.09e+00, Power=6.33e-01
  [eval] val_mse=1.843e+00  (n=2997)
Epoch 00029: Time=   6.7s, Loss=4.28e+00, Inv=4.28e+00, For=9.27e+00, Power=6.26e-01
  [eval] val_mse=1.815e+00  (n=2997)
Epoch 00030: Time=   6.8s, Loss=4.22e+00, Inv=4.22e+00, For=9.50e+00, Power=6.24e-01
  [eval] val_mse=1.814e+00  (n=2997)
Epoch 00031: Time=   6.8s, Loss=4.16e+00, Inv=4.16e+00, For=9.81e+00, Power=6.19e-01
  [eval] val_mse=1.833e+00  (n=2997)
Epoch 00032: Time=   6.9s, Loss=4.12e+00, Inv=4.12e+00, For=9.93e+00, Power=6.16e-01
  [eval] val_mse=1.807e+00  (n=2997)
Epoch 00033: Time=   6.9s, Loss=4.07e+00, Inv=4.07e+00, For=1.02e+01, Power=6.13e-01
  [eval] val_mse=1.810e+00  (n=2997)
Epoch 00034: Time=   7.0s, Loss=4.02e+00, Inv=4.02e+00, For=1.04e+01, Power=6.11e-01
  [eval] val_mse=1.828e+00  (n=2997)
Epoch 00035: Time=   7.0s, Loss=3.99e+00, Inv=3.99e+00, For=1.06e+01, Power=6.08e-01
  [eval] val_mse=1.855e+00  (n=2997)
Epoch 00036: Time=   7.1s, Loss=3.96e+00, Inv=3.96e+00, For=1.08e+01, Power=6.06e-01
  [eval] val_mse=1.867e+00  (n=2997)
Epoch 00037: Time=   7.1s, Loss=3.93e+00, Inv=3.93e+00, For=1.10e+01, Power=6.05e-01
  [eval] val_mse=1.873e+00  (n=2997)
Epoch 00038: Time=   7.2s, Loss=3.90e+00, Inv=3.90e+00, For=1.12e+01, Power=6.03e-01
  [eval] val_mse=1.881e+00  (n=2997)
Epoch 00039: Time=   7.2s, Loss=3.87e+00, Inv=3.87e+00, For=1.14e+01, Power=6.02e-01
  [eval] val_mse=1.873e+00  (n=2997)
Epoch 00040: Time=   7.3s, Loss=3.85e+00, Inv=3.85e+00, For=1.16e+01, Power=6.00e-01
  [eval] val_mse=1.894e+00  (n=2997)
Epoch 00041: Time=   7.3s, Loss=3.84e+00, Inv=3.84e+00, For=1.17e+01, Power=5.99e-01
  [eval] val_mse=1.931e+00  (n=2997)
Epoch 00042: Time=   7.4s, Loss=3.81e+00, Inv=3.81e+00, For=1.19e+01, Power=5.97e-01
  [eval] val_mse=1.920e+00  (n=2997)
  [early_stop] stop at epoch=42 (best_epoch=32, best_val_mse=1.807e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 5.488e-01
Torque MSE  = 1.334e-01
Torque RMSE = 3.653e-01
Per-joint MSE : 1.768e-01 2.979e-01 1.373e-01 7.909e-02 5.254e-02 5.693e-02
Per-joint RMSE: 4.205e-01 5.458e-01 3.706e-01 2.812e-01 2.292e-01 2.386e-01
Comp Time per Sample = 2.184e-04s / 4578.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256_d3 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-x8jtts9p because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3', 'n_width': 256, 'n_depth': 3, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7ec73fb168c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
  type = structured
  hp_preset = lutter_like_256_d3
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:54:28.471575: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:54:30.363751: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=1.06e+04, Inv=1.06e+04, For=5.77e+00, Power=1.47e+03
  [eval] val_mse=1.342e+02  (n=2997)
Epoch 00002: Time=   5.5s, Loss=4.27e+02, Inv=4.27e+02, For=5.43e+00, Power=9.59e+01
  [eval] val_mse=3.775e+01  (n=2997)
Epoch 00003: Time=   5.6s, Loss=1.56e+02, Inv=1.56e+02, For=5.17e+00, Power=3.02e+01
  [eval] val_mse=1.966e+01  (n=2997)
Epoch 00004: Time=   5.7s, Loss=8.75e+01, Inv=8.75e+01, For=4.97e+00, Power=1.50e+01
  [eval] val_mse=1.297e+01  (n=2997)
Epoch 00005: Time=   5.7s, Loss=5.65e+01, Inv=5.65e+01, For=4.81e+00, Power=8.88e+00
  [eval] val_mse=9.662e+00  (n=2997)
Epoch 00006: Time=   5.8s, Loss=3.95e+01, Inv=3.95e+01, For=4.67e+00, Power=5.83e+00
  [eval] val_mse=7.760e+00  (n=2997)
Epoch 00007: Time=   5.8s, Loss=2.93e+01, Inv=2.93e+01, For=4.56e+00, Power=4.15e+00
  [eval] val_mse=6.443e+00  (n=2997)
Epoch 00008: Time=   5.9s, Loss=2.27e+01, Inv=2.27e+01, For=4.49e+00, Power=3.10e+00
  [eval] val_mse=5.587e+00  (n=2997)
Epoch 00009: Time=   5.9s, Loss=1.83e+01, Inv=1.83e+01, For=4.46e+00, Power=2.43e+00
  [eval] val_mse=5.023e+00  (n=2997)
Epoch 00010: Time=   6.0s, Loss=1.53e+01, Inv=1.53e+01, For=4.48e+00, Power=1.97e+00
  [eval] val_mse=4.640e+00  (n=2997)
Epoch 00011: Time=   6.0s, Loss=1.32e+01, Inv=1.32e+01, For=4.58e+00, Power=1.67e+00
  [eval] val_mse=4.334e+00  (n=2997)
Epoch 00012: Time=   6.1s, Loss=1.16e+01, Inv=1.16e+01, For=4.71e+00, Power=1.44e+00
  [eval] val_mse=4.035e+00  (n=2997)
Epoch 00013: Time=   6.1s, Loss=1.04e+01, Inv=1.04e+01, For=4.87e+00, Power=1.28e+00
  [eval] val_mse=3.778e+00  (n=2997)
Epoch 00014: Time=   6.2s, Loss=9.43e+00, Inv=9.43e+00, For=5.06e+00, Power=1.15e+00
  [eval] val_mse=3.544e+00  (n=2997)
Epoch 00015: Time=   6.2s, Loss=8.65e+00, Inv=8.65e+00, For=5.29e+00, Power=1.06e+00
  [eval] val_mse=3.370e+00  (n=2997)
Epoch 00016: Time=   6.3s, Loss=8.01e+00, Inv=8.01e+00, For=5.53e+00, Power=9.85e-01
  [eval] val_mse=3.184e+00  (n=2997)
Epoch 00017: Time=   6.3s, Loss=7.48e+00, Inv=7.48e+00, For=5.78e+00, Power=9.26e-01
  [eval] val_mse=3.030e+00  (n=2997)
Epoch 00018: Time=   6.4s, Loss=7.04e+00, Inv=7.04e+00, For=6.05e+00, Power=8.77e-01
  [eval] val_mse=2.910e+00  (n=2997)
Epoch 00019: Time=   6.4s, Loss=6.67e+00, Inv=6.67e+00, For=6.38e+00, Power=8.40e-01
  [eval] val_mse=2.829e+00  (n=2997)
Epoch 00020: Time=   6.5s, Loss=6.34e+00, Inv=6.34e+00, For=6.66e+00, Power=8.07e-01
  [eval] val_mse=2.736e+00  (n=2997)
Epoch 00021: Time=   6.5s, Loss=6.06e+00, Inv=6.06e+00, For=6.97e+00, Power=7.80e-01
  [eval] val_mse=2.659e+00  (n=2997)
Epoch 00022: Time=   6.6s, Loss=5.82e+00, Inv=5.82e+00, For=7.27e+00, Power=7.57e-01
  [eval] val_mse=2.605e+00  (n=2997)
Epoch 00023: Time=   6.6s, Loss=5.61e+00, Inv=5.61e+00, For=7.59e+00, Power=7.37e-01
  [eval] val_mse=2.528e+00  (n=2997)
Epoch 00024: Time=   6.7s, Loss=5.42e+00, Inv=5.42e+00, For=7.92e+00, Power=7.20e-01
  [eval] val_mse=2.457e+00  (n=2997)
Epoch 00025: Time=   6.7s, Loss=5.26e+00, Inv=5.26e+00, For=8.22e+00, Power=7.06e-01
  [eval] val_mse=2.431e+00  (n=2997)
Epoch 00026: Time=   6.8s, Loss=5.11e+00, Inv=5.11e+00, For=8.56e+00, Power=6.94e-01
  [eval] val_mse=2.377e+00  (n=2997)
Epoch 00027: Time=   6.8s, Loss=4.98e+00, Inv=4.98e+00, For=8.87e+00, Power=6.84e-01
  [eval] val_mse=2.336e+00  (n=2997)
Epoch 00028: Time=   6.9s, Loss=4.87e+00, Inv=4.87e+00, For=9.13e+00, Power=6.74e-01
  [eval] val_mse=2.298e+00  (n=2997)
Epoch 00029: Time=   6.9s, Loss=4.77e+00, Inv=4.77e+00, For=9.44e+00, Power=6.67e-01
  [eval] val_mse=2.265e+00  (n=2997)
Epoch 00030: Time=   7.0s, Loss=4.68e+00, Inv=4.68e+00, For=9.78e+00, Power=6.60e-01
  [eval] val_mse=2.236e+00  (n=2997)
Epoch 00031: Time=   7.0s, Loss=4.59e+00, Inv=4.59e+00, For=1.01e+01, Power=6.53e-01
  [eval] val_mse=2.182e+00  (n=2997)
Epoch 00032: Time=   7.1s, Loss=4.52e+00, Inv=4.52e+00, For=1.04e+01, Power=6.48e-01
  [eval] val_mse=2.147e+00  (n=2997)
Epoch 00033: Time=   7.1s, Loss=4.46e+00, Inv=4.46e+00, For=1.07e+01, Power=6.43e-01
  [eval] val_mse=2.134e+00  (n=2997)
Epoch 00034: Time=   7.2s, Loss=4.39e+00, Inv=4.39e+00, For=1.09e+01, Power=6.39e-01
  [eval] val_mse=2.141e+00  (n=2997)
Epoch 00035: Time=   7.2s, Loss=4.34e+00, Inv=4.34e+00, For=1.12e+01, Power=6.36e-01
  [eval] val_mse=2.083e+00  (n=2997)
Epoch 00036: Time=   7.3s, Loss=4.29e+00, Inv=4.29e+00, For=1.16e+01, Power=6.34e-01
  [eval] val_mse=2.045e+00  (n=2997)
Epoch 00037: Time=   7.3s, Loss=4.25e+00, Inv=4.25e+00, For=1.18e+01, Power=6.30e-01
  [eval] val_mse=2.049e+00  (n=2997)
Epoch 00038: Time=   7.4s, Loss=4.20e+00, Inv=4.20e+00, For=1.21e+01, Power=6.28e-01
  [eval] val_mse=2.049e+00  (n=2997)
Epoch 00039: Time=   7.4s, Loss=4.17e+00, Inv=4.17e+00, For=1.23e+01, Power=6.24e-01
  [eval] val_mse=2.004e+00  (n=2997)
Epoch 00040: Time=   7.5s, Loss=4.13e+00, Inv=4.13e+00, For=1.25e+01, Power=6.23e-01
  [eval] val_mse=1.989e+00  (n=2997)
Epoch 00041: Time=   7.5s, Loss=4.10e+00, Inv=4.10e+00, For=1.28e+01, Power=6.22e-01
  [eval] val_mse=2.023e+00  (n=2997)
Epoch 00042: Time=   7.6s, Loss=4.07e+00, Inv=4.07e+00, For=1.30e+01, Power=6.20e-01
  [eval] val_mse=1.956e+00  (n=2997)
Epoch 00043: Time=   7.6s, Loss=4.04e+00, Inv=4.04e+00, For=1.32e+01, Power=6.18e-01
  [eval] val_mse=1.966e+00  (n=2997)
Epoch 00044: Time=   7.7s, Loss=4.02e+00, Inv=4.02e+00, For=1.35e+01, Power=6.17e-01
  [eval] val_mse=1.941e+00  (n=2997)
Epoch 00045: Time=   7.7s, Loss=3.99e+00, Inv=3.99e+00, For=1.36e+01, Power=6.16e-01
  [eval] val_mse=1.953e+00  (n=2997)
Epoch 00046: Time=   7.8s, Loss=3.97e+00, Inv=3.97e+00, For=1.40e+01, Power=6.15e-01
  [eval] val_mse=1.913e+00  (n=2997)
Epoch 00047: Time=   7.8s, Loss=3.94e+00, Inv=3.94e+00, For=1.41e+01, Power=6.13e-01
  [eval] val_mse=1.894e+00  (n=2997)
Epoch 00048: Time=   7.9s, Loss=3.92e+00, Inv=3.92e+00, For=1.43e+01, Power=6.11e-01
  [eval] val_mse=1.907e+00  (n=2997)
Epoch 00049: Time=   7.9s, Loss=3.90e+00, Inv=3.90e+00, For=1.45e+01, Power=6.11e-01
  [eval] val_mse=1.862e+00  (n=2997)
Epoch 00050: Time=   8.0s, Loss=3.88e+00, Inv=3.88e+00, For=1.47e+01, Power=6.11e-01
  [eval] val_mse=1.869e+00  (n=2997)
Epoch 00051: Time=   8.0s, Loss=3.87e+00, Inv=3.87e+00, For=1.49e+01, Power=6.10e-01
  [eval] val_mse=1.861e+00  (n=2997)
Epoch 00052: Time=   8.1s, Loss=3.85e+00, Inv=3.85e+00, For=1.51e+01, Power=6.09e-01
  [eval] val_mse=1.876e+00  (n=2997)
Epoch 00053: Time=   8.1s, Loss=3.84e+00, Inv=3.84e+00, For=1.52e+01, Power=6.08e-01
  [eval] val_mse=1.834e+00  (n=2997)
Epoch 00054: Time=   8.2s, Loss=3.82e+00, Inv=3.82e+00, For=1.54e+01, Power=6.07e-01
  [eval] val_mse=1.833e+00  (n=2997)
Epoch 00055: Time=   8.2s, Loss=3.81e+00, Inv=3.81e+00, For=1.56e+01, Power=6.07e-01
  [eval] val_mse=1.819e+00  (n=2997)
Epoch 00056: Time=   8.3s, Loss=3.79e+00, Inv=3.79e+00, For=1.57e+01, Power=6.06e-01
  [eval] val_mse=1.847e+00  (n=2997)
Epoch 00057: Time=   8.3s, Loss=3.78e+00, Inv=3.78e+00, For=1.59e+01, Power=6.06e-01
  [eval] val_mse=1.843e+00  (n=2997)
Epoch 00058: Time=   8.4s, Loss=3.77e+00, Inv=3.77e+00, For=1.61e+01, Power=6.04e-01
  [eval] val_mse=1.810e+00  (n=2997)
Epoch 00059: Time=   8.4s, Loss=3.75e+00, Inv=3.75e+00, For=1.62e+01, Power=6.02e-01
  [eval] val_mse=1.817e+00  (n=2997)
Epoch 00060: Time=   8.5s, Loss=3.74e+00, Inv=3.74e+00, For=1.64e+01, Power=6.03e-01
  [eval] val_mse=1.815e+00  (n=2997)
Epoch 00061: Time=   8.5s, Loss=3.73e+00, Inv=3.73e+00, For=1.66e+01, Power=6.01e-01
  [eval] val_mse=1.780e+00  (n=2997)
Epoch 00062: Time=   8.6s, Loss=3.72e+00, Inv=3.72e+00, For=1.68e+01, Power=6.02e-01
  [eval] val_mse=1.788e+00  (n=2997)
Epoch 00063: Time=   8.6s, Loss=3.71e+00, Inv=3.71e+00, For=1.69e+01, Power=6.01e-01
  [eval] val_mse=1.789e+00  (n=2997)
Epoch 00064: Time=   8.7s, Loss=3.70e+00, Inv=3.70e+00, For=1.71e+01, Power=6.01e-01
  [eval] val_mse=1.762e+00  (n=2997)
Epoch 00065: Time=   8.7s, Loss=3.69e+00, Inv=3.69e+00, For=1.71e+01, Power=5.99e-01
  [eval] val_mse=1.741e+00  (n=2997)
Epoch 00066: Time=   8.8s, Loss=3.68e+00, Inv=3.68e+00, For=1.74e+01, Power=5.99e-01
  [eval] val_mse=1.762e+00  (n=2997)
Epoch 00067: Time=   8.8s, Loss=3.66e+00, Inv=3.66e+00, For=1.75e+01, Power=5.99e-01
  [eval] val_mse=1.766e+00  (n=2997)
Epoch 00068: Time=   8.9s, Loss=3.66e+00, Inv=3.66e+00, For=1.77e+01, Power=5.97e-01
  [eval] val_mse=1.758e+00  (n=2997)
Epoch 00069: Time=   8.9s, Loss=3.65e+00, Inv=3.65e+00, For=1.79e+01, Power=5.98e-01
  [eval] val_mse=1.748e+00  (n=2997)
Epoch 00070: Time=   9.0s, Loss=3.64e+00, Inv=3.64e+00, For=1.80e+01, Power=5.98e-01
  [eval] val_mse=1.742e+00  (n=2997)
Epoch 00071: Time=   9.0s, Loss=3.63e+00, Inv=3.63e+00, For=1.81e+01, Power=5.97e-01
  [eval] val_mse=1.725e+00  (n=2997)
Epoch 00072: Time=   9.1s, Loss=3.63e+00, Inv=3.63e+00, For=1.83e+01, Power=5.96e-01
  [eval] val_mse=1.719e+00  (n=2997)
Epoch 00073: Time=   9.1s, Loss=3.62e+00, Inv=3.62e+00, For=1.85e+01, Power=5.96e-01
  [eval] val_mse=1.731e+00  (n=2997)
Epoch 00074: Time=   9.2s, Loss=3.61e+00, Inv=3.61e+00, For=1.87e+01, Power=5.95e-01
  [eval] val_mse=1.694e+00  (n=2997)
Epoch 00075: Time=   9.2s, Loss=3.60e+00, Inv=3.60e+00, For=1.88e+01, Power=5.94e-01
  [eval] val_mse=1.696e+00  (n=2997)
Epoch 00076: Time=   9.3s, Loss=3.60e+00, Inv=3.60e+00, For=1.88e+01, Power=5.94e-01
  [eval] val_mse=1.704e+00  (n=2997)
Epoch 00077: Time=   9.3s, Loss=3.59e+00, Inv=3.59e+00, For=1.91e+01, Power=5.94e-01
  [eval] val_mse=1.711e+00  (n=2997)
Epoch 00078: Time=   9.4s, Loss=3.58e+00, Inv=3.58e+00, For=1.93e+01, Power=5.93e-01
  [eval] val_mse=1.696e+00  (n=2997)
Epoch 00079: Time=   9.4s, Loss=3.58e+00, Inv=3.58e+00, For=1.95e+01, Power=5.93e-01
  [eval] val_mse=1.710e+00  (n=2997)
Epoch 00080: Time=   9.5s, Loss=3.57e+00, Inv=3.57e+00, For=1.96e+01, Power=5.93e-01
  [eval] val_mse=1.715e+00  (n=2997)
Epoch 00081: Time=   9.5s, Loss=3.56e+00, Inv=3.56e+00, For=1.98e+01, Power=5.92e-01
  [eval] val_mse=1.665e+00  (n=2997)
Epoch 00082: Time=   9.6s, Loss=3.56e+00, Inv=3.56e+00, For=1.99e+01, Power=5.92e-01
  [eval] val_mse=1.699e+00  (n=2997)
Epoch 00083: Time=   9.6s, Loss=3.55e+00, Inv=3.55e+00, For=2.01e+01, Power=5.92e-01
  [eval] val_mse=1.679e+00  (n=2997)
Epoch 00084: Time=   9.7s, Loss=3.55e+00, Inv=3.55e+00, For=2.03e+01, Power=5.91e-01
  [eval] val_mse=1.670e+00  (n=2997)
Epoch 00085: Time=   9.7s, Loss=3.54e+00, Inv=3.54e+00, For=2.05e+01, Power=5.90e-01
  [eval] val_mse=1.685e+00  (n=2997)
Epoch 00086: Time=   9.8s, Loss=3.53e+00, Inv=3.53e+00, For=2.07e+01, Power=5.90e-01
  [eval] val_mse=1.679e+00  (n=2997)
Epoch 00087: Time=   9.8s, Loss=3.53e+00, Inv=3.53e+00, For=2.07e+01, Power=5.90e-01
  [eval] val_mse=1.655e+00  (n=2997)
Epoch 00088: Time=   9.9s, Loss=3.53e+00, Inv=3.53e+00, For=2.10e+01, Power=5.89e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00089: Time=   9.9s, Loss=3.52e+00, Inv=3.52e+00, For=2.11e+01, Power=5.89e-01
  [eval] val_mse=1.673e+00  (n=2997)
Epoch 00090: Time=  10.0s, Loss=3.52e+00, Inv=3.52e+00, For=2.13e+01, Power=5.89e-01
  [eval] val_mse=1.645e+00  (n=2997)
Epoch 00091: Time=  10.0s, Loss=3.51e+00, Inv=3.51e+00, For=2.15e+01, Power=5.87e-01
  [eval] val_mse=1.648e+00  (n=2997)
Epoch 00092: Time=  10.1s, Loss=3.51e+00, Inv=3.51e+00, For=2.16e+01, Power=5.87e-01
  [eval] val_mse=1.655e+00  (n=2997)
Epoch 00093: Time=  10.1s, Loss=3.51e+00, Inv=3.51e+00, For=2.18e+01, Power=5.88e-01
  [eval] val_mse=1.638e+00  (n=2997)
Epoch 00094: Time=  10.2s, Loss=3.50e+00, Inv=3.50e+00, For=2.21e+01, Power=5.88e-01
  [eval] val_mse=1.621e+00  (n=2997)
Epoch 00095: Time=  10.2s, Loss=3.50e+00, Inv=3.50e+00, For=2.22e+01, Power=5.86e-01
  [eval] val_mse=1.647e+00  (n=2997)
Epoch 00096: Time=  10.3s, Loss=3.49e+00, Inv=3.49e+00, For=2.24e+01, Power=5.88e-01
  [eval] val_mse=1.642e+00  (n=2997)
Epoch 00097: Time=  10.3s, Loss=3.49e+00, Inv=3.49e+00, For=2.27e+01, Power=5.87e-01
  [eval] val_mse=1.604e+00  (n=2997)
Epoch 00098: Time=  10.4s, Loss=3.49e+00, Inv=3.49e+00, For=2.25e+01, Power=5.87e-01
  [eval] val_mse=1.612e+00  (n=2997)
Epoch 00099: Time=  10.4s, Loss=3.48e+00, Inv=3.48e+00, For=2.29e+01, Power=5.87e-01
  [eval] val_mse=1.637e+00  (n=2997)
Epoch 00100: Time=  10.5s, Loss=3.49e+00, Inv=3.49e+00, For=2.31e+01, Power=5.85e-01
  [eval] val_mse=1.631e+00  (n=2997)
Epoch 00101: Time=  10.5s, Loss=3.47e+00, Inv=3.47e+00, For=2.33e+01, Power=5.86e-01
  [eval] val_mse=1.615e+00  (n=2997)
Epoch 00102: Time=  10.6s, Loss=3.47e+00, Inv=3.47e+00, For=2.34e+01, Power=5.85e-01
  [eval] val_mse=1.631e+00  (n=2997)
Epoch 00103: Time=  10.6s, Loss=3.47e+00, Inv=3.47e+00, For=2.37e+01, Power=5.84e-01
  [eval] val_mse=1.599e+00  (n=2997)
Epoch 00104: Time=  10.7s, Loss=3.46e+00, Inv=3.46e+00, For=2.38e+01, Power=5.84e-01
  [eval] val_mse=1.614e+00  (n=2997)
Epoch 00105: Time=  10.7s, Loss=3.46e+00, Inv=3.46e+00, For=2.39e+01, Power=5.85e-01
  [eval] val_mse=1.582e+00  (n=2997)
Epoch 00106: Time=  10.8s, Loss=3.45e+00, Inv=3.45e+00, For=2.42e+01, Power=5.85e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00107: Time=  10.8s, Loss=3.45e+00, Inv=3.45e+00, For=2.44e+01, Power=5.85e-01
  [eval] val_mse=1.606e+00  (n=2997)
Epoch 00108: Time=  10.9s, Loss=3.45e+00, Inv=3.45e+00, For=2.44e+01, Power=5.84e-01
  [eval] val_mse=1.574e+00  (n=2997)
Epoch 00109: Time=  10.9s, Loss=3.45e+00, Inv=3.45e+00, For=2.49e+01, Power=5.84e-01
  [eval] val_mse=1.581e+00  (n=2997)
Epoch 00110: Time=  11.0s, Loss=3.44e+00, Inv=3.44e+00, For=2.48e+01, Power=5.84e-01
  [eval] val_mse=1.599e+00  (n=2997)
Epoch 00111: Time=  11.0s, Loss=3.44e+00, Inv=3.44e+00, For=2.51e+01, Power=5.84e-01
  [eval] val_mse=1.576e+00  (n=2997)
Epoch 00112: Time=  11.1s, Loss=3.44e+00, Inv=3.44e+00, For=2.53e+01, Power=5.84e-01
  [eval] val_mse=1.603e+00  (n=2997)
Epoch 00113: Time=  11.1s, Loss=3.43e+00, Inv=3.43e+00, For=2.52e+01, Power=5.83e-01
  [eval] val_mse=1.584e+00  (n=2997)
Epoch 00114: Time=  11.2s, Loss=3.43e+00, Inv=3.43e+00, For=2.58e+01, Power=5.84e-01
  [eval] val_mse=1.564e+00  (n=2997)
Epoch 00115: Time=  11.2s, Loss=3.43e+00, Inv=3.43e+00, For=2.59e+01, Power=5.84e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00116: Time=  11.3s, Loss=3.43e+00, Inv=3.43e+00, For=2.59e+01, Power=5.84e-01
  [eval] val_mse=1.552e+00  (n=2997)
Epoch 00117: Time=  11.3s, Loss=3.43e+00, Inv=3.43e+00, For=2.62e+01, Power=5.84e-01
  [eval] val_mse=1.550e+00  (n=2997)
Epoch 00118: Time=  11.4s, Loss=3.42e+00, Inv=3.42e+00, For=2.62e+01, Power=5.84e-01
  [eval] val_mse=1.581e+00  (n=2997)
Epoch 00119: Time=  11.4s, Loss=3.43e+00, Inv=3.43e+00, For=2.66e+01, Power=5.83e-01
  [eval] val_mse=1.535e+00  (n=2997)
Epoch 00120: Time=  11.5s, Loss=3.42e+00, Inv=3.42e+00, For=2.66e+01, Power=5.83e-01
  [eval] val_mse=1.571e+00  (n=2997)
Epoch 00121: Time=  11.5s, Loss=3.42e+00, Inv=3.42e+00, For=2.70e+01, Power=5.84e-01
  [eval] val_mse=1.563e+00  (n=2997)
Epoch 00122: Time=  11.6s, Loss=3.41e+00, Inv=3.41e+00, For=2.69e+01, Power=5.83e-01
  [eval] val_mse=1.546e+00  (n=2997)
Epoch 00123: Time=  11.6s, Loss=3.41e+00, Inv=3.41e+00, For=2.74e+01, Power=5.83e-01
  [eval] val_mse=1.547e+00  (n=2997)
Epoch 00124: Time=  11.7s, Loss=3.41e+00, Inv=3.41e+00, For=2.72e+01, Power=5.83e-01
  [eval] val_mse=1.541e+00  (n=2997)
Epoch 00125: Time=  11.7s, Loss=3.41e+00, Inv=3.41e+00, For=2.78e+01, Power=5.82e-01
  [eval] val_mse=1.551e+00  (n=2997)
Epoch 00126: Time=  11.8s, Loss=3.41e+00, Inv=3.41e+00, For=2.79e+01, Power=5.81e-01
  [eval] val_mse=1.555e+00  (n=2997)
Epoch 00127: Time=  11.8s, Loss=3.40e+00, Inv=3.40e+00, For=2.78e+01, Power=5.82e-01
  [eval] val_mse=1.553e+00  (n=2997)
Epoch 00128: Time=  11.9s, Loss=3.40e+00, Inv=3.40e+00, For=2.82e+01, Power=5.82e-01
  [eval] val_mse=1.551e+00  (n=2997)
Epoch 00129: Time=  11.9s, Loss=3.40e+00, Inv=3.40e+00, For=2.82e+01, Power=5.82e-01
  [eval] val_mse=1.557e+00  (n=2997)
  [early_stop] stop at epoch=129 (best_epoch=119, best_val_mse=1.535e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3
  [val] Torque RMSE = 5.058e-01
Torque MSE  = 1.221e-01
Torque RMSE = 3.494e-01
Per-joint MSE : 1.559e-01 3.524e-01 1.170e-01 3.569e-02 3.808e-02 3.354e-02
Per-joint RMSE: 3.949e-01 5.937e-01 3.420e-01 1.889e-01 1.952e-01 1.831e-01
Comp Time per Sample = 2.327e-04s / 4298.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_d3_actsoftplus_b1024_lr1e-4_wd1e-5_w256_d3/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 0 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-yhmt6y4c because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7543fc5868c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:54:51.929035: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:54:53.751828: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=1.52e+04, Inv=1.52e+04, For=5.97e+00, Power=2.91e+03
  [eval] val_mse=5.210e+02  (n=7000)
Epoch 00002: Time=   5.5s, Loss=2.27e+03, Inv=2.27e+03, For=5.84e+00, Power=6.07e+02
  [eval] val_mse=2.164e+02  (n=7000)
Epoch 00003: Time=   5.5s, Loss=9.69e+02, Inv=9.69e+02, For=5.71e+00, Power=2.49e+02
  [eval] val_mse=1.306e+02  (n=7000)
Epoch 00004: Time=   5.5s, Loss=5.59e+02, Inv=5.59e+02, For=5.67e+00, Power=1.40e+02
  [eval] val_mse=9.023e+01  (n=7000)
Epoch 00005: Time=   5.6s, Loss=3.64e+02, Inv=3.64e+02, For=5.65e+00, Power=8.89e+01
  [eval] val_mse=6.678e+01  (n=7000)
Epoch 00006: Time=   5.6s, Loss=2.54e+02, Inv=2.54e+02, For=5.63e+00, Power=6.08e+01
  [eval] val_mse=5.193e+01  (n=7000)
Epoch 00007: Time=   5.6s, Loss=1.86e+02, Inv=1.86e+02, For=5.60e+00, Power=4.33e+01
  [eval] val_mse=4.175e+01  (n=7000)
Epoch 00008: Time=   5.7s, Loss=1.43e+02, Inv=1.43e+02, For=5.64e+00, Power=3.24e+01
  [eval] val_mse=3.468e+01  (n=7000)
Epoch 00009: Time=   5.7s, Loss=1.13e+02, Inv=1.13e+02, For=5.73e+00, Power=2.55e+01
  [eval] val_mse=2.922e+01  (n=7000)
Epoch 00010: Time=   5.7s, Loss=9.14e+01, Inv=9.14e+01, For=5.80e+00, Power=2.00e+01
  [eval] val_mse=2.507e+01  (n=7000)
Epoch 00011: Time=   5.8s, Loss=7.59e+01, Inv=7.59e+01, For=5.90e+00, Power=1.63e+01
  [eval] val_mse=2.177e+01  (n=7000)
Epoch 00012: Time=   5.8s, Loss=6.38e+01, Inv=6.38e+01, For=6.01e+00, Power=1.34e+01
  [eval] val_mse=1.916e+01  (n=7000)
Epoch 00013: Time=   5.8s, Loss=5.47e+01, Inv=5.47e+01, For=6.15e+00, Power=1.12e+01
  [eval] val_mse=1.703e+01  (n=7000)
Epoch 00014: Time=   5.9s, Loss=4.74e+01, Inv=4.74e+01, For=6.27e+00, Power=9.54e+00
  [eval] val_mse=1.523e+01  (n=7000)
Epoch 00015: Time=   5.9s, Loss=4.17e+01, Inv=4.17e+01, For=6.44e+00, Power=8.26e+00
  [eval] val_mse=1.372e+01  (n=7000)
Epoch 00016: Time=   6.0s, Loss=3.71e+01, Inv=3.71e+01, For=6.60e+00, Power=7.21e+00
  [eval] val_mse=1.242e+01  (n=7000)
Epoch 00017: Time=   6.0s, Loss=3.32e+01, Inv=3.32e+01, For=6.79e+00, Power=6.32e+00
  [eval] val_mse=1.131e+01  (n=7000)
Epoch 00018: Time=   6.0s, Loss=2.99e+01, Inv=2.99e+01, For=6.96e+00, Power=5.57e+00
  [eval] val_mse=1.034e+01  (n=7000)
Epoch 00019: Time=   6.1s, Loss=2.72e+01, Inv=2.72e+01, For=7.15e+00, Power=4.98e+00
  [eval] val_mse=9.490e+00  (n=7000)
Epoch 00020: Time=   6.1s, Loss=2.49e+01, Inv=2.49e+01, For=7.33e+00, Power=4.51e+00
  [eval] val_mse=8.737e+00  (n=7000)
Epoch 00021: Time=   6.1s, Loss=2.28e+01, Inv=2.28e+01, For=7.54e+00, Power=4.09e+00
  [eval] val_mse=8.078e+00  (n=7000)
Epoch 00022: Time=   6.2s, Loss=2.11e+01, Inv=2.11e+01, For=7.70e+00, Power=3.71e+00
  [eval] val_mse=7.485e+00  (n=7000)
Epoch 00023: Time=   6.2s, Loss=1.96e+01, Inv=1.96e+01, For=7.93e+00, Power=3.39e+00
  [eval] val_mse=6.952e+00  (n=7000)
Epoch 00024: Time=   6.2s, Loss=1.83e+01, Inv=1.83e+01, For=8.14e+00, Power=3.13e+00
  [eval] val_mse=6.466e+00  (n=7000)
Epoch 00025: Time=   6.3s, Loss=1.71e+01, Inv=1.71e+01, For=8.35e+00, Power=2.90e+00
  [eval] val_mse=6.036e+00  (n=7000)
Epoch 00026: Time=   6.3s, Loss=1.60e+01, Inv=1.60e+01, For=8.58e+00, Power=2.69e+00
  [eval] val_mse=5.642e+00  (n=7000)
Epoch 00027: Time=   6.3s, Loss=1.51e+01, Inv=1.51e+01, For=8.82e+00, Power=2.51e+00
  [eval] val_mse=5.292e+00  (n=7000)
Epoch 00028: Time=   6.4s, Loss=1.43e+01, Inv=1.43e+01, For=9.06e+00, Power=2.37e+00
  [eval] val_mse=4.971e+00  (n=7000)
Epoch 00029: Time=   6.4s, Loss=1.36e+01, Inv=1.36e+01, For=9.29e+00, Power=2.22e+00
  [eval] val_mse=4.669e+00  (n=7000)
Epoch 00030: Time=   6.4s, Loss=1.29e+01, Inv=1.29e+01, For=9.50e+00, Power=2.08e+00
  [eval] val_mse=4.399e+00  (n=7000)
Epoch 00031: Time=   6.5s, Loss=1.22e+01, Inv=1.22e+01, For=9.74e+00, Power=1.96e+00
  [eval] val_mse=4.153e+00  (n=7000)
Epoch 00032: Time=   6.5s, Loss=1.17e+01, Inv=1.17e+01, For=9.96e+00, Power=1.86e+00
  [eval] val_mse=3.929e+00  (n=7000)
Epoch 00033: Time=   6.5s, Loss=1.12e+01, Inv=1.12e+01, For=1.02e+01, Power=1.78e+00
  [eval] val_mse=3.719e+00  (n=7000)
Epoch 00034: Time=   6.6s, Loss=1.07e+01, Inv=1.07e+01, For=1.05e+01, Power=1.69e+00
  [eval] val_mse=3.524e+00  (n=7000)
Epoch 00035: Time=   6.6s, Loss=1.03e+01, Inv=1.03e+01, For=1.07e+01, Power=1.62e+00
  [eval] val_mse=3.347e+00  (n=7000)
Epoch 00036: Time=   6.6s, Loss=9.90e+00, Inv=9.90e+00, For=1.10e+01, Power=1.56e+00
  [eval] val_mse=3.183e+00  (n=7000)
Epoch 00037: Time=   6.7s, Loss=9.53e+00, Inv=9.53e+00, For=1.12e+01, Power=1.49e+00
  [eval] val_mse=3.031e+00  (n=7000)
Epoch 00038: Time=   6.7s, Loss=9.21e+00, Inv=9.21e+00, For=1.15e+01, Power=1.43e+00
  [eval] val_mse=2.892e+00  (n=7000)
Epoch 00039: Time=   6.7s, Loss=8.89e+00, Inv=8.89e+00, For=1.18e+01, Power=1.39e+00
  [eval] val_mse=2.758e+00  (n=7000)
Epoch 00040: Time=   6.8s, Loss=8.61e+00, Inv=8.61e+00, For=1.21e+01, Power=1.34e+00
  [eval] val_mse=2.638e+00  (n=7000)
Epoch 00041: Time=   6.8s, Loss=8.32e+00, Inv=8.32e+00, For=1.24e+01, Power=1.29e+00
  [eval] val_mse=2.524e+00  (n=7000)
Epoch 00042: Time=   6.8s, Loss=8.10e+00, Inv=8.10e+00, For=1.27e+01, Power=1.26e+00
  [eval] val_mse=2.419e+00  (n=7000)
Epoch 00043: Time=   6.9s, Loss=7.86e+00, Inv=7.86e+00, For=1.30e+01, Power=1.22e+00
  [eval] val_mse=2.321e+00  (n=7000)
Epoch 00044: Time=   6.9s, Loss=7.66e+00, Inv=7.66e+00, For=1.34e+01, Power=1.18e+00
  [eval] val_mse=2.231e+00  (n=7000)
Epoch 00045: Time=   6.9s, Loss=7.46e+00, Inv=7.46e+00, For=1.37e+01, Power=1.16e+00
  [eval] val_mse=2.141e+00  (n=7000)
Epoch 00046: Time=   7.0s, Loss=7.25e+00, Inv=7.25e+00, For=1.41e+01, Power=1.12e+00
  [eval] val_mse=2.062e+00  (n=7000)
Epoch 00047: Time=   7.0s, Loss=7.07e+00, Inv=7.07e+00, For=1.45e+01, Power=1.10e+00
  [eval] val_mse=1.985e+00  (n=7000)
Epoch 00048: Time=   7.0s, Loss=6.91e+00, Inv=6.91e+00, For=1.49e+01, Power=1.07e+00
  [eval] val_mse=1.915e+00  (n=7000)
Epoch 00049: Time=   7.1s, Loss=6.75e+00, Inv=6.75e+00, For=1.53e+01, Power=1.04e+00
  [eval] val_mse=1.847e+00  (n=7000)
Epoch 00050: Time=   7.1s, Loss=6.63e+00, Inv=6.63e+00, For=1.58e+01, Power=1.03e+00
  [eval] val_mse=1.785e+00  (n=7000)
Epoch 00051: Time=   7.1s, Loss=6.48e+00, Inv=6.48e+00, For=1.61e+01, Power=1.01e+00
  [eval] val_mse=1.725e+00  (n=7000)
Epoch 00052: Time=   7.2s, Loss=6.36e+00, Inv=6.36e+00, For=1.66e+01, Power=9.86e-01
  [eval] val_mse=1.667e+00  (n=7000)
Epoch 00053: Time=   7.2s, Loss=6.24e+00, Inv=6.24e+00, For=1.71e+01, Power=9.78e-01
  [eval] val_mse=1.615e+00  (n=7000)
Epoch 00054: Time=   7.2s, Loss=6.13e+00, Inv=6.13e+00, For=1.77e+01, Power=9.58e-01
  [eval] val_mse=1.564e+00  (n=7000)
Epoch 00055: Time=   7.3s, Loss=6.02e+00, Inv=6.02e+00, For=1.82e+01, Power=9.45e-01
  [eval] val_mse=1.517e+00  (n=7000)
Epoch 00056: Time=   7.3s, Loss=5.92e+00, Inv=5.92e+00, For=1.87e+01, Power=9.29e-01
  [eval] val_mse=1.471e+00  (n=7000)
Epoch 00057: Time=   7.3s, Loss=5.82e+00, Inv=5.82e+00, For=1.92e+01, Power=9.15e-01
  [eval] val_mse=1.427e+00  (n=7000)
Epoch 00058: Time=   7.4s, Loss=5.75e+00, Inv=5.75e+00, For=1.99e+01, Power=8.98e-01
  [eval] val_mse=1.386e+00  (n=7000)
Epoch 00059: Time=   7.4s, Loss=5.65e+00, Inv=5.65e+00, For=2.04e+01, Power=8.85e-01
  [eval] val_mse=1.347e+00  (n=7000)
Epoch 00060: Time=   7.4s, Loss=5.58e+00, Inv=5.58e+00, For=2.11e+01, Power=8.81e-01
  [eval] val_mse=1.309e+00  (n=7000)
Epoch 00061: Time=   7.5s, Loss=5.50e+00, Inv=5.50e+00, For=2.18e+01, Power=8.73e-01
  [eval] val_mse=1.274e+00  (n=7000)
Epoch 00062: Time=   7.5s, Loss=5.43e+00, Inv=5.43e+00, For=2.24e+01, Power=8.59e-01
  [eval] val_mse=1.240e+00  (n=7000)
Epoch 00063: Time=   7.5s, Loss=5.35e+00, Inv=5.35e+00, For=2.31e+01, Power=8.50e-01
  [eval] val_mse=1.208e+00  (n=7000)
Epoch 00064: Time=   7.6s, Loss=5.29e+00, Inv=5.29e+00, For=2.37e+01, Power=8.42e-01
  [eval] val_mse=1.177e+00  (n=7000)
Epoch 00065: Time=   7.6s, Loss=5.22e+00, Inv=5.22e+00, For=2.45e+01, Power=8.37e-01
  [eval] val_mse=1.148e+00  (n=7000)
Epoch 00066: Time=   7.6s, Loss=5.15e+00, Inv=5.15e+00, For=2.51e+01, Power=8.27e-01
  [eval] val_mse=1.121e+00  (n=7000)
Epoch 00067: Time=   7.7s, Loss=5.10e+00, Inv=5.10e+00, For=2.59e+01, Power=8.21e-01
  [eval] val_mse=1.094e+00  (n=7000)
Epoch 00068: Time=   7.7s, Loss=5.04e+00, Inv=5.04e+00, For=2.66e+01, Power=8.09e-01
  [eval] val_mse=1.069e+00  (n=7000)
Epoch 00069: Time=   7.8s, Loss=4.99e+00, Inv=4.99e+00, For=2.74e+01, Power=8.03e-01
  [eval] val_mse=1.044e+00  (n=7000)
Epoch 00070: Time=   7.8s, Loss=4.94e+00, Inv=4.94e+00, For=2.82e+01, Power=8.02e-01
  [eval] val_mse=1.020e+00  (n=7000)
Epoch 00071: Time=   7.8s, Loss=4.89e+00, Inv=4.89e+00, For=2.91e+01, Power=7.91e-01
  [eval] val_mse=9.978e-01  (n=7000)
Epoch 00072: Time=   7.9s, Loss=4.85e+00, Inv=4.85e+00, For=2.99e+01, Power=7.91e-01
  [eval] val_mse=9.771e-01  (n=7000)
Epoch 00073: Time=   7.9s, Loss=4.79e+00, Inv=4.79e+00, For=3.07e+01, Power=7.83e-01
  [eval] val_mse=9.564e-01  (n=7000)
Epoch 00074: Time=   7.9s, Loss=4.76e+00, Inv=4.76e+00, For=3.16e+01, Power=7.79e-01
  [eval] val_mse=9.377e-01  (n=7000)
Epoch 00075: Time=   8.0s, Loss=4.72e+00, Inv=4.72e+00, For=3.25e+01, Power=7.78e-01
  [eval] val_mse=9.191e-01  (n=7000)
Epoch 00076: Time=   8.0s, Loss=4.67e+00, Inv=4.67e+00, For=3.35e+01, Power=7.71e-01
  [eval] val_mse=9.009e-01  (n=7000)
Epoch 00077: Time=   8.0s, Loss=4.62e+00, Inv=4.62e+00, For=3.42e+01, Power=7.64e-01
  [eval] val_mse=8.831e-01  (n=7000)
Epoch 00078: Time=   8.1s, Loss=4.59e+00, Inv=4.59e+00, For=3.54e+01, Power=7.61e-01
  [eval] val_mse=8.661e-01  (n=7000)
Epoch 00079: Time=   8.1s, Loss=4.55e+00, Inv=4.55e+00, For=3.62e+01, Power=7.57e-01
  [eval] val_mse=8.501e-01  (n=7000)
Epoch 00080: Time=   8.1s, Loss=4.52e+00, Inv=4.52e+00, For=3.74e+01, Power=7.55e-01
  [eval] val_mse=8.350e-01  (n=7000)
Epoch 00081: Time=   8.2s, Loss=4.48e+00, Inv=4.48e+00, For=3.82e+01, Power=7.54e-01
  [eval] val_mse=8.211e-01  (n=7000)
Epoch 00082: Time=   8.2s, Loss=4.46e+00, Inv=4.46e+00, For=3.96e+01, Power=7.50e-01
  [eval] val_mse=8.065e-01  (n=7000)
Epoch 00083: Time=   8.2s, Loss=4.43e+00, Inv=4.43e+00, For=4.07e+01, Power=7.49e-01
  [eval] val_mse=7.932e-01  (n=7000)
Epoch 00084: Time=   8.3s, Loss=4.40e+00, Inv=4.40e+00, For=4.18e+01, Power=7.43e-01
  [eval] val_mse=7.803e-01  (n=7000)
Epoch 00085: Time=   8.3s, Loss=4.36e+00, Inv=4.36e+00, For=4.31e+01, Power=7.40e-01
  [eval] val_mse=7.681e-01  (n=7000)
Epoch 00086: Time=   8.3s, Loss=4.34e+00, Inv=4.34e+00, For=4.41e+01, Power=7.38e-01
  [eval] val_mse=7.558e-01  (n=7000)
Epoch 00087: Time=   8.4s, Loss=4.30e+00, Inv=4.30e+00, For=4.53e+01, Power=7.35e-01
  [eval] val_mse=7.438e-01  (n=7000)
Epoch 00088: Time=   8.4s, Loss=4.28e+00, Inv=4.28e+00, For=4.65e+01, Power=7.33e-01
  [eval] val_mse=7.324e-01  (n=7000)
Epoch 00089: Time=   8.4s, Loss=4.25e+00, Inv=4.25e+00, For=4.77e+01, Power=7.32e-01
  [eval] val_mse=7.218e-01  (n=7000)
Epoch 00090: Time=   8.5s, Loss=4.23e+00, Inv=4.23e+00, For=4.91e+01, Power=7.30e-01
  [eval] val_mse=7.117e-01  (n=7000)
Epoch 00091: Time=   8.5s, Loss=4.20e+00, Inv=4.20e+00, For=5.04e+01, Power=7.27e-01
  [eval] val_mse=7.016e-01  (n=7000)
Epoch 00092: Time=   8.5s, Loss=4.18e+00, Inv=4.18e+00, For=5.16e+01, Power=7.26e-01
  [eval] val_mse=6.923e-01  (n=7000)
Epoch 00093: Time=   8.6s, Loss=4.15e+00, Inv=4.15e+00, For=5.30e+01, Power=7.22e-01
  [eval] val_mse=6.831e-01  (n=7000)
Epoch 00094: Time=   8.6s, Loss=4.13e+00, Inv=4.13e+00, For=5.46e+01, Power=7.23e-01
  [eval] val_mse=6.736e-01  (n=7000)
Epoch 00095: Time=   8.6s, Loss=4.10e+00, Inv=4.10e+00, For=5.59e+01, Power=7.18e-01
  [eval] val_mse=6.651e-01  (n=7000)
Epoch 00096: Time=   8.7s, Loss=4.08e+00, Inv=4.08e+00, For=5.76e+01, Power=7.15e-01
  [eval] val_mse=6.572e-01  (n=7000)
Epoch 00097: Time=   8.7s, Loss=4.06e+00, Inv=4.06e+00, For=5.88e+01, Power=7.15e-01
  [eval] val_mse=6.488e-01  (n=7000)
Epoch 00098: Time=   8.7s, Loss=4.04e+00, Inv=4.04e+00, For=6.07e+01, Power=7.15e-01
  [eval] val_mse=6.409e-01  (n=7000)
Epoch 00099: Time=   8.8s, Loss=4.02e+00, Inv=4.02e+00, For=6.22e+01, Power=7.15e-01
  [eval] val_mse=6.339e-01  (n=7000)
Epoch 00100: Time=   8.8s, Loss=4.00e+00, Inv=4.00e+00, For=6.39e+01, Power=7.14e-01
  [eval] val_mse=6.264e-01  (n=7000)
Epoch 00101: Time=   8.8s, Loss=3.98e+00, Inv=3.98e+00, For=6.54e+01, Power=7.10e-01
  [eval] val_mse=6.198e-01  (n=7000)
Epoch 00102: Time=   8.9s, Loss=3.96e+00, Inv=3.96e+00, For=6.71e+01, Power=7.07e-01
  [eval] val_mse=6.127e-01  (n=7000)
Epoch 00103: Time=   8.9s, Loss=3.94e+00, Inv=3.94e+00, For=6.87e+01, Power=7.05e-01
  [eval] val_mse=6.066e-01  (n=7000)
Epoch 00104: Time=   8.9s, Loss=3.92e+00, Inv=3.92e+00, For=7.12e+01, Power=7.06e-01
  [eval] val_mse=6.005e-01  (n=7000)
Epoch 00105: Time=   9.0s, Loss=3.91e+00, Inv=3.91e+00, For=7.23e+01, Power=7.07e-01
  [eval] val_mse=5.941e-01  (n=7000)
Epoch 00106: Time=   9.0s, Loss=3.88e+00, Inv=3.88e+00, For=7.42e+01, Power=7.04e-01
  [eval] val_mse=5.885e-01  (n=7000)
Epoch 00107: Time=   9.0s, Loss=3.86e+00, Inv=3.86e+00, For=7.60e+01, Power=7.02e-01
  [eval] val_mse=5.824e-01  (n=7000)
Epoch 00108: Time=   9.1s, Loss=3.85e+00, Inv=3.85e+00, For=7.83e+01, Power=7.03e-01
  [eval] val_mse=5.767e-01  (n=7000)
Epoch 00109: Time=   9.1s, Loss=3.83e+00, Inv=3.83e+00, For=8.01e+01, Power=7.02e-01
  [eval] val_mse=5.719e-01  (n=7000)
Epoch 00110: Time=   9.1s, Loss=3.81e+00, Inv=3.81e+00, For=8.19e+01, Power=6.97e-01
  [eval] val_mse=5.667e-01  (n=7000)
Epoch 00111: Time=   9.2s, Loss=3.80e+00, Inv=3.80e+00, For=8.38e+01, Power=7.00e-01
  [eval] val_mse=5.621e-01  (n=7000)
Epoch 00112: Time=   9.2s, Loss=3.79e+00, Inv=3.79e+00, For=8.65e+01, Power=7.01e-01
  [eval] val_mse=5.572e-01  (n=7000)
Epoch 00113: Time=   9.2s, Loss=3.78e+00, Inv=3.78e+00, For=8.74e+01, Power=7.01e-01
  [eval] val_mse=5.525e-01  (n=7000)
Epoch 00114: Time=   9.3s, Loss=3.76e+00, Inv=3.76e+00, For=9.04e+01, Power=6.98e-01
  [eval] val_mse=5.484e-01  (n=7000)
Epoch 00115: Time=   9.3s, Loss=3.75e+00, Inv=3.75e+00, For=9.23e+01, Power=6.96e-01
  [eval] val_mse=5.440e-01  (n=7000)
Epoch 00116: Time=   9.3s, Loss=3.73e+00, Inv=3.73e+00, For=9.44e+01, Power=6.95e-01
  [eval] val_mse=5.393e-01  (n=7000)
Epoch 00117: Time=   9.4s, Loss=3.72e+00, Inv=3.72e+00, For=9.70e+01, Power=6.94e-01
  [eval] val_mse=5.350e-01  (n=7000)
Epoch 00118: Time=   9.4s, Loss=3.71e+00, Inv=3.71e+00, For=9.90e+01, Power=6.92e-01
  [eval] val_mse=5.311e-01  (n=7000)
Epoch 00119: Time=   9.5s, Loss=3.69e+00, Inv=3.69e+00, For=1.02e+02, Power=6.92e-01
  [eval] val_mse=5.274e-01  (n=7000)
Epoch 00120: Time=   9.5s, Loss=3.68e+00, Inv=3.68e+00, For=1.04e+02, Power=6.94e-01
  [eval] val_mse=5.237e-01  (n=7000)
Epoch 00121: Time=   9.5s, Loss=3.67e+00, Inv=3.67e+00, For=1.06e+02, Power=6.95e-01
  [eval] val_mse=5.195e-01  (n=7000)
Epoch 00122: Time=   9.6s, Loss=3.66e+00, Inv=3.66e+00, For=1.09e+02, Power=6.93e-01
  [eval] val_mse=5.159e-01  (n=7000)
Epoch 00123: Time=   9.6s, Loss=3.64e+00, Inv=3.64e+00, For=1.11e+02, Power=6.92e-01
  [eval] val_mse=5.127e-01  (n=7000)
Epoch 00124: Time=   9.6s, Loss=3.64e+00, Inv=3.64e+00, For=1.13e+02, Power=6.94e-01
  [eval] val_mse=5.094e-01  (n=7000)
Epoch 00125: Time=   9.7s, Loss=3.62e+00, Inv=3.62e+00, For=1.16e+02, Power=6.92e-01
  [eval] val_mse=5.058e-01  (n=7000)
Epoch 00126: Time=   9.7s, Loss=3.61e+00, Inv=3.61e+00, For=1.19e+02, Power=6.93e-01
  [eval] val_mse=5.033e-01  (n=7000)
Epoch 00127: Time=   9.7s, Loss=3.60e+00, Inv=3.60e+00, For=1.21e+02, Power=6.91e-01
  [eval] val_mse=4.996e-01  (n=7000)
Epoch 00128: Time=   9.8s, Loss=3.59e+00, Inv=3.59e+00, For=1.25e+02, Power=6.89e-01
  [eval] val_mse=4.965e-01  (n=7000)
Epoch 00129: Time=   9.8s, Loss=3.58e+00, Inv=3.58e+00, For=1.26e+02, Power=6.89e-01
  [eval] val_mse=4.936e-01  (n=7000)
Epoch 00130: Time=   9.8s, Loss=3.58e+00, Inv=3.58e+00, For=1.30e+02, Power=6.89e-01
  [eval] val_mse=4.911e-01  (n=7000)
Epoch 00131: Time=   9.9s, Loss=3.56e+00, Inv=3.56e+00, For=1.32e+02, Power=6.91e-01
  [eval] val_mse=4.879e-01  (n=7000)
Epoch 00132: Time=   9.9s, Loss=3.55e+00, Inv=3.55e+00, For=1.35e+02, Power=6.88e-01
  [eval] val_mse=4.851e-01  (n=7000)
Epoch 00133: Time=   9.9s, Loss=3.54e+00, Inv=3.54e+00, For=1.37e+02, Power=6.89e-01
  [eval] val_mse=4.826e-01  (n=7000)
Epoch 00134: Time=  10.0s, Loss=3.53e+00, Inv=3.53e+00, For=1.39e+02, Power=6.88e-01
  [eval] val_mse=4.800e-01  (n=7000)
Epoch 00135: Time=  10.0s, Loss=3.52e+00, Inv=3.52e+00, For=1.43e+02, Power=6.86e-01
  [eval] val_mse=4.773e-01  (n=7000)
Epoch 00136: Time=  10.0s, Loss=3.52e+00, Inv=3.52e+00, For=1.46e+02, Power=6.89e-01
  [eval] val_mse=4.748e-01  (n=7000)
Epoch 00137: Time=  10.1s, Loss=3.51e+00, Inv=3.51e+00, For=1.48e+02, Power=6.88e-01
  [eval] val_mse=4.722e-01  (n=7000)
Epoch 00138: Time=  10.1s, Loss=3.50e+00, Inv=3.50e+00, For=1.53e+02, Power=6.84e-01
  [eval] val_mse=4.694e-01  (n=7000)
Epoch 00139: Time=  10.1s, Loss=3.49e+00, Inv=3.49e+00, For=1.54e+02, Power=6.87e-01
  [eval] val_mse=4.676e-01  (n=7000)
Epoch 00140: Time=  10.2s, Loss=3.49e+00, Inv=3.49e+00, For=1.57e+02, Power=6.88e-01
  [eval] val_mse=4.655e-01  (n=7000)
Epoch 00141: Time=  10.2s, Loss=3.48e+00, Inv=3.48e+00, For=1.61e+02, Power=6.88e-01
  [eval] val_mse=4.626e-01  (n=7000)
Epoch 00142: Time=  10.2s, Loss=3.47e+00, Inv=3.47e+00, For=1.64e+02, Power=6.87e-01
  [eval] val_mse=4.603e-01  (n=7000)
Epoch 00143: Time=  10.3s, Loss=3.46e+00, Inv=3.46e+00, For=1.66e+02, Power=6.85e-01
  [eval] val_mse=4.580e-01  (n=7000)
Epoch 00144: Time=  10.3s, Loss=3.46e+00, Inv=3.46e+00, For=1.70e+02, Power=6.87e-01
  [eval] val_mse=4.561e-01  (n=7000)
Epoch 00145: Time=  10.3s, Loss=3.45e+00, Inv=3.45e+00, For=1.72e+02, Power=6.86e-01
  [eval] val_mse=4.539e-01  (n=7000)
Epoch 00146: Time=  10.4s, Loss=3.44e+00, Inv=3.44e+00, For=1.76e+02, Power=6.86e-01
  [eval] val_mse=4.518e-01  (n=7000)
Epoch 00147: Time=  10.4s, Loss=3.43e+00, Inv=3.43e+00, For=1.79e+02, Power=6.84e-01
  [eval] val_mse=4.501e-01  (n=7000)
Epoch 00148: Time=  10.4s, Loss=3.43e+00, Inv=3.43e+00, For=1.83e+02, Power=6.85e-01
  [eval] val_mse=4.484e-01  (n=7000)
Epoch 00149: Time=  10.5s, Loss=3.43e+00, Inv=3.43e+00, For=1.86e+02, Power=6.86e-01
  [eval] val_mse=4.460e-01  (n=7000)
Epoch 00150: Time=  10.5s, Loss=3.42e+00, Inv=3.42e+00, For=1.90e+02, Power=6.87e-01
  [eval] val_mse=4.444e-01  (n=7000)
Epoch 00151: Time=  10.5s, Loss=3.41e+00, Inv=3.41e+00, For=1.94e+02, Power=6.87e-01
  [eval] val_mse=4.418e-01  (n=7000)
Epoch 00152: Time=  10.6s, Loss=3.40e+00, Inv=3.40e+00, For=1.97e+02, Power=6.82e-01
  [eval] val_mse=4.403e-01  (n=7000)
Epoch 00153: Time=  10.6s, Loss=3.39e+00, Inv=3.39e+00, For=1.98e+02, Power=6.81e-01
  [eval] val_mse=4.382e-01  (n=7000)
Epoch 00154: Time=  10.6s, Loss=3.39e+00, Inv=3.39e+00, For=2.03e+02, Power=6.84e-01
  [eval] val_mse=4.366e-01  (n=7000)
Epoch 00155: Time=  10.7s, Loss=3.39e+00, Inv=3.39e+00, For=2.06e+02, Power=6.85e-01
  [eval] val_mse=4.349e-01  (n=7000)
Epoch 00156: Time=  10.7s, Loss=3.38e+00, Inv=3.38e+00, For=2.10e+02, Power=6.82e-01
  [eval] val_mse=4.340e-01  (n=7000)
Epoch 00157: Time=  10.7s, Loss=3.38e+00, Inv=3.38e+00, For=2.12e+02, Power=6.84e-01
  [eval] val_mse=4.317e-01  (n=7000)
Epoch 00158: Time=  10.8s, Loss=3.38e+00, Inv=3.38e+00, For=2.16e+02, Power=6.87e-01
  [eval] val_mse=4.300e-01  (n=7000)
Epoch 00159: Time=  10.8s, Loss=3.37e+00, Inv=3.37e+00, For=2.20e+02, Power=6.87e-01
  [eval] val_mse=4.277e-01  (n=7000)
Epoch 00160: Time=  10.8s, Loss=3.36e+00, Inv=3.36e+00, For=2.23e+02, Power=6.85e-01
  [eval] val_mse=4.267e-01  (n=7000)
Epoch 00161: Time=  10.9s, Loss=3.36e+00, Inv=3.36e+00, For=2.26e+02, Power=6.85e-01
  [eval] val_mse=4.250e-01  (n=7000)
Epoch 00162: Time=  10.9s, Loss=3.35e+00, Inv=3.35e+00, For=2.31e+02, Power=6.85e-01
  [eval] val_mse=4.240e-01  (n=7000)
Epoch 00163: Time=  10.9s, Loss=3.35e+00, Inv=3.35e+00, For=2.35e+02, Power=6.83e-01
  [eval] val_mse=4.214e-01  (n=7000)
Epoch 00164: Time=  11.0s, Loss=3.35e+00, Inv=3.35e+00, For=2.42e+02, Power=6.86e-01
  [eval] val_mse=4.205e-01  (n=7000)
Epoch 00165: Time=  11.0s, Loss=3.34e+00, Inv=3.34e+00, For=2.43e+02, Power=6.86e-01
  [eval] val_mse=4.192e-01  (n=7000)
Epoch 00166: Time=  11.0s, Loss=3.33e+00, Inv=3.33e+00, For=2.46e+02, Power=6.83e-01
  [eval] val_mse=4.174e-01  (n=7000)
Epoch 00167: Time=  11.1s, Loss=3.33e+00, Inv=3.33e+00, For=2.49e+02, Power=6.85e-01
  [eval] val_mse=4.165e-01  (n=7000)
Epoch 00168: Time=  11.1s, Loss=3.33e+00, Inv=3.33e+00, For=2.54e+02, Power=6.85e-01
  [eval] val_mse=4.144e-01  (n=7000)
Epoch 00169: Time=  11.1s, Loss=3.32e+00, Inv=3.32e+00, For=2.57e+02, Power=6.80e-01
  [eval] val_mse=4.127e-01  (n=7000)
Epoch 00170: Time=  11.2s, Loss=3.32e+00, Inv=3.32e+00, For=2.59e+02, Power=6.84e-01
  [eval] val_mse=4.116e-01  (n=7000)
Epoch 00171: Time=  11.2s, Loss=3.31e+00, Inv=3.31e+00, For=2.65e+02, Power=6.85e-01
  [eval] val_mse=4.103e-01  (n=7000)
Epoch 00172: Time=  11.3s, Loss=3.31e+00, Inv=3.31e+00, For=2.69e+02, Power=6.82e-01
  [eval] val_mse=4.087e-01  (n=7000)
Epoch 00173: Time=  11.3s, Loss=3.30e+00, Inv=3.30e+00, For=2.73e+02, Power=6.80e-01
  [eval] val_mse=4.077e-01  (n=7000)
Epoch 00174: Time=  11.3s, Loss=3.30e+00, Inv=3.30e+00, For=2.74e+02, Power=6.84e-01
  [eval] val_mse=4.062e-01  (n=7000)
Epoch 00175: Time=  11.4s, Loss=3.30e+00, Inv=3.30e+00, For=2.79e+02, Power=6.86e-01
  [eval] val_mse=4.052e-01  (n=7000)
Epoch 00176: Time=  11.4s, Loss=3.29e+00, Inv=3.29e+00, For=2.86e+02, Power=6.86e-01
  [eval] val_mse=4.040e-01  (n=7000)
Epoch 00177: Time=  11.4s, Loss=3.29e+00, Inv=3.29e+00, For=2.89e+02, Power=6.83e-01
  [eval] val_mse=4.027e-01  (n=7000)
Epoch 00178: Time=  11.5s, Loss=3.29e+00, Inv=3.29e+00, For=2.95e+02, Power=6.83e-01
  [eval] val_mse=4.013e-01  (n=7000)
Epoch 00179: Time=  11.5s, Loss=3.28e+00, Inv=3.28e+00, For=2.96e+02, Power=6.84e-01
  [eval] val_mse=4.000e-01  (n=7000)
Epoch 00180: Time=  11.5s, Loss=3.28e+00, Inv=3.28e+00, For=3.03e+02, Power=6.85e-01
  [eval] val_mse=3.992e-01  (n=7000)
Epoch 00181: Time=  11.6s, Loss=3.27e+00, Inv=3.27e+00, For=2.99e+02, Power=6.82e-01
  [eval] val_mse=3.977e-01  (n=7000)
Epoch 00182: Time=  11.6s, Loss=3.27e+00, Inv=3.27e+00, For=3.10e+02, Power=6.85e-01
  [eval] val_mse=3.970e-01  (n=7000)
Epoch 00183: Time=  11.6s, Loss=3.27e+00, Inv=3.27e+00, For=3.15e+02, Power=6.81e-01
  [eval] val_mse=3.950e-01  (n=7000)
Epoch 00184: Time=  11.7s, Loss=3.26e+00, Inv=3.26e+00, For=3.13e+02, Power=6.82e-01
  [eval] val_mse=3.943e-01  (n=7000)
Epoch 00185: Time=  11.7s, Loss=3.26e+00, Inv=3.26e+00, For=3.20e+02, Power=6.82e-01
  [eval] val_mse=3.933e-01  (n=7000)
Epoch 00186: Time=  11.7s, Loss=3.26e+00, Inv=3.26e+00, For=3.30e+02, Power=6.83e-01
  [eval] val_mse=3.929e-01  (n=7000)
Epoch 00187: Time=  11.8s, Loss=3.25e+00, Inv=3.25e+00, For=3.28e+02, Power=6.82e-01
  [eval] val_mse=3.914e-01  (n=7000)
Epoch 00188: Time=  11.8s, Loss=3.25e+00, Inv=3.25e+00, For=3.34e+02, Power=6.81e-01
  [eval] val_mse=3.905e-01  (n=7000)
Epoch 00189: Time=  11.8s, Loss=3.25e+00, Inv=3.25e+00, For=3.40e+02, Power=6.80e-01
  [eval] val_mse=3.892e-01  (n=7000)
Epoch 00190: Time=  11.9s, Loss=3.24e+00, Inv=3.24e+00, For=3.40e+02, Power=6.83e-01
  [eval] val_mse=3.883e-01  (n=7000)
Epoch 00191: Time=  11.9s, Loss=3.24e+00, Inv=3.24e+00, For=3.51e+02, Power=6.83e-01
  [eval] val_mse=3.869e-01  (n=7000)
Epoch 00192: Time=  11.9s, Loss=3.24e+00, Inv=3.24e+00, For=3.54e+02, Power=6.82e-01
  [eval] val_mse=3.865e-01  (n=7000)
Epoch 00193: Time=  12.0s, Loss=3.23e+00, Inv=3.23e+00, For=3.50e+02, Power=6.82e-01
  [eval] val_mse=3.857e-01  (n=7000)
Epoch 00194: Time=  12.0s, Loss=3.24e+00, Inv=3.24e+00, For=3.63e+02, Power=6.83e-01
  [eval] val_mse=3.846e-01  (n=7000)
Epoch 00195: Time=  12.0s, Loss=3.23e+00, Inv=3.23e+00, For=3.65e+02, Power=6.81e-01
  [eval] val_mse=3.833e-01  (n=7000)
Epoch 00196: Time=  12.1s, Loss=3.23e+00, Inv=3.23e+00, For=3.72e+02, Power=6.83e-01
  [eval] val_mse=3.819e-01  (n=7000)
Epoch 00197: Time=  12.1s, Loss=3.22e+00, Inv=3.22e+00, For=3.71e+02, Power=6.82e-01
  [eval] val_mse=3.823e-01  (n=7000)
Epoch 00198: Time=  12.1s, Loss=3.22e+00, Inv=3.22e+00, For=3.81e+02, Power=6.85e-01
  [eval] val_mse=3.801e-01  (n=7000)
Epoch 00199: Time=  12.2s, Loss=3.21e+00, Inv=3.21e+00, For=3.81e+02, Power=6.79e-01
  [eval] val_mse=3.797e-01  (n=7000)
Epoch 00200: Time=  12.2s, Loss=3.21e+00, Inv=3.21e+00, For=3.85e+02, Power=6.83e-01
  [eval] val_mse=3.788e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 2.513e-01
Torque MSE  = 8.007e-02
Torque RMSE = 2.830e-01
Per-joint MSE : 7.629e-02 2.000e-01 4.462e-02 2.016e-02 1.071e-01 3.229e-02
Per-joint RMSE: 2.762e-01 4.472e-01 2.112e-01 1.420e-01 3.273e-01 1.797e-01
Comp Time per Sample = 3.055e-04s / 3273.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-9i6qx5kt because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x70763230a8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:55:14.433008: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:55:16.272367: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=4.20e+03, Inv=4.20e+03, For=5.89e+00, Power=8.32e+02
  [eval] val_mse=1.462e+02  (n=7000)
Epoch 00002: Time=   5.8s, Loss=6.44e+02, Inv=6.44e+02, For=5.66e+00, Power=1.50e+02
  [eval] val_mse=5.321e+01  (n=7000)
Epoch 00003: Time=   5.9s, Loss=2.60e+02, Inv=2.60e+02, For=5.44e+00, Power=6.34e+01
  [eval] val_mse=3.047e+01  (n=7000)
Epoch 00004: Time=   5.9s, Loss=1.54e+02, Inv=1.54e+02, For=5.33e+00, Power=3.57e+01
  [eval] val_mse=2.097e+01  (n=7000)
Epoch 00005: Time=   5.9s, Loss=1.05e+02, Inv=1.05e+02, For=5.28e+00, Power=2.32e+01
  [eval] val_mse=1.594e+01  (n=7000)
Epoch 00006: Time=   6.0s, Loss=7.73e+01, Inv=7.73e+01, For=5.17e+00, Power=1.61e+01
  [eval] val_mse=1.279e+01  (n=7000)
Epoch 00007: Time=   6.0s, Loss=6.03e+01, Inv=6.03e+01, For=5.14e+00, Power=1.20e+01
  [eval] val_mse=1.065e+01  (n=7000)
Epoch 00008: Time=   6.0s, Loss=4.86e+01, Inv=4.86e+01, For=5.13e+00, Power=9.26e+00
  [eval] val_mse=9.060e+00  (n=7000)
Epoch 00009: Time=   6.1s, Loss=4.03e+01, Inv=4.03e+01, For=5.16e+00, Power=7.34e+00
  [eval] val_mse=7.870e+00  (n=7000)
Epoch 00010: Time=   6.1s, Loss=3.43e+01, Inv=3.43e+01, For=5.23e+00, Power=6.04e+00
  [eval] val_mse=6.902e+00  (n=7000)
Epoch 00011: Time=   6.1s, Loss=2.95e+01, Inv=2.95e+01, For=5.29e+00, Power=5.05e+00
  [eval] val_mse=6.118e+00  (n=7000)
Epoch 00012: Time=   6.2s, Loss=2.58e+01, Inv=2.58e+01, For=5.38e+00, Power=4.31e+00
  [eval] val_mse=5.469e+00  (n=7000)
Epoch 00013: Time=   6.2s, Loss=2.28e+01, Inv=2.28e+01, For=5.51e+00, Power=3.72e+00
  [eval] val_mse=4.924e+00  (n=7000)
Epoch 00014: Time=   6.3s, Loss=2.05e+01, Inv=2.05e+01, For=5.64e+00, Power=3.26e+00
  [eval] val_mse=4.456e+00  (n=7000)
Epoch 00015: Time=   6.3s, Loss=1.85e+01, Inv=1.85e+01, For=5.83e+00, Power=2.90e+00
  [eval] val_mse=4.062e+00  (n=7000)
Epoch 00016: Time=   6.3s, Loss=1.69e+01, Inv=1.69e+01, For=6.02e+00, Power=2.61e+00
  [eval] val_mse=3.716e+00  (n=7000)
Epoch 00017: Time=   6.4s, Loss=1.54e+01, Inv=1.54e+01, For=6.23e+00, Power=2.36e+00
  [eval] val_mse=3.412e+00  (n=7000)
Epoch 00018: Time=   6.4s, Loss=1.42e+01, Inv=1.42e+01, For=6.47e+00, Power=2.16e+00
  [eval] val_mse=3.148e+00  (n=7000)
Epoch 00019: Time=   6.4s, Loss=1.32e+01, Inv=1.32e+01, For=6.74e+00, Power=1.99e+00
  [eval] val_mse=2.918e+00  (n=7000)
Epoch 00020: Time=   6.5s, Loss=1.23e+01, Inv=1.23e+01, For=6.96e+00, Power=1.84e+00
  [eval] val_mse=2.712e+00  (n=7000)
Epoch 00021: Time=   6.5s, Loss=1.16e+01, Inv=1.16e+01, For=7.25e+00, Power=1.71e+00
  [eval] val_mse=2.532e+00  (n=7000)
Epoch 00022: Time=   6.5s, Loss=1.09e+01, Inv=1.09e+01, For=7.53e+00, Power=1.60e+00
  [eval] val_mse=2.371e+00  (n=7000)
Epoch 00023: Time=   6.6s, Loss=1.03e+01, Inv=1.03e+01, For=7.82e+00, Power=1.52e+00
  [eval] val_mse=2.227e+00  (n=7000)
Epoch 00024: Time=   6.6s, Loss=9.78e+00, Inv=9.78e+00, For=8.16e+00, Power=1.44e+00
  [eval] val_mse=2.097e+00  (n=7000)
Epoch 00025: Time=   6.6s, Loss=9.28e+00, Inv=9.28e+00, For=8.44e+00, Power=1.37e+00
  [eval] val_mse=1.983e+00  (n=7000)
Epoch 00026: Time=   6.7s, Loss=8.86e+00, Inv=8.86e+00, For=8.73e+00, Power=1.30e+00
  [eval] val_mse=1.879e+00  (n=7000)
Epoch 00027: Time=   6.7s, Loss=8.48e+00, Inv=8.48e+00, For=8.99e+00, Power=1.25e+00
  [eval] val_mse=1.788e+00  (n=7000)
Epoch 00028: Time=   6.7s, Loss=8.14e+00, Inv=8.14e+00, For=9.33e+00, Power=1.20e+00
  [eval] val_mse=1.704e+00  (n=7000)
Epoch 00029: Time=   6.8s, Loss=7.84e+00, Inv=7.84e+00, For=9.64e+00, Power=1.16e+00
  [eval] val_mse=1.627e+00  (n=7000)
Epoch 00030: Time=   6.8s, Loss=7.56e+00, Inv=7.56e+00, For=9.96e+00, Power=1.12e+00
  [eval] val_mse=1.557e+00  (n=7000)
Epoch 00031: Time=   6.8s, Loss=7.31e+00, Inv=7.31e+00, For=1.02e+01, Power=1.09e+00
  [eval] val_mse=1.497e+00  (n=7000)
Epoch 00032: Time=   6.9s, Loss=7.07e+00, Inv=7.07e+00, For=1.05e+01, Power=1.06e+00
  [eval] val_mse=1.438e+00  (n=7000)
Epoch 00033: Time=   6.9s, Loss=6.87e+00, Inv=6.87e+00, For=1.08e+01, Power=1.03e+00
  [eval] val_mse=1.386e+00  (n=7000)
Epoch 00034: Time=   6.9s, Loss=6.67e+00, Inv=6.67e+00, For=1.11e+01, Power=1.00e+00
  [eval] val_mse=1.336e+00  (n=7000)
Epoch 00035: Time=   7.0s, Loss=6.50e+00, Inv=6.50e+00, For=1.14e+01, Power=9.89e-01
  [eval] val_mse=1.292e+00  (n=7000)
Epoch 00036: Time=   7.0s, Loss=6.32e+00, Inv=6.32e+00, For=1.17e+01, Power=9.64e-01
  [eval] val_mse=1.249e+00  (n=7000)
Epoch 00037: Time=   7.0s, Loss=6.18e+00, Inv=6.18e+00, For=1.20e+01, Power=9.47e-01
  [eval] val_mse=1.213e+00  (n=7000)
Epoch 00038: Time=   7.1s, Loss=6.04e+00, Inv=6.04e+00, For=1.23e+01, Power=9.33e-01
  [eval] val_mse=1.176e+00  (n=7000)
Epoch 00039: Time=   7.1s, Loss=5.92e+00, Inv=5.92e+00, For=1.27e+01, Power=9.16e-01
  [eval] val_mse=1.144e+00  (n=7000)
Epoch 00040: Time=   7.1s, Loss=5.80e+00, Inv=5.80e+00, For=1.29e+01, Power=9.05e-01
  [eval] val_mse=1.112e+00  (n=7000)
Epoch 00041: Time=   7.2s, Loss=5.69e+00, Inv=5.69e+00, For=1.32e+01, Power=8.94e-01
  [eval] val_mse=1.083e+00  (n=7000)
Epoch 00042: Time=   7.2s, Loss=5.58e+00, Inv=5.58e+00, For=1.36e+01, Power=8.81e-01
  [eval] val_mse=1.056e+00  (n=7000)
Epoch 00043: Time=   7.2s, Loss=5.49e+00, Inv=5.49e+00, For=1.39e+01, Power=8.71e-01
  [eval] val_mse=1.030e+00  (n=7000)
Epoch 00044: Time=   7.3s, Loss=5.40e+00, Inv=5.40e+00, For=1.43e+01, Power=8.56e-01
  [eval] val_mse=1.006e+00  (n=7000)
Epoch 00045: Time=   7.3s, Loss=5.32e+00, Inv=5.32e+00, For=1.46e+01, Power=8.52e-01
  [eval] val_mse=9.819e-01  (n=7000)
Epoch 00046: Time=   7.3s, Loss=5.23e+00, Inv=5.23e+00, For=1.50e+01, Power=8.42e-01
  [eval] val_mse=9.609e-01  (n=7000)
Epoch 00047: Time=   7.4s, Loss=5.17e+00, Inv=5.17e+00, For=1.54e+01, Power=8.34e-01
  [eval] val_mse=9.396e-01  (n=7000)
Epoch 00048: Time=   7.4s, Loss=5.09e+00, Inv=5.09e+00, For=1.57e+01, Power=8.30e-01
  [eval] val_mse=9.198e-01  (n=7000)
Epoch 00049: Time=   7.4s, Loss=5.03e+00, Inv=5.03e+00, For=1.61e+01, Power=8.22e-01
  [eval] val_mse=9.016e-01  (n=7000)
Epoch 00050: Time=   7.5s, Loss=4.96e+00, Inv=4.96e+00, For=1.65e+01, Power=8.17e-01
  [eval] val_mse=8.841e-01  (n=7000)
Epoch 00051: Time=   7.5s, Loss=4.91e+00, Inv=4.91e+00, For=1.68e+01, Power=8.09e-01
  [eval] val_mse=8.663e-01  (n=7000)
Epoch 00052: Time=   7.5s, Loss=4.85e+00, Inv=4.85e+00, For=1.73e+01, Power=8.07e-01
  [eval] val_mse=8.506e-01  (n=7000)
Epoch 00053: Time=   7.6s, Loss=4.79e+00, Inv=4.79e+00, For=1.76e+01, Power=7.99e-01
  [eval] val_mse=8.338e-01  (n=7000)
Epoch 00054: Time=   7.6s, Loss=4.74e+00, Inv=4.74e+00, For=1.80e+01, Power=7.95e-01
  [eval] val_mse=8.192e-01  (n=7000)
Epoch 00055: Time=   7.6s, Loss=4.69e+00, Inv=4.69e+00, For=1.86e+01, Power=7.94e-01
  [eval] val_mse=8.040e-01  (n=7000)
Epoch 00056: Time=   7.7s, Loss=4.64e+00, Inv=4.64e+00, For=1.89e+01, Power=7.84e-01
  [eval] val_mse=7.914e-01  (n=7000)
Epoch 00057: Time=   7.7s, Loss=4.60e+00, Inv=4.60e+00, For=1.93e+01, Power=7.84e-01
  [eval] val_mse=7.781e-01  (n=7000)
Epoch 00058: Time=   7.7s, Loss=4.56e+00, Inv=4.56e+00, For=1.99e+01, Power=7.77e-01
  [eval] val_mse=7.644e-01  (n=7000)
Epoch 00059: Time=   7.8s, Loss=4.51e+00, Inv=4.51e+00, For=2.00e+01, Power=7.74e-01
  [eval] val_mse=7.520e-01  (n=7000)
Epoch 00060: Time=   7.8s, Loss=4.48e+00, Inv=4.48e+00, For=2.06e+01, Power=7.72e-01
  [eval] val_mse=7.417e-01  (n=7000)
Epoch 00061: Time=   7.8s, Loss=4.43e+00, Inv=4.43e+00, For=2.12e+01, Power=7.65e-01
  [eval] val_mse=7.298e-01  (n=7000)
Epoch 00062: Time=   7.9s, Loss=4.40e+00, Inv=4.40e+00, For=2.15e+01, Power=7.64e-01
  [eval] val_mse=7.195e-01  (n=7000)
Epoch 00063: Time=   7.9s, Loss=4.37e+00, Inv=4.37e+00, For=2.20e+01, Power=7.65e-01
  [eval] val_mse=7.080e-01  (n=7000)
Epoch 00064: Time=   7.9s, Loss=4.33e+00, Inv=4.33e+00, For=2.25e+01, Power=7.59e-01
  [eval] val_mse=6.992e-01  (n=7000)
Epoch 00065: Time=   8.0s, Loss=4.30e+00, Inv=4.30e+00, For=2.30e+01, Power=7.59e-01
  [eval] val_mse=6.890e-01  (n=7000)
Epoch 00066: Time=   8.0s, Loss=4.26e+00, Inv=4.26e+00, For=2.33e+01, Power=7.57e-01
  [eval] val_mse=6.795e-01  (n=7000)
Epoch 00067: Time=   8.0s, Loss=4.23e+00, Inv=4.23e+00, For=2.39e+01, Power=7.51e-01
  [eval] val_mse=6.709e-01  (n=7000)
Epoch 00068: Time=   8.1s, Loss=4.21e+00, Inv=4.21e+00, For=2.44e+01, Power=7.52e-01
  [eval] val_mse=6.614e-01  (n=7000)
Epoch 00069: Time=   8.1s, Loss=4.17e+00, Inv=4.17e+00, For=2.49e+01, Power=7.47e-01
  [eval] val_mse=6.546e-01  (n=7000)
Epoch 00070: Time=   8.1s, Loss=4.14e+00, Inv=4.14e+00, For=2.53e+01, Power=7.44e-01
  [eval] val_mse=6.458e-01  (n=7000)
Epoch 00071: Time=   8.2s, Loss=4.12e+00, Inv=4.12e+00, For=2.59e+01, Power=7.46e-01
  [eval] val_mse=6.377e-01  (n=7000)
Epoch 00072: Time=   8.2s, Loss=4.09e+00, Inv=4.09e+00, For=2.66e+01, Power=7.42e-01
  [eval] val_mse=6.306e-01  (n=7000)
Epoch 00073: Time=   8.2s, Loss=4.07e+00, Inv=4.07e+00, For=2.70e+01, Power=7.42e-01
  [eval] val_mse=6.230e-01  (n=7000)
Epoch 00074: Time=   8.3s, Loss=4.04e+00, Inv=4.04e+00, For=2.75e+01, Power=7.38e-01
  [eval] val_mse=6.151e-01  (n=7000)
Epoch 00075: Time=   8.3s, Loss=4.02e+00, Inv=4.02e+00, For=2.78e+01, Power=7.38e-01
  [eval] val_mse=6.083e-01  (n=7000)
Epoch 00076: Time=   8.3s, Loss=3.99e+00, Inv=3.99e+00, For=2.90e+01, Power=7.35e-01
  [eval] val_mse=6.029e-01  (n=7000)
Epoch 00077: Time=   8.4s, Loss=3.97e+00, Inv=3.97e+00, For=2.90e+01, Power=7.32e-01
  [eval] val_mse=5.959e-01  (n=7000)
Epoch 00078: Time=   8.4s, Loss=3.95e+00, Inv=3.95e+00, For=2.97e+01, Power=7.34e-01
  [eval] val_mse=5.894e-01  (n=7000)
Epoch 00079: Time=   8.4s, Loss=3.93e+00, Inv=3.93e+00, For=3.05e+01, Power=7.33e-01
  [eval] val_mse=5.842e-01  (n=7000)
Epoch 00080: Time=   8.5s, Loss=3.91e+00, Inv=3.91e+00, For=3.05e+01, Power=7.32e-01
  [eval] val_mse=5.772e-01  (n=7000)
Epoch 00081: Time=   8.5s, Loss=3.89e+00, Inv=3.89e+00, For=3.17e+01, Power=7.30e-01
  [eval] val_mse=5.725e-01  (n=7000)
Epoch 00082: Time=   8.5s, Loss=3.87e+00, Inv=3.87e+00, For=3.22e+01, Power=7.26e-01
  [eval] val_mse=5.665e-01  (n=7000)
Epoch 00083: Time=   8.6s, Loss=3.84e+00, Inv=3.84e+00, For=3.23e+01, Power=7.21e-01
  [eval] val_mse=5.601e-01  (n=7000)
Epoch 00084: Time=   8.6s, Loss=3.83e+00, Inv=3.83e+00, For=3.34e+01, Power=7.25e-01
  [eval] val_mse=5.563e-01  (n=7000)
Epoch 00085: Time=   8.7s, Loss=3.81e+00, Inv=3.81e+00, For=3.40e+01, Power=7.21e-01
  [eval] val_mse=5.508e-01  (n=7000)
Epoch 00086: Time=   8.7s, Loss=3.80e+00, Inv=3.80e+00, For=3.45e+01, Power=7.22e-01
  [eval] val_mse=5.465e-01  (n=7000)
Epoch 00087: Time=   8.7s, Loss=3.78e+00, Inv=3.78e+00, For=3.47e+01, Power=7.22e-01
  [eval] val_mse=5.410e-01  (n=7000)
Epoch 00088: Time=   8.8s, Loss=3.76e+00, Inv=3.76e+00, For=3.56e+01, Power=7.19e-01
  [eval] val_mse=5.363e-01  (n=7000)
Epoch 00089: Time=   8.8s, Loss=3.74e+00, Inv=3.74e+00, For=3.66e+01, Power=7.19e-01
  [eval] val_mse=5.317e-01  (n=7000)
Epoch 00090: Time=   8.8s, Loss=3.72e+00, Inv=3.72e+00, For=3.68e+01, Power=7.18e-01
  [eval] val_mse=5.276e-01  (n=7000)
Epoch 00091: Time=   8.9s, Loss=3.72e+00, Inv=3.72e+00, For=3.79e+01, Power=7.18e-01
  [eval] val_mse=5.239e-01  (n=7000)
Epoch 00092: Time=   8.9s, Loss=3.70e+00, Inv=3.70e+00, For=3.85e+01, Power=7.15e-01
  [eval] val_mse=5.187e-01  (n=7000)
Epoch 00093: Time=   8.9s, Loss=3.69e+00, Inv=3.69e+00, For=3.85e+01, Power=7.13e-01
  [eval] val_mse=5.150e-01  (n=7000)
Epoch 00094: Time=   9.0s, Loss=3.67e+00, Inv=3.67e+00, For=3.96e+01, Power=7.15e-01
  [eval] val_mse=5.107e-01  (n=7000)
Epoch 00095: Time=   9.0s, Loss=3.66e+00, Inv=3.66e+00, For=4.07e+01, Power=7.13e-01
  [eval] val_mse=5.076e-01  (n=7000)
Epoch 00096: Time=   9.0s, Loss=3.65e+00, Inv=3.65e+00, For=4.07e+01, Power=7.16e-01
  [eval] val_mse=5.032e-01  (n=7000)
Epoch 00097: Time=   9.1s, Loss=3.64e+00, Inv=3.64e+00, For=4.14e+01, Power=7.11e-01
  [eval] val_mse=4.992e-01  (n=7000)
Epoch 00098: Time=   9.1s, Loss=3.62e+00, Inv=3.62e+00, For=4.26e+01, Power=7.11e-01
  [eval] val_mse=4.958e-01  (n=7000)
Epoch 00099: Time=   9.1s, Loss=3.61e+00, Inv=3.61e+00, For=4.25e+01, Power=7.08e-01
  [eval] val_mse=4.920e-01  (n=7000)
Epoch 00100: Time=   9.2s, Loss=3.60e+00, Inv=3.60e+00, For=4.37e+01, Power=7.07e-01
  [eval] val_mse=4.889e-01  (n=7000)
Epoch 00101: Time=   9.2s, Loss=3.59e+00, Inv=3.59e+00, For=4.40e+01, Power=7.07e-01
  [eval] val_mse=4.857e-01  (n=7000)
Epoch 00102: Time=   9.2s, Loss=3.57e+00, Inv=3.57e+00, For=4.51e+01, Power=7.03e-01
  [eval] val_mse=4.823e-01  (n=7000)
Epoch 00103: Time=   9.3s, Loss=3.57e+00, Inv=3.57e+00, For=4.56e+01, Power=7.09e-01
  [eval] val_mse=4.786e-01  (n=7000)
Epoch 00104: Time=   9.3s, Loss=3.56e+00, Inv=3.56e+00, For=4.62e+01, Power=7.09e-01
  [eval] val_mse=4.765e-01  (n=7000)
Epoch 00105: Time=   9.3s, Loss=3.55e+00, Inv=3.55e+00, For=4.73e+01, Power=7.03e-01
  [eval] val_mse=4.729e-01  (n=7000)
Epoch 00106: Time=   9.4s, Loss=3.54e+00, Inv=3.54e+00, For=4.75e+01, Power=7.00e-01
  [eval] val_mse=4.699e-01  (n=7000)
Epoch 00107: Time=   9.4s, Loss=3.53e+00, Inv=3.53e+00, For=4.82e+01, Power=7.04e-01
  [eval] val_mse=4.670e-01  (n=7000)
Epoch 00108: Time=   9.4s, Loss=3.52e+00, Inv=3.52e+00, For=4.94e+01, Power=7.03e-01
  [eval] val_mse=4.639e-01  (n=7000)
Epoch 00109: Time=   9.5s, Loss=3.51e+00, Inv=3.51e+00, For=5.00e+01, Power=7.03e-01
  [eval] val_mse=4.616e-01  (n=7000)
Epoch 00110: Time=   9.5s, Loss=3.50e+00, Inv=3.50e+00, For=4.96e+01, Power=7.01e-01
  [eval] val_mse=4.583e-01  (n=7000)
Epoch 00111: Time=   9.5s, Loss=3.50e+00, Inv=3.50e+00, For=5.14e+01, Power=7.04e-01
  [eval] val_mse=4.557e-01  (n=7000)
Epoch 00112: Time=   9.6s, Loss=3.49e+00, Inv=3.49e+00, For=5.21e+01, Power=7.02e-01
  [eval] val_mse=4.530e-01  (n=7000)
Epoch 00113: Time=   9.6s, Loss=3.48e+00, Inv=3.48e+00, For=5.24e+01, Power=7.00e-01
  [eval] val_mse=4.505e-01  (n=7000)
Epoch 00114: Time=   9.6s, Loss=3.47e+00, Inv=3.47e+00, For=5.35e+01, Power=6.99e-01
  [eval] val_mse=4.483e-01  (n=7000)
Epoch 00115: Time=   9.7s, Loss=3.46e+00, Inv=3.46e+00, For=5.42e+01, Power=6.98e-01
  [eval] val_mse=4.465e-01  (n=7000)
Epoch 00116: Time=   9.7s, Loss=3.45e+00, Inv=3.45e+00, For=5.41e+01, Power=6.98e-01
  [eval] val_mse=4.433e-01  (n=7000)
Epoch 00117: Time=   9.7s, Loss=3.44e+00, Inv=3.44e+00, For=5.57e+01, Power=6.96e-01
  [eval] val_mse=4.408e-01  (n=7000)
Epoch 00118: Time=   9.8s, Loss=3.43e+00, Inv=3.43e+00, For=5.58e+01, Power=6.94e-01
  [eval] val_mse=4.383e-01  (n=7000)
Epoch 00119: Time=   9.8s, Loss=3.43e+00, Inv=3.43e+00, For=5.65e+01, Power=6.94e-01
  [eval] val_mse=4.370e-01  (n=7000)
Epoch 00120: Time=   9.8s, Loss=3.42e+00, Inv=3.42e+00, For=5.73e+01, Power=6.92e-01
  [eval] val_mse=4.338e-01  (n=7000)
Epoch 00121: Time=   9.9s, Loss=3.42e+00, Inv=3.42e+00, For=5.99e+01, Power=6.95e-01
  [eval] val_mse=4.324e-01  (n=7000)
Epoch 00122: Time=   9.9s, Loss=3.42e+00, Inv=3.42e+00, For=5.88e+01, Power=6.97e-01
  [eval] val_mse=4.295e-01  (n=7000)
Epoch 00123: Time=   9.9s, Loss=3.41e+00, Inv=3.41e+00, For=5.94e+01, Power=6.96e-01
  [eval] val_mse=4.278e-01  (n=7000)
Epoch 00124: Time=  10.0s, Loss=3.40e+00, Inv=3.40e+00, For=6.00e+01, Power=6.94e-01
  [eval] val_mse=4.262e-01  (n=7000)
Epoch 00125: Time=  10.0s, Loss=3.40e+00, Inv=3.40e+00, For=6.20e+01, Power=6.95e-01
  [eval] val_mse=4.238e-01  (n=7000)
Epoch 00126: Time=  10.0s, Loss=3.39e+00, Inv=3.39e+00, For=6.16e+01, Power=6.93e-01
  [eval] val_mse=4.216e-01  (n=7000)
Epoch 00127: Time=  10.1s, Loss=3.38e+00, Inv=3.38e+00, For=6.29e+01, Power=6.91e-01
  [eval] val_mse=4.203e-01  (n=7000)
Epoch 00128: Time=  10.1s, Loss=3.38e+00, Inv=3.38e+00, For=6.41e+01, Power=6.91e-01
  [eval] val_mse=4.181e-01  (n=7000)
Epoch 00129: Time=  10.1s, Loss=3.37e+00, Inv=3.37e+00, For=6.36e+01, Power=6.91e-01
  [eval] val_mse=4.158e-01  (n=7000)
Epoch 00130: Time=  10.2s, Loss=3.36e+00, Inv=3.36e+00, For=6.56e+01, Power=6.90e-01
  [eval] val_mse=4.147e-01  (n=7000)
Epoch 00131: Time=  10.2s, Loss=3.36e+00, Inv=3.36e+00, For=6.52e+01, Power=6.92e-01
  [eval] val_mse=4.127e-01  (n=7000)
Epoch 00132: Time=  10.3s, Loss=3.35e+00, Inv=3.35e+00, For=6.73e+01, Power=6.91e-01
  [eval] val_mse=4.105e-01  (n=7000)
Epoch 00133: Time=  10.3s, Loss=3.35e+00, Inv=3.35e+00, For=6.82e+01, Power=6.90e-01
  [eval] val_mse=4.097e-01  (n=7000)
Epoch 00134: Time=  10.3s, Loss=3.34e+00, Inv=3.34e+00, For=6.85e+01, Power=6.89e-01
  [eval] val_mse=4.081e-01  (n=7000)
Epoch 00135: Time=  10.4s, Loss=3.34e+00, Inv=3.34e+00, For=6.92e+01, Power=6.90e-01
  [eval] val_mse=4.066e-01  (n=7000)
Epoch 00136: Time=  10.4s, Loss=3.33e+00, Inv=3.33e+00, For=7.03e+01, Power=6.91e-01
  [eval] val_mse=4.054e-01  (n=7000)
Epoch 00137: Time=  10.4s, Loss=3.33e+00, Inv=3.33e+00, For=7.09e+01, Power=6.89e-01
  [eval] val_mse=4.034e-01  (n=7000)
Epoch 00138: Time=  10.5s, Loss=3.32e+00, Inv=3.32e+00, For=7.11e+01, Power=6.87e-01
  [eval] val_mse=4.012e-01  (n=7000)
Epoch 00139: Time=  10.5s, Loss=3.32e+00, Inv=3.32e+00, For=7.21e+01, Power=6.86e-01
  [eval] val_mse=4.006e-01  (n=7000)
Epoch 00140: Time=  10.5s, Loss=3.32e+00, Inv=3.32e+00, For=7.29e+01, Power=6.88e-01
  [eval] val_mse=3.986e-01  (n=7000)
Epoch 00141: Time=  10.6s, Loss=3.31e+00, Inv=3.31e+00, For=7.46e+01, Power=6.88e-01
  [eval] val_mse=3.980e-01  (n=7000)
Epoch 00142: Time=  10.6s, Loss=3.31e+00, Inv=3.31e+00, For=7.49e+01, Power=6.89e-01
  [eval] val_mse=3.965e-01  (n=7000)
Epoch 00143: Time=  10.6s, Loss=3.30e+00, Inv=3.30e+00, For=7.57e+01, Power=6.89e-01
  [eval] val_mse=3.952e-01  (n=7000)
Epoch 00144: Time=  10.7s, Loss=3.30e+00, Inv=3.30e+00, For=7.79e+01, Power=6.90e-01
  [eval] val_mse=3.939e-01  (n=7000)
Epoch 00145: Time=  10.7s, Loss=3.30e+00, Inv=3.30e+00, For=7.65e+01, Power=6.90e-01
  [eval] val_mse=3.922e-01  (n=7000)
Epoch 00146: Time=  10.7s, Loss=3.29e+00, Inv=3.29e+00, For=7.84e+01, Power=6.84e-01
  [eval] val_mse=3.918e-01  (n=7000)
Epoch 00147: Time=  10.8s, Loss=3.28e+00, Inv=3.28e+00, For=8.06e+01, Power=6.88e-01
  [eval] val_mse=3.908e-01  (n=7000)
Epoch 00148: Time=  10.8s, Loss=3.28e+00, Inv=3.28e+00, For=7.98e+01, Power=6.87e-01
  [eval] val_mse=3.894e-01  (n=7000)
Epoch 00149: Time=  10.8s, Loss=3.28e+00, Inv=3.28e+00, For=8.08e+01, Power=6.85e-01
  [eval] val_mse=3.882e-01  (n=7000)
Epoch 00150: Time=  10.9s, Loss=3.27e+00, Inv=3.27e+00, For=8.22e+01, Power=6.86e-01
  [eval] val_mse=3.867e-01  (n=7000)
Epoch 00151: Time=  10.9s, Loss=3.27e+00, Inv=3.27e+00, For=8.50e+01, Power=6.87e-01
  [eval] val_mse=3.861e-01  (n=7000)
Epoch 00152: Time=  10.9s, Loss=3.27e+00, Inv=3.27e+00, For=8.38e+01, Power=6.86e-01
  [eval] val_mse=3.851e-01  (n=7000)
Epoch 00153: Time=  11.0s, Loss=3.26e+00, Inv=3.26e+00, For=8.39e+01, Power=6.85e-01
  [eval] val_mse=3.841e-01  (n=7000)
Epoch 00154: Time=  11.0s, Loss=3.26e+00, Inv=3.26e+00, For=8.56e+01, Power=6.87e-01
  [eval] val_mse=3.830e-01  (n=7000)
Epoch 00155: Time=  11.0s, Loss=3.25e+00, Inv=3.25e+00, For=8.74e+01, Power=6.85e-01
  [eval] val_mse=3.819e-01  (n=7000)
Epoch 00156: Time=  11.1s, Loss=3.25e+00, Inv=3.25e+00, For=8.65e+01, Power=6.87e-01
  [eval] val_mse=3.809e-01  (n=7000)
Epoch 00157: Time=  11.1s, Loss=3.24e+00, Inv=3.24e+00, For=9.02e+01, Power=6.85e-01
  [eval] val_mse=3.806e-01  (n=7000)
Epoch 00158: Time=  11.1s, Loss=3.24e+00, Inv=3.24e+00, For=8.84e+01, Power=6.83e-01
  [eval] val_mse=3.797e-01  (n=7000)
Epoch 00159: Time=  11.2s, Loss=3.24e+00, Inv=3.24e+00, For=9.15e+01, Power=6.85e-01
  [eval] val_mse=3.786e-01  (n=7000)
Epoch 00160: Time=  11.2s, Loss=3.24e+00, Inv=3.24e+00, For=9.16e+01, Power=6.84e-01
  [eval] val_mse=3.772e-01  (n=7000)
Epoch 00161: Time=  11.2s, Loss=3.23e+00, Inv=3.23e+00, For=9.23e+01, Power=6.84e-01
  [eval] val_mse=3.771e-01  (n=7000)
Epoch 00162: Time=  11.3s, Loss=3.23e+00, Inv=3.23e+00, For=9.49e+01, Power=6.86e-01
  [eval] val_mse=3.757e-01  (n=7000)
Epoch 00163: Time=  11.3s, Loss=3.23e+00, Inv=3.23e+00, For=9.48e+01, Power=6.86e-01
  [eval] val_mse=3.753e-01  (n=7000)
Epoch 00164: Time=  11.3s, Loss=3.22e+00, Inv=3.22e+00, For=9.53e+01, Power=6.84e-01
  [eval] val_mse=3.741e-01  (n=7000)
Epoch 00165: Time=  11.4s, Loss=3.22e+00, Inv=3.22e+00, For=9.56e+01, Power=6.86e-01
  [eval] val_mse=3.734e-01  (n=7000)
Epoch 00166: Time=  11.4s, Loss=3.22e+00, Inv=3.22e+00, For=9.76e+01, Power=6.84e-01
  [eval] val_mse=3.726e-01  (n=7000)
Epoch 00167: Time=  11.5s, Loss=3.21e+00, Inv=3.21e+00, For=9.96e+01, Power=6.85e-01
  [eval] val_mse=3.721e-01  (n=7000)
Epoch 00168: Time=  11.5s, Loss=3.21e+00, Inv=3.21e+00, For=9.93e+01, Power=6.85e-01
  [eval] val_mse=3.715e-01  (n=7000)
Epoch 00169: Time=  11.5s, Loss=3.21e+00, Inv=3.21e+00, For=1.01e+02, Power=6.84e-01
  [eval] val_mse=3.708e-01  (n=7000)
Epoch 00170: Time=  11.6s, Loss=3.21e+00, Inv=3.21e+00, For=1.02e+02, Power=6.85e-01
  [eval] val_mse=3.705e-01  (n=7000)
Epoch 00171: Time=  11.6s, Loss=3.20e+00, Inv=3.20e+00, For=1.03e+02, Power=6.86e-01
  [eval] val_mse=3.696e-01  (n=7000)
Epoch 00172: Time=  11.6s, Loss=3.20e+00, Inv=3.20e+00, For=1.05e+02, Power=6.85e-01
  [eval] val_mse=3.683e-01  (n=7000)
Epoch 00173: Time=  11.7s, Loss=3.20e+00, Inv=3.20e+00, For=1.05e+02, Power=6.84e-01
  [eval] val_mse=3.682e-01  (n=7000)
Epoch 00174: Time=  11.7s, Loss=3.20e+00, Inv=3.20e+00, For=1.07e+02, Power=6.86e-01
  [eval] val_mse=3.672e-01  (n=7000)
Epoch 00175: Time=  11.7s, Loss=3.19e+00, Inv=3.19e+00, For=1.06e+02, Power=6.83e-01
  [eval] val_mse=3.666e-01  (n=7000)
Epoch 00176: Time=  11.8s, Loss=3.19e+00, Inv=3.19e+00, For=1.10e+02, Power=6.84e-01
  [eval] val_mse=3.669e-01  (n=7000)
Epoch 00177: Time=  11.8s, Loss=3.19e+00, Inv=3.19e+00, For=1.09e+02, Power=6.82e-01
  [eval] val_mse=3.656e-01  (n=7000)
Epoch 00178: Time=  11.8s, Loss=3.18e+00, Inv=3.18e+00, For=1.11e+02, Power=6.84e-01
  [eval] val_mse=3.651e-01  (n=7000)
Epoch 00179: Time=  11.9s, Loss=3.18e+00, Inv=3.18e+00, For=1.11e+02, Power=6.82e-01
  [eval] val_mse=3.644e-01  (n=7000)
Epoch 00180: Time=  11.9s, Loss=3.18e+00, Inv=3.18e+00, For=1.13e+02, Power=6.80e-01
  [eval] val_mse=3.640e-01  (n=7000)
Epoch 00181: Time=  11.9s, Loss=3.18e+00, Inv=3.18e+00, For=1.15e+02, Power=6.83e-01
  [eval] val_mse=3.636e-01  (n=7000)
Epoch 00182: Time=  12.0s, Loss=3.17e+00, Inv=3.17e+00, For=1.16e+02, Power=6.80e-01
  [eval] val_mse=3.632e-01  (n=7000)
Epoch 00183: Time=  12.0s, Loss=3.17e+00, Inv=3.17e+00, For=1.16e+02, Power=6.78e-01
  [eval] val_mse=3.627e-01  (n=7000)
Epoch 00184: Time=  12.0s, Loss=3.17e+00, Inv=3.17e+00, For=1.19e+02, Power=6.82e-01
  [eval] val_mse=3.624e-01  (n=7000)
Epoch 00185: Time=  12.1s, Loss=3.17e+00, Inv=3.17e+00, For=1.18e+02, Power=6.82e-01
  [eval] val_mse=3.614e-01  (n=7000)
Epoch 00186: Time=  12.1s, Loss=3.17e+00, Inv=3.17e+00, For=1.21e+02, Power=6.85e-01
  [eval] val_mse=3.611e-01  (n=7000)
Epoch 00187: Time=  12.1s, Loss=3.16e+00, Inv=3.16e+00, For=1.21e+02, Power=6.81e-01
  [eval] val_mse=3.603e-01  (n=7000)
Epoch 00188: Time=  12.2s, Loss=3.16e+00, Inv=3.16e+00, For=1.24e+02, Power=6.82e-01
  [eval] val_mse=3.603e-01  (n=7000)
Epoch 00189: Time=  12.2s, Loss=3.16e+00, Inv=3.16e+00, For=1.23e+02, Power=6.81e-01
  [eval] val_mse=3.592e-01  (n=7000)
Epoch 00190: Time=  12.2s, Loss=3.16e+00, Inv=3.16e+00, For=1.25e+02, Power=6.84e-01
  [eval] val_mse=3.594e-01  (n=7000)
Epoch 00191: Time=  12.3s, Loss=3.15e+00, Inv=3.15e+00, For=1.26e+02, Power=6.83e-01
  [eval] val_mse=3.584e-01  (n=7000)
Epoch 00192: Time=  12.3s, Loss=3.15e+00, Inv=3.15e+00, For=1.27e+02, Power=6.82e-01
  [eval] val_mse=3.581e-01  (n=7000)
Epoch 00193: Time=  12.3s, Loss=3.15e+00, Inv=3.15e+00, For=1.29e+02, Power=6.81e-01
  [eval] val_mse=3.574e-01  (n=7000)
Epoch 00194: Time=  12.4s, Loss=3.15e+00, Inv=3.15e+00, For=1.30e+02, Power=6.83e-01
  [eval] val_mse=3.571e-01  (n=7000)
Epoch 00195: Time=  12.4s, Loss=3.14e+00, Inv=3.14e+00, For=1.31e+02, Power=6.84e-01
  [eval] val_mse=3.563e-01  (n=7000)
Epoch 00196: Time=  12.4s, Loss=3.14e+00, Inv=3.14e+00, For=1.33e+02, Power=6.83e-01
  [eval] val_mse=3.564e-01  (n=7000)
Epoch 00197: Time=  12.5s, Loss=3.14e+00, Inv=3.14e+00, For=1.34e+02, Power=6.84e-01
  [eval] val_mse=3.558e-01  (n=7000)
Epoch 00198: Time=  12.5s, Loss=3.14e+00, Inv=3.14e+00, For=1.35e+02, Power=6.84e-01
  [eval] val_mse=3.556e-01  (n=7000)
Epoch 00199: Time=  12.5s, Loss=3.13e+00, Inv=3.13e+00, For=1.35e+02, Power=6.82e-01
  [eval] val_mse=3.547e-01  (n=7000)
Epoch 00200: Time=  12.6s, Loss=3.13e+00, Inv=3.13e+00, For=1.37e+02, Power=6.80e-01
  [eval] val_mse=3.546e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 2.431e-01
Torque MSE  = 1.231e-01
Torque RMSE = 3.508e-01
Per-joint MSE : 7.632e-02 4.241e-01 5.665e-02 2.317e-02 1.406e-01 1.750e-02
Per-joint RMSE: 2.763e-01 6.513e-01 2.380e-01 1.522e-01 3.749e-01 1.323e-01
Comp Time per Sample = 2.721e-04s / 3674.5Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-cb7vubfc because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7ac9aa0828c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:55:36.936800: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:55:38.798123: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.4s, Loss=9.43e+03, Inv=9.43e+03, For=5.90e+00, Power=8.36e+02
  [eval] val_mse=2.969e+02  (n=7000)
Epoch 00002: Time=   5.9s, Loss=1.41e+03, Inv=1.41e+03, For=5.73e+00, Power=1.64e+02
  [eval] val_mse=1.422e+02  (n=7000)
Epoch 00003: Time=   5.9s, Loss=6.17e+02, Inv=6.17e+02, For=5.60e+00, Power=8.81e+01
  [eval] val_mse=8.894e+01  (n=7000)
Epoch 00004: Time=   5.9s, Loss=3.62e+02, Inv=3.62e+02, For=5.54e+00, Power=5.60e+01
  [eval] val_mse=6.275e+01  (n=7000)
Epoch 00005: Time=   6.0s, Loss=2.38e+02, Inv=2.38e+02, For=5.47e+00, Power=3.88e+01
  [eval] val_mse=4.754e+01  (n=7000)
Epoch 00006: Time=   6.0s, Loss=1.69e+02, Inv=1.69e+02, For=5.38e+00, Power=2.81e+01
  [eval] val_mse=3.800e+01  (n=7000)
Epoch 00007: Time=   6.1s, Loss=1.27e+02, Inv=1.27e+02, For=5.34e+00, Power=2.14e+01
  [eval] val_mse=3.135e+01  (n=7000)
Epoch 00008: Time=   6.1s, Loss=9.87e+01, Inv=9.87e+01, For=5.30e+00, Power=1.68e+01
  [eval] val_mse=2.654e+01  (n=7000)
Epoch 00009: Time=   6.1s, Loss=8.02e+01, Inv=8.02e+01, For=5.29e+00, Power=1.35e+01
  [eval] val_mse=2.285e+01  (n=7000)
Epoch 00010: Time=   6.2s, Loss=6.67e+01, Inv=6.67e+01, For=5.31e+00, Power=1.12e+01
  [eval] val_mse=1.992e+01  (n=7000)
Epoch 00011: Time=   6.2s, Loss=5.62e+01, Inv=5.62e+01, For=5.30e+00, Power=9.27e+00
  [eval] val_mse=1.757e+01  (n=7000)
Epoch 00012: Time=   6.2s, Loss=4.85e+01, Inv=4.85e+01, For=5.32e+00, Power=7.94e+00
  [eval] val_mse=1.562e+01  (n=7000)
Epoch 00013: Time=   6.3s, Loss=4.23e+01, Inv=4.23e+01, For=5.35e+00, Power=6.82e+00
  [eval] val_mse=1.398e+01  (n=7000)
Epoch 00014: Time=   6.3s, Loss=3.72e+01, Inv=3.72e+01, For=5.40e+00, Power=6.00e+00
  [eval] val_mse=1.259e+01  (n=7000)
Epoch 00015: Time=   6.3s, Loss=3.32e+01, Inv=3.32e+01, For=5.44e+00, Power=5.26e+00
  [eval] val_mse=1.142e+01  (n=7000)
Epoch 00016: Time=   6.4s, Loss=2.97e+01, Inv=2.97e+01, For=5.49e+00, Power=4.67e+00
  [eval] val_mse=1.040e+01  (n=7000)
Epoch 00017: Time=   6.4s, Loss=2.69e+01, Inv=2.69e+01, For=5.56e+00, Power=4.23e+00
  [eval] val_mse=9.501e+00  (n=7000)
Epoch 00018: Time=   6.4s, Loss=2.46e+01, Inv=2.46e+01, For=5.65e+00, Power=3.81e+00
  [eval] val_mse=8.726e+00  (n=7000)
Epoch 00019: Time=   6.5s, Loss=2.25e+01, Inv=2.25e+01, For=5.71e+00, Power=3.44e+00
  [eval] val_mse=8.042e+00  (n=7000)
Epoch 00020: Time=   6.5s, Loss=2.06e+01, Inv=2.06e+01, For=5.79e+00, Power=3.15e+00
  [eval] val_mse=7.449e+00  (n=7000)
Epoch 00021: Time=   6.5s, Loss=1.91e+01, Inv=1.91e+01, For=5.89e+00, Power=2.91e+00
  [eval] val_mse=6.908e+00  (n=7000)
Epoch 00022: Time=   6.6s, Loss=1.78e+01, Inv=1.78e+01, For=5.98e+00, Power=2.68e+00
  [eval] val_mse=6.438e+00  (n=7000)
Epoch 00023: Time=   6.6s, Loss=1.66e+01, Inv=1.66e+01, For=6.10e+00, Power=2.50e+00
  [eval] val_mse=6.001e+00  (n=7000)
Epoch 00024: Time=   6.6s, Loss=1.55e+01, Inv=1.55e+01, For=6.20e+00, Power=2.31e+00
  [eval] val_mse=5.626e+00  (n=7000)
Epoch 00025: Time=   6.7s, Loss=1.46e+01, Inv=1.46e+01, For=6.30e+00, Power=2.15e+00
  [eval] val_mse=5.274e+00  (n=7000)
Epoch 00026: Time=   6.7s, Loss=1.38e+01, Inv=1.38e+01, For=6.42e+00, Power=2.02e+00
  [eval] val_mse=4.955e+00  (n=7000)
Epoch 00027: Time=   6.7s, Loss=1.30e+01, Inv=1.30e+01, For=6.54e+00, Power=1.91e+00
  [eval] val_mse=4.679e+00  (n=7000)
Epoch 00028: Time=   6.8s, Loss=1.24e+01, Inv=1.24e+01, For=6.65e+00, Power=1.81e+00
  [eval] val_mse=4.424e+00  (n=7000)
Epoch 00029: Time=   6.8s, Loss=1.18e+01, Inv=1.18e+01, For=6.77e+00, Power=1.71e+00
  [eval] val_mse=4.183e+00  (n=7000)
Epoch 00030: Time=   6.8s, Loss=1.12e+01, Inv=1.12e+01, For=6.92e+00, Power=1.64e+00
  [eval] val_mse=3.972e+00  (n=7000)
Epoch 00031: Time=   6.9s, Loss=1.07e+01, Inv=1.07e+01, For=7.05e+00, Power=1.56e+00
  [eval] val_mse=3.775e+00  (n=7000)
Epoch 00032: Time=   6.9s, Loss=1.02e+01, Inv=1.02e+01, For=7.19e+00, Power=1.49e+00
  [eval] val_mse=3.597e+00  (n=7000)
Epoch 00033: Time=   6.9s, Loss=9.83e+00, Inv=9.83e+00, For=7.32e+00, Power=1.42e+00
  [eval] val_mse=3.432e+00  (n=7000)
Epoch 00034: Time=   7.0s, Loss=9.47e+00, Inv=9.47e+00, For=7.49e+00, Power=1.37e+00
  [eval] val_mse=3.280e+00  (n=7000)
Epoch 00035: Time=   7.0s, Loss=9.12e+00, Inv=9.12e+00, For=7.65e+00, Power=1.32e+00
  [eval] val_mse=3.134e+00  (n=7000)
Epoch 00036: Time=   7.0s, Loss=8.80e+00, Inv=8.80e+00, For=7.79e+00, Power=1.28e+00
  [eval] val_mse=3.009e+00  (n=7000)
Epoch 00037: Time=   7.1s, Loss=8.50e+00, Inv=8.50e+00, For=7.97e+00, Power=1.23e+00
  [eval] val_mse=2.883e+00  (n=7000)
Epoch 00038: Time=   7.1s, Loss=8.22e+00, Inv=8.22e+00, For=8.16e+00, Power=1.20e+00
  [eval] val_mse=2.775e+00  (n=7000)
Epoch 00039: Time=   7.1s, Loss=7.98e+00, Inv=7.98e+00, For=8.36e+00, Power=1.16e+00
  [eval] val_mse=2.670e+00  (n=7000)
Epoch 00040: Time=   7.2s, Loss=7.75e+00, Inv=7.75e+00, For=8.55e+00, Power=1.13e+00
  [eval] val_mse=2.574e+00  (n=7000)
Epoch 00041: Time=   7.2s, Loss=7.55e+00, Inv=7.55e+00, For=8.75e+00, Power=1.10e+00
  [eval] val_mse=2.484e+00  (n=7000)
Epoch 00042: Time=   7.2s, Loss=7.34e+00, Inv=7.34e+00, For=8.94e+00, Power=1.07e+00
  [eval] val_mse=2.398e+00  (n=7000)
Epoch 00043: Time=   7.3s, Loss=7.17e+00, Inv=7.17e+00, For=9.20e+00, Power=1.06e+00
  [eval] val_mse=2.320e+00  (n=7000)
Epoch 00044: Time=   7.3s, Loss=7.00e+00, Inv=7.00e+00, For=9.43e+00, Power=1.03e+00
  [eval] val_mse=2.244e+00  (n=7000)
Epoch 00045: Time=   7.3s, Loss=6.83e+00, Inv=6.83e+00, For=9.66e+00, Power=1.01e+00
  [eval] val_mse=2.175e+00  (n=7000)
Epoch 00046: Time=   7.4s, Loss=6.69e+00, Inv=6.69e+00, For=9.91e+00, Power=9.89e-01
  [eval] val_mse=2.111e+00  (n=7000)
Epoch 00047: Time=   7.4s, Loss=6.54e+00, Inv=6.54e+00, For=1.01e+01, Power=9.69e-01
  [eval] val_mse=2.046e+00  (n=7000)
Epoch 00048: Time=   7.4s, Loss=6.41e+00, Inv=6.41e+00, For=1.04e+01, Power=9.52e-01
  [eval] val_mse=1.989e+00  (n=7000)
Epoch 00049: Time=   7.5s, Loss=6.29e+00, Inv=6.29e+00, For=1.07e+01, Power=9.39e-01
  [eval] val_mse=1.933e+00  (n=7000)
Epoch 00050: Time=   7.5s, Loss=6.18e+00, Inv=6.18e+00, For=1.10e+01, Power=9.26e-01
  [eval] val_mse=1.881e+00  (n=7000)
Epoch 00051: Time=   7.5s, Loss=6.07e+00, Inv=6.07e+00, For=1.12e+01, Power=9.10e-01
  [eval] val_mse=1.829e+00  (n=7000)
Epoch 00052: Time=   7.6s, Loss=5.97e+00, Inv=5.97e+00, For=1.15e+01, Power=8.99e-01
  [eval] val_mse=1.781e+00  (n=7000)
Epoch 00053: Time=   7.6s, Loss=5.88e+00, Inv=5.88e+00, For=1.19e+01, Power=8.90e-01
  [eval] val_mse=1.738e+00  (n=7000)
Epoch 00054: Time=   7.6s, Loss=5.79e+00, Inv=5.79e+00, For=1.21e+01, Power=8.79e-01
  [eval] val_mse=1.693e+00  (n=7000)
Epoch 00055: Time=   7.7s, Loss=5.71e+00, Inv=5.71e+00, For=1.25e+01, Power=8.71e-01
  [eval] val_mse=1.652e+00  (n=7000)
Epoch 00056: Time=   7.7s, Loss=5.62e+00, Inv=5.62e+00, For=1.28e+01, Power=8.61e-01
  [eval] val_mse=1.611e+00  (n=7000)
Epoch 00057: Time=   7.7s, Loss=5.55e+00, Inv=5.55e+00, For=1.31e+01, Power=8.55e-01
  [eval] val_mse=1.574e+00  (n=7000)
Epoch 00058: Time=   7.8s, Loss=5.47e+00, Inv=5.47e+00, For=1.34e+01, Power=8.44e-01
  [eval] val_mse=1.538e+00  (n=7000)
Epoch 00059: Time=   7.8s, Loss=5.41e+00, Inv=5.41e+00, For=1.38e+01, Power=8.41e-01
  [eval] val_mse=1.502e+00  (n=7000)
Epoch 00060: Time=   7.8s, Loss=5.34e+00, Inv=5.34e+00, For=1.41e+01, Power=8.33e-01
  [eval] val_mse=1.471e+00  (n=7000)
Epoch 00061: Time=   7.9s, Loss=5.28e+00, Inv=5.28e+00, For=1.44e+01, Power=8.27e-01
  [eval] val_mse=1.437e+00  (n=7000)
Epoch 00062: Time=   7.9s, Loss=5.22e+00, Inv=5.22e+00, For=1.48e+01, Power=8.20e-01
  [eval] val_mse=1.407e+00  (n=7000)
Epoch 00063: Time=   7.9s, Loss=5.16e+00, Inv=5.16e+00, For=1.51e+01, Power=8.12e-01
  [eval] val_mse=1.376e+00  (n=7000)
Epoch 00064: Time=   8.0s, Loss=5.11e+00, Inv=5.11e+00, For=1.55e+01, Power=8.09e-01
  [eval] val_mse=1.347e+00  (n=7000)
Epoch 00065: Time=   8.0s, Loss=5.05e+00, Inv=5.05e+00, For=1.58e+01, Power=8.03e-01
  [eval] val_mse=1.320e+00  (n=7000)
Epoch 00066: Time=   8.0s, Loss=5.00e+00, Inv=5.00e+00, For=1.62e+01, Power=7.99e-01
  [eval] val_mse=1.293e+00  (n=7000)
Epoch 00067: Time=   8.1s, Loss=4.95e+00, Inv=4.95e+00, For=1.66e+01, Power=7.97e-01
  [eval] val_mse=1.268e+00  (n=7000)
Epoch 00068: Time=   8.1s, Loss=4.90e+00, Inv=4.90e+00, For=1.69e+01, Power=7.90e-01
  [eval] val_mse=1.243e+00  (n=7000)
Epoch 00069: Time=   8.1s, Loss=4.87e+00, Inv=4.87e+00, For=1.74e+01, Power=7.84e-01
  [eval] val_mse=1.220e+00  (n=7000)
Epoch 00070: Time=   8.2s, Loss=4.82e+00, Inv=4.82e+00, For=1.77e+01, Power=7.81e-01
  [eval] val_mse=1.195e+00  (n=7000)
Epoch 00071: Time=   8.2s, Loss=4.78e+00, Inv=4.78e+00, For=1.81e+01, Power=7.81e-01
  [eval] val_mse=1.172e+00  (n=7000)
Epoch 00072: Time=   8.2s, Loss=4.74e+00, Inv=4.74e+00, For=1.85e+01, Power=7.76e-01
  [eval] val_mse=1.151e+00  (n=7000)
Epoch 00073: Time=   8.3s, Loss=4.70e+00, Inv=4.70e+00, For=1.89e+01, Power=7.73e-01
  [eval] val_mse=1.131e+00  (n=7000)
Epoch 00074: Time=   8.3s, Loss=4.66e+00, Inv=4.66e+00, For=1.93e+01, Power=7.68e-01
  [eval] val_mse=1.112e+00  (n=7000)
Epoch 00075: Time=   8.3s, Loss=4.63e+00, Inv=4.63e+00, For=1.97e+01, Power=7.66e-01
  [eval] val_mse=1.091e+00  (n=7000)
Epoch 00076: Time=   8.4s, Loss=4.60e+00, Inv=4.60e+00, For=2.01e+01, Power=7.67e-01
  [eval] val_mse=1.072e+00  (n=7000)
Epoch 00077: Time=   8.4s, Loss=4.56e+00, Inv=4.56e+00, For=2.06e+01, Power=7.63e-01
  [eval] val_mse=1.053e+00  (n=7000)
Epoch 00078: Time=   8.4s, Loss=4.52e+00, Inv=4.52e+00, For=2.10e+01, Power=7.60e-01
  [eval] val_mse=1.036e+00  (n=7000)
Epoch 00079: Time=   8.5s, Loss=4.49e+00, Inv=4.49e+00, For=2.13e+01, Power=7.53e-01
  [eval] val_mse=1.019e+00  (n=7000)
Epoch 00080: Time=   8.5s, Loss=4.47e+00, Inv=4.47e+00, For=2.17e+01, Power=7.57e-01
  [eval] val_mse=1.002e+00  (n=7000)
Epoch 00081: Time=   8.5s, Loss=4.44e+00, Inv=4.44e+00, For=2.22e+01, Power=7.54e-01
  [eval] val_mse=9.839e-01  (n=7000)
Epoch 00082: Time=   8.6s, Loss=4.41e+00, Inv=4.41e+00, For=2.27e+01, Power=7.53e-01
  [eval] val_mse=9.702e-01  (n=7000)
Epoch 00083: Time=   8.6s, Loss=4.38e+00, Inv=4.38e+00, For=2.31e+01, Power=7.51e-01
  [eval] val_mse=9.549e-01  (n=7000)
Epoch 00084: Time=   8.6s, Loss=4.35e+00, Inv=4.35e+00, For=2.35e+01, Power=7.49e-01
  [eval] val_mse=9.404e-01  (n=7000)
Epoch 00085: Time=   8.7s, Loss=4.32e+00, Inv=4.32e+00, For=2.40e+01, Power=7.45e-01
  [eval] val_mse=9.249e-01  (n=7000)
Epoch 00086: Time=   8.7s, Loss=4.30e+00, Inv=4.30e+00, For=2.45e+01, Power=7.45e-01
  [eval] val_mse=9.121e-01  (n=7000)
Epoch 00087: Time=   8.7s, Loss=4.28e+00, Inv=4.28e+00, For=2.49e+01, Power=7.44e-01
  [eval] val_mse=8.964e-01  (n=7000)
Epoch 00088: Time=   8.8s, Loss=4.25e+00, Inv=4.25e+00, For=2.53e+01, Power=7.41e-01
  [eval] val_mse=8.842e-01  (n=7000)
Epoch 00089: Time=   8.8s, Loss=4.22e+00, Inv=4.22e+00, For=2.58e+01, Power=7.41e-01
  [eval] val_mse=8.724e-01  (n=7000)
Epoch 00090: Time=   8.8s, Loss=4.20e+00, Inv=4.20e+00, For=2.63e+01, Power=7.36e-01
  [eval] val_mse=8.589e-01  (n=7000)
Epoch 00091: Time=   8.9s, Loss=4.18e+00, Inv=4.18e+00, For=2.68e+01, Power=7.40e-01
  [eval] val_mse=8.455e-01  (n=7000)
Epoch 00092: Time=   8.9s, Loss=4.15e+00, Inv=4.15e+00, For=2.72e+01, Power=7.37e-01
  [eval] val_mse=8.345e-01  (n=7000)
Epoch 00093: Time=   8.9s, Loss=4.13e+00, Inv=4.13e+00, For=2.77e+01, Power=7.34e-01
  [eval] val_mse=8.232e-01  (n=7000)
Epoch 00094: Time=   9.0s, Loss=4.11e+00, Inv=4.11e+00, For=2.83e+01, Power=7.34e-01
  [eval] val_mse=8.125e-01  (n=7000)
Epoch 00095: Time=   9.0s, Loss=4.08e+00, Inv=4.08e+00, For=2.86e+01, Power=7.30e-01
  [eval] val_mse=8.014e-01  (n=7000)
Epoch 00096: Time=   9.0s, Loss=4.06e+00, Inv=4.06e+00, For=2.92e+01, Power=7.30e-01
  [eval] val_mse=7.903e-01  (n=7000)
Epoch 00097: Time=   9.1s, Loss=4.05e+00, Inv=4.05e+00, For=2.96e+01, Power=7.32e-01
  [eval] val_mse=7.803e-01  (n=7000)
Epoch 00098: Time=   9.1s, Loss=4.03e+00, Inv=4.03e+00, For=3.01e+01, Power=7.29e-01
  [eval] val_mse=7.702e-01  (n=7000)
Epoch 00099: Time=   9.1s, Loss=4.01e+00, Inv=4.01e+00, For=3.07e+01, Power=7.28e-01
  [eval] val_mse=7.604e-01  (n=7000)
Epoch 00100: Time=   9.2s, Loss=3.99e+00, Inv=3.99e+00, For=3.12e+01, Power=7.26e-01
  [eval] val_mse=7.515e-01  (n=7000)
Epoch 00101: Time=   9.2s, Loss=3.97e+00, Inv=3.97e+00, For=3.17e+01, Power=7.25e-01
  [eval] val_mse=7.424e-01  (n=7000)
Epoch 00102: Time=   9.2s, Loss=3.95e+00, Inv=3.95e+00, For=3.21e+01, Power=7.25e-01
  [eval] val_mse=7.334e-01  (n=7000)
Epoch 00103: Time=   9.3s, Loss=3.93e+00, Inv=3.93e+00, For=3.26e+01, Power=7.22e-01
  [eval] val_mse=7.239e-01  (n=7000)
Epoch 00104: Time=   9.3s, Loss=3.91e+00, Inv=3.91e+00, For=3.32e+01, Power=7.23e-01
  [eval] val_mse=7.168e-01  (n=7000)
Epoch 00105: Time=   9.3s, Loss=3.89e+00, Inv=3.89e+00, For=3.38e+01, Power=7.22e-01
  [eval] val_mse=7.072e-01  (n=7000)
Epoch 00106: Time=   9.4s, Loss=3.88e+00, Inv=3.88e+00, For=3.43e+01, Power=7.21e-01
  [eval] val_mse=6.995e-01  (n=7000)
Epoch 00107: Time=   9.4s, Loss=3.86e+00, Inv=3.86e+00, For=3.47e+01, Power=7.19e-01
  [eval] val_mse=6.913e-01  (n=7000)
Epoch 00108: Time=   9.4s, Loss=3.85e+00, Inv=3.85e+00, For=3.53e+01, Power=7.18e-01
  [eval] val_mse=6.833e-01  (n=7000)
Epoch 00109: Time=   9.5s, Loss=3.83e+00, Inv=3.83e+00, For=3.59e+01, Power=7.19e-01
  [eval] val_mse=6.762e-01  (n=7000)
Epoch 00110: Time=   9.5s, Loss=3.81e+00, Inv=3.81e+00, For=3.63e+01, Power=7.17e-01
  [eval] val_mse=6.685e-01  (n=7000)
Epoch 00111: Time=   9.5s, Loss=3.80e+00, Inv=3.80e+00, For=3.67e+01, Power=7.20e-01
  [eval] val_mse=6.620e-01  (n=7000)
Epoch 00112: Time=   9.6s, Loss=3.79e+00, Inv=3.79e+00, For=3.75e+01, Power=7.17e-01
  [eval] val_mse=6.546e-01  (n=7000)
Epoch 00113: Time=   9.6s, Loss=3.78e+00, Inv=3.78e+00, For=3.80e+01, Power=7.16e-01
  [eval] val_mse=6.481e-01  (n=7000)
Epoch 00114: Time=   9.6s, Loss=3.76e+00, Inv=3.76e+00, For=3.85e+01, Power=7.18e-01
  [eval] val_mse=6.418e-01  (n=7000)
Epoch 00115: Time=   9.7s, Loss=3.75e+00, Inv=3.75e+00, For=3.91e+01, Power=7.15e-01
  [eval] val_mse=6.356e-01  (n=7000)
Epoch 00116: Time=   9.7s, Loss=3.73e+00, Inv=3.73e+00, For=3.97e+01, Power=7.09e-01
  [eval] val_mse=6.285e-01  (n=7000)
Epoch 00117: Time=   9.7s, Loss=3.72e+00, Inv=3.72e+00, For=4.03e+01, Power=7.14e-01
  [eval] val_mse=6.229e-01  (n=7000)
Epoch 00118: Time=   9.8s, Loss=3.70e+00, Inv=3.70e+00, For=4.08e+01, Power=7.13e-01
  [eval] val_mse=6.167e-01  (n=7000)
Epoch 00119: Time=   9.8s, Loss=3.69e+00, Inv=3.69e+00, For=4.14e+01, Power=7.13e-01
  [eval] val_mse=6.106e-01  (n=7000)
Epoch 00120: Time=   9.8s, Loss=3.68e+00, Inv=3.68e+00, For=4.20e+01, Power=7.12e-01
  [eval] val_mse=6.044e-01  (n=7000)
Epoch 00121: Time=   9.9s, Loss=3.67e+00, Inv=3.67e+00, For=4.25e+01, Power=7.10e-01
  [eval] val_mse=5.996e-01  (n=7000)
Epoch 00122: Time=   9.9s, Loss=3.66e+00, Inv=3.66e+00, For=4.33e+01, Power=7.08e-01
  [eval] val_mse=5.947e-01  (n=7000)
Epoch 00123: Time=   9.9s, Loss=3.65e+00, Inv=3.65e+00, For=4.38e+01, Power=7.07e-01
  [eval] val_mse=5.889e-01  (n=7000)
Epoch 00124: Time=  10.0s, Loss=3.64e+00, Inv=3.64e+00, For=4.43e+01, Power=7.08e-01
  [eval] val_mse=5.833e-01  (n=7000)
Epoch 00125: Time=  10.0s, Loss=3.62e+00, Inv=3.62e+00, For=4.49e+01, Power=7.06e-01
  [eval] val_mse=5.778e-01  (n=7000)
Epoch 00126: Time=  10.0s, Loss=3.62e+00, Inv=3.62e+00, For=4.55e+01, Power=7.08e-01
  [eval] val_mse=5.726e-01  (n=7000)
Epoch 00127: Time=  10.1s, Loss=3.61e+00, Inv=3.61e+00, For=4.62e+01, Power=7.09e-01
  [eval] val_mse=5.686e-01  (n=7000)
Epoch 00128: Time=  10.1s, Loss=3.59e+00, Inv=3.59e+00, For=4.66e+01, Power=7.03e-01
  [eval] val_mse=5.632e-01  (n=7000)
Epoch 00129: Time=  10.1s, Loss=3.59e+00, Inv=3.59e+00, For=4.74e+01, Power=7.08e-01
  [eval] val_mse=5.586e-01  (n=7000)
Epoch 00130: Time=  10.2s, Loss=3.57e+00, Inv=3.57e+00, For=4.78e+01, Power=7.05e-01
  [eval] val_mse=5.535e-01  (n=7000)
Epoch 00131: Time=  10.2s, Loss=3.57e+00, Inv=3.57e+00, For=4.85e+01, Power=7.08e-01
  [eval] val_mse=5.498e-01  (n=7000)
Epoch 00132: Time=  10.2s, Loss=3.56e+00, Inv=3.56e+00, For=4.92e+01, Power=7.07e-01
  [eval] val_mse=5.446e-01  (n=7000)
Epoch 00133: Time=  10.3s, Loss=3.55e+00, Inv=3.55e+00, For=4.99e+01, Power=7.05e-01
  [eval] val_mse=5.405e-01  (n=7000)
Epoch 00134: Time=  10.3s, Loss=3.54e+00, Inv=3.54e+00, For=5.02e+01, Power=7.02e-01
  [eval] val_mse=5.359e-01  (n=7000)
Epoch 00135: Time=  10.3s, Loss=3.53e+00, Inv=3.53e+00, For=5.09e+01, Power=7.03e-01
  [eval] val_mse=5.317e-01  (n=7000)
Epoch 00136: Time=  10.4s, Loss=3.52e+00, Inv=3.52e+00, For=5.15e+01, Power=7.02e-01
  [eval] val_mse=5.284e-01  (n=7000)
Epoch 00137: Time=  10.4s, Loss=3.51e+00, Inv=3.51e+00, For=5.23e+01, Power=7.01e-01
  [eval] val_mse=5.247e-01  (n=7000)
Epoch 00138: Time=  10.4s, Loss=3.51e+00, Inv=3.51e+00, For=5.28e+01, Power=7.00e-01
  [eval] val_mse=5.202e-01  (n=7000)
Epoch 00139: Time=  10.5s, Loss=3.49e+00, Inv=3.49e+00, For=5.36e+01, Power=6.99e-01
  [eval] val_mse=5.163e-01  (n=7000)
Epoch 00140: Time=  10.5s, Loss=3.49e+00, Inv=3.49e+00, For=5.40e+01, Power=7.01e-01
  [eval] val_mse=5.126e-01  (n=7000)
Epoch 00141: Time=  10.5s, Loss=3.48e+00, Inv=3.48e+00, For=5.47e+01, Power=6.99e-01
  [eval] val_mse=5.092e-01  (n=7000)
Epoch 00142: Time=  10.6s, Loss=3.47e+00, Inv=3.47e+00, For=5.53e+01, Power=7.00e-01
  [eval] val_mse=5.045e-01  (n=7000)
Epoch 00143: Time=  10.6s, Loss=3.47e+00, Inv=3.47e+00, For=5.59e+01, Power=7.00e-01
  [eval] val_mse=5.010e-01  (n=7000)
Epoch 00144: Time=  10.6s, Loss=3.46e+00, Inv=3.46e+00, For=5.66e+01, Power=6.96e-01
  [eval] val_mse=4.975e-01  (n=7000)
Epoch 00145: Time=  10.7s, Loss=3.45e+00, Inv=3.45e+00, For=5.73e+01, Power=6.98e-01
  [eval] val_mse=4.941e-01  (n=7000)
Epoch 00146: Time=  10.7s, Loss=3.44e+00, Inv=3.44e+00, For=5.79e+01, Power=6.98e-01
  [eval] val_mse=4.913e-01  (n=7000)
Epoch 00147: Time=  10.8s, Loss=3.44e+00, Inv=3.44e+00, For=5.86e+01, Power=6.96e-01
  [eval] val_mse=4.887e-01  (n=7000)
Epoch 00148: Time=  10.8s, Loss=3.43e+00, Inv=3.43e+00, For=5.95e+01, Power=6.99e-01
  [eval] val_mse=4.848e-01  (n=7000)
Epoch 00149: Time=  10.8s, Loss=3.42e+00, Inv=3.42e+00, For=5.99e+01, Power=6.96e-01
  [eval] val_mse=4.816e-01  (n=7000)
Epoch 00150: Time=  10.9s, Loss=3.42e+00, Inv=3.42e+00, For=6.07e+01, Power=6.98e-01
  [eval] val_mse=4.782e-01  (n=7000)
Epoch 00151: Time=  10.9s, Loss=3.41e+00, Inv=3.41e+00, For=6.12e+01, Power=6.97e-01
  [eval] val_mse=4.752e-01  (n=7000)
Epoch 00152: Time=  10.9s, Loss=3.40e+00, Inv=3.40e+00, For=6.17e+01, Power=6.93e-01
  [eval] val_mse=4.722e-01  (n=7000)
Epoch 00153: Time=  11.0s, Loss=3.40e+00, Inv=3.40e+00, For=6.26e+01, Power=6.94e-01
  [eval] val_mse=4.690e-01  (n=7000)
Epoch 00154: Time=  11.0s, Loss=3.39e+00, Inv=3.39e+00, For=6.36e+01, Power=6.94e-01
  [eval] val_mse=4.659e-01  (n=7000)
Epoch 00155: Time=  11.0s, Loss=3.38e+00, Inv=3.38e+00, For=6.40e+01, Power=6.96e-01
  [eval] val_mse=4.634e-01  (n=7000)
Epoch 00156: Time=  11.1s, Loss=3.38e+00, Inv=3.38e+00, For=6.50e+01, Power=6.94e-01
  [eval] val_mse=4.610e-01  (n=7000)
Epoch 00157: Time=  11.1s, Loss=3.37e+00, Inv=3.37e+00, For=6.54e+01, Power=6.92e-01
  [eval] val_mse=4.589e-01  (n=7000)
Epoch 00158: Time=  11.1s, Loss=3.36e+00, Inv=3.36e+00, For=6.59e+01, Power=6.92e-01
  [eval] val_mse=4.553e-01  (n=7000)
Epoch 00159: Time=  11.2s, Loss=3.36e+00, Inv=3.36e+00, For=6.63e+01, Power=6.93e-01
  [eval] val_mse=4.527e-01  (n=7000)
Epoch 00160: Time=  11.2s, Loss=3.36e+00, Inv=3.36e+00, For=6.74e+01, Power=6.91e-01
  [eval] val_mse=4.505e-01  (n=7000)
Epoch 00161: Time=  11.2s, Loss=3.35e+00, Inv=3.35e+00, For=6.81e+01, Power=6.92e-01
  [eval] val_mse=4.481e-01  (n=7000)
Epoch 00162: Time=  11.3s, Loss=3.35e+00, Inv=3.35e+00, For=6.93e+01, Power=6.94e-01
  [eval] val_mse=4.451e-01  (n=7000)
Epoch 00163: Time=  11.3s, Loss=3.34e+00, Inv=3.34e+00, For=6.94e+01, Power=6.93e-01
  [eval] val_mse=4.430e-01  (n=7000)
Epoch 00164: Time=  11.3s, Loss=3.33e+00, Inv=3.33e+00, For=7.04e+01, Power=6.90e-01
  [eval] val_mse=4.403e-01  (n=7000)
Epoch 00165: Time=  11.4s, Loss=3.33e+00, Inv=3.33e+00, For=7.10e+01, Power=6.90e-01
  [eval] val_mse=4.388e-01  (n=7000)
Epoch 00166: Time=  11.4s, Loss=3.32e+00, Inv=3.32e+00, For=7.19e+01, Power=6.90e-01
  [eval] val_mse=4.365e-01  (n=7000)
Epoch 00167: Time=  11.4s, Loss=3.32e+00, Inv=3.32e+00, For=7.28e+01, Power=6.90e-01
  [eval] val_mse=4.339e-01  (n=7000)
Epoch 00168: Time=  11.5s, Loss=3.31e+00, Inv=3.31e+00, For=7.31e+01, Power=6.90e-01
  [eval] val_mse=4.319e-01  (n=7000)
Epoch 00169: Time=  11.5s, Loss=3.30e+00, Inv=3.30e+00, For=7.35e+01, Power=6.85e-01
  [eval] val_mse=4.304e-01  (n=7000)
Epoch 00170: Time=  11.5s, Loss=3.30e+00, Inv=3.30e+00, For=7.47e+01, Power=6.87e-01
  [eval] val_mse=4.282e-01  (n=7000)
Epoch 00171: Time=  11.6s, Loss=3.29e+00, Inv=3.29e+00, For=7.59e+01, Power=6.90e-01
  [eval] val_mse=4.261e-01  (n=7000)
Epoch 00172: Time=  11.6s, Loss=3.29e+00, Inv=3.29e+00, For=7.64e+01, Power=6.90e-01
  [eval] val_mse=4.244e-01  (n=7000)
Epoch 00173: Time=  11.6s, Loss=3.29e+00, Inv=3.29e+00, For=7.70e+01, Power=6.90e-01
  [eval] val_mse=4.222e-01  (n=7000)
Epoch 00174: Time=  11.7s, Loss=3.28e+00, Inv=3.28e+00, For=7.74e+01, Power=6.88e-01
  [eval] val_mse=4.202e-01  (n=7000)
Epoch 00175: Time=  11.7s, Loss=3.27e+00, Inv=3.27e+00, For=7.85e+01, Power=6.84e-01
  [eval] val_mse=4.184e-01  (n=7000)
Epoch 00176: Time=  11.7s, Loss=3.27e+00, Inv=3.27e+00, For=7.98e+01, Power=6.87e-01
  [eval] val_mse=4.160e-01  (n=7000)
Epoch 00177: Time=  11.8s, Loss=3.27e+00, Inv=3.27e+00, For=8.04e+01, Power=6.86e-01
  [eval] val_mse=4.153e-01  (n=7000)
Epoch 00178: Time=  11.8s, Loss=3.26e+00, Inv=3.26e+00, For=8.13e+01, Power=6.87e-01
  [eval] val_mse=4.140e-01  (n=7000)
Epoch 00179: Time=  11.8s, Loss=3.26e+00, Inv=3.26e+00, For=8.24e+01, Power=6.84e-01
  [eval] val_mse=4.116e-01  (n=7000)
Epoch 00180: Time=  11.9s, Loss=3.25e+00, Inv=3.25e+00, For=8.30e+01, Power=6.87e-01
  [eval] val_mse=4.105e-01  (n=7000)
Epoch 00181: Time=  11.9s, Loss=3.25e+00, Inv=3.25e+00, For=8.38e+01, Power=6.87e-01
  [eval] val_mse=4.086e-01  (n=7000)
Epoch 00182: Time=  11.9s, Loss=3.25e+00, Inv=3.25e+00, For=8.49e+01, Power=6.86e-01
  [eval] val_mse=4.076e-01  (n=7000)
Epoch 00183: Time=  12.0s, Loss=3.25e+00, Inv=3.25e+00, For=8.54e+01, Power=6.86e-01
  [eval] val_mse=4.058e-01  (n=7000)
Epoch 00184: Time=  12.0s, Loss=3.24e+00, Inv=3.24e+00, For=8.66e+01, Power=6.85e-01
  [eval] val_mse=4.038e-01  (n=7000)
Epoch 00185: Time=  12.0s, Loss=3.23e+00, Inv=3.23e+00, For=8.72e+01, Power=6.87e-01
  [eval] val_mse=4.030e-01  (n=7000)
Epoch 00186: Time=  12.1s, Loss=3.23e+00, Inv=3.23e+00, For=8.80e+01, Power=6.85e-01
  [eval] val_mse=4.012e-01  (n=7000)
Epoch 00187: Time=  12.1s, Loss=3.23e+00, Inv=3.23e+00, For=8.95e+01, Power=6.84e-01
  [eval] val_mse=4.004e-01  (n=7000)
Epoch 00188: Time=  12.1s, Loss=3.23e+00, Inv=3.23e+00, For=9.01e+01, Power=6.84e-01
  [eval] val_mse=3.991e-01  (n=7000)
Epoch 00189: Time=  12.2s, Loss=3.22e+00, Inv=3.22e+00, For=9.13e+01, Power=6.84e-01
  [eval] val_mse=3.975e-01  (n=7000)
Epoch 00190: Time=  12.2s, Loss=3.21e+00, Inv=3.21e+00, For=9.22e+01, Power=6.82e-01
  [eval] val_mse=3.963e-01  (n=7000)
Epoch 00191: Time=  12.2s, Loss=3.21e+00, Inv=3.21e+00, For=9.32e+01, Power=6.83e-01
  [eval] val_mse=3.948e-01  (n=7000)
Epoch 00192: Time=  12.3s, Loss=3.21e+00, Inv=3.21e+00, For=9.45e+01, Power=6.83e-01
  [eval] val_mse=3.938e-01  (n=7000)
Epoch 00193: Time=  12.3s, Loss=3.21e+00, Inv=3.21e+00, For=9.51e+01, Power=6.84e-01
  [eval] val_mse=3.928e-01  (n=7000)
Epoch 00194: Time=  12.3s, Loss=3.20e+00, Inv=3.20e+00, For=9.63e+01, Power=6.84e-01
  [eval] val_mse=3.917e-01  (n=7000)
Epoch 00195: Time=  12.4s, Loss=3.20e+00, Inv=3.20e+00, For=9.69e+01, Power=6.85e-01
  [eval] val_mse=3.901e-01  (n=7000)
Epoch 00196: Time=  12.4s, Loss=3.19e+00, Inv=3.19e+00, For=9.79e+01, Power=6.84e-01
  [eval] val_mse=3.892e-01  (n=7000)
Epoch 00197: Time=  12.4s, Loss=3.19e+00, Inv=3.19e+00, For=1.00e+02, Power=6.84e-01
  [eval] val_mse=3.885e-01  (n=7000)
Epoch 00198: Time=  12.5s, Loss=3.19e+00, Inv=3.19e+00, For=1.00e+02, Power=6.83e-01
  [eval] val_mse=3.872e-01  (n=7000)
Epoch 00199: Time=  12.5s, Loss=3.18e+00, Inv=3.18e+00, For=1.02e+02, Power=6.84e-01
  [eval] val_mse=3.863e-01  (n=7000)
Epoch 00200: Time=  12.5s, Loss=3.18e+00, Inv=3.18e+00, For=1.02e+02, Power=6.85e-01
  [eval] val_mse=3.851e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 2.533e-01
Torque MSE  = 1.152e-01
Torque RMSE = 3.393e-01
Per-joint MSE : 7.871e-02 1.829e-01 6.929e-02 1.820e-02 3.250e-01 1.679e-02
Per-joint RMSE: 2.806e-01 4.277e-01 2.632e-01 1.349e-01 5.701e-01 1.296e-01
Comp Time per Sample = 2.799e-04s / 3573.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-r1lki0q0 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7e713ada68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:55:59.486631: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:56:01.361751: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.0s, Loss=8.54e+03, Inv=8.54e+03, For=5.85e+00, Power=1.48e+03
  [eval] val_mse=5.576e+02  (n=7000)
Epoch 00002: Time=   5.5s, Loss=1.85e+03, Inv=1.85e+03, For=5.73e+00, Power=3.47e+02
  [eval] val_mse=2.276e+02  (n=7000)
Epoch 00003: Time=   5.6s, Loss=7.65e+02, Inv=7.65e+02, For=5.65e+00, Power=1.68e+02
  [eval] val_mse=1.339e+02  (n=7000)
Epoch 00004: Time=   5.6s, Loss=4.30e+02, Inv=4.30e+02, For=5.59e+00, Power=9.71e+01
  [eval] val_mse=9.191e+01  (n=7000)
Epoch 00005: Time=   5.7s, Loss=2.81e+02, Inv=2.81e+02, For=5.54e+00, Power=6.39e+01
  [eval] val_mse=6.822e+01  (n=7000)
Epoch 00006: Time=   5.7s, Loss=2.00e+02, Inv=2.00e+02, For=5.47e+00, Power=4.50e+01
  [eval] val_mse=5.279e+01  (n=7000)
Epoch 00007: Time=   5.7s, Loss=1.50e+02, Inv=1.50e+02, For=5.43e+00, Power=3.33e+01
  [eval] val_mse=4.211e+01  (n=7000)
Epoch 00008: Time=   5.8s, Loss=1.17e+02, Inv=1.17e+02, For=5.39e+00, Power=2.53e+01
  [eval] val_mse=3.443e+01  (n=7000)
Epoch 00009: Time=   5.8s, Loss=9.43e+01, Inv=9.43e+01, For=5.39e+00, Power=2.00e+01
  [eval] val_mse=2.858e+01  (n=7000)
Epoch 00010: Time=   5.8s, Loss=7.75e+01, Inv=7.75e+01, For=5.38e+00, Power=1.61e+01
  [eval] val_mse=2.405e+01  (n=7000)
Epoch 00011: Time=   5.9s, Loss=6.49e+01, Inv=6.49e+01, For=5.39e+00, Power=1.31e+01
  [eval] val_mse=2.048e+01  (n=7000)
Epoch 00012: Time=   5.9s, Loss=5.51e+01, Inv=5.51e+01, For=5.38e+00, Power=1.08e+01
  [eval] val_mse=1.766e+01  (n=7000)
Epoch 00013: Time=   5.9s, Loss=4.74e+01, Inv=4.74e+01, For=5.40e+00, Power=9.10e+00
  [eval] val_mse=1.533e+01  (n=7000)
Epoch 00014: Time=   6.0s, Loss=4.14e+01, Inv=4.14e+01, For=5.42e+00, Power=7.77e+00
  [eval] val_mse=1.346e+01  (n=7000)
Epoch 00015: Time=   6.0s, Loss=3.64e+01, Inv=3.64e+01, For=5.44e+00, Power=6.72e+00
  [eval] val_mse=1.189e+01  (n=7000)
Epoch 00016: Time=   6.0s, Loss=3.23e+01, Inv=3.23e+01, For=5.50e+00, Power=5.86e+00
  [eval] val_mse=1.059e+01  (n=7000)
Epoch 00017: Time=   6.1s, Loss=2.90e+01, Inv=2.90e+01, For=5.57e+00, Power=5.15e+00
  [eval] val_mse=9.494e+00  (n=7000)
Epoch 00018: Time=   6.1s, Loss=2.61e+01, Inv=2.61e+01, For=5.63e+00, Power=4.57e+00
  [eval] val_mse=8.553e+00  (n=7000)
Epoch 00019: Time=   6.1s, Loss=2.37e+01, Inv=2.37e+01, For=5.68e+00, Power=4.10e+00
  [eval] val_mse=7.751e+00  (n=7000)
Epoch 00020: Time=   6.2s, Loss=2.17e+01, Inv=2.17e+01, For=5.77e+00, Power=3.69e+00
  [eval] val_mse=7.049e+00  (n=7000)
Epoch 00021: Time=   6.2s, Loss=2.00e+01, Inv=2.00e+01, For=5.84e+00, Power=3.33e+00
  [eval] val_mse=6.450e+00  (n=7000)
Epoch 00022: Time=   6.2s, Loss=1.84e+01, Inv=1.84e+01, For=5.95e+00, Power=3.07e+00
  [eval] val_mse=5.934e+00  (n=7000)
Epoch 00023: Time=   6.3s, Loss=1.71e+01, Inv=1.71e+01, For=6.04e+00, Power=2.80e+00
  [eval] val_mse=5.472e+00  (n=7000)
Epoch 00024: Time=   6.3s, Loss=1.59e+01, Inv=1.59e+01, For=6.14e+00, Power=2.60e+00
  [eval] val_mse=5.072e+00  (n=7000)
Epoch 00025: Time=   6.3s, Loss=1.49e+01, Inv=1.49e+01, For=6.24e+00, Power=2.41e+00
  [eval] val_mse=4.712e+00  (n=7000)
Epoch 00026: Time=   6.4s, Loss=1.40e+01, Inv=1.40e+01, For=6.36e+00, Power=2.24e+00
  [eval] val_mse=4.388e+00  (n=7000)
Epoch 00027: Time=   6.4s, Loss=1.32e+01, Inv=1.32e+01, For=6.48e+00, Power=2.09e+00
  [eval] val_mse=4.099e+00  (n=7000)
Epoch 00028: Time=   6.5s, Loss=1.25e+01, Inv=1.25e+01, For=6.62e+00, Power=1.97e+00
  [eval] val_mse=3.843e+00  (n=7000)
Epoch 00029: Time=   6.5s, Loss=1.19e+01, Inv=1.19e+01, For=6.77e+00, Power=1.86e+00
  [eval] val_mse=3.611e+00  (n=7000)
Epoch 00030: Time=   6.5s, Loss=1.13e+01, Inv=1.13e+01, For=6.92e+00, Power=1.76e+00
  [eval] val_mse=3.399e+00  (n=7000)
Epoch 00031: Time=   6.6s, Loss=1.08e+01, Inv=1.08e+01, For=7.05e+00, Power=1.67e+00
  [eval] val_mse=3.207e+00  (n=7000)
Epoch 00032: Time=   6.6s, Loss=1.03e+01, Inv=1.03e+01, For=7.24e+00, Power=1.59e+00
  [eval] val_mse=3.033e+00  (n=7000)
Epoch 00033: Time=   6.6s, Loss=9.85e+00, Inv=9.85e+00, For=7.36e+00, Power=1.51e+00
  [eval] val_mse=2.873e+00  (n=7000)
Epoch 00034: Time=   6.7s, Loss=9.47e+00, Inv=9.47e+00, For=7.56e+00, Power=1.45e+00
  [eval] val_mse=2.727e+00  (n=7000)
Epoch 00035: Time=   6.7s, Loss=9.10e+00, Inv=9.10e+00, For=7.74e+00, Power=1.39e+00
  [eval] val_mse=2.600e+00  (n=7000)
Epoch 00036: Time=   6.7s, Loss=8.79e+00, Inv=8.79e+00, For=7.97e+00, Power=1.34e+00
  [eval] val_mse=2.476e+00  (n=7000)
Epoch 00037: Time=   6.8s, Loss=8.48e+00, Inv=8.48e+00, For=8.13e+00, Power=1.29e+00
  [eval] val_mse=2.359e+00  (n=7000)
Epoch 00038: Time=   6.8s, Loss=8.21e+00, Inv=8.21e+00, For=8.37e+00, Power=1.25e+00
  [eval] val_mse=2.256e+00  (n=7000)
Epoch 00039: Time=   6.8s, Loss=7.96e+00, Inv=7.96e+00, For=8.60e+00, Power=1.21e+00
  [eval] val_mse=2.159e+00  (n=7000)
Epoch 00040: Time=   6.9s, Loss=7.72e+00, Inv=7.72e+00, For=8.80e+00, Power=1.17e+00
  [eval] val_mse=2.070e+00  (n=7000)
Epoch 00041: Time=   6.9s, Loss=7.51e+00, Inv=7.51e+00, For=9.06e+00, Power=1.15e+00
  [eval] val_mse=1.985e+00  (n=7000)
Epoch 00042: Time=   6.9s, Loss=7.32e+00, Inv=7.32e+00, For=9.27e+00, Power=1.11e+00
  [eval] val_mse=1.906e+00  (n=7000)
Epoch 00043: Time=   7.0s, Loss=7.12e+00, Inv=7.12e+00, For=9.53e+00, Power=1.08e+00
  [eval] val_mse=1.836e+00  (n=7000)
Epoch 00044: Time=   7.0s, Loss=6.96e+00, Inv=6.96e+00, For=9.80e+00, Power=1.06e+00
  [eval] val_mse=1.769e+00  (n=7000)
Epoch 00045: Time=   7.0s, Loss=6.79e+00, Inv=6.79e+00, For=1.00e+01, Power=1.04e+00
  [eval] val_mse=1.705e+00  (n=7000)
Epoch 00046: Time=   7.1s, Loss=6.64e+00, Inv=6.64e+00, For=1.03e+01, Power=1.01e+00
  [eval] val_mse=1.645e+00  (n=7000)
Epoch 00047: Time=   7.1s, Loss=6.50e+00, Inv=6.50e+00, For=1.06e+01, Power=9.98e-01
  [eval] val_mse=1.588e+00  (n=7000)
Epoch 00048: Time=   7.1s, Loss=6.36e+00, Inv=6.36e+00, For=1.09e+01, Power=9.74e-01
  [eval] val_mse=1.535e+00  (n=7000)
Epoch 00049: Time=   7.2s, Loss=6.25e+00, Inv=6.25e+00, For=1.12e+01, Power=9.64e-01
  [eval] val_mse=1.486e+00  (n=7000)
Epoch 00050: Time=   7.2s, Loss=6.13e+00, Inv=6.13e+00, For=1.15e+01, Power=9.48e-01
  [eval] val_mse=1.437e+00  (n=7000)
Epoch 00051: Time=   7.2s, Loss=6.02e+00, Inv=6.02e+00, For=1.18e+01, Power=9.33e-01
  [eval] val_mse=1.394e+00  (n=7000)
Epoch 00052: Time=   7.3s, Loss=5.91e+00, Inv=5.91e+00, For=1.21e+01, Power=9.20e-01
  [eval] val_mse=1.352e+00  (n=7000)
Epoch 00053: Time=   7.3s, Loss=5.82e+00, Inv=5.82e+00, For=1.24e+01, Power=9.10e-01
  [eval] val_mse=1.313e+00  (n=7000)
Epoch 00054: Time=   7.3s, Loss=5.72e+00, Inv=5.72e+00, For=1.27e+01, Power=8.94e-01
  [eval] val_mse=1.275e+00  (n=7000)
Epoch 00055: Time=   7.4s, Loss=5.64e+00, Inv=5.64e+00, For=1.30e+01, Power=8.86e-01
  [eval] val_mse=1.238e+00  (n=7000)
Epoch 00056: Time=   7.4s, Loss=5.55e+00, Inv=5.55e+00, For=1.33e+01, Power=8.72e-01
  [eval] val_mse=1.203e+00  (n=7000)
Epoch 00057: Time=   7.4s, Loss=5.48e+00, Inv=5.48e+00, For=1.37e+01, Power=8.64e-01
  [eval] val_mse=1.172e+00  (n=7000)
Epoch 00058: Time=   7.5s, Loss=5.40e+00, Inv=5.40e+00, For=1.40e+01, Power=8.58e-01
  [eval] val_mse=1.139e+00  (n=7000)
Epoch 00059: Time=   7.5s, Loss=5.33e+00, Inv=5.33e+00, For=1.44e+01, Power=8.49e-01
  [eval] val_mse=1.109e+00  (n=7000)
Epoch 00060: Time=   7.5s, Loss=5.26e+00, Inv=5.26e+00, For=1.46e+01, Power=8.43e-01
  [eval] val_mse=1.081e+00  (n=7000)
Epoch 00061: Time=   7.6s, Loss=5.19e+00, Inv=5.19e+00, For=1.50e+01, Power=8.31e-01
  [eval] val_mse=1.054e+00  (n=7000)
Epoch 00062: Time=   7.6s, Loss=5.13e+00, Inv=5.13e+00, For=1.54e+01, Power=8.27e-01
  [eval] val_mse=1.029e+00  (n=7000)
Epoch 00063: Time=   7.6s, Loss=5.07e+00, Inv=5.07e+00, For=1.57e+01, Power=8.21e-01
  [eval] val_mse=1.006e+00  (n=7000)
Epoch 00064: Time=   7.7s, Loss=5.01e+00, Inv=5.01e+00, For=1.59e+01, Power=8.16e-01
  [eval] val_mse=9.813e-01  (n=7000)
Epoch 00065: Time=   7.7s, Loss=4.95e+00, Inv=4.95e+00, For=1.64e+01, Power=8.08e-01
  [eval] val_mse=9.590e-01  (n=7000)
Epoch 00066: Time=   7.7s, Loss=4.90e+00, Inv=4.90e+00, For=1.68e+01, Power=8.07e-01
  [eval] val_mse=9.371e-01  (n=7000)
Epoch 00067: Time=   7.8s, Loss=4.85e+00, Inv=4.85e+00, For=1.70e+01, Power=7.99e-01
  [eval] val_mse=9.168e-01  (n=7000)
Epoch 00068: Time=   7.8s, Loss=4.80e+00, Inv=4.80e+00, For=1.74e+01, Power=7.93e-01
  [eval] val_mse=8.964e-01  (n=7000)
Epoch 00069: Time=   7.8s, Loss=4.75e+00, Inv=4.75e+00, For=1.77e+01, Power=7.89e-01
  [eval] val_mse=8.785e-01  (n=7000)
Epoch 00070: Time=   7.9s, Loss=4.71e+00, Inv=4.71e+00, For=1.80e+01, Power=7.85e-01
  [eval] val_mse=8.590e-01  (n=7000)
Epoch 00071: Time=   7.9s, Loss=4.66e+00, Inv=4.66e+00, For=1.85e+01, Power=7.80e-01
  [eval] val_mse=8.413e-01  (n=7000)
Epoch 00072: Time=   7.9s, Loss=4.61e+00, Inv=4.61e+00, For=1.87e+01, Power=7.72e-01
  [eval] val_mse=8.253e-01  (n=7000)
Epoch 00073: Time=   8.0s, Loss=4.58e+00, Inv=4.58e+00, For=1.91e+01, Power=7.74e-01
  [eval] val_mse=8.090e-01  (n=7000)
Epoch 00074: Time=   8.0s, Loss=4.53e+00, Inv=4.53e+00, For=1.94e+01, Power=7.67e-01
  [eval] val_mse=7.943e-01  (n=7000)
Epoch 00075: Time=   8.0s, Loss=4.50e+00, Inv=4.50e+00, For=1.98e+01, Power=7.67e-01
  [eval] val_mse=7.781e-01  (n=7000)
Epoch 00076: Time=   8.1s, Loss=4.46e+00, Inv=4.46e+00, For=2.02e+01, Power=7.65e-01
  [eval] val_mse=7.645e-01  (n=7000)
Epoch 00077: Time=   8.1s, Loss=4.42e+00, Inv=4.42e+00, For=2.04e+01, Power=7.56e-01
  [eval] val_mse=7.509e-01  (n=7000)
Epoch 00078: Time=   8.1s, Loss=4.39e+00, Inv=4.39e+00, For=2.09e+01, Power=7.59e-01
  [eval] val_mse=7.380e-01  (n=7000)
Epoch 00079: Time=   8.2s, Loss=4.36e+00, Inv=4.36e+00, For=2.11e+01, Power=7.54e-01
  [eval] val_mse=7.263e-01  (n=7000)
Epoch 00080: Time=   8.2s, Loss=4.32e+00, Inv=4.32e+00, For=2.16e+01, Power=7.52e-01
  [eval] val_mse=7.129e-01  (n=7000)
Epoch 00081: Time=   8.2s, Loss=4.29e+00, Inv=4.29e+00, For=2.19e+01, Power=7.49e-01
  [eval] val_mse=7.010e-01  (n=7000)
Epoch 00082: Time=   8.3s, Loss=4.27e+00, Inv=4.27e+00, For=2.22e+01, Power=7.49e-01
  [eval] val_mse=6.903e-01  (n=7000)
Epoch 00083: Time=   8.3s, Loss=4.23e+00, Inv=4.23e+00, For=2.27e+01, Power=7.47e-01
  [eval] val_mse=6.803e-01  (n=7000)
Epoch 00084: Time=   8.4s, Loss=4.20e+00, Inv=4.20e+00, For=2.31e+01, Power=7.43e-01
  [eval] val_mse=6.698e-01  (n=7000)
Epoch 00085: Time=   8.4s, Loss=4.18e+00, Inv=4.18e+00, For=2.34e+01, Power=7.42e-01
  [eval] val_mse=6.599e-01  (n=7000)
Epoch 00086: Time=   8.4s, Loss=4.15e+00, Inv=4.15e+00, For=2.36e+01, Power=7.39e-01
  [eval] val_mse=6.492e-01  (n=7000)
Epoch 00087: Time=   8.5s, Loss=4.12e+00, Inv=4.12e+00, For=2.43e+01, Power=7.37e-01
  [eval] val_mse=6.412e-01  (n=7000)
Epoch 00088: Time=   8.5s, Loss=4.10e+00, Inv=4.10e+00, For=2.44e+01, Power=7.36e-01
  [eval] val_mse=6.319e-01  (n=7000)
Epoch 00089: Time=   8.5s, Loss=4.07e+00, Inv=4.07e+00, For=2.50e+01, Power=7.34e-01
  [eval] val_mse=6.230e-01  (n=7000)
Epoch 00090: Time=   8.6s, Loss=4.05e+00, Inv=4.05e+00, For=2.52e+01, Power=7.34e-01
  [eval] val_mse=6.138e-01  (n=7000)
Epoch 00091: Time=   8.6s, Loss=4.02e+00, Inv=4.02e+00, For=2.55e+01, Power=7.28e-01
  [eval] val_mse=6.063e-01  (n=7000)
Epoch 00092: Time=   8.6s, Loss=4.00e+00, Inv=4.00e+00, For=2.59e+01, Power=7.30e-01
  [eval] val_mse=5.984e-01  (n=7000)
Epoch 00093: Time=   8.7s, Loss=3.98e+00, Inv=3.98e+00, For=2.64e+01, Power=7.24e-01
  [eval] val_mse=5.912e-01  (n=7000)
Epoch 00094: Time=   8.7s, Loss=3.95e+00, Inv=3.95e+00, For=2.65e+01, Power=7.24e-01
  [eval] val_mse=5.841e-01  (n=7000)
Epoch 00095: Time=   8.7s, Loss=3.93e+00, Inv=3.93e+00, For=2.71e+01, Power=7.25e-01
  [eval] val_mse=5.776e-01  (n=7000)
Epoch 00096: Time=   8.8s, Loss=3.91e+00, Inv=3.91e+00, For=2.75e+01, Power=7.23e-01
  [eval] val_mse=5.706e-01  (n=7000)
Epoch 00097: Time=   8.8s, Loss=3.89e+00, Inv=3.89e+00, For=2.78e+01, Power=7.22e-01
  [eval] val_mse=5.640e-01  (n=7000)
Epoch 00098: Time=   8.8s, Loss=3.88e+00, Inv=3.88e+00, For=2.82e+01, Power=7.22e-01
  [eval] val_mse=5.577e-01  (n=7000)
Epoch 00099: Time=   8.9s, Loss=3.85e+00, Inv=3.85e+00, For=2.87e+01, Power=7.16e-01
  [eval] val_mse=5.515e-01  (n=7000)
Epoch 00100: Time=   8.9s, Loss=3.84e+00, Inv=3.84e+00, For=2.92e+01, Power=7.20e-01
  [eval] val_mse=5.464e-01  (n=7000)
Epoch 00101: Time=   8.9s, Loss=3.82e+00, Inv=3.82e+00, For=2.93e+01, Power=7.15e-01
  [eval] val_mse=5.413e-01  (n=7000)
Epoch 00102: Time=   9.0s, Loss=3.80e+00, Inv=3.80e+00, For=2.97e+01, Power=7.18e-01
  [eval] val_mse=5.362e-01  (n=7000)
Epoch 00103: Time=   9.0s, Loss=3.79e+00, Inv=3.79e+00, For=3.01e+01, Power=7.15e-01
  [eval] val_mse=5.311e-01  (n=7000)
Epoch 00104: Time=   9.0s, Loss=3.77e+00, Inv=3.77e+00, For=3.07e+01, Power=7.16e-01
  [eval] val_mse=5.259e-01  (n=7000)
Epoch 00105: Time=   9.1s, Loss=3.75e+00, Inv=3.75e+00, For=3.09e+01, Power=7.14e-01
  [eval] val_mse=5.204e-01  (n=7000)
Epoch 00106: Time=   9.1s, Loss=3.74e+00, Inv=3.74e+00, For=3.13e+01, Power=7.13e-01
  [eval] val_mse=5.157e-01  (n=7000)
Epoch 00107: Time=   9.1s, Loss=3.72e+00, Inv=3.72e+00, For=3.17e+01, Power=7.11e-01
  [eval] val_mse=5.117e-01  (n=7000)
Epoch 00108: Time=   9.2s, Loss=3.71e+00, Inv=3.71e+00, For=3.22e+01, Power=7.13e-01
  [eval] val_mse=5.068e-01  (n=7000)
Epoch 00109: Time=   9.2s, Loss=3.69e+00, Inv=3.69e+00, For=3.24e+01, Power=7.11e-01
  [eval] val_mse=5.022e-01  (n=7000)
Epoch 00110: Time=   9.2s, Loss=3.68e+00, Inv=3.68e+00, For=3.32e+01, Power=7.08e-01
  [eval] val_mse=4.984e-01  (n=7000)
Epoch 00111: Time=   9.3s, Loss=3.67e+00, Inv=3.67e+00, For=3.31e+01, Power=7.11e-01
  [eval] val_mse=4.938e-01  (n=7000)
Epoch 00112: Time=   9.3s, Loss=3.65e+00, Inv=3.65e+00, For=3.39e+01, Power=7.06e-01
  [eval] val_mse=4.908e-01  (n=7000)
Epoch 00113: Time=   9.4s, Loss=3.64e+00, Inv=3.64e+00, For=3.42e+01, Power=7.07e-01
  [eval] val_mse=4.869e-01  (n=7000)
Epoch 00114: Time=   9.4s, Loss=3.63e+00, Inv=3.63e+00, For=3.44e+01, Power=7.07e-01
  [eval] val_mse=4.831e-01  (n=7000)
Epoch 00115: Time=   9.4s, Loss=3.62e+00, Inv=3.62e+00, For=3.53e+01, Power=7.07e-01
  [eval] val_mse=4.799e-01  (n=7000)
Epoch 00116: Time=   9.5s, Loss=3.61e+00, Inv=3.61e+00, For=3.54e+01, Power=7.08e-01
  [eval] val_mse=4.761e-01  (n=7000)
Epoch 00117: Time=   9.5s, Loss=3.59e+00, Inv=3.59e+00, For=3.62e+01, Power=7.07e-01
  [eval] val_mse=4.727e-01  (n=7000)
Epoch 00118: Time=   9.5s, Loss=3.58e+00, Inv=3.58e+00, For=3.59e+01, Power=7.01e-01
  [eval] val_mse=4.683e-01  (n=7000)
Epoch 00119: Time=   9.6s, Loss=3.57e+00, Inv=3.57e+00, For=3.69e+01, Power=7.04e-01
  [eval] val_mse=4.662e-01  (n=7000)
Epoch 00120: Time=   9.6s, Loss=3.56e+00, Inv=3.56e+00, For=3.72e+01, Power=7.02e-01
  [eval] val_mse=4.633e-01  (n=7000)
Epoch 00121: Time=   9.7s, Loss=3.55e+00, Inv=3.55e+00, For=3.76e+01, Power=7.04e-01
  [eval] val_mse=4.602e-01  (n=7000)
Epoch 00122: Time=   9.7s, Loss=3.54e+00, Inv=3.54e+00, For=3.84e+01, Power=7.03e-01
  [eval] val_mse=4.571e-01  (n=7000)
Epoch 00123: Time=   9.7s, Loss=3.53e+00, Inv=3.53e+00, For=3.81e+01, Power=7.00e-01
  [eval] val_mse=4.546e-01  (n=7000)
Epoch 00124: Time=   9.8s, Loss=3.52e+00, Inv=3.52e+00, For=3.91e+01, Power=7.03e-01
  [eval] val_mse=4.514e-01  (n=7000)
Epoch 00125: Time=   9.8s, Loss=3.51e+00, Inv=3.51e+00, For=3.91e+01, Power=7.00e-01
  [eval] val_mse=4.486e-01  (n=7000)
Epoch 00126: Time=   9.8s, Loss=3.50e+00, Inv=3.50e+00, For=3.98e+01, Power=7.00e-01
  [eval] val_mse=4.459e-01  (n=7000)
Epoch 00127: Time=   9.9s, Loss=3.49e+00, Inv=3.49e+00, For=4.04e+01, Power=7.00e-01
  [eval] val_mse=4.443e-01  (n=7000)
Epoch 00128: Time=   9.9s, Loss=3.48e+00, Inv=3.48e+00, For=4.03e+01, Power=7.00e-01
  [eval] val_mse=4.411e-01  (n=7000)
Epoch 00129: Time=   9.9s, Loss=3.48e+00, Inv=3.48e+00, For=4.11e+01, Power=7.01e-01
  [eval] val_mse=4.390e-01  (n=7000)
Epoch 00130: Time=  10.0s, Loss=3.47e+00, Inv=3.47e+00, For=4.19e+01, Power=6.98e-01
  [eval] val_mse=4.361e-01  (n=7000)
Epoch 00131: Time=  10.0s, Loss=3.46e+00, Inv=3.46e+00, For=4.16e+01, Power=6.99e-01
  [eval] val_mse=4.345e-01  (n=7000)
Epoch 00132: Time=  10.0s, Loss=3.45e+00, Inv=3.45e+00, For=4.29e+01, Power=6.98e-01
  [eval] val_mse=4.315e-01  (n=7000)
Epoch 00133: Time=  10.1s, Loss=3.45e+00, Inv=3.45e+00, For=4.28e+01, Power=7.00e-01
  [eval] val_mse=4.301e-01  (n=7000)
Epoch 00134: Time=  10.1s, Loss=3.44e+00, Inv=3.44e+00, For=4.31e+01, Power=7.02e-01
  [eval] val_mse=4.274e-01  (n=7000)
Epoch 00135: Time=  10.2s, Loss=3.43e+00, Inv=3.43e+00, For=4.36e+01, Power=6.99e-01
  [eval] val_mse=4.258e-01  (n=7000)
Epoch 00136: Time=  10.2s, Loss=3.42e+00, Inv=3.42e+00, For=4.43e+01, Power=6.96e-01
  [eval] val_mse=4.236e-01  (n=7000)
Epoch 00137: Time=  10.2s, Loss=3.42e+00, Inv=3.42e+00, For=4.45e+01, Power=6.99e-01
  [eval] val_mse=4.215e-01  (n=7000)
Epoch 00138: Time=  10.3s, Loss=3.41e+00, Inv=3.41e+00, For=4.56e+01, Power=6.98e-01
  [eval] val_mse=4.205e-01  (n=7000)
Epoch 00139: Time=  10.3s, Loss=3.41e+00, Inv=3.41e+00, For=4.56e+01, Power=6.97e-01
  [eval] val_mse=4.183e-01  (n=7000)
Epoch 00140: Time=  10.3s, Loss=3.40e+00, Inv=3.40e+00, For=4.61e+01, Power=6.94e-01
  [eval] val_mse=4.162e-01  (n=7000)
Epoch 00141: Time=  10.4s, Loss=3.39e+00, Inv=3.39e+00, For=4.66e+01, Power=6.96e-01
  [eval] val_mse=4.142e-01  (n=7000)
Epoch 00142: Time=  10.4s, Loss=3.38e+00, Inv=3.38e+00, For=4.70e+01, Power=6.94e-01
  [eval] val_mse=4.128e-01  (n=7000)
Epoch 00143: Time=  10.4s, Loss=3.37e+00, Inv=3.37e+00, For=4.73e+01, Power=6.93e-01
  [eval] val_mse=4.115e-01  (n=7000)
Epoch 00144: Time=  10.5s, Loss=3.37e+00, Inv=3.37e+00, For=4.84e+01, Power=6.92e-01
  [eval] val_mse=4.099e-01  (n=7000)
Epoch 00145: Time=  10.5s, Loss=3.37e+00, Inv=3.37e+00, For=4.81e+01, Power=6.95e-01
  [eval] val_mse=4.079e-01  (n=7000)
Epoch 00146: Time=  10.5s, Loss=3.36e+00, Inv=3.36e+00, For=4.93e+01, Power=6.95e-01
  [eval] val_mse=4.071e-01  (n=7000)
Epoch 00147: Time=  10.6s, Loss=3.35e+00, Inv=3.35e+00, For=4.92e+01, Power=6.94e-01
  [eval] val_mse=4.045e-01  (n=7000)
Epoch 00148: Time=  10.6s, Loss=3.35e+00, Inv=3.35e+00, For=5.02e+01, Power=6.91e-01
  [eval] val_mse=4.032e-01  (n=7000)
Epoch 00149: Time=  10.6s, Loss=3.34e+00, Inv=3.34e+00, For=5.02e+01, Power=6.92e-01
  [eval] val_mse=4.024e-01  (n=7000)
Epoch 00150: Time=  10.7s, Loss=3.34e+00, Inv=3.34e+00, For=5.11e+01, Power=6.93e-01
  [eval] val_mse=4.004e-01  (n=7000)
Epoch 00151: Time=  10.7s, Loss=3.33e+00, Inv=3.33e+00, For=5.12e+01, Power=6.93e-01
  [eval] val_mse=4.000e-01  (n=7000)
Epoch 00152: Time=  10.8s, Loss=3.33e+00, Inv=3.33e+00, For=5.19e+01, Power=6.93e-01
  [eval] val_mse=3.988e-01  (n=7000)
Epoch 00153: Time=  10.8s, Loss=3.32e+00, Inv=3.32e+00, For=5.23e+01, Power=6.92e-01
  [eval] val_mse=3.965e-01  (n=7000)
Epoch 00154: Time=  10.8s, Loss=3.32e+00, Inv=3.32e+00, For=5.30e+01, Power=6.94e-01
  [eval] val_mse=3.948e-01  (n=7000)
Epoch 00155: Time=  10.9s, Loss=3.31e+00, Inv=3.31e+00, For=5.35e+01, Power=6.92e-01
  [eval] val_mse=3.943e-01  (n=7000)
Epoch 00156: Time=  10.9s, Loss=3.31e+00, Inv=3.31e+00, For=5.35e+01, Power=6.92e-01
  [eval] val_mse=3.926e-01  (n=7000)
Epoch 00157: Time=  10.9s, Loss=3.30e+00, Inv=3.30e+00, For=5.46e+01, Power=6.90e-01
  [eval] val_mse=3.918e-01  (n=7000)
Epoch 00158: Time=  11.0s, Loss=3.30e+00, Inv=3.30e+00, For=5.48e+01, Power=6.90e-01
  [eval] val_mse=3.912e-01  (n=7000)
Epoch 00159: Time=  11.0s, Loss=3.29e+00, Inv=3.29e+00, For=5.54e+01, Power=6.91e-01
  [eval] val_mse=3.897e-01  (n=7000)
Epoch 00160: Time=  11.0s, Loss=3.29e+00, Inv=3.29e+00, For=5.57e+01, Power=6.91e-01
  [eval] val_mse=3.883e-01  (n=7000)
Epoch 00161: Time=  11.1s, Loss=3.29e+00, Inv=3.29e+00, For=5.63e+01, Power=6.90e-01
  [eval] val_mse=3.869e-01  (n=7000)
Epoch 00162: Time=  11.1s, Loss=3.28e+00, Inv=3.28e+00, For=5.68e+01, Power=6.93e-01
  [eval] val_mse=3.866e-01  (n=7000)
Epoch 00163: Time=  11.1s, Loss=3.28e+00, Inv=3.28e+00, For=5.75e+01, Power=6.91e-01
  [eval] val_mse=3.855e-01  (n=7000)
Epoch 00164: Time=  11.2s, Loss=3.27e+00, Inv=3.27e+00, For=5.71e+01, Power=6.90e-01
  [eval] val_mse=3.843e-01  (n=7000)
Epoch 00165: Time=  11.2s, Loss=3.27e+00, Inv=3.27e+00, For=5.88e+01, Power=6.91e-01
  [eval] val_mse=3.836e-01  (n=7000)
Epoch 00166: Time=  11.2s, Loss=3.26e+00, Inv=3.26e+00, For=5.83e+01, Power=6.91e-01
  [eval] val_mse=3.835e-01  (n=7000)
Epoch 00167: Time=  11.3s, Loss=3.26e+00, Inv=3.26e+00, For=5.96e+01, Power=6.90e-01
  [eval] val_mse=3.819e-01  (n=7000)
Epoch 00168: Time=  11.3s, Loss=3.26e+00, Inv=3.26e+00, For=6.01e+01, Power=6.92e-01
  [eval] val_mse=3.810e-01  (n=7000)
Epoch 00169: Time=  11.4s, Loss=3.25e+00, Inv=3.25e+00, For=6.02e+01, Power=6.91e-01
  [eval] val_mse=3.799e-01  (n=7000)
Epoch 00170: Time=  11.4s, Loss=3.25e+00, Inv=3.25e+00, For=6.07e+01, Power=6.90e-01
  [eval] val_mse=3.793e-01  (n=7000)
Epoch 00171: Time=  11.4s, Loss=3.24e+00, Inv=3.24e+00, For=6.14e+01, Power=6.86e-01
  [eval] val_mse=3.783e-01  (n=7000)
Epoch 00172: Time=  11.5s, Loss=3.24e+00, Inv=3.24e+00, For=6.24e+01, Power=6.92e-01
  [eval] val_mse=3.774e-01  (n=7000)
Epoch 00173: Time=  11.5s, Loss=3.23e+00, Inv=3.23e+00, For=6.22e+01, Power=6.87e-01
  [eval] val_mse=3.772e-01  (n=7000)
Epoch 00174: Time=  11.5s, Loss=3.23e+00, Inv=3.23e+00, For=6.32e+01, Power=6.89e-01
  [eval] val_mse=3.763e-01  (n=7000)
Epoch 00175: Time=  11.6s, Loss=3.23e+00, Inv=3.23e+00, For=6.37e+01, Power=6.92e-01
  [eval] val_mse=3.742e-01  (n=7000)
Epoch 00176: Time=  11.6s, Loss=3.22e+00, Inv=3.22e+00, For=6.36e+01, Power=6.87e-01
  [eval] val_mse=3.746e-01  (n=7000)
Epoch 00177: Time=  11.6s, Loss=3.22e+00, Inv=3.22e+00, For=6.45e+01, Power=6.88e-01
  [eval] val_mse=3.736e-01  (n=7000)
Epoch 00178: Time=  11.7s, Loss=3.22e+00, Inv=3.22e+00, For=6.46e+01, Power=6.87e-01
  [eval] val_mse=3.736e-01  (n=7000)
Epoch 00179: Time=  11.7s, Loss=3.21e+00, Inv=3.21e+00, For=6.63e+01, Power=6.85e-01
  [eval] val_mse=3.726e-01  (n=7000)
Epoch 00180: Time=  11.7s, Loss=3.21e+00, Inv=3.21e+00, For=6.63e+01, Power=6.87e-01
  [eval] val_mse=3.717e-01  (n=7000)
Epoch 00181: Time=  11.8s, Loss=3.21e+00, Inv=3.21e+00, For=6.64e+01, Power=6.87e-01
  [eval] val_mse=3.706e-01  (n=7000)
Epoch 00182: Time=  11.8s, Loss=3.21e+00, Inv=3.21e+00, For=6.75e+01, Power=6.87e-01
  [eval] val_mse=3.706e-01  (n=7000)
Epoch 00183: Time=  11.8s, Loss=3.20e+00, Inv=3.20e+00, For=6.79e+01, Power=6.86e-01
  [eval] val_mse=3.698e-01  (n=7000)
Epoch 00184: Time=  11.9s, Loss=3.20e+00, Inv=3.20e+00, For=6.81e+01, Power=6.89e-01
  [eval] val_mse=3.694e-01  (n=7000)
Epoch 00185: Time=  11.9s, Loss=3.19e+00, Inv=3.19e+00, For=6.87e+01, Power=6.86e-01
  [eval] val_mse=3.690e-01  (n=7000)
Epoch 00186: Time=  11.9s, Loss=3.19e+00, Inv=3.19e+00, For=6.95e+01, Power=6.87e-01
  [eval] val_mse=3.678e-01  (n=7000)
Epoch 00187: Time=  12.0s, Loss=3.19e+00, Inv=3.19e+00, For=6.94e+01, Power=6.85e-01
  [eval] val_mse=3.672e-01  (n=7000)
Epoch 00188: Time=  12.0s, Loss=3.19e+00, Inv=3.19e+00, For=7.02e+01, Power=6.86e-01
  [eval] val_mse=3.661e-01  (n=7000)
Epoch 00189: Time=  12.0s, Loss=3.18e+00, Inv=3.18e+00, For=7.10e+01, Power=6.86e-01
  [eval] val_mse=3.657e-01  (n=7000)
Epoch 00190: Time=  12.1s, Loss=3.17e+00, Inv=3.17e+00, For=7.14e+01, Power=6.84e-01
  [eval] val_mse=3.656e-01  (n=7000)
Epoch 00191: Time=  12.1s, Loss=3.17e+00, Inv=3.17e+00, For=7.16e+01, Power=6.85e-01
  [eval] val_mse=3.641e-01  (n=7000)
Epoch 00192: Time=  12.1s, Loss=3.17e+00, Inv=3.17e+00, For=7.31e+01, Power=6.86e-01
  [eval] val_mse=3.651e-01  (n=7000)
Epoch 00193: Time=  12.2s, Loss=3.17e+00, Inv=3.17e+00, For=7.20e+01, Power=6.86e-01
  [eval] val_mse=3.634e-01  (n=7000)
Epoch 00194: Time=  12.2s, Loss=3.17e+00, Inv=3.17e+00, For=7.39e+01, Power=6.86e-01
  [eval] val_mse=3.639e-01  (n=7000)
Epoch 00195: Time=  12.3s, Loss=3.17e+00, Inv=3.17e+00, For=7.42e+01, Power=6.85e-01
  [eval] val_mse=3.629e-01  (n=7000)
Epoch 00196: Time=  12.3s, Loss=3.17e+00, Inv=3.17e+00, For=7.39e+01, Power=6.88e-01
  [eval] val_mse=3.630e-01  (n=7000)
Epoch 00197: Time=  12.3s, Loss=3.17e+00, Inv=3.17e+00, For=7.53e+01, Power=6.85e-01
  [eval] val_mse=3.619e-01  (n=7000)
Epoch 00198: Time=  12.4s, Loss=3.15e+00, Inv=3.15e+00, For=7.58e+01, Power=6.83e-01
  [eval] val_mse=3.618e-01  (n=7000)
Epoch 00199: Time=  12.4s, Loss=3.15e+00, Inv=3.15e+00, For=7.50e+01, Power=6.86e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00200: Time=  12.4s, Loss=3.15e+00, Inv=3.15e+00, For=7.69e+01, Power=6.84e-01
  [eval] val_mse=3.602e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 2.450e-01
Torque MSE  = 1.667e-01
Torque RMSE = 4.083e-01
Per-joint MSE : 7.810e-02 5.318e-01 6.448e-02 2.126e-02 2.888e-01 1.601e-02
Per-joint RMSE: 2.795e-01 7.292e-01 2.539e-01 1.458e-01 5.374e-01 1.265e-01
Comp Time per Sample = 2.976e-04s / 3360.3Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-9idfllr0 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x75b73fda68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:56:22.134718: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:56:23.978583: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=1.88e+04, Inv=1.88e+04, For=5.83e+00, Power=1.70e+03
  [eval] val_mse=5.714e+02  (n=7000)
Epoch 00002: Time=   5.6s, Loss=3.63e+03, Inv=3.63e+03, For=5.72e+00, Power=3.36e+02
  [eval] val_mse=2.599e+02  (n=7000)
Epoch 00003: Time=   5.6s, Loss=1.48e+03, Inv=1.48e+03, For=5.67e+00, Power=1.36e+02
  [eval] val_mse=1.550e+02  (n=7000)
Epoch 00004: Time=   5.6s, Loss=8.20e+02, Inv=8.20e+02, For=5.66e+00, Power=7.56e+01
  [eval] val_mse=1.020e+02  (n=7000)
Epoch 00005: Time=   5.7s, Loss=5.23e+02, Inv=5.23e+02, For=5.68e+00, Power=4.82e+01
  [eval] val_mse=7.159e+01  (n=7000)
Epoch 00006: Time=   5.7s, Loss=3.62e+02, Inv=3.62e+02, For=5.68e+00, Power=3.37e+01
  [eval] val_mse=5.283e+01  (n=7000)
Epoch 00007: Time=   5.7s, Loss=2.66e+02, Inv=2.66e+02, For=5.72e+00, Power=2.48e+01
  [eval] val_mse=4.054e+01  (n=7000)
Epoch 00008: Time=   5.8s, Loss=2.04e+02, Inv=2.04e+02, For=5.80e+00, Power=1.93e+01
  [eval] val_mse=3.211e+01  (n=7000)
Epoch 00009: Time=   5.8s, Loss=1.63e+02, Inv=1.63e+02, For=5.89e+00, Power=1.54e+01
  [eval] val_mse=2.597e+01  (n=7000)
Epoch 00010: Time=   5.8s, Loss=1.32e+02, Inv=1.32e+02, For=5.98e+00, Power=1.26e+01
  [eval] val_mse=2.149e+01  (n=7000)
Epoch 00011: Time=   5.9s, Loss=1.10e+02, Inv=1.10e+02, For=6.10e+00, Power=1.05e+01
  [eval] val_mse=1.802e+01  (n=7000)
Epoch 00012: Time=   5.9s, Loss=9.25e+01, Inv=9.25e+01, For=6.22e+00, Power=8.87e+00
  [eval] val_mse=1.537e+01  (n=7000)
Epoch 00013: Time=   6.0s, Loss=7.92e+01, Inv=7.92e+01, For=6.37e+00, Power=7.62e+00
  [eval] val_mse=1.328e+01  (n=7000)
Epoch 00014: Time=   6.0s, Loss=6.85e+01, Inv=6.85e+01, For=6.51e+00, Power=6.57e+00
  [eval] val_mse=1.161e+01  (n=7000)
Epoch 00015: Time=   6.0s, Loss=6.00e+01, Inv=6.00e+01, For=6.70e+00, Power=5.81e+00
  [eval] val_mse=1.024e+01  (n=7000)
Epoch 00016: Time=   6.1s, Loss=5.34e+01, Inv=5.34e+01, For=6.90e+00, Power=5.16e+00
  [eval] val_mse=9.109e+00  (n=7000)
Epoch 00017: Time=   6.1s, Loss=4.76e+01, Inv=4.76e+01, For=7.09e+00, Power=4.63e+00
  [eval] val_mse=8.148e+00  (n=7000)
Epoch 00018: Time=   6.1s, Loss=4.25e+01, Inv=4.25e+01, For=7.30e+00, Power=4.14e+00
  [eval] val_mse=7.348e+00  (n=7000)
Epoch 00019: Time=   6.2s, Loss=3.85e+01, Inv=3.85e+01, For=7.47e+00, Power=3.78e+00
  [eval] val_mse=6.651e+00  (n=7000)
Epoch 00020: Time=   6.2s, Loss=3.49e+01, Inv=3.49e+01, For=7.69e+00, Power=3.45e+00
  [eval] val_mse=6.062e+00  (n=7000)
Epoch 00021: Time=   6.2s, Loss=3.20e+01, Inv=3.20e+01, For=7.85e+00, Power=3.14e+00
  [eval] val_mse=5.547e+00  (n=7000)
Epoch 00022: Time=   6.3s, Loss=2.93e+01, Inv=2.93e+01, For=8.05e+00, Power=2.91e+00
  [eval] val_mse=5.096e+00  (n=7000)
Epoch 00023: Time=   6.3s, Loss=2.70e+01, Inv=2.70e+01, For=8.24e+00, Power=2.70e+00
  [eval] val_mse=4.707e+00  (n=7000)
Epoch 00024: Time=   6.3s, Loss=2.49e+01, Inv=2.49e+01, For=8.40e+00, Power=2.51e+00
  [eval] val_mse=4.357e+00  (n=7000)
Epoch 00025: Time=   6.4s, Loss=2.33e+01, Inv=2.33e+01, For=8.59e+00, Power=2.35e+00
  [eval] val_mse=4.050e+00  (n=7000)
Epoch 00026: Time=   6.4s, Loss=2.16e+01, Inv=2.16e+01, For=8.73e+00, Power=2.20e+00
  [eval] val_mse=3.777e+00  (n=7000)
Epoch 00027: Time=   6.4s, Loss=2.02e+01, Inv=2.02e+01, For=8.88e+00, Power=2.08e+00
  [eval] val_mse=3.538e+00  (n=7000)
Epoch 00028: Time=   6.5s, Loss=1.90e+01, Inv=1.90e+01, For=9.00e+00, Power=1.96e+00
  [eval] val_mse=3.315e+00  (n=7000)
Epoch 00029: Time=   6.5s, Loss=1.78e+01, Inv=1.78e+01, For=9.12e+00, Power=1.86e+00
  [eval] val_mse=3.122e+00  (n=7000)
Epoch 00030: Time=   6.5s, Loss=1.69e+01, Inv=1.69e+01, For=9.26e+00, Power=1.77e+00
  [eval] val_mse=2.943e+00  (n=7000)
Epoch 00031: Time=   6.6s, Loss=1.60e+01, Inv=1.60e+01, For=9.43e+00, Power=1.69e+00
  [eval] val_mse=2.787e+00  (n=7000)
Epoch 00032: Time=   6.6s, Loss=1.51e+01, Inv=1.51e+01, For=9.54e+00, Power=1.61e+00
  [eval] val_mse=2.643e+00  (n=7000)
Epoch 00033: Time=   6.6s, Loss=1.44e+01, Inv=1.44e+01, For=9.71e+00, Power=1.54e+00
  [eval] val_mse=2.514e+00  (n=7000)
Epoch 00034: Time=   6.7s, Loss=1.37e+01, Inv=1.37e+01, For=9.83e+00, Power=1.48e+00
  [eval] val_mse=2.395e+00  (n=7000)
Epoch 00035: Time=   6.7s, Loss=1.31e+01, Inv=1.31e+01, For=9.97e+00, Power=1.43e+00
  [eval] val_mse=2.285e+00  (n=7000)
Epoch 00036: Time=   6.7s, Loss=1.25e+01, Inv=1.25e+01, For=1.01e+01, Power=1.38e+00
  [eval] val_mse=2.188e+00  (n=7000)
Epoch 00037: Time=   6.8s, Loss=1.20e+01, Inv=1.20e+01, For=1.03e+01, Power=1.34e+00
  [eval] val_mse=2.095e+00  (n=7000)
Epoch 00038: Time=   6.8s, Loss=1.16e+01, Inv=1.16e+01, For=1.04e+01, Power=1.29e+00
  [eval] val_mse=2.015e+00  (n=7000)
Epoch 00039: Time=   6.8s, Loss=1.11e+01, Inv=1.11e+01, For=1.06e+01, Power=1.25e+00
  [eval] val_mse=1.937e+00  (n=7000)
Epoch 00040: Time=   6.9s, Loss=1.07e+01, Inv=1.07e+01, For=1.08e+01, Power=1.22e+00
  [eval] val_mse=1.868e+00  (n=7000)
Epoch 00041: Time=   6.9s, Loss=1.03e+01, Inv=1.03e+01, For=1.10e+01, Power=1.18e+00
  [eval] val_mse=1.802e+00  (n=7000)
Epoch 00042: Time=   6.9s, Loss=9.97e+00, Inv=9.97e+00, For=1.12e+01, Power=1.15e+00
  [eval] val_mse=1.742e+00  (n=7000)
Epoch 00043: Time=   7.0s, Loss=9.65e+00, Inv=9.65e+00, For=1.14e+01, Power=1.13e+00
  [eval] val_mse=1.689e+00  (n=7000)
Epoch 00044: Time=   7.0s, Loss=9.35e+00, Inv=9.35e+00, For=1.17e+01, Power=1.10e+00
  [eval] val_mse=1.635e+00  (n=7000)
Epoch 00045: Time=   7.0s, Loss=9.08e+00, Inv=9.08e+00, For=1.20e+01, Power=1.08e+00
  [eval] val_mse=1.589e+00  (n=7000)
Epoch 00046: Time=   7.1s, Loss=8.82e+00, Inv=8.82e+00, For=1.22e+01, Power=1.06e+00
  [eval] val_mse=1.543e+00  (n=7000)
Epoch 00047: Time=   7.1s, Loss=8.58e+00, Inv=8.58e+00, For=1.25e+01, Power=1.04e+00
  [eval] val_mse=1.501e+00  (n=7000)
Epoch 00048: Time=   7.2s, Loss=8.36e+00, Inv=8.36e+00, For=1.29e+01, Power=1.02e+00
  [eval] val_mse=1.460e+00  (n=7000)
Epoch 00049: Time=   7.2s, Loss=8.13e+00, Inv=8.13e+00, For=1.31e+01, Power=9.99e-01
  [eval] val_mse=1.423e+00  (n=7000)
Epoch 00050: Time=   7.2s, Loss=7.92e+00, Inv=7.92e+00, For=1.34e+01, Power=9.83e-01
  [eval] val_mse=1.388e+00  (n=7000)
Epoch 00051: Time=   7.3s, Loss=7.72e+00, Inv=7.72e+00, For=1.38e+01, Power=9.70e-01
  [eval] val_mse=1.355e+00  (n=7000)
Epoch 00052: Time=   7.3s, Loss=7.56e+00, Inv=7.56e+00, For=1.41e+01, Power=9.55e-01
  [eval] val_mse=1.324e+00  (n=7000)
Epoch 00053: Time=   7.3s, Loss=7.39e+00, Inv=7.39e+00, For=1.45e+01, Power=9.41e-01
  [eval] val_mse=1.296e+00  (n=7000)
Epoch 00054: Time=   7.4s, Loss=7.22e+00, Inv=7.22e+00, For=1.48e+01, Power=9.26e-01
  [eval] val_mse=1.266e+00  (n=7000)
Epoch 00055: Time=   7.4s, Loss=7.09e+00, Inv=7.09e+00, For=1.52e+01, Power=9.17e-01
  [eval] val_mse=1.242e+00  (n=7000)
Epoch 00056: Time=   7.4s, Loss=6.94e+00, Inv=6.94e+00, For=1.56e+01, Power=9.07e-01
  [eval] val_mse=1.214e+00  (n=7000)
Epoch 00057: Time=   7.5s, Loss=6.81e+00, Inv=6.81e+00, For=1.60e+01, Power=8.98e-01
  [eval] val_mse=1.190e+00  (n=7000)
Epoch 00058: Time=   7.5s, Loss=6.68e+00, Inv=6.68e+00, For=1.64e+01, Power=8.85e-01
  [eval] val_mse=1.166e+00  (n=7000)
Epoch 00059: Time=   7.5s, Loss=6.55e+00, Inv=6.55e+00, For=1.68e+01, Power=8.78e-01
  [eval] val_mse=1.145e+00  (n=7000)
Epoch 00060: Time=   7.6s, Loss=6.45e+00, Inv=6.45e+00, For=1.72e+01, Power=8.70e-01
  [eval] val_mse=1.124e+00  (n=7000)
Epoch 00061: Time=   7.6s, Loss=6.33e+00, Inv=6.33e+00, For=1.76e+01, Power=8.59e-01
  [eval] val_mse=1.103e+00  (n=7000)
Epoch 00062: Time=   7.6s, Loss=6.25e+00, Inv=6.25e+00, For=1.81e+01, Power=8.54e-01
  [eval] val_mse=1.085e+00  (n=7000)
Epoch 00063: Time=   7.7s, Loss=6.14e+00, Inv=6.14e+00, For=1.85e+01, Power=8.41e-01
  [eval] val_mse=1.066e+00  (n=7000)
Epoch 00064: Time=   7.7s, Loss=6.04e+00, Inv=6.04e+00, For=1.89e+01, Power=8.38e-01
  [eval] val_mse=1.046e+00  (n=7000)
Epoch 00065: Time=   7.7s, Loss=5.96e+00, Inv=5.96e+00, For=1.94e+01, Power=8.30e-01
  [eval] val_mse=1.031e+00  (n=7000)
Epoch 00066: Time=   7.8s, Loss=5.87e+00, Inv=5.87e+00, For=1.99e+01, Power=8.27e-01
  [eval] val_mse=1.014e+00  (n=7000)
Epoch 00067: Time=   7.8s, Loss=5.79e+00, Inv=5.79e+00, For=2.03e+01, Power=8.19e-01
  [eval] val_mse=9.975e-01  (n=7000)
Epoch 00068: Time=   7.8s, Loss=5.71e+00, Inv=5.71e+00, For=2.08e+01, Power=8.13e-01
  [eval] val_mse=9.817e-01  (n=7000)
Epoch 00069: Time=   7.9s, Loss=5.64e+00, Inv=5.64e+00, For=2.12e+01, Power=8.07e-01
  [eval] val_mse=9.665e-01  (n=7000)
Epoch 00070: Time=   7.9s, Loss=5.56e+00, Inv=5.56e+00, For=2.17e+01, Power=8.08e-01
  [eval] val_mse=9.521e-01  (n=7000)
Epoch 00071: Time=   7.9s, Loss=5.50e+00, Inv=5.50e+00, For=2.23e+01, Power=8.01e-01
  [eval] val_mse=9.390e-01  (n=7000)
Epoch 00072: Time=   8.0s, Loss=5.42e+00, Inv=5.42e+00, For=2.27e+01, Power=7.95e-01
  [eval] val_mse=9.260e-01  (n=7000)
Epoch 00073: Time=   8.0s, Loss=5.37e+00, Inv=5.37e+00, For=2.33e+01, Power=7.93e-01
  [eval] val_mse=9.143e-01  (n=7000)
Epoch 00074: Time=   8.0s, Loss=5.31e+00, Inv=5.31e+00, For=2.38e+01, Power=7.87e-01
  [eval] val_mse=9.004e-01  (n=7000)
Epoch 00075: Time=   8.1s, Loss=5.25e+00, Inv=5.25e+00, For=2.43e+01, Power=7.85e-01
  [eval] val_mse=8.897e-01  (n=7000)
Epoch 00076: Time=   8.1s, Loss=5.19e+00, Inv=5.19e+00, For=2.49e+01, Power=7.79e-01
  [eval] val_mse=8.762e-01  (n=7000)
Epoch 00077: Time=   8.1s, Loss=5.13e+00, Inv=5.13e+00, For=2.54e+01, Power=7.78e-01
  [eval] val_mse=8.660e-01  (n=7000)
Epoch 00078: Time=   8.2s, Loss=5.09e+00, Inv=5.09e+00, For=2.60e+01, Power=7.72e-01
  [eval] val_mse=8.556e-01  (n=7000)
Epoch 00079: Time=   8.2s, Loss=5.03e+00, Inv=5.03e+00, For=2.66e+01, Power=7.69e-01
  [eval] val_mse=8.448e-01  (n=7000)
Epoch 00080: Time=   8.2s, Loss=4.98e+00, Inv=4.98e+00, For=2.71e+01, Power=7.64e-01
  [eval] val_mse=8.350e-01  (n=7000)
Epoch 00081: Time=   8.3s, Loss=4.93e+00, Inv=4.93e+00, For=2.78e+01, Power=7.67e-01
  [eval] val_mse=8.257e-01  (n=7000)
Epoch 00082: Time=   8.3s, Loss=4.89e+00, Inv=4.89e+00, For=2.83e+01, Power=7.60e-01
  [eval] val_mse=8.166e-01  (n=7000)
Epoch 00083: Time=   8.3s, Loss=4.85e+00, Inv=4.85e+00, For=2.90e+01, Power=7.56e-01
  [eval] val_mse=8.073e-01  (n=7000)
Epoch 00084: Time=   8.4s, Loss=4.80e+00, Inv=4.80e+00, For=2.96e+01, Power=7.54e-01
  [eval] val_mse=7.992e-01  (n=7000)
Epoch 00085: Time=   8.4s, Loss=4.77e+00, Inv=4.77e+00, For=3.03e+01, Power=7.53e-01
  [eval] val_mse=7.902e-01  (n=7000)
Epoch 00086: Time=   8.4s, Loss=4.72e+00, Inv=4.72e+00, For=3.09e+01, Power=7.51e-01
  [eval] val_mse=7.815e-01  (n=7000)
Epoch 00087: Time=   8.5s, Loss=4.69e+00, Inv=4.69e+00, For=3.17e+01, Power=7.45e-01
  [eval] val_mse=7.738e-01  (n=7000)
Epoch 00088: Time=   8.5s, Loss=4.64e+00, Inv=4.64e+00, For=3.23e+01, Power=7.47e-01
  [eval] val_mse=7.662e-01  (n=7000)
Epoch 00089: Time=   8.5s, Loss=4.60e+00, Inv=4.60e+00, For=3.30e+01, Power=7.43e-01
  [eval] val_mse=7.584e-01  (n=7000)
Epoch 00090: Time=   8.6s, Loss=4.57e+00, Inv=4.57e+00, For=3.37e+01, Power=7.39e-01
  [eval] val_mse=7.506e-01  (n=7000)
Epoch 00091: Time=   8.6s, Loss=4.54e+00, Inv=4.54e+00, For=3.44e+01, Power=7.40e-01
  [eval] val_mse=7.433e-01  (n=7000)
Epoch 00092: Time=   8.7s, Loss=4.50e+00, Inv=4.50e+00, For=3.51e+01, Power=7.38e-01
  [eval] val_mse=7.372e-01  (n=7000)
Epoch 00093: Time=   8.7s, Loss=4.47e+00, Inv=4.47e+00, For=3.60e+01, Power=7.34e-01
  [eval] val_mse=7.305e-01  (n=7000)
Epoch 00094: Time=   8.7s, Loss=4.44e+00, Inv=4.44e+00, For=3.67e+01, Power=7.34e-01
  [eval] val_mse=7.239e-01  (n=7000)
Epoch 00095: Time=   8.8s, Loss=4.41e+00, Inv=4.41e+00, For=3.77e+01, Power=7.35e-01
  [eval] val_mse=7.175e-01  (n=7000)
Epoch 00096: Time=   8.8s, Loss=4.38e+00, Inv=4.38e+00, For=3.83e+01, Power=7.32e-01
  [eval] val_mse=7.113e-01  (n=7000)
Epoch 00097: Time=   8.8s, Loss=4.35e+00, Inv=4.35e+00, For=3.91e+01, Power=7.28e-01
  [eval] val_mse=7.060e-01  (n=7000)
Epoch 00098: Time=   8.9s, Loss=4.33e+00, Inv=4.33e+00, For=4.01e+01, Power=7.27e-01
  [eval] val_mse=7.008e-01  (n=7000)
Epoch 00099: Time=   8.9s, Loss=4.30e+00, Inv=4.30e+00, For=4.11e+01, Power=7.27e-01
  [eval] val_mse=6.953e-01  (n=7000)
Epoch 00100: Time=   8.9s, Loss=4.27e+00, Inv=4.27e+00, For=4.18e+01, Power=7.26e-01
  [eval] val_mse=6.894e-01  (n=7000)
Epoch 00101: Time=   9.0s, Loss=4.24e+00, Inv=4.24e+00, For=4.28e+01, Power=7.23e-01
  [eval] val_mse=6.845e-01  (n=7000)
Epoch 00102: Time=   9.0s, Loss=4.21e+00, Inv=4.21e+00, For=4.36e+01, Power=7.20e-01
  [eval] val_mse=6.795e-01  (n=7000)
Epoch 00103: Time=   9.0s, Loss=4.19e+00, Inv=4.19e+00, For=4.46e+01, Power=7.20e-01
  [eval] val_mse=6.741e-01  (n=7000)
Epoch 00104: Time=   9.1s, Loss=4.17e+00, Inv=4.17e+00, For=4.57e+01, Power=7.20e-01
  [eval] val_mse=6.693e-01  (n=7000)
Epoch 00105: Time=   9.1s, Loss=4.14e+00, Inv=4.14e+00, For=4.66e+01, Power=7.19e-01
  [eval] val_mse=6.640e-01  (n=7000)
Epoch 00106: Time=   9.1s, Loss=4.12e+00, Inv=4.12e+00, For=4.74e+01, Power=7.14e-01
  [eval] val_mse=6.601e-01  (n=7000)
Epoch 00107: Time=   9.2s, Loss=4.10e+00, Inv=4.10e+00, For=4.85e+01, Power=7.15e-01
  [eval] val_mse=6.561e-01  (n=7000)
Epoch 00108: Time=   9.2s, Loss=4.07e+00, Inv=4.07e+00, For=4.98e+01, Power=7.13e-01
  [eval] val_mse=6.516e-01  (n=7000)
Epoch 00109: Time=   9.2s, Loss=4.06e+00, Inv=4.06e+00, For=5.10e+01, Power=7.15e-01
  [eval] val_mse=6.469e-01  (n=7000)
Epoch 00110: Time=   9.3s, Loss=4.03e+00, Inv=4.03e+00, For=5.18e+01, Power=7.13e-01
  [eval] val_mse=6.434e-01  (n=7000)
Epoch 00111: Time=   9.3s, Loss=4.02e+00, Inv=4.02e+00, For=5.31e+01, Power=7.12e-01
  [eval] val_mse=6.387e-01  (n=7000)
Epoch 00112: Time=   9.3s, Loss=4.00e+00, Inv=4.00e+00, For=5.44e+01, Power=7.12e-01
  [eval] val_mse=6.345e-01  (n=7000)
Epoch 00113: Time=   9.4s, Loss=3.98e+00, Inv=3.98e+00, For=5.53e+01, Power=7.11e-01
  [eval] val_mse=6.310e-01  (n=7000)
Epoch 00114: Time=   9.4s, Loss=3.96e+00, Inv=3.96e+00, For=5.66e+01, Power=7.10e-01
  [eval] val_mse=6.275e-01  (n=7000)
Epoch 00115: Time=   9.4s, Loss=3.94e+00, Inv=3.94e+00, For=5.77e+01, Power=7.08e-01
  [eval] val_mse=6.239e-01  (n=7000)
Epoch 00116: Time=   9.5s, Loss=3.93e+00, Inv=3.93e+00, For=5.89e+01, Power=7.08e-01
  [eval] val_mse=6.211e-01  (n=7000)
Epoch 00117: Time=   9.5s, Loss=3.90e+00, Inv=3.90e+00, For=6.06e+01, Power=7.05e-01
  [eval] val_mse=6.170e-01  (n=7000)
Epoch 00118: Time=   9.5s, Loss=3.89e+00, Inv=3.89e+00, For=6.15e+01, Power=7.05e-01
  [eval] val_mse=6.137e-01  (n=7000)
Epoch 00119: Time=   9.6s, Loss=3.87e+00, Inv=3.87e+00, For=6.29e+01, Power=7.05e-01
  [eval] val_mse=6.107e-01  (n=7000)
Epoch 00120: Time=   9.6s, Loss=3.86e+00, Inv=3.86e+00, For=6.42e+01, Power=7.03e-01
  [eval] val_mse=6.072e-01  (n=7000)
Epoch 00121: Time=   9.6s, Loss=3.84e+00, Inv=3.84e+00, For=6.58e+01, Power=7.06e-01
  [eval] val_mse=6.037e-01  (n=7000)
Epoch 00122: Time=   9.7s, Loss=3.83e+00, Inv=3.83e+00, For=6.69e+01, Power=7.06e-01
  [eval] val_mse=6.000e-01  (n=7000)
Epoch 00123: Time=   9.7s, Loss=3.81e+00, Inv=3.81e+00, For=6.89e+01, Power=7.04e-01
  [eval] val_mse=5.970e-01  (n=7000)
Epoch 00124: Time=   9.7s, Loss=3.80e+00, Inv=3.80e+00, For=7.01e+01, Power=7.04e-01
  [eval] val_mse=5.946e-01  (n=7000)
Epoch 00125: Time=   9.8s, Loss=3.79e+00, Inv=3.79e+00, For=7.12e+01, Power=7.01e-01
  [eval] val_mse=5.911e-01  (n=7000)
Epoch 00126: Time=   9.8s, Loss=3.77e+00, Inv=3.77e+00, For=7.29e+01, Power=7.04e-01
  [eval] val_mse=5.874e-01  (n=7000)
Epoch 00127: Time=   9.8s, Loss=3.76e+00, Inv=3.76e+00, For=7.44e+01, Power=7.01e-01
  [eval] val_mse=5.846e-01  (n=7000)
Epoch 00128: Time=   9.9s, Loss=3.75e+00, Inv=3.75e+00, For=7.59e+01, Power=7.01e-01
  [eval] val_mse=5.816e-01  (n=7000)
Epoch 00129: Time=   9.9s, Loss=3.73e+00, Inv=3.73e+00, For=7.72e+01, Power=7.01e-01
  [eval] val_mse=5.806e-01  (n=7000)
Epoch 00130: Time=   9.9s, Loss=3.72e+00, Inv=3.72e+00, For=7.95e+01, Power=6.99e-01
  [eval] val_mse=5.762e-01  (n=7000)
Epoch 00131: Time=  10.0s, Loss=3.71e+00, Inv=3.71e+00, For=8.11e+01, Power=6.99e-01
  [eval] val_mse=5.740e-01  (n=7000)
Epoch 00132: Time=  10.0s, Loss=3.69e+00, Inv=3.69e+00, For=8.20e+01, Power=6.98e-01
  [eval] val_mse=5.710e-01  (n=7000)
Epoch 00133: Time=  10.0s, Loss=3.69e+00, Inv=3.69e+00, For=8.47e+01, Power=6.98e-01
  [eval] val_mse=5.680e-01  (n=7000)
Epoch 00134: Time=  10.1s, Loss=3.68e+00, Inv=3.68e+00, For=8.57e+01, Power=6.97e-01
  [eval] val_mse=5.660e-01  (n=7000)
Epoch 00135: Time=  10.1s, Loss=3.66e+00, Inv=3.66e+00, For=8.80e+01, Power=6.97e-01
  [eval] val_mse=5.622e-01  (n=7000)
Epoch 00136: Time=  10.2s, Loss=3.65e+00, Inv=3.65e+00, For=8.93e+01, Power=6.95e-01
  [eval] val_mse=5.608e-01  (n=7000)
Epoch 00137: Time=  10.2s, Loss=3.64e+00, Inv=3.64e+00, For=9.17e+01, Power=6.97e-01
  [eval] val_mse=5.577e-01  (n=7000)
Epoch 00138: Time=  10.2s, Loss=3.63e+00, Inv=3.63e+00, For=9.28e+01, Power=6.96e-01
  [eval] val_mse=5.555e-01  (n=7000)
Epoch 00139: Time=  10.3s, Loss=3.62e+00, Inv=3.62e+00, For=9.49e+01, Power=6.96e-01
  [eval] val_mse=5.528e-01  (n=7000)
Epoch 00140: Time=  10.3s, Loss=3.61e+00, Inv=3.61e+00, For=9.66e+01, Power=6.92e-01
  [eval] val_mse=5.500e-01  (n=7000)
Epoch 00141: Time=  10.3s, Loss=3.60e+00, Inv=3.60e+00, For=9.85e+01, Power=6.96e-01
  [eval] val_mse=5.479e-01  (n=7000)
Epoch 00142: Time=  10.4s, Loss=3.59e+00, Inv=3.59e+00, For=1.00e+02, Power=6.95e-01
  [eval] val_mse=5.458e-01  (n=7000)
Epoch 00143: Time=  10.4s, Loss=3.59e+00, Inv=3.59e+00, For=1.02e+02, Power=6.96e-01
  [eval] val_mse=5.429e-01  (n=7000)
Epoch 00144: Time=  10.4s, Loss=3.57e+00, Inv=3.57e+00, For=1.04e+02, Power=6.93e-01
  [eval] val_mse=5.406e-01  (n=7000)
Epoch 00145: Time=  10.5s, Loss=3.57e+00, Inv=3.57e+00, For=1.07e+02, Power=6.96e-01
  [eval] val_mse=5.389e-01  (n=7000)
Epoch 00146: Time=  10.5s, Loss=3.56e+00, Inv=3.56e+00, For=1.09e+02, Power=6.95e-01
  [eval] val_mse=5.363e-01  (n=7000)
Epoch 00147: Time=  10.5s, Loss=3.55e+00, Inv=3.55e+00, For=1.11e+02, Power=6.92e-01
  [eval] val_mse=5.344e-01  (n=7000)
Epoch 00148: Time=  10.6s, Loss=3.54e+00, Inv=3.54e+00, For=1.13e+02, Power=6.91e-01
  [eval] val_mse=5.319e-01  (n=7000)
Epoch 00149: Time=  10.6s, Loss=3.53e+00, Inv=3.53e+00, For=1.16e+02, Power=6.92e-01
  [eval] val_mse=5.286e-01  (n=7000)
Epoch 00150: Time=  10.6s, Loss=3.53e+00, Inv=3.53e+00, For=1.17e+02, Power=6.92e-01
  [eval] val_mse=5.269e-01  (n=7000)
Epoch 00151: Time=  10.7s, Loss=3.52e+00, Inv=3.52e+00, For=1.19e+02, Power=6.92e-01
  [eval] val_mse=5.243e-01  (n=7000)
Epoch 00152: Time=  10.7s, Loss=3.51e+00, Inv=3.51e+00, For=1.21e+02, Power=6.91e-01
  [eval] val_mse=5.233e-01  (n=7000)
Epoch 00153: Time=  10.7s, Loss=3.50e+00, Inv=3.50e+00, For=1.24e+02, Power=6.92e-01
  [eval] val_mse=5.199e-01  (n=7000)
Epoch 00154: Time=  10.8s, Loss=3.50e+00, Inv=3.50e+00, For=1.25e+02, Power=6.91e-01
  [eval] val_mse=5.190e-01  (n=7000)
Epoch 00155: Time=  10.8s, Loss=3.49e+00, Inv=3.49e+00, For=1.29e+02, Power=6.92e-01
  [eval] val_mse=5.175e-01  (n=7000)
Epoch 00156: Time=  10.8s, Loss=3.48e+00, Inv=3.48e+00, For=1.31e+02, Power=6.93e-01
  [eval] val_mse=5.145e-01  (n=7000)
Epoch 00157: Time=  10.9s, Loss=3.47e+00, Inv=3.47e+00, For=1.31e+02, Power=6.94e-01
  [eval] val_mse=5.134e-01  (n=7000)
Epoch 00158: Time=  10.9s, Loss=3.47e+00, Inv=3.47e+00, For=1.36e+02, Power=6.90e-01
  [eval] val_mse=5.099e-01  (n=7000)
Epoch 00159: Time=  11.0s, Loss=3.46e+00, Inv=3.46e+00, For=1.37e+02, Power=6.89e-01
  [eval] val_mse=5.085e-01  (n=7000)
Epoch 00160: Time=  11.0s, Loss=3.45e+00, Inv=3.45e+00, For=1.40e+02, Power=6.91e-01
  [eval] val_mse=5.070e-01  (n=7000)
Epoch 00161: Time=  11.0s, Loss=3.44e+00, Inv=3.44e+00, For=1.43e+02, Power=6.91e-01
  [eval] val_mse=5.050e-01  (n=7000)
Epoch 00162: Time=  11.1s, Loss=3.43e+00, Inv=3.43e+00, For=1.45e+02, Power=6.89e-01
  [eval] val_mse=5.030e-01  (n=7000)
Epoch 00163: Time=  11.1s, Loss=3.43e+00, Inv=3.43e+00, For=1.47e+02, Power=6.92e-01
  [eval] val_mse=5.017e-01  (n=7000)
Epoch 00164: Time=  11.1s, Loss=3.42e+00, Inv=3.42e+00, For=1.50e+02, Power=6.89e-01
  [eval] val_mse=4.985e-01  (n=7000)
Epoch 00165: Time=  11.2s, Loss=3.42e+00, Inv=3.42e+00, For=1.53e+02, Power=6.91e-01
  [eval] val_mse=4.967e-01  (n=7000)
Epoch 00166: Time=  11.2s, Loss=3.41e+00, Inv=3.41e+00, For=1.53e+02, Power=6.90e-01
  [eval] val_mse=4.969e-01  (n=7000)
Epoch 00167: Time=  11.2s, Loss=3.41e+00, Inv=3.41e+00, For=1.58e+02, Power=6.90e-01
  [eval] val_mse=4.940e-01  (n=7000)
Epoch 00168: Time=  11.3s, Loss=3.40e+00, Inv=3.40e+00, For=1.60e+02, Power=6.91e-01
  [eval] val_mse=4.929e-01  (n=7000)
Epoch 00169: Time=  11.3s, Loss=3.39e+00, Inv=3.39e+00, For=1.62e+02, Power=6.85e-01
  [eval] val_mse=4.912e-01  (n=7000)
Epoch 00170: Time=  11.3s, Loss=3.39e+00, Inv=3.39e+00, For=1.65e+02, Power=6.89e-01
  [eval] val_mse=4.888e-01  (n=7000)
Epoch 00171: Time=  11.4s, Loss=3.39e+00, Inv=3.39e+00, For=1.69e+02, Power=6.90e-01
  [eval] val_mse=4.863e-01  (n=7000)
Epoch 00172: Time=  11.4s, Loss=3.38e+00, Inv=3.38e+00, For=1.70e+02, Power=6.88e-01
  [eval] val_mse=4.862e-01  (n=7000)
Epoch 00173: Time=  11.4s, Loss=3.38e+00, Inv=3.38e+00, For=1.72e+02, Power=6.90e-01
  [eval] val_mse=4.844e-01  (n=7000)
Epoch 00174: Time=  11.5s, Loss=3.37e+00, Inv=3.37e+00, For=1.76e+02, Power=6.90e-01
  [eval] val_mse=4.828e-01  (n=7000)
Epoch 00175: Time=  11.5s, Loss=3.36e+00, Inv=3.36e+00, For=1.77e+02, Power=6.87e-01
  [eval] val_mse=4.820e-01  (n=7000)
Epoch 00176: Time=  11.5s, Loss=3.36e+00, Inv=3.36e+00, For=1.83e+02, Power=6.92e-01
  [eval] val_mse=4.788e-01  (n=7000)
Epoch 00177: Time=  11.6s, Loss=3.35e+00, Inv=3.35e+00, For=1.81e+02, Power=6.85e-01
  [eval] val_mse=4.786e-01  (n=7000)
Epoch 00178: Time=  11.6s, Loss=3.34e+00, Inv=3.34e+00, For=1.86e+02, Power=6.87e-01
  [eval] val_mse=4.757e-01  (n=7000)
Epoch 00179: Time=  11.6s, Loss=3.34e+00, Inv=3.34e+00, For=1.87e+02, Power=6.89e-01
  [eval] val_mse=4.762e-01  (n=7000)
Epoch 00180: Time=  11.7s, Loss=3.34e+00, Inv=3.34e+00, For=1.92e+02, Power=6.87e-01
  [eval] val_mse=4.730e-01  (n=7000)
Epoch 00181: Time=  11.7s, Loss=3.33e+00, Inv=3.33e+00, For=1.96e+02, Power=6.89e-01
  [eval] val_mse=4.720e-01  (n=7000)
Epoch 00182: Time=  11.7s, Loss=3.32e+00, Inv=3.32e+00, For=1.96e+02, Power=6.84e-01
  [eval] val_mse=4.711e-01  (n=7000)
Epoch 00183: Time=  11.8s, Loss=3.33e+00, Inv=3.33e+00, For=1.99e+02, Power=6.91e-01
  [eval] val_mse=4.696e-01  (n=7000)
Epoch 00184: Time=  11.8s, Loss=3.32e+00, Inv=3.32e+00, For=2.03e+02, Power=6.85e-01
  [eval] val_mse=4.678e-01  (n=7000)
Epoch 00185: Time=  11.8s, Loss=3.31e+00, Inv=3.31e+00, For=2.06e+02, Power=6.87e-01
  [eval] val_mse=4.661e-01  (n=7000)
Epoch 00186: Time=  11.9s, Loss=3.31e+00, Inv=3.31e+00, For=2.08e+02, Power=6.83e-01
  [eval] val_mse=4.654e-01  (n=7000)
Epoch 00187: Time=  11.9s, Loss=3.30e+00, Inv=3.30e+00, For=2.11e+02, Power=6.86e-01
  [eval] val_mse=4.640e-01  (n=7000)
Epoch 00188: Time=  11.9s, Loss=3.30e+00, Inv=3.30e+00, For=2.13e+02, Power=6.87e-01
  [eval] val_mse=4.627e-01  (n=7000)
Epoch 00189: Time=  12.0s, Loss=3.29e+00, Inv=3.29e+00, For=2.14e+02, Power=6.86e-01
  [eval] val_mse=4.612e-01  (n=7000)
Epoch 00190: Time=  12.0s, Loss=3.29e+00, Inv=3.29e+00, For=2.18e+02, Power=6.84e-01
  [eval] val_mse=4.606e-01  (n=7000)
Epoch 00191: Time=  12.0s, Loss=3.29e+00, Inv=3.29e+00, For=2.23e+02, Power=6.87e-01
  [eval] val_mse=4.587e-01  (n=7000)
Epoch 00192: Time=  12.1s, Loss=3.28e+00, Inv=3.28e+00, For=2.24e+02, Power=6.86e-01
  [eval] val_mse=4.588e-01  (n=7000)
Epoch 00193: Time=  12.1s, Loss=3.28e+00, Inv=3.28e+00, For=2.27e+02, Power=6.85e-01
  [eval] val_mse=4.562e-01  (n=7000)
Epoch 00194: Time=  12.1s, Loss=3.28e+00, Inv=3.28e+00, For=2.30e+02, Power=6.85e-01
  [eval] val_mse=4.558e-01  (n=7000)
Epoch 00195: Time=  12.2s, Loss=3.27e+00, Inv=3.27e+00, For=2.32e+02, Power=6.86e-01
  [eval] val_mse=4.563e-01  (n=7000)
Epoch 00196: Time=  12.2s, Loss=3.27e+00, Inv=3.27e+00, For=2.40e+02, Power=6.85e-01
  [eval] val_mse=4.528e-01  (n=7000)
Epoch 00197: Time=  12.2s, Loss=3.26e+00, Inv=3.26e+00, For=2.36e+02, Power=6.84e-01
  [eval] val_mse=4.521e-01  (n=7000)
Epoch 00198: Time=  12.3s, Loss=3.26e+00, Inv=3.26e+00, For=2.42e+02, Power=6.87e-01
  [eval] val_mse=4.510e-01  (n=7000)
Epoch 00199: Time=  12.3s, Loss=3.26e+00, Inv=3.26e+00, For=2.46e+02, Power=6.86e-01
  [eval] val_mse=4.489e-01  (n=7000)
Epoch 00200: Time=  12.3s, Loss=3.25e+00, Inv=3.25e+00, For=2.45e+02, Power=6.86e-01
  [eval] val_mse=4.489e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 2.735e-01
Torque MSE  = 1.129e-01
Torque RMSE = 3.360e-01
Per-joint MSE : 9.533e-02 1.989e-01 9.820e-02 2.090e-02 2.463e-01 1.762e-02
Per-joint RMSE: 3.087e-01 4.460e-01 3.134e-01 1.446e-01 4.963e-01 1.328e-01
Comp Time per Sample = 2.863e-04s / 3492.8Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 1 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-tswklx87 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x726693e2e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:56:45.934209: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:56:47.780105: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=2.04e+04, Inv=2.04e+04, For=5.87e+00, Power=2.83e+03
  [eval] val_mse=4.515e+02  (n=2997)
Epoch 00002: Time=   5.3s, Loss=2.98e+03, Inv=2.98e+03, For=5.76e+00, Power=5.27e+02
  [eval] val_mse=1.789e+02  (n=2997)
Epoch 00003: Time=   5.4s, Loss=1.29e+03, Inv=1.29e+03, For=5.65e+00, Power=2.28e+02
  [eval] val_mse=1.003e+02  (n=2997)
Epoch 00004: Time=   5.4s, Loss=7.39e+02, Inv=7.39e+02, For=5.54e+00, Power=1.29e+02
  [eval] val_mse=6.521e+01  (n=2997)
Epoch 00005: Time=   5.5s, Loss=4.80e+02, Inv=4.80e+02, For=5.45e+00, Power=8.29e+01
  [eval] val_mse=4.623e+01  (n=2997)
Epoch 00006: Time=   5.5s, Loss=3.37e+02, Inv=3.37e+02, For=5.35e+00, Power=5.82e+01
  [eval] val_mse=3.457e+01  (n=2997)
Epoch 00007: Time=   5.5s, Loss=2.49e+02, Inv=2.49e+02, For=5.27e+00, Power=4.29e+01
  [eval] val_mse=2.710e+01  (n=2997)
Epoch 00008: Time=   5.6s, Loss=1.91e+02, Inv=1.91e+02, For=5.21e+00, Power=3.27e+01
  [eval] val_mse=2.194e+01  (n=2997)
Epoch 00009: Time=   5.6s, Loss=1.51e+02, Inv=1.51e+02, For=5.15e+00, Power=2.59e+01
  [eval] val_mse=1.818e+01  (n=2997)
Epoch 00010: Time=   5.6s, Loss=1.23e+02, Inv=1.23e+02, For=5.11e+00, Power=2.09e+01
  [eval] val_mse=1.548e+01  (n=2997)
Epoch 00011: Time=   5.7s, Loss=1.01e+02, Inv=1.01e+02, For=5.08e+00, Power=1.70e+01
  [eval] val_mse=1.341e+01  (n=2997)
Epoch 00012: Time=   5.7s, Loss=8.49e+01, Inv=8.49e+01, For=5.06e+00, Power=1.42e+01
  [eval] val_mse=1.184e+01  (n=2997)
Epoch 00013: Time=   5.8s, Loss=7.23e+01, Inv=7.23e+01, For=5.05e+00, Power=1.20e+01
  [eval] val_mse=1.059e+01  (n=2997)
Epoch 00014: Time=   5.8s, Loss=6.23e+01, Inv=6.23e+01, For=5.06e+00, Power=1.03e+01
  [eval] val_mse=9.610e+00  (n=2997)
Epoch 00015: Time=   5.8s, Loss=5.42e+01, Inv=5.42e+01, For=5.07e+00, Power=8.89e+00
  [eval] val_mse=8.775e+00  (n=2997)
Epoch 00016: Time=   5.9s, Loss=4.76e+01, Inv=4.76e+01, For=5.11e+00, Power=7.73e+00
  [eval] val_mse=8.116e+00  (n=2997)
Epoch 00017: Time=   5.9s, Loss=4.22e+01, Inv=4.22e+01, For=5.15e+00, Power=6.78e+00
  [eval] val_mse=7.549e+00  (n=2997)
Epoch 00018: Time=   5.9s, Loss=3.76e+01, Inv=3.76e+01, For=5.20e+00, Power=6.01e+00
  [eval] val_mse=7.069e+00  (n=2997)
Epoch 00019: Time=   6.0s, Loss=3.38e+01, Inv=3.38e+01, For=5.25e+00, Power=5.35e+00
  [eval] val_mse=6.662e+00  (n=2997)
Epoch 00020: Time=   6.0s, Loss=3.06e+01, Inv=3.06e+01, For=5.32e+00, Power=4.78e+00
  [eval] val_mse=6.308e+00  (n=2997)
Epoch 00021: Time=   6.0s, Loss=2.78e+01, Inv=2.78e+01, For=5.41e+00, Power=4.31e+00
  [eval] val_mse=5.989e+00  (n=2997)
Epoch 00022: Time=   6.1s, Loss=2.54e+01, Inv=2.54e+01, For=5.50e+00, Power=3.91e+00
  [eval] val_mse=5.711e+00  (n=2997)
Epoch 00023: Time=   6.1s, Loss=2.33e+01, Inv=2.33e+01, For=5.61e+00, Power=3.56e+00
  [eval] val_mse=5.455e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=2.15e+01, Inv=2.15e+01, For=5.74e+00, Power=3.26e+00
  [eval] val_mse=5.224e+00  (n=2997)
Epoch 00025: Time=   6.2s, Loss=2.00e+01, Inv=2.00e+01, For=5.88e+00, Power=2.99e+00
  [eval] val_mse=5.018e+00  (n=2997)
Epoch 00026: Time=   6.2s, Loss=1.86e+01, Inv=1.86e+01, For=6.04e+00, Power=2.76e+00
  [eval] val_mse=4.822e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=1.73e+01, Inv=1.73e+01, For=6.21e+00, Power=2.56e+00
  [eval] val_mse=4.640e+00  (n=2997)
Epoch 00028: Time=   6.3s, Loss=1.63e+01, Inv=1.63e+01, For=6.41e+00, Power=2.38e+00
  [eval] val_mse=4.475e+00  (n=2997)
Epoch 00029: Time=   6.3s, Loss=1.53e+01, Inv=1.53e+01, For=6.62e+00, Power=2.22e+00
  [eval] val_mse=4.318e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=1.44e+01, Inv=1.44e+01, For=6.85e+00, Power=2.07e+00
  [eval] val_mse=4.172e+00  (n=2997)
Epoch 00031: Time=   6.4s, Loss=1.36e+01, Inv=1.36e+01, For=7.11e+00, Power=1.95e+00
  [eval] val_mse=4.038e+00  (n=2997)
Epoch 00032: Time=   6.4s, Loss=1.29e+01, Inv=1.29e+01, For=7.38e+00, Power=1.83e+00
  [eval] val_mse=3.913e+00  (n=2997)
Epoch 00033: Time=   6.5s, Loss=1.23e+01, Inv=1.23e+01, For=7.66e+00, Power=1.72e+00
  [eval] val_mse=3.797e+00  (n=2997)
Epoch 00034: Time=   6.5s, Loss=1.17e+01, Inv=1.17e+01, For=7.98e+00, Power=1.64e+00
  [eval] val_mse=3.688e+00  (n=2997)
Epoch 00035: Time=   6.5s, Loss=1.12e+01, Inv=1.12e+01, For=8.32e+00, Power=1.55e+00
  [eval] val_mse=3.580e+00  (n=2997)
Epoch 00036: Time=   6.6s, Loss=1.07e+01, Inv=1.07e+01, For=8.70e+00, Power=1.48e+00
  [eval] val_mse=3.485e+00  (n=2997)
Epoch 00037: Time=   6.6s, Loss=1.02e+01, Inv=1.02e+01, For=9.05e+00, Power=1.41e+00
  [eval] val_mse=3.395e+00  (n=2997)
Epoch 00038: Time=   6.6s, Loss=9.84e+00, Inv=9.84e+00, For=9.44e+00, Power=1.35e+00
  [eval] val_mse=3.310e+00  (n=2997)
Epoch 00039: Time=   6.7s, Loss=9.48e+00, Inv=9.48e+00, For=9.87e+00, Power=1.29e+00
  [eval] val_mse=3.234e+00  (n=2997)
Epoch 00040: Time=   6.7s, Loss=9.15e+00, Inv=9.15e+00, For=1.03e+01, Power=1.24e+00
  [eval] val_mse=3.160e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=8.85e+00, Inv=8.85e+00, For=1.08e+01, Power=1.19e+00
  [eval] val_mse=3.095e+00  (n=2997)
Epoch 00042: Time=   6.8s, Loss=8.57e+00, Inv=8.57e+00, For=1.12e+01, Power=1.15e+00
  [eval] val_mse=3.020e+00  (n=2997)
Epoch 00043: Time=   6.8s, Loss=8.31e+00, Inv=8.31e+00, For=1.17e+01, Power=1.11e+00
  [eval] val_mse=2.961e+00  (n=2997)
Epoch 00044: Time=   6.9s, Loss=8.07e+00, Inv=8.07e+00, For=1.22e+01, Power=1.08e+00
  [eval] val_mse=2.906e+00  (n=2997)
Epoch 00045: Time=   6.9s, Loss=7.85e+00, Inv=7.85e+00, For=1.28e+01, Power=1.04e+00
  [eval] val_mse=2.846e+00  (n=2997)
Epoch 00046: Time=   6.9s, Loss=7.63e+00, Inv=7.63e+00, For=1.33e+01, Power=1.01e+00
  [eval] val_mse=2.798e+00  (n=2997)
Epoch 00047: Time=   7.0s, Loss=7.44e+00, Inv=7.44e+00, For=1.39e+01, Power=9.84e-01
  [eval] val_mse=2.742e+00  (n=2997)
Epoch 00048: Time=   7.0s, Loss=7.27e+00, Inv=7.27e+00, For=1.45e+01, Power=9.59e-01
  [eval] val_mse=2.702e+00  (n=2997)
Epoch 00049: Time=   7.0s, Loss=7.10e+00, Inv=7.10e+00, For=1.51e+01, Power=9.35e-01
  [eval] val_mse=2.646e+00  (n=2997)
Epoch 00050: Time=   7.1s, Loss=6.95e+00, Inv=6.95e+00, For=1.57e+01, Power=9.14e-01
  [eval] val_mse=2.609e+00  (n=2997)
Epoch 00051: Time=   7.1s, Loss=6.80e+00, Inv=6.80e+00, For=1.64e+01, Power=8.94e-01
  [eval] val_mse=2.567e+00  (n=2997)
Epoch 00052: Time=   7.1s, Loss=6.66e+00, Inv=6.66e+00, For=1.69e+01, Power=8.75e-01
  [eval] val_mse=2.530e+00  (n=2997)
Epoch 00053: Time=   7.2s, Loss=6.53e+00, Inv=6.53e+00, For=1.76e+01, Power=8.56e-01
  [eval] val_mse=2.490e+00  (n=2997)
Epoch 00054: Time=   7.2s, Loss=6.41e+00, Inv=6.41e+00, For=1.83e+01, Power=8.40e-01
  [eval] val_mse=2.453e+00  (n=2997)
Epoch 00055: Time=   7.2s, Loss=6.30e+00, Inv=6.30e+00, For=1.90e+01, Power=8.25e-01
  [eval] val_mse=2.424e+00  (n=2997)
Epoch 00056: Time=   7.3s, Loss=6.19e+00, Inv=6.19e+00, For=1.97e+01, Power=8.12e-01
  [eval] val_mse=2.394e+00  (n=2997)
Epoch 00057: Time=   7.3s, Loss=6.09e+00, Inv=6.09e+00, For=2.05e+01, Power=7.98e-01
  [eval] val_mse=2.354e+00  (n=2997)
Epoch 00058: Time=   7.3s, Loss=6.00e+00, Inv=6.00e+00, For=2.12e+01, Power=7.86e-01
  [eval] val_mse=2.325e+00  (n=2997)
Epoch 00059: Time=   7.4s, Loss=5.90e+00, Inv=5.90e+00, For=2.20e+01, Power=7.75e-01
  [eval] val_mse=2.302e+00  (n=2997)
Epoch 00060: Time=   7.4s, Loss=5.81e+00, Inv=5.81e+00, For=2.27e+01, Power=7.64e-01
  [eval] val_mse=2.267e+00  (n=2997)
Epoch 00061: Time=   7.4s, Loss=5.73e+00, Inv=5.73e+00, For=2.35e+01, Power=7.54e-01
  [eval] val_mse=2.240e+00  (n=2997)
Epoch 00062: Time=   7.5s, Loss=5.65e+00, Inv=5.65e+00, For=2.44e+01, Power=7.45e-01
  [eval] val_mse=2.218e+00  (n=2997)
Epoch 00063: Time=   7.5s, Loss=5.58e+00, Inv=5.58e+00, For=2.52e+01, Power=7.36e-01
  [eval] val_mse=2.193e+00  (n=2997)
Epoch 00064: Time=   7.5s, Loss=5.50e+00, Inv=5.50e+00, For=2.61e+01, Power=7.27e-01
  [eval] val_mse=2.168e+00  (n=2997)
Epoch 00065: Time=   7.6s, Loss=5.44e+00, Inv=5.44e+00, For=2.70e+01, Power=7.21e-01
  [eval] val_mse=2.149e+00  (n=2997)
Epoch 00066: Time=   7.6s, Loss=5.37e+00, Inv=5.37e+00, For=2.79e+01, Power=7.12e-01
  [eval] val_mse=2.123e+00  (n=2997)
Epoch 00067: Time=   7.7s, Loss=5.31e+00, Inv=5.31e+00, For=2.87e+01, Power=7.05e-01
  [eval] val_mse=2.105e+00  (n=2997)
Epoch 00068: Time=   7.7s, Loss=5.25e+00, Inv=5.25e+00, For=2.96e+01, Power=7.00e-01
  [eval] val_mse=2.083e+00  (n=2997)
Epoch 00069: Time=   7.7s, Loss=5.20e+00, Inv=5.20e+00, For=3.06e+01, Power=6.93e-01
  [eval] val_mse=2.060e+00  (n=2997)
Epoch 00070: Time=   7.8s, Loss=5.14e+00, Inv=5.14e+00, For=3.15e+01, Power=6.87e-01
  [eval] val_mse=2.043e+00  (n=2997)
Epoch 00071: Time=   7.8s, Loss=5.09e+00, Inv=5.09e+00, For=3.25e+01, Power=6.83e-01
  [eval] val_mse=2.025e+00  (n=2997)
Epoch 00072: Time=   7.8s, Loss=5.04e+00, Inv=5.04e+00, For=3.35e+01, Power=6.75e-01
  [eval] val_mse=2.008e+00  (n=2997)
Epoch 00073: Time=   7.9s, Loss=5.00e+00, Inv=5.00e+00, For=3.44e+01, Power=6.72e-01
  [eval] val_mse=1.993e+00  (n=2997)
Epoch 00074: Time=   7.9s, Loss=4.95e+00, Inv=4.95e+00, For=3.54e+01, Power=6.68e-01
  [eval] val_mse=1.974e+00  (n=2997)
Epoch 00075: Time=   7.9s, Loss=4.91e+00, Inv=4.91e+00, For=3.64e+01, Power=6.64e-01
  [eval] val_mse=1.955e+00  (n=2997)
Epoch 00076: Time=   8.0s, Loss=4.86e+00, Inv=4.86e+00, For=3.74e+01, Power=6.59e-01
  [eval] val_mse=1.942e+00  (n=2997)
Epoch 00077: Time=   8.0s, Loss=4.83e+00, Inv=4.83e+00, For=3.84e+01, Power=6.55e-01
  [eval] val_mse=1.928e+00  (n=2997)
Epoch 00078: Time=   8.0s, Loss=4.79e+00, Inv=4.79e+00, For=3.93e+01, Power=6.52e-01
  [eval] val_mse=1.910e+00  (n=2997)
Epoch 00079: Time=   8.1s, Loss=4.75e+00, Inv=4.75e+00, For=4.05e+01, Power=6.49e-01
  [eval] val_mse=1.896e+00  (n=2997)
Epoch 00080: Time=   8.1s, Loss=4.71e+00, Inv=4.71e+00, For=4.15e+01, Power=6.44e-01
  [eval] val_mse=1.873e+00  (n=2997)
Epoch 00081: Time=   8.1s, Loss=4.68e+00, Inv=4.68e+00, For=4.26e+01, Power=6.42e-01
  [eval] val_mse=1.864e+00  (n=2997)
Epoch 00082: Time=   8.2s, Loss=4.64e+00, Inv=4.64e+00, For=4.35e+01, Power=6.40e-01
  [eval] val_mse=1.850e+00  (n=2997)
Epoch 00083: Time=   8.2s, Loss=4.61e+00, Inv=4.61e+00, For=4.47e+01, Power=6.36e-01
  [eval] val_mse=1.841e+00  (n=2997)
Epoch 00084: Time=   8.2s, Loss=4.58e+00, Inv=4.58e+00, For=4.58e+01, Power=6.34e-01
  [eval] val_mse=1.823e+00  (n=2997)
Epoch 00085: Time=   8.3s, Loss=4.55e+00, Inv=4.55e+00, For=4.70e+01, Power=6.31e-01
  [eval] val_mse=1.805e+00  (n=2997)
Epoch 00086: Time=   8.3s, Loss=4.52e+00, Inv=4.52e+00, For=4.78e+01, Power=6.28e-01
  [eval] val_mse=1.801e+00  (n=2997)
Epoch 00087: Time=   8.4s, Loss=4.49e+00, Inv=4.49e+00, For=4.91e+01, Power=6.27e-01
  [eval] val_mse=1.793e+00  (n=2997)
Epoch 00088: Time=   8.4s, Loss=4.46e+00, Inv=4.46e+00, For=5.01e+01, Power=6.23e-01
  [eval] val_mse=1.777e+00  (n=2997)
Epoch 00089: Time=   8.4s, Loss=4.44e+00, Inv=4.44e+00, For=5.11e+01, Power=6.22e-01
  [eval] val_mse=1.770e+00  (n=2997)
Epoch 00090: Time=   8.5s, Loss=4.42e+00, Inv=4.42e+00, For=5.23e+01, Power=6.21e-01
  [eval] val_mse=1.753e+00  (n=2997)
Epoch 00091: Time=   8.5s, Loss=4.39e+00, Inv=4.39e+00, For=5.32e+01, Power=6.17e-01
  [eval] val_mse=1.748e+00  (n=2997)
Epoch 00092: Time=   8.5s, Loss=4.37e+00, Inv=4.37e+00, For=5.44e+01, Power=6.17e-01
  [eval] val_mse=1.733e+00  (n=2997)
Epoch 00093: Time=   8.6s, Loss=4.35e+00, Inv=4.35e+00, For=5.57e+01, Power=6.16e-01
  [eval] val_mse=1.724e+00  (n=2997)
Epoch 00094: Time=   8.6s, Loss=4.32e+00, Inv=4.32e+00, For=5.66e+01, Power=6.14e-01
  [eval] val_mse=1.714e+00  (n=2997)
Epoch 00095: Time=   8.7s, Loss=4.30e+00, Inv=4.30e+00, For=5.77e+01, Power=6.12e-01
  [eval] val_mse=1.704e+00  (n=2997)
Epoch 00096: Time=   8.7s, Loss=4.28e+00, Inv=4.28e+00, For=5.86e+01, Power=6.11e-01
  [eval] val_mse=1.690e+00  (n=2997)
Epoch 00097: Time=   8.7s, Loss=4.26e+00, Inv=4.26e+00, For=6.00e+01, Power=6.09e-01
  [eval] val_mse=1.679e+00  (n=2997)
Epoch 00098: Time=   8.8s, Loss=4.24e+00, Inv=4.24e+00, For=6.08e+01, Power=6.07e-01
  [eval] val_mse=1.673e+00  (n=2997)
Epoch 00099: Time=   8.8s, Loss=4.22e+00, Inv=4.22e+00, For=6.21e+01, Power=6.06e-01
  [eval] val_mse=1.666e+00  (n=2997)
Epoch 00100: Time=   8.8s, Loss=4.20e+00, Inv=4.20e+00, For=6.30e+01, Power=6.06e-01
  [eval] val_mse=1.653e+00  (n=2997)
Epoch 00101: Time=   8.9s, Loss=4.18e+00, Inv=4.18e+00, For=6.39e+01, Power=6.02e-01
  [eval] val_mse=1.653e+00  (n=2997)
Epoch 00102: Time=   8.9s, Loss=4.16e+00, Inv=4.16e+00, For=6.51e+01, Power=6.02e-01
  [eval] val_mse=1.634e+00  (n=2997)
Epoch 00103: Time=   9.0s, Loss=4.15e+00, Inv=4.15e+00, For=6.61e+01, Power=6.02e-01
  [eval] val_mse=1.626e+00  (n=2997)
Epoch 00104: Time=   9.0s, Loss=4.13e+00, Inv=4.13e+00, For=6.71e+01, Power=6.02e-01
  [eval] val_mse=1.624e+00  (n=2997)
Epoch 00105: Time=   9.0s, Loss=4.11e+00, Inv=4.11e+00, For=6.79e+01, Power=5.99e-01
  [eval] val_mse=1.615e+00  (n=2997)
Epoch 00106: Time=   9.1s, Loss=4.10e+00, Inv=4.10e+00, For=6.91e+01, Power=5.99e-01
  [eval] val_mse=1.605e+00  (n=2997)
Epoch 00107: Time=   9.1s, Loss=4.08e+00, Inv=4.08e+00, For=7.00e+01, Power=5.98e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00108: Time=   9.1s, Loss=4.07e+00, Inv=4.07e+00, For=7.07e+01, Power=5.97e-01
  [eval] val_mse=1.584e+00  (n=2997)
Epoch 00109: Time=   9.2s, Loss=4.05e+00, Inv=4.05e+00, For=7.18e+01, Power=5.97e-01
  [eval] val_mse=1.580e+00  (n=2997)
Epoch 00110: Time=   9.2s, Loss=4.04e+00, Inv=4.04e+00, For=7.25e+01, Power=5.95e-01
  [eval] val_mse=1.575e+00  (n=2997)
Epoch 00111: Time=   9.2s, Loss=4.02e+00, Inv=4.02e+00, For=7.37e+01, Power=5.95e-01
  [eval] val_mse=1.563e+00  (n=2997)
Epoch 00112: Time=   9.3s, Loss=4.01e+00, Inv=4.01e+00, For=7.41e+01, Power=5.95e-01
  [eval] val_mse=1.560e+00  (n=2997)
Epoch 00113: Time=   9.3s, Loss=4.00e+00, Inv=4.00e+00, For=7.54e+01, Power=5.93e-01
  [eval] val_mse=1.555e+00  (n=2997)
Epoch 00114: Time=   9.3s, Loss=3.98e+00, Inv=3.98e+00, For=7.59e+01, Power=5.94e-01
  [eval] val_mse=1.563e+00  (n=2997)
Epoch 00115: Time=   9.4s, Loss=3.97e+00, Inv=3.97e+00, For=7.66e+01, Power=5.93e-01
  [eval] val_mse=1.549e+00  (n=2997)
Epoch 00116: Time=   9.4s, Loss=3.96e+00, Inv=3.96e+00, For=7.80e+01, Power=5.93e-01
  [eval] val_mse=1.541e+00  (n=2997)
Epoch 00117: Time=   9.5s, Loss=3.94e+00, Inv=3.94e+00, For=7.83e+01, Power=5.91e-01
  [eval] val_mse=1.539e+00  (n=2997)
Epoch 00118: Time=   9.5s, Loss=3.93e+00, Inv=3.93e+00, For=7.91e+01, Power=5.91e-01
  [eval] val_mse=1.533e+00  (n=2997)
Epoch 00119: Time=   9.5s, Loss=3.92e+00, Inv=3.92e+00, For=7.98e+01, Power=5.91e-01
  [eval] val_mse=1.525e+00  (n=2997)
Epoch 00120: Time=   9.6s, Loss=3.91e+00, Inv=3.91e+00, For=8.05e+01, Power=5.90e-01
  [eval] val_mse=1.522e+00  (n=2997)
Epoch 00121: Time=   9.6s, Loss=3.90e+00, Inv=3.90e+00, For=8.14e+01, Power=5.90e-01
  [eval] val_mse=1.517e+00  (n=2997)
Epoch 00122: Time=   9.6s, Loss=3.88e+00, Inv=3.88e+00, For=8.19e+01, Power=5.89e-01
  [eval] val_mse=1.522e+00  (n=2997)
Epoch 00123: Time=   9.7s, Loss=3.87e+00, Inv=3.87e+00, For=8.24e+01, Power=5.89e-01
  [eval] val_mse=1.508e+00  (n=2997)
Epoch 00124: Time=   9.7s, Loss=3.87e+00, Inv=3.87e+00, For=8.28e+01, Power=5.88e-01
  [eval] val_mse=1.516e+00  (n=2997)
Epoch 00125: Time=   9.7s, Loss=3.86e+00, Inv=3.86e+00, For=8.37e+01, Power=5.88e-01
  [eval] val_mse=1.508e+00  (n=2997)
Epoch 00126: Time=   9.8s, Loss=3.84e+00, Inv=3.84e+00, For=8.41e+01, Power=5.87e-01
  [eval] val_mse=1.507e+00  (n=2997)
Epoch 00127: Time=   9.8s, Loss=3.83e+00, Inv=3.83e+00, For=8.46e+01, Power=5.87e-01
  [eval] val_mse=1.495e+00  (n=2997)
Epoch 00128: Time=   9.9s, Loss=3.83e+00, Inv=3.83e+00, For=8.52e+01, Power=5.87e-01
  [eval] val_mse=1.503e+00  (n=2997)
Epoch 00129: Time=   9.9s, Loss=3.82e+00, Inv=3.82e+00, For=8.55e+01, Power=5.86e-01
  [eval] val_mse=1.495e+00  (n=2997)
Epoch 00130: Time=   9.9s, Loss=3.81e+00, Inv=3.81e+00, For=8.62e+01, Power=5.86e-01
  [eval] val_mse=1.502e+00  (n=2997)
Epoch 00131: Time=  10.0s, Loss=3.80e+00, Inv=3.80e+00, For=8.69e+01, Power=5.86e-01
  [eval] val_mse=1.496e+00  (n=2997)
Epoch 00132: Time=  10.0s, Loss=3.79e+00, Inv=3.79e+00, For=8.71e+01, Power=5.86e-01
  [eval] val_mse=1.488e+00  (n=2997)
Epoch 00133: Time=  10.0s, Loss=3.78e+00, Inv=3.78e+00, For=8.75e+01, Power=5.85e-01
  [eval] val_mse=1.491e+00  (n=2997)
Epoch 00134: Time=  10.1s, Loss=3.77e+00, Inv=3.77e+00, For=8.79e+01, Power=5.85e-01
  [eval] val_mse=1.491e+00  (n=2997)
Epoch 00135: Time=  10.1s, Loss=3.76e+00, Inv=3.76e+00, For=8.85e+01, Power=5.83e-01
  [eval] val_mse=1.490e+00  (n=2997)
Epoch 00136: Time=  10.2s, Loss=3.75e+00, Inv=3.75e+00, For=8.88e+01, Power=5.84e-01
  [eval] val_mse=1.484e+00  (n=2997)
Epoch 00137: Time=  10.2s, Loss=3.75e+00, Inv=3.75e+00, For=8.89e+01, Power=5.84e-01
  [eval] val_mse=1.491e+00  (n=2997)
Epoch 00138: Time=  10.2s, Loss=3.74e+00, Inv=3.74e+00, For=8.91e+01, Power=5.84e-01
  [eval] val_mse=1.485e+00  (n=2997)
Epoch 00139: Time=  10.3s, Loss=3.73e+00, Inv=3.73e+00, For=8.96e+01, Power=5.85e-01
  [eval] val_mse=1.494e+00  (n=2997)
Epoch 00140: Time=  10.3s, Loss=3.72e+00, Inv=3.72e+00, For=8.95e+01, Power=5.84e-01
  [eval] val_mse=1.488e+00  (n=2997)
Epoch 00141: Time=  10.4s, Loss=3.72e+00, Inv=3.72e+00, For=9.03e+01, Power=5.82e-01
  [eval] val_mse=1.494e+00  (n=2997)
Epoch 00142: Time=  10.4s, Loss=3.71e+00, Inv=3.71e+00, For=9.05e+01, Power=5.83e-01
  [eval] val_mse=1.495e+00  (n=2997)
Epoch 00143: Time=  10.4s, Loss=3.70e+00, Inv=3.70e+00, For=9.04e+01, Power=5.83e-01
  [eval] val_mse=1.502e+00  (n=2997)
Epoch 00144: Time=  10.5s, Loss=3.70e+00, Inv=3.70e+00, For=9.07e+01, Power=5.82e-01
  [eval] val_mse=1.495e+00  (n=2997)
Epoch 00145: Time=  10.5s, Loss=3.69e+00, Inv=3.69e+00, For=9.11e+01, Power=5.83e-01
  [eval] val_mse=1.495e+00  (n=2997)
Epoch 00146: Time=  10.5s, Loss=3.68e+00, Inv=3.68e+00, For=9.11e+01, Power=5.81e-01
  [eval] val_mse=1.500e+00  (n=2997)
  [early_stop] stop at epoch=146 (best_epoch=136, best_val_mse=1.484e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 4.974e-01
Torque MSE  = 1.240e-01
Torque RMSE = 3.521e-01
Per-joint MSE : 1.659e-01 2.744e-01 1.362e-01 5.941e-02 5.398e-02 5.380e-02
Per-joint RMSE: 4.074e-01 5.239e-01 3.691e-01 2.437e-01 2.323e-01 2.319e-01
Comp Time per Sample = 2.109e-04s / 4741.6Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-g_k3pt3i because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x74ba8d0a28c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:57:06.635643: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:57:08.466770: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=6.89e+03, Inv=6.89e+03, For=5.82e+00, Power=8.80e+02
  [eval] val_mse=2.211e+02  (n=2997)
Epoch 00002: Time=   5.4s, Loss=9.81e+02, Inv=9.81e+02, For=5.63e+00, Power=1.77e+02
  [eval] val_mse=8.738e+01  (n=2997)
Epoch 00003: Time=   5.5s, Loss=4.20e+02, Inv=4.20e+02, For=5.48e+00, Power=7.92e+01
  [eval] val_mse=4.982e+01  (n=2997)
Epoch 00004: Time=   5.5s, Loss=2.50e+02, Inv=2.50e+02, For=5.34e+00, Power=4.59e+01
  [eval] val_mse=3.341e+01  (n=2997)
Epoch 00005: Time=   5.5s, Loss=1.67e+02, Inv=1.67e+02, For=5.22e+00, Power=3.00e+01
  [eval] val_mse=2.474e+01  (n=2997)
Epoch 00006: Time=   5.6s, Loss=1.21e+02, Inv=1.21e+02, For=5.13e+00, Power=2.10e+01
  [eval] val_mse=1.951e+01  (n=2997)
Epoch 00007: Time=   5.6s, Loss=9.12e+01, Inv=9.12e+01, For=5.05e+00, Power=1.55e+01
  [eval] val_mse=1.599e+01  (n=2997)
Epoch 00008: Time=   5.6s, Loss=7.17e+01, Inv=7.17e+01, For=5.02e+00, Power=1.19e+01
  [eval] val_mse=1.354e+01  (n=2997)
Epoch 00009: Time=   5.7s, Loss=5.79e+01, Inv=5.79e+01, For=4.99e+00, Power=9.33e+00
  [eval] val_mse=1.175e+01  (n=2997)
Epoch 00010: Time=   5.7s, Loss=4.79e+01, Inv=4.79e+01, For=5.00e+00, Power=7.53e+00
  [eval] val_mse=1.042e+01  (n=2997)
Epoch 00011: Time=   5.7s, Loss=4.05e+01, Inv=4.05e+01, For=5.04e+00, Power=6.24e+00
  [eval] val_mse=9.347e+00  (n=2997)
Epoch 00012: Time=   5.8s, Loss=3.47e+01, Inv=3.47e+01, For=5.10e+00, Power=5.24e+00
  [eval] val_mse=8.516e+00  (n=2997)
Epoch 00013: Time=   5.8s, Loss=3.02e+01, Inv=3.02e+01, For=5.18e+00, Power=4.48e+00
  [eval] val_mse=7.830e+00  (n=2997)
Epoch 00014: Time=   5.8s, Loss=2.66e+01, Inv=2.66e+01, For=5.28e+00, Power=3.87e+00
  [eval] val_mse=7.264e+00  (n=2997)
Epoch 00015: Time=   5.9s, Loss=2.37e+01, Inv=2.37e+01, For=5.40e+00, Power=3.40e+00
  [eval] val_mse=6.785e+00  (n=2997)
Epoch 00016: Time=   5.9s, Loss=2.12e+01, Inv=2.12e+01, For=5.54e+00, Power=3.01e+00
  [eval] val_mse=6.360e+00  (n=2997)
Epoch 00017: Time=   5.9s, Loss=1.92e+01, Inv=1.92e+01, For=5.70e+00, Power=2.68e+00
  [eval] val_mse=6.000e+00  (n=2997)
Epoch 00018: Time=   6.0s, Loss=1.75e+01, Inv=1.75e+01, For=5.87e+00, Power=2.44e+00
  [eval] val_mse=5.683e+00  (n=2997)
Epoch 00019: Time=   6.0s, Loss=1.61e+01, Inv=1.61e+01, For=6.05e+00, Power=2.21e+00
  [eval] val_mse=5.397e+00  (n=2997)
Epoch 00020: Time=   6.0s, Loss=1.48e+01, Inv=1.48e+01, For=6.25e+00, Power=2.03e+00
  [eval] val_mse=5.138e+00  (n=2997)
Epoch 00021: Time=   6.1s, Loss=1.38e+01, Inv=1.38e+01, For=6.45e+00, Power=1.88e+00
  [eval] val_mse=4.908e+00  (n=2997)
Epoch 00022: Time=   6.1s, Loss=1.28e+01, Inv=1.28e+01, For=6.67e+00, Power=1.74e+00
  [eval] val_mse=4.693e+00  (n=2997)
Epoch 00023: Time=   6.1s, Loss=1.20e+01, Inv=1.20e+01, For=6.88e+00, Power=1.62e+00
  [eval] val_mse=4.506e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=1.13e+01, Inv=1.13e+01, For=7.12e+00, Power=1.52e+00
  [eval] val_mse=4.330e+00  (n=2997)
Epoch 00025: Time=   6.2s, Loss=1.06e+01, Inv=1.06e+01, For=7.37e+00, Power=1.44e+00
  [eval] val_mse=4.172e+00  (n=2997)
Epoch 00026: Time=   6.2s, Loss=1.01e+01, Inv=1.01e+01, For=7.61e+00, Power=1.36e+00
  [eval] val_mse=4.022e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=9.57e+00, Inv=9.57e+00, For=7.86e+00, Power=1.29e+00
  [eval] val_mse=3.890e+00  (n=2997)
Epoch 00028: Time=   6.3s, Loss=9.13e+00, Inv=9.13e+00, For=8.09e+00, Power=1.23e+00
  [eval] val_mse=3.762e+00  (n=2997)
Epoch 00029: Time=   6.4s, Loss=8.72e+00, Inv=8.72e+00, For=8.36e+00, Power=1.18e+00
  [eval] val_mse=3.648e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=8.36e+00, Inv=8.36e+00, For=8.64e+00, Power=1.13e+00
  [eval] val_mse=3.551e+00  (n=2997)
Epoch 00031: Time=   6.4s, Loss=8.03e+00, Inv=8.03e+00, For=8.87e+00, Power=1.09e+00
  [eval] val_mse=3.452e+00  (n=2997)
Epoch 00032: Time=   6.5s, Loss=7.74e+00, Inv=7.74e+00, For=9.18e+00, Power=1.05e+00
  [eval] val_mse=3.367e+00  (n=2997)
Epoch 00033: Time=   6.5s, Loss=7.47e+00, Inv=7.47e+00, For=9.45e+00, Power=1.01e+00
  [eval] val_mse=3.285e+00  (n=2997)
Epoch 00034: Time=   6.5s, Loss=7.23e+00, Inv=7.23e+00, For=9.71e+00, Power=9.81e-01
  [eval] val_mse=3.212e+00  (n=2997)
Epoch 00035: Time=   6.6s, Loss=7.01e+00, Inv=7.01e+00, For=9.98e+00, Power=9.53e-01
  [eval] val_mse=3.139e+00  (n=2997)
Epoch 00036: Time=   6.6s, Loss=6.81e+00, Inv=6.81e+00, For=1.03e+01, Power=9.29e-01
  [eval] val_mse=3.083e+00  (n=2997)
Epoch 00037: Time=   6.6s, Loss=6.63e+00, Inv=6.63e+00, For=1.05e+01, Power=9.06e-01
  [eval] val_mse=3.016e+00  (n=2997)
Epoch 00038: Time=   6.7s, Loss=6.46e+00, Inv=6.46e+00, For=1.08e+01, Power=8.85e-01
  [eval] val_mse=2.959e+00  (n=2997)
Epoch 00039: Time=   6.7s, Loss=6.30e+00, Inv=6.30e+00, For=1.11e+01, Power=8.66e-01
  [eval] val_mse=2.909e+00  (n=2997)
Epoch 00040: Time=   6.7s, Loss=6.16e+00, Inv=6.16e+00, For=1.13e+01, Power=8.49e-01
  [eval] val_mse=2.856e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=6.03e+00, Inv=6.03e+00, For=1.16e+01, Power=8.34e-01
  [eval] val_mse=2.813e+00  (n=2997)
Epoch 00042: Time=   6.8s, Loss=5.90e+00, Inv=5.90e+00, For=1.18e+01, Power=8.18e-01
  [eval] val_mse=2.765e+00  (n=2997)
Epoch 00043: Time=   6.8s, Loss=5.79e+00, Inv=5.79e+00, For=1.21e+01, Power=8.05e-01
  [eval] val_mse=2.721e+00  (n=2997)
Epoch 00044: Time=   6.9s, Loss=5.68e+00, Inv=5.68e+00, For=1.24e+01, Power=7.92e-01
  [eval] val_mse=2.680e+00  (n=2997)
Epoch 00045: Time=   6.9s, Loss=5.59e+00, Inv=5.59e+00, For=1.26e+01, Power=7.81e-01
  [eval] val_mse=2.637e+00  (n=2997)
Epoch 00046: Time=   6.9s, Loss=5.49e+00, Inv=5.49e+00, For=1.29e+01, Power=7.71e-01
  [eval] val_mse=2.606e+00  (n=2997)
Epoch 00047: Time=   7.0s, Loss=5.41e+00, Inv=5.41e+00, For=1.31e+01, Power=7.60e-01
  [eval] val_mse=2.565e+00  (n=2997)
Epoch 00048: Time=   7.0s, Loss=5.33e+00, Inv=5.33e+00, For=1.34e+01, Power=7.52e-01
  [eval] val_mse=2.539e+00  (n=2997)
Epoch 00049: Time=   7.1s, Loss=5.25e+00, Inv=5.25e+00, For=1.36e+01, Power=7.43e-01
  [eval] val_mse=2.499e+00  (n=2997)
Epoch 00050: Time=   7.1s, Loss=5.18e+00, Inv=5.18e+00, For=1.38e+01, Power=7.35e-01
  [eval] val_mse=2.468e+00  (n=2997)
Epoch 00051: Time=   7.1s, Loss=5.10e+00, Inv=5.10e+00, For=1.41e+01, Power=7.27e-01
  [eval] val_mse=2.437e+00  (n=2997)
Epoch 00052: Time=   7.2s, Loss=5.04e+00, Inv=5.04e+00, For=1.43e+01, Power=7.21e-01
  [eval] val_mse=2.408e+00  (n=2997)
Epoch 00053: Time=   7.2s, Loss=4.99e+00, Inv=4.99e+00, For=1.45e+01, Power=7.14e-01
  [eval] val_mse=2.381e+00  (n=2997)
Epoch 00054: Time=   7.2s, Loss=4.92e+00, Inv=4.92e+00, For=1.49e+01, Power=7.08e-01
  [eval] val_mse=2.354e+00  (n=2997)
Epoch 00055: Time=   7.3s, Loss=4.87e+00, Inv=4.87e+00, For=1.51e+01, Power=7.01e-01
  [eval] val_mse=2.329e+00  (n=2997)
Epoch 00056: Time=   7.3s, Loss=4.82e+00, Inv=4.82e+00, For=1.53e+01, Power=6.96e-01
  [eval] val_mse=2.296e+00  (n=2997)
Epoch 00057: Time=   7.4s, Loss=4.78e+00, Inv=4.78e+00, For=1.55e+01, Power=6.93e-01
  [eval] val_mse=2.272e+00  (n=2997)
Epoch 00058: Time=   7.4s, Loss=4.73e+00, Inv=4.73e+00, For=1.58e+01, Power=6.88e-01
  [eval] val_mse=2.249e+00  (n=2997)
Epoch 00059: Time=   7.4s, Loss=4.69e+00, Inv=4.69e+00, For=1.61e+01, Power=6.82e-01
  [eval] val_mse=2.229e+00  (n=2997)
Epoch 00060: Time=   7.5s, Loss=4.64e+00, Inv=4.64e+00, For=1.62e+01, Power=6.78e-01
  [eval] val_mse=2.208e+00  (n=2997)
Epoch 00061: Time=   7.5s, Loss=4.60e+00, Inv=4.60e+00, For=1.65e+01, Power=6.75e-01
  [eval] val_mse=2.175e+00  (n=2997)
Epoch 00062: Time=   7.5s, Loss=4.57e+00, Inv=4.57e+00, For=1.68e+01, Power=6.72e-01
  [eval] val_mse=2.159e+00  (n=2997)
Epoch 00063: Time=   7.6s, Loss=4.53e+00, Inv=4.53e+00, For=1.70e+01, Power=6.67e-01
  [eval] val_mse=2.147e+00  (n=2997)
Epoch 00064: Time=   7.6s, Loss=4.49e+00, Inv=4.49e+00, For=1.72e+01, Power=6.64e-01
  [eval] val_mse=2.124e+00  (n=2997)
Epoch 00065: Time=   7.6s, Loss=4.46e+00, Inv=4.46e+00, For=1.76e+01, Power=6.61e-01
  [eval] val_mse=2.112e+00  (n=2997)
Epoch 00066: Time=   7.7s, Loss=4.43e+00, Inv=4.43e+00, For=1.78e+01, Power=6.58e-01
  [eval] val_mse=2.090e+00  (n=2997)
Epoch 00067: Time=   7.7s, Loss=4.40e+00, Inv=4.40e+00, For=1.80e+01, Power=6.55e-01
  [eval] val_mse=2.073e+00  (n=2997)
Epoch 00068: Time=   7.7s, Loss=4.37e+00, Inv=4.37e+00, For=1.82e+01, Power=6.52e-01
  [eval] val_mse=2.062e+00  (n=2997)
Epoch 00069: Time=   7.8s, Loss=4.34e+00, Inv=4.34e+00, For=1.87e+01, Power=6.49e-01
  [eval] val_mse=2.038e+00  (n=2997)
Epoch 00070: Time=   7.8s, Loss=4.32e+00, Inv=4.32e+00, For=1.87e+01, Power=6.47e-01
  [eval] val_mse=2.022e+00  (n=2997)
Epoch 00071: Time=   7.8s, Loss=4.29e+00, Inv=4.29e+00, For=1.92e+01, Power=6.45e-01
  [eval] val_mse=2.005e+00  (n=2997)
Epoch 00072: Time=   7.9s, Loss=4.27e+00, Inv=4.27e+00, For=1.93e+01, Power=6.41e-01
  [eval] val_mse=1.992e+00  (n=2997)
Epoch 00073: Time=   7.9s, Loss=4.25e+00, Inv=4.25e+00, For=1.96e+01, Power=6.41e-01
  [eval] val_mse=1.968e+00  (n=2997)
Epoch 00074: Time=   7.9s, Loss=4.22e+00, Inv=4.22e+00, For=2.00e+01, Power=6.38e-01
  [eval] val_mse=1.959e+00  (n=2997)
Epoch 00075: Time=   8.0s, Loss=4.20e+00, Inv=4.20e+00, For=2.01e+01, Power=6.36e-01
  [eval] val_mse=1.947e+00  (n=2997)
Epoch 00076: Time=   8.0s, Loss=4.18e+00, Inv=4.18e+00, For=2.05e+01, Power=6.35e-01
  [eval] val_mse=1.932e+00  (n=2997)
Epoch 00077: Time=   8.1s, Loss=4.16e+00, Inv=4.16e+00, For=2.07e+01, Power=6.33e-01
  [eval] val_mse=1.925e+00  (n=2997)
Epoch 00078: Time=   8.1s, Loss=4.14e+00, Inv=4.14e+00, For=2.11e+01, Power=6.30e-01
  [eval] val_mse=1.904e+00  (n=2997)
Epoch 00079: Time=   8.1s, Loss=4.12e+00, Inv=4.12e+00, For=2.14e+01, Power=6.28e-01
  [eval] val_mse=1.899e+00  (n=2997)
Epoch 00080: Time=   8.2s, Loss=4.10e+00, Inv=4.10e+00, For=2.15e+01, Power=6.27e-01
  [eval] val_mse=1.883e+00  (n=2997)
Epoch 00081: Time=   8.2s, Loss=4.08e+00, Inv=4.08e+00, For=2.19e+01, Power=6.24e-01
  [eval] val_mse=1.873e+00  (n=2997)
Epoch 00082: Time=   8.2s, Loss=4.07e+00, Inv=4.07e+00, For=2.23e+01, Power=6.24e-01
  [eval] val_mse=1.853e+00  (n=2997)
Epoch 00083: Time=   8.3s, Loss=4.05e+00, Inv=4.05e+00, For=2.26e+01, Power=6.22e-01
  [eval] val_mse=1.844e+00  (n=2997)
Epoch 00084: Time=   8.3s, Loss=4.04e+00, Inv=4.04e+00, For=2.27e+01, Power=6.21e-01
  [eval] val_mse=1.828e+00  (n=2997)
Epoch 00085: Time=   8.3s, Loss=4.02e+00, Inv=4.02e+00, For=2.34e+01, Power=6.19e-01
  [eval] val_mse=1.828e+00  (n=2997)
Epoch 00086: Time=   8.4s, Loss=4.00e+00, Inv=4.00e+00, For=2.34e+01, Power=6.18e-01
  [eval] val_mse=1.810e+00  (n=2997)
Epoch 00087: Time=   8.4s, Loss=3.99e+00, Inv=3.99e+00, For=2.38e+01, Power=6.17e-01
  [eval] val_mse=1.805e+00  (n=2997)
Epoch 00088: Time=   8.4s, Loss=3.97e+00, Inv=3.97e+00, For=2.40e+01, Power=6.15e-01
  [eval] val_mse=1.797e+00  (n=2997)
Epoch 00089: Time=   8.5s, Loss=3.96e+00, Inv=3.96e+00, For=2.45e+01, Power=6.14e-01
  [eval] val_mse=1.799e+00  (n=2997)
Epoch 00090: Time=   8.5s, Loss=3.95e+00, Inv=3.95e+00, For=2.45e+01, Power=6.14e-01
  [eval] val_mse=1.777e+00  (n=2997)
Epoch 00091: Time=   8.5s, Loss=3.93e+00, Inv=3.93e+00, For=2.53e+01, Power=6.12e-01
  [eval] val_mse=1.761e+00  (n=2997)
Epoch 00092: Time=   8.6s, Loss=3.92e+00, Inv=3.92e+00, For=2.51e+01, Power=6.12e-01
  [eval] val_mse=1.755e+00  (n=2997)
Epoch 00093: Time=   8.6s, Loss=3.91e+00, Inv=3.91e+00, For=2.58e+01, Power=6.10e-01
  [eval] val_mse=1.748e+00  (n=2997)
Epoch 00094: Time=   8.6s, Loss=3.90e+00, Inv=3.90e+00, For=2.60e+01, Power=6.10e-01
  [eval] val_mse=1.738e+00  (n=2997)
Epoch 00095: Time=   8.7s, Loss=3.89e+00, Inv=3.89e+00, For=2.65e+01, Power=6.08e-01
  [eval] val_mse=1.725e+00  (n=2997)
Epoch 00096: Time=   8.7s, Loss=3.88e+00, Inv=3.88e+00, For=2.67e+01, Power=6.07e-01
  [eval] val_mse=1.726e+00  (n=2997)
Epoch 00097: Time=   8.7s, Loss=3.86e+00, Inv=3.86e+00, For=2.71e+01, Power=6.07e-01
  [eval] val_mse=1.708e+00  (n=2997)
Epoch 00098: Time=   8.8s, Loss=3.85e+00, Inv=3.85e+00, For=2.76e+01, Power=6.06e-01
  [eval] val_mse=1.706e+00  (n=2997)
Epoch 00099: Time=   8.8s, Loss=3.84e+00, Inv=3.84e+00, For=2.78e+01, Power=6.03e-01
  [eval] val_mse=1.692e+00  (n=2997)
Epoch 00100: Time=   8.8s, Loss=3.83e+00, Inv=3.83e+00, For=2.81e+01, Power=6.04e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00101: Time=   8.9s, Loss=3.82e+00, Inv=3.82e+00, For=2.83e+01, Power=6.02e-01
  [eval] val_mse=1.690e+00  (n=2997)
Epoch 00102: Time=   8.9s, Loss=3.81e+00, Inv=3.81e+00, For=2.90e+01, Power=6.03e-01
  [eval] val_mse=1.679e+00  (n=2997)
Epoch 00103: Time=   8.9s, Loss=3.80e+00, Inv=3.80e+00, For=2.91e+01, Power=6.02e-01
  [eval] val_mse=1.673e+00  (n=2997)
Epoch 00104: Time=   9.0s, Loss=3.79e+00, Inv=3.79e+00, For=2.96e+01, Power=6.01e-01
  [eval] val_mse=1.676e+00  (n=2997)
Epoch 00105: Time=   9.0s, Loss=3.78e+00, Inv=3.78e+00, For=3.00e+01, Power=5.98e-01
  [eval] val_mse=1.665e+00  (n=2997)
Epoch 00106: Time=   9.1s, Loss=3.77e+00, Inv=3.77e+00, For=3.03e+01, Power=6.00e-01
  [eval] val_mse=1.661e+00  (n=2997)
Epoch 00107: Time=   9.1s, Loss=3.76e+00, Inv=3.76e+00, For=3.05e+01, Power=5.97e-01
  [eval] val_mse=1.645e+00  (n=2997)
Epoch 00108: Time=   9.1s, Loss=3.75e+00, Inv=3.75e+00, For=3.10e+01, Power=5.99e-01
  [eval] val_mse=1.652e+00  (n=2997)
Epoch 00109: Time=   9.2s, Loss=3.74e+00, Inv=3.74e+00, For=3.13e+01, Power=5.97e-01
  [eval] val_mse=1.641e+00  (n=2997)
Epoch 00110: Time=   9.2s, Loss=3.74e+00, Inv=3.74e+00, For=3.18e+01, Power=5.95e-01
  [eval] val_mse=1.631e+00  (n=2997)
Epoch 00111: Time=   9.2s, Loss=3.73e+00, Inv=3.73e+00, For=3.19e+01, Power=5.96e-01
  [eval] val_mse=1.625e+00  (n=2997)
Epoch 00112: Time=   9.3s, Loss=3.72e+00, Inv=3.72e+00, For=3.26e+01, Power=5.95e-01
  [eval] val_mse=1.637e+00  (n=2997)
Epoch 00113: Time=   9.3s, Loss=3.72e+00, Inv=3.72e+00, For=3.33e+01, Power=5.96e-01
  [eval] val_mse=1.631e+00  (n=2997)
Epoch 00114: Time=   9.3s, Loss=3.70e+00, Inv=3.70e+00, For=3.29e+01, Power=5.94e-01
  [eval] val_mse=1.632e+00  (n=2997)
Epoch 00115: Time=   9.4s, Loss=3.70e+00, Inv=3.70e+00, For=3.36e+01, Power=5.94e-01
  [eval] val_mse=1.620e+00  (n=2997)
Epoch 00116: Time=   9.4s, Loss=3.69e+00, Inv=3.69e+00, For=3.39e+01, Power=5.93e-01
  [eval] val_mse=1.611e+00  (n=2997)
Epoch 00117: Time=   9.4s, Loss=3.68e+00, Inv=3.68e+00, For=3.46e+01, Power=5.93e-01
  [eval] val_mse=1.616e+00  (n=2997)
Epoch 00118: Time=   9.5s, Loss=3.68e+00, Inv=3.68e+00, For=3.47e+01, Power=5.92e-01
  [eval] val_mse=1.621e+00  (n=2997)
Epoch 00119: Time=   9.5s, Loss=3.67e+00, Inv=3.67e+00, For=3.50e+01, Power=5.90e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00120: Time=   9.5s, Loss=3.66e+00, Inv=3.66e+00, For=3.56e+01, Power=5.90e-01
  [eval] val_mse=1.614e+00  (n=2997)
Epoch 00121: Time=   9.6s, Loss=3.66e+00, Inv=3.66e+00, For=3.56e+01, Power=5.90e-01
  [eval] val_mse=1.616e+00  (n=2997)
Epoch 00122: Time=   9.6s, Loss=3.65e+00, Inv=3.65e+00, For=3.65e+01, Power=5.91e-01
  [eval] val_mse=1.605e+00  (n=2997)
Epoch 00123: Time=   9.6s, Loss=3.64e+00, Inv=3.64e+00, For=3.64e+01, Power=5.89e-01
  [eval] val_mse=1.611e+00  (n=2997)
Epoch 00124: Time=   9.7s, Loss=3.64e+00, Inv=3.64e+00, For=3.72e+01, Power=5.89e-01
  [eval] val_mse=1.611e+00  (n=2997)
Epoch 00125: Time=   9.7s, Loss=3.63e+00, Inv=3.63e+00, For=3.73e+01, Power=5.88e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00126: Time=   9.7s, Loss=3.62e+00, Inv=3.62e+00, For=3.77e+01, Power=5.88e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00127: Time=   9.8s, Loss=3.62e+00, Inv=3.62e+00, For=3.82e+01, Power=5.88e-01
  [eval] val_mse=1.611e+00  (n=2997)
Epoch 00128: Time=   9.8s, Loss=3.61e+00, Inv=3.61e+00, For=3.84e+01, Power=5.88e-01
  [eval] val_mse=1.602e+00  (n=2997)
Epoch 00129: Time=   9.8s, Loss=3.61e+00, Inv=3.61e+00, For=3.88e+01, Power=5.87e-01
  [eval] val_mse=1.611e+00  (n=2997)
Epoch 00130: Time=   9.9s, Loss=3.60e+00, Inv=3.60e+00, For=3.92e+01, Power=5.87e-01
  [eval] val_mse=1.616e+00  (n=2997)
Epoch 00131: Time=   9.9s, Loss=3.60e+00, Inv=3.60e+00, For=3.96e+01, Power=5.87e-01
  [eval] val_mse=1.619e+00  (n=2997)
Epoch 00132: Time=   9.9s, Loss=3.59e+00, Inv=3.59e+00, For=3.99e+01, Power=5.86e-01
  [eval] val_mse=1.608e+00  (n=2997)
Epoch 00133: Time=  10.0s, Loss=3.58e+00, Inv=3.58e+00, For=4.02e+01, Power=5.86e-01
  [eval] val_mse=1.626e+00  (n=2997)
Epoch 00134: Time=  10.0s, Loss=3.58e+00, Inv=3.58e+00, For=4.08e+01, Power=5.86e-01
  [eval] val_mse=1.630e+00  (n=2997)
Epoch 00135: Time=  10.1s, Loss=3.58e+00, Inv=3.58e+00, For=4.11e+01, Power=5.86e-01
  [eval] val_mse=1.629e+00  (n=2997)
Epoch 00136: Time=  10.1s, Loss=3.57e+00, Inv=3.57e+00, For=4.14e+01, Power=5.85e-01
  [eval] val_mse=1.632e+00  (n=2997)
Epoch 00137: Time=  10.1s, Loss=3.57e+00, Inv=3.57e+00, For=4.17e+01, Power=5.86e-01
  [eval] val_mse=1.633e+00  (n=2997)
Epoch 00138: Time=  10.2s, Loss=3.56e+00, Inv=3.56e+00, For=4.21e+01, Power=5.86e-01
  [eval] val_mse=1.646e+00  (n=2997)
  [early_stop] stop at epoch=138 (best_epoch=128, best_val_mse=1.602e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 5.167e-01
Torque MSE  = 1.251e-01
Torque RMSE = 3.537e-01
Per-joint MSE : 1.532e-01 3.244e-01 1.191e-01 6.117e-02 4.734e-02 4.536e-02
Per-joint RMSE: 3.914e-01 5.696e-01 3.451e-01 2.473e-01 2.176e-01 2.130e-01
Comp Time per Sample = 2.129e-04s / 4696.0Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-7r6q42qb because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x722bcf1de8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:57:26.740754: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:57:28.600555: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=1.71e+04, Inv=1.71e+04, For=5.80e+00, Power=9.83e+02
  [eval] val_mse=2.416e+02  (n=2997)
Epoch 00002: Time=   5.6s, Loss=2.62e+03, Inv=2.62e+03, For=5.70e+00, Power=2.33e+02
  [eval] val_mse=1.099e+02  (n=2997)
Epoch 00003: Time=   5.6s, Loss=1.09e+03, Inv=1.09e+03, For=5.61e+00, Power=1.22e+02
  [eval] val_mse=6.669e+01  (n=2997)
Epoch 00004: Time=   5.7s, Loss=6.22e+02, Inv=6.22e+02, For=5.51e+00, Power=7.50e+01
  [eval] val_mse=4.507e+01  (n=2997)
Epoch 00005: Time=   5.7s, Loss=4.06e+02, Inv=4.06e+02, For=5.43e+00, Power=5.03e+01
  [eval] val_mse=3.308e+01  (n=2997)
Epoch 00006: Time=   5.7s, Loss=2.85e+02, Inv=2.85e+02, For=5.33e+00, Power=3.58e+01
  [eval] val_mse=2.578e+01  (n=2997)
Epoch 00007: Time=   5.8s, Loss=2.12e+02, Inv=2.12e+02, For=5.27e+00, Power=2.67e+01
  [eval] val_mse=2.084e+01  (n=2997)
Epoch 00008: Time=   5.8s, Loss=1.64e+02, Inv=1.64e+02, For=5.18e+00, Power=2.04e+01
  [eval] val_mse=1.744e+01  (n=2997)
Epoch 00009: Time=   5.8s, Loss=1.31e+02, Inv=1.31e+02, For=5.13e+00, Power=1.62e+01
  [eval] val_mse=1.491e+01  (n=2997)
Epoch 00010: Time=   5.9s, Loss=1.07e+02, Inv=1.07e+02, For=5.07e+00, Power=1.31e+01
  [eval] val_mse=1.303e+01  (n=2997)
Epoch 00011: Time=   5.9s, Loss=8.91e+01, Inv=8.91e+01, For=5.02e+00, Power=1.08e+01
  [eval] val_mse=1.161e+01  (n=2997)
Epoch 00012: Time=   5.9s, Loss=7.54e+01, Inv=7.54e+01, For=4.98e+00, Power=8.96e+00
  [eval] val_mse=1.045e+01  (n=2997)
Epoch 00013: Time=   6.0s, Loss=6.49e+01, Inv=6.49e+01, For=4.96e+00, Power=7.62e+00
  [eval] val_mse=9.524e+00  (n=2997)
Epoch 00014: Time=   6.0s, Loss=5.65e+01, Inv=5.65e+01, For=4.95e+00, Power=6.54e+00
  [eval] val_mse=8.747e+00  (n=2997)
Epoch 00015: Time=   6.0s, Loss=4.96e+01, Inv=4.96e+01, For=4.94e+00, Power=5.66e+00
  [eval] val_mse=8.113e+00  (n=2997)
Epoch 00016: Time=   6.1s, Loss=4.41e+01, Inv=4.41e+01, For=4.95e+00, Power=4.95e+00
  [eval] val_mse=7.579e+00  (n=2997)
Epoch 00017: Time=   6.1s, Loss=3.94e+01, Inv=3.94e+01, For=4.96e+00, Power=4.38e+00
  [eval] val_mse=7.106e+00  (n=2997)
Epoch 00018: Time=   6.1s, Loss=3.55e+01, Inv=3.55e+01, For=4.97e+00, Power=3.91e+00
  [eval] val_mse=6.698e+00  (n=2997)
Epoch 00019: Time=   6.2s, Loss=3.22e+01, Inv=3.22e+01, For=5.00e+00, Power=3.50e+00
  [eval] val_mse=6.343e+00  (n=2997)
Epoch 00020: Time=   6.2s, Loss=2.93e+01, Inv=2.93e+01, For=5.03e+00, Power=3.15e+00
  [eval] val_mse=6.025e+00  (n=2997)
Epoch 00021: Time=   6.2s, Loss=2.68e+01, Inv=2.68e+01, For=5.06e+00, Power=2.87e+00
  [eval] val_mse=5.737e+00  (n=2997)
Epoch 00022: Time=   6.3s, Loss=2.47e+01, Inv=2.47e+01, For=5.10e+00, Power=2.62e+00
  [eval] val_mse=5.476e+00  (n=2997)
Epoch 00023: Time=   6.3s, Loss=2.29e+01, Inv=2.29e+01, For=5.15e+00, Power=2.41e+00
  [eval] val_mse=5.237e+00  (n=2997)
Epoch 00024: Time=   6.3s, Loss=2.12e+01, Inv=2.12e+01, For=5.20e+00, Power=2.23e+00
  [eval] val_mse=5.016e+00  (n=2997)
Epoch 00025: Time=   6.4s, Loss=1.98e+01, Inv=1.98e+01, For=5.25e+00, Power=2.07e+00
  [eval] val_mse=4.814e+00  (n=2997)
Epoch 00026: Time=   6.4s, Loss=1.85e+01, Inv=1.85e+01, For=5.30e+00, Power=1.93e+00
  [eval] val_mse=4.627e+00  (n=2997)
Epoch 00027: Time=   6.4s, Loss=1.73e+01, Inv=1.73e+01, For=5.34e+00, Power=1.81e+00
  [eval] val_mse=4.450e+00  (n=2997)
Epoch 00028: Time=   6.5s, Loss=1.63e+01, Inv=1.63e+01, For=5.40e+00, Power=1.69e+00
  [eval] val_mse=4.288e+00  (n=2997)
Epoch 00029: Time=   6.5s, Loss=1.53e+01, Inv=1.53e+01, For=5.46e+00, Power=1.60e+00
  [eval] val_mse=4.135e+00  (n=2997)
Epoch 00030: Time=   6.6s, Loss=1.45e+01, Inv=1.45e+01, For=5.52e+00, Power=1.52e+00
  [eval] val_mse=3.996e+00  (n=2997)
Epoch 00031: Time=   6.6s, Loss=1.37e+01, Inv=1.37e+01, For=5.57e+00, Power=1.44e+00
  [eval] val_mse=3.864e+00  (n=2997)
Epoch 00032: Time=   6.6s, Loss=1.30e+01, Inv=1.30e+01, For=5.64e+00, Power=1.37e+00
  [eval] val_mse=3.742e+00  (n=2997)
Epoch 00033: Time=   6.7s, Loss=1.24e+01, Inv=1.24e+01, For=5.71e+00, Power=1.30e+00
  [eval] val_mse=3.631e+00  (n=2997)
Epoch 00034: Time=   6.7s, Loss=1.18e+01, Inv=1.18e+01, For=5.77e+00, Power=1.25e+00
  [eval] val_mse=3.527e+00  (n=2997)
Epoch 00035: Time=   6.7s, Loss=1.13e+01, Inv=1.13e+01, For=5.85e+00, Power=1.20e+00
  [eval] val_mse=3.432e+00  (n=2997)
Epoch 00036: Time=   6.8s, Loss=1.09e+01, Inv=1.09e+01, For=5.93e+00, Power=1.15e+00
  [eval] val_mse=3.344e+00  (n=2997)
Epoch 00037: Time=   6.8s, Loss=1.04e+01, Inv=1.04e+01, For=6.01e+00, Power=1.11e+00
  [eval] val_mse=3.262e+00  (n=2997)
Epoch 00038: Time=   6.8s, Loss=1.00e+01, Inv=1.00e+01, For=6.10e+00, Power=1.07e+00
  [eval] val_mse=3.190e+00  (n=2997)
Epoch 00039: Time=   6.9s, Loss=9.65e+00, Inv=9.65e+00, For=6.18e+00, Power=1.04e+00
  [eval] val_mse=3.122e+00  (n=2997)
Epoch 00040: Time=   6.9s, Loss=9.33e+00, Inv=9.33e+00, For=6.30e+00, Power=1.01e+00
  [eval] val_mse=3.060e+00  (n=2997)
Epoch 00041: Time=   6.9s, Loss=9.03e+00, Inv=9.03e+00, For=6.39e+00, Power=9.83e-01
  [eval] val_mse=3.004e+00  (n=2997)
Epoch 00042: Time=   7.0s, Loss=8.74e+00, Inv=8.74e+00, For=6.50e+00, Power=9.56e-01
  [eval] val_mse=2.955e+00  (n=2997)
Epoch 00043: Time=   7.0s, Loss=8.48e+00, Inv=8.48e+00, For=6.62e+00, Power=9.33e-01
  [eval] val_mse=2.903e+00  (n=2997)
Epoch 00044: Time=   7.0s, Loss=8.25e+00, Inv=8.25e+00, For=6.75e+00, Power=9.12e-01
  [eval] val_mse=2.858e+00  (n=2997)
Epoch 00045: Time=   7.1s, Loss=8.01e+00, Inv=8.01e+00, For=6.87e+00, Power=8.91e-01
  [eval] val_mse=2.813e+00  (n=2997)
Epoch 00046: Time=   7.1s, Loss=7.80e+00, Inv=7.80e+00, For=7.00e+00, Power=8.74e-01
  [eval] val_mse=2.768e+00  (n=2997)
Epoch 00047: Time=   7.1s, Loss=7.61e+00, Inv=7.61e+00, For=7.14e+00, Power=8.58e-01
  [eval] val_mse=2.728e+00  (n=2997)
Epoch 00048: Time=   7.2s, Loss=7.43e+00, Inv=7.43e+00, For=7.28e+00, Power=8.43e-01
  [eval] val_mse=2.692e+00  (n=2997)
Epoch 00049: Time=   7.2s, Loss=7.27e+00, Inv=7.27e+00, For=7.42e+00, Power=8.29e-01
  [eval] val_mse=2.653e+00  (n=2997)
Epoch 00050: Time=   7.2s, Loss=7.10e+00, Inv=7.10e+00, For=7.57e+00, Power=8.16e-01
  [eval] val_mse=2.617e+00  (n=2997)
Epoch 00051: Time=   7.3s, Loss=6.96e+00, Inv=6.96e+00, For=7.74e+00, Power=8.04e-01
  [eval] val_mse=2.584e+00  (n=2997)
Epoch 00052: Time=   7.3s, Loss=6.82e+00, Inv=6.82e+00, For=7.89e+00, Power=7.93e-01
  [eval] val_mse=2.553e+00  (n=2997)
Epoch 00053: Time=   7.3s, Loss=6.68e+00, Inv=6.68e+00, For=8.06e+00, Power=7.83e-01
  [eval] val_mse=2.515e+00  (n=2997)
Epoch 00054: Time=   7.4s, Loss=6.56e+00, Inv=6.56e+00, For=8.22e+00, Power=7.72e-01
  [eval] val_mse=2.486e+00  (n=2997)
Epoch 00055: Time=   7.4s, Loss=6.44e+00, Inv=6.44e+00, For=8.39e+00, Power=7.64e-01
  [eval] val_mse=2.456e+00  (n=2997)
Epoch 00056: Time=   7.4s, Loss=6.33e+00, Inv=6.33e+00, For=8.57e+00, Power=7.57e-01
  [eval] val_mse=2.424e+00  (n=2997)
Epoch 00057: Time=   7.5s, Loss=6.23e+00, Inv=6.23e+00, For=8.73e+00, Power=7.48e-01
  [eval] val_mse=2.392e+00  (n=2997)
Epoch 00058: Time=   7.5s, Loss=6.13e+00, Inv=6.13e+00, For=8.91e+00, Power=7.41e-01
  [eval] val_mse=2.364e+00  (n=2997)
Epoch 00059: Time=   7.5s, Loss=6.03e+00, Inv=6.03e+00, For=9.10e+00, Power=7.34e-01
  [eval] val_mse=2.335e+00  (n=2997)
Epoch 00060: Time=   7.6s, Loss=5.94e+00, Inv=5.94e+00, For=9.27e+00, Power=7.28e-01
  [eval] val_mse=2.308e+00  (n=2997)
Epoch 00061: Time=   7.6s, Loss=5.86e+00, Inv=5.86e+00, For=9.46e+00, Power=7.23e-01
  [eval] val_mse=2.285e+00  (n=2997)
Epoch 00062: Time=   7.6s, Loss=5.78e+00, Inv=5.78e+00, For=9.64e+00, Power=7.17e-01
  [eval] val_mse=2.255e+00  (n=2997)
Epoch 00063: Time=   7.7s, Loss=5.70e+00, Inv=5.70e+00, For=9.83e+00, Power=7.11e-01
  [eval] val_mse=2.232e+00  (n=2997)
Epoch 00064: Time=   7.7s, Loss=5.62e+00, Inv=5.62e+00, For=1.00e+01, Power=7.06e-01
  [eval] val_mse=2.205e+00  (n=2997)
Epoch 00065: Time=   7.8s, Loss=5.55e+00, Inv=5.55e+00, For=1.02e+01, Power=7.02e-01
  [eval] val_mse=2.187e+00  (n=2997)
Epoch 00066: Time=   7.8s, Loss=5.49e+00, Inv=5.49e+00, For=1.04e+01, Power=6.97e-01
  [eval] val_mse=2.159e+00  (n=2997)
Epoch 00067: Time=   7.8s, Loss=5.42e+00, Inv=5.42e+00, For=1.06e+01, Power=6.92e-01
  [eval] val_mse=2.137e+00  (n=2997)
Epoch 00068: Time=   7.9s, Loss=5.36e+00, Inv=5.36e+00, For=1.08e+01, Power=6.89e-01
  [eval] val_mse=2.115e+00  (n=2997)
Epoch 00069: Time=   7.9s, Loss=5.30e+00, Inv=5.30e+00, For=1.10e+01, Power=6.85e-01
  [eval] val_mse=2.092e+00  (n=2997)
Epoch 00070: Time=   7.9s, Loss=5.24e+00, Inv=5.24e+00, For=1.12e+01, Power=6.82e-01
  [eval] val_mse=2.075e+00  (n=2997)
Epoch 00071: Time=   8.0s, Loss=5.19e+00, Inv=5.19e+00, For=1.14e+01, Power=6.78e-01
  [eval] val_mse=2.053e+00  (n=2997)
Epoch 00072: Time=   8.0s, Loss=5.13e+00, Inv=5.13e+00, For=1.16e+01, Power=6.76e-01
  [eval] val_mse=2.031e+00  (n=2997)
Epoch 00073: Time=   8.0s, Loss=5.09e+00, Inv=5.09e+00, For=1.18e+01, Power=6.73e-01
  [eval] val_mse=2.019e+00  (n=2997)
Epoch 00074: Time=   8.1s, Loss=5.03e+00, Inv=5.03e+00, For=1.20e+01, Power=6.69e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00075: Time=   8.1s, Loss=4.99e+00, Inv=4.99e+00, For=1.22e+01, Power=6.65e-01
  [eval] val_mse=1.982e+00  (n=2997)
Epoch 00076: Time=   8.1s, Loss=4.95e+00, Inv=4.95e+00, For=1.25e+01, Power=6.64e-01
  [eval] val_mse=1.963e+00  (n=2997)
Epoch 00077: Time=   8.2s, Loss=4.90e+00, Inv=4.90e+00, For=1.26e+01, Power=6.61e-01
  [eval] val_mse=1.943e+00  (n=2997)
Epoch 00078: Time=   8.2s, Loss=4.86e+00, Inv=4.86e+00, For=1.29e+01, Power=6.59e-01
  [eval] val_mse=1.924e+00  (n=2997)
Epoch 00079: Time=   8.2s, Loss=4.82e+00, Inv=4.82e+00, For=1.31e+01, Power=6.55e-01
  [eval] val_mse=1.911e+00  (n=2997)
Epoch 00080: Time=   8.3s, Loss=4.78e+00, Inv=4.78e+00, For=1.33e+01, Power=6.54e-01
  [eval] val_mse=1.895e+00  (n=2997)
Epoch 00081: Time=   8.3s, Loss=4.74e+00, Inv=4.74e+00, For=1.35e+01, Power=6.52e-01
  [eval] val_mse=1.879e+00  (n=2997)
Epoch 00082: Time=   8.3s, Loss=4.70e+00, Inv=4.70e+00, For=1.37e+01, Power=6.50e-01
  [eval] val_mse=1.863e+00  (n=2997)
Epoch 00083: Time=   8.4s, Loss=4.67e+00, Inv=4.67e+00, For=1.39e+01, Power=6.48e-01
  [eval] val_mse=1.849e+00  (n=2997)
Epoch 00084: Time=   8.4s, Loss=4.64e+00, Inv=4.64e+00, For=1.41e+01, Power=6.46e-01
  [eval] val_mse=1.836e+00  (n=2997)
Epoch 00085: Time=   8.4s, Loss=4.60e+00, Inv=4.60e+00, For=1.44e+01, Power=6.45e-01
  [eval] val_mse=1.822e+00  (n=2997)
Epoch 00086: Time=   8.5s, Loss=4.57e+00, Inv=4.57e+00, For=1.46e+01, Power=6.43e-01
  [eval] val_mse=1.812e+00  (n=2997)
Epoch 00087: Time=   8.5s, Loss=4.54e+00, Inv=4.54e+00, For=1.48e+01, Power=6.41e-01
  [eval] val_mse=1.804e+00  (n=2997)
Epoch 00088: Time=   8.5s, Loss=4.51e+00, Inv=4.51e+00, For=1.51e+01, Power=6.39e-01
  [eval] val_mse=1.782e+00  (n=2997)
Epoch 00089: Time=   8.6s, Loss=4.48e+00, Inv=4.48e+00, For=1.53e+01, Power=6.37e-01
  [eval] val_mse=1.773e+00  (n=2997)
Epoch 00090: Time=   8.6s, Loss=4.45e+00, Inv=4.45e+00, For=1.55e+01, Power=6.36e-01
  [eval] val_mse=1.761e+00  (n=2997)
Epoch 00091: Time=   8.6s, Loss=4.43e+00, Inv=4.43e+00, For=1.57e+01, Power=6.34e-01
  [eval] val_mse=1.750e+00  (n=2997)
Epoch 00092: Time=   8.7s, Loss=4.39e+00, Inv=4.39e+00, For=1.60e+01, Power=6.33e-01
  [eval] val_mse=1.737e+00  (n=2997)
Epoch 00093: Time=   8.7s, Loss=4.37e+00, Inv=4.37e+00, For=1.62e+01, Power=6.30e-01
  [eval] val_mse=1.732e+00  (n=2997)
Epoch 00094: Time=   8.8s, Loss=4.35e+00, Inv=4.35e+00, For=1.64e+01, Power=6.29e-01
  [eval] val_mse=1.713e+00  (n=2997)
Epoch 00095: Time=   8.8s, Loss=4.32e+00, Inv=4.32e+00, For=1.66e+01, Power=6.28e-01
  [eval] val_mse=1.712e+00  (n=2997)
Epoch 00096: Time=   8.8s, Loss=4.30e+00, Inv=4.30e+00, For=1.68e+01, Power=6.28e-01
  [eval] val_mse=1.709e+00  (n=2997)
Epoch 00097: Time=   8.9s, Loss=4.28e+00, Inv=4.28e+00, For=1.71e+01, Power=6.26e-01
  [eval] val_mse=1.692e+00  (n=2997)
Epoch 00098: Time=   8.9s, Loss=4.26e+00, Inv=4.26e+00, For=1.73e+01, Power=6.26e-01
  [eval] val_mse=1.684e+00  (n=2997)
Epoch 00099: Time=   8.9s, Loss=4.23e+00, Inv=4.23e+00, For=1.75e+01, Power=6.23e-01
  [eval] val_mse=1.679e+00  (n=2997)
Epoch 00100: Time=   9.0s, Loss=4.21e+00, Inv=4.21e+00, For=1.77e+01, Power=6.23e-01
  [eval] val_mse=1.667e+00  (n=2997)
Epoch 00101: Time=   9.0s, Loss=4.19e+00, Inv=4.19e+00, For=1.80e+01, Power=6.21e-01
  [eval] val_mse=1.670e+00  (n=2997)
Epoch 00102: Time=   9.0s, Loss=4.17e+00, Inv=4.17e+00, For=1.82e+01, Power=6.20e-01
  [eval] val_mse=1.661e+00  (n=2997)
Epoch 00103: Time=   9.1s, Loss=4.15e+00, Inv=4.15e+00, For=1.84e+01, Power=6.19e-01
  [eval] val_mse=1.642e+00  (n=2997)
Epoch 00104: Time=   9.1s, Loss=4.13e+00, Inv=4.13e+00, For=1.86e+01, Power=6.18e-01
  [eval] val_mse=1.644e+00  (n=2997)
Epoch 00105: Time=   9.1s, Loss=4.11e+00, Inv=4.11e+00, For=1.89e+01, Power=6.16e-01
  [eval] val_mse=1.634e+00  (n=2997)
Epoch 00106: Time=   9.2s, Loss=4.10e+00, Inv=4.10e+00, For=1.91e+01, Power=6.15e-01
  [eval] val_mse=1.632e+00  (n=2997)
Epoch 00107: Time=   9.2s, Loss=4.08e+00, Inv=4.08e+00, For=1.93e+01, Power=6.14e-01
  [eval] val_mse=1.628e+00  (n=2997)
Epoch 00108: Time=   9.2s, Loss=4.06e+00, Inv=4.06e+00, For=1.96e+01, Power=6.14e-01
  [eval] val_mse=1.629e+00  (n=2997)
Epoch 00109: Time=   9.3s, Loss=4.04e+00, Inv=4.04e+00, For=1.98e+01, Power=6.13e-01
  [eval] val_mse=1.621e+00  (n=2997)
Epoch 00110: Time=   9.3s, Loss=4.03e+00, Inv=4.03e+00, For=2.01e+01, Power=6.12e-01
  [eval] val_mse=1.615e+00  (n=2997)
Epoch 00111: Time=   9.3s, Loss=4.02e+00, Inv=4.02e+00, For=2.03e+01, Power=6.11e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00112: Time=   9.4s, Loss=4.00e+00, Inv=4.00e+00, For=2.05e+01, Power=6.10e-01
  [eval] val_mse=1.617e+00  (n=2997)
Epoch 00113: Time=   9.4s, Loss=3.98e+00, Inv=3.98e+00, For=2.08e+01, Power=6.09e-01
  [eval] val_mse=1.602e+00  (n=2997)
Epoch 00114: Time=   9.4s, Loss=3.97e+00, Inv=3.97e+00, For=2.10e+01, Power=6.08e-01
  [eval] val_mse=1.599e+00  (n=2997)
Epoch 00115: Time=   9.5s, Loss=3.96e+00, Inv=3.96e+00, For=2.12e+01, Power=6.08e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00116: Time=   9.5s, Loss=3.94e+00, Inv=3.94e+00, For=2.14e+01, Power=6.07e-01
  [eval] val_mse=1.603e+00  (n=2997)
Epoch 00117: Time=   9.5s, Loss=3.93e+00, Inv=3.93e+00, For=2.17e+01, Power=6.06e-01
  [eval] val_mse=1.599e+00  (n=2997)
Epoch 00118: Time=   9.6s, Loss=3.92e+00, Inv=3.92e+00, For=2.19e+01, Power=6.04e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00119: Time=   9.6s, Loss=3.90e+00, Inv=3.90e+00, For=2.22e+01, Power=6.04e-01
  [eval] val_mse=1.588e+00  (n=2997)
Epoch 00120: Time=   9.6s, Loss=3.89e+00, Inv=3.89e+00, For=2.24e+01, Power=6.04e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00121: Time=   9.7s, Loss=3.88e+00, Inv=3.88e+00, For=2.26e+01, Power=6.03e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00122: Time=   9.7s, Loss=3.87e+00, Inv=3.87e+00, For=2.29e+01, Power=6.02e-01
  [eval] val_mse=1.593e+00  (n=2997)
Epoch 00123: Time=   9.7s, Loss=3.86e+00, Inv=3.86e+00, For=2.32e+01, Power=6.02e-01
  [eval] val_mse=1.588e+00  (n=2997)
Epoch 00124: Time=   9.8s, Loss=3.84e+00, Inv=3.84e+00, For=2.34e+01, Power=6.02e-01
  [eval] val_mse=1.583e+00  (n=2997)
Epoch 00125: Time=   9.8s, Loss=3.83e+00, Inv=3.83e+00, For=2.37e+01, Power=6.02e-01
  [eval] val_mse=1.598e+00  (n=2997)
Epoch 00126: Time=   9.9s, Loss=3.82e+00, Inv=3.82e+00, For=2.38e+01, Power=6.00e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00127: Time=   9.9s, Loss=3.82e+00, Inv=3.82e+00, For=2.41e+01, Power=6.01e-01
  [eval] val_mse=1.611e+00  (n=2997)
Epoch 00128: Time=   9.9s, Loss=3.80e+00, Inv=3.80e+00, For=2.44e+01, Power=5.99e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00129: Time=  10.0s, Loss=3.79e+00, Inv=3.79e+00, For=2.46e+01, Power=5.98e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00130: Time=  10.0s, Loss=3.79e+00, Inv=3.79e+00, For=2.48e+01, Power=5.99e-01
  [eval] val_mse=1.604e+00  (n=2997)
Epoch 00131: Time=  10.0s, Loss=3.78e+00, Inv=3.78e+00, For=2.51e+01, Power=5.98e-01
  [eval] val_mse=1.607e+00  (n=2997)
Epoch 00132: Time=  10.1s, Loss=3.77e+00, Inv=3.77e+00, For=2.54e+01, Power=5.97e-01
  [eval] val_mse=1.608e+00  (n=2997)
Epoch 00133: Time=  10.1s, Loss=3.76e+00, Inv=3.76e+00, For=2.55e+01, Power=5.97e-01
  [eval] val_mse=1.609e+00  (n=2997)
Epoch 00134: Time=  10.1s, Loss=3.75e+00, Inv=3.75e+00, For=2.58e+01, Power=5.96e-01
  [eval] val_mse=1.613e+00  (n=2997)
  [early_stop] stop at epoch=134 (best_epoch=124, best_val_mse=1.583e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 5.136e-01
Torque MSE  = 1.240e-01
Torque RMSE = 3.521e-01
Per-joint MSE : 1.668e-01 2.748e-01 1.292e-01 7.103e-02 5.236e-02 4.985e-02
Per-joint RMSE: 4.084e-01 5.242e-01 3.594e-01 2.665e-01 2.288e-01 2.233e-01
Comp Time per Sample = 1.892e-04s / 5285.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-ycgxabik because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x735c4e2968c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:57:46.663381: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:57:48.456849: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.2s, Loss=2.06e+04, Inv=2.06e+04, For=5.86e+00, Power=1.96e+03
  [eval] val_mse=5.494e+02  (n=2997)
Epoch 00002: Time=   5.5s, Loss=4.18e+03, Inv=4.18e+03, For=5.77e+00, Power=5.24e+02
  [eval] val_mse=2.180e+02  (n=2997)
Epoch 00003: Time=   5.5s, Loss=1.77e+03, Inv=1.77e+03, For=5.71e+00, Power=2.47e+02
  [eval] val_mse=1.157e+02  (n=2997)
Epoch 00004: Time=   5.5s, Loss=9.88e+02, Inv=9.88e+02, For=5.66e+00, Power=1.47e+02
  [eval] val_mse=7.214e+01  (n=2997)
Epoch 00005: Time=   5.6s, Loss=6.27e+02, Inv=6.27e+02, For=5.60e+00, Power=9.66e+01
  [eval] val_mse=4.941e+01  (n=2997)
Epoch 00006: Time=   5.6s, Loss=4.32e+02, Inv=4.32e+02, For=5.53e+00, Power=6.67e+01
  [eval] val_mse=3.598e+01  (n=2997)
Epoch 00007: Time=   5.7s, Loss=3.15e+02, Inv=3.15e+02, For=5.48e+00, Power=4.86e+01
  [eval] val_mse=2.743e+01  (n=2997)
Epoch 00008: Time=   5.7s, Loss=2.40e+02, Inv=2.40e+02, For=5.43e+00, Power=3.67e+01
  [eval] val_mse=2.179e+01  (n=2997)
Epoch 00009: Time=   5.7s, Loss=1.88e+02, Inv=1.88e+02, For=5.40e+00, Power=2.84e+01
  [eval] val_mse=1.784e+01  (n=2997)
Epoch 00010: Time=   5.8s, Loss=1.52e+02, Inv=1.52e+02, For=5.36e+00, Power=2.25e+01
  [eval] val_mse=1.501e+01  (n=2997)
Epoch 00011: Time=   5.8s, Loss=1.24e+02, Inv=1.24e+02, For=5.32e+00, Power=1.82e+01
  [eval] val_mse=1.286e+01  (n=2997)
Epoch 00012: Time=   5.8s, Loss=1.04e+02, Inv=1.04e+02, For=5.30e+00, Power=1.50e+01
  [eval] val_mse=1.123e+01  (n=2997)
Epoch 00013: Time=   5.9s, Loss=8.84e+01, Inv=8.84e+01, For=5.29e+00, Power=1.26e+01
  [eval] val_mse=9.964e+00  (n=2997)
Epoch 00014: Time=   5.9s, Loss=7.61e+01, Inv=7.61e+01, For=5.28e+00, Power=1.06e+01
  [eval] val_mse=8.948e+00  (n=2997)
Epoch 00015: Time=   5.9s, Loss=6.62e+01, Inv=6.62e+01, For=5.30e+00, Power=9.16e+00
  [eval] val_mse=8.115e+00  (n=2997)
Epoch 00016: Time=   6.0s, Loss=5.81e+01, Inv=5.81e+01, For=5.31e+00, Power=7.93e+00
  [eval] val_mse=7.437e+00  (n=2997)
Epoch 00017: Time=   6.0s, Loss=5.15e+01, Inv=5.15e+01, For=5.34e+00, Power=6.93e+00
  [eval] val_mse=6.859e+00  (n=2997)
Epoch 00018: Time=   6.0s, Loss=4.59e+01, Inv=4.59e+01, For=5.36e+00, Power=6.12e+00
  [eval] val_mse=6.366e+00  (n=2997)
Epoch 00019: Time=   6.1s, Loss=4.13e+01, Inv=4.13e+01, For=5.41e+00, Power=5.44e+00
  [eval] val_mse=5.946e+00  (n=2997)
Epoch 00020: Time=   6.1s, Loss=3.73e+01, Inv=3.73e+01, For=5.45e+00, Power=4.87e+00
  [eval] val_mse=5.577e+00  (n=2997)
Epoch 00021: Time=   6.1s, Loss=3.39e+01, Inv=3.39e+01, For=5.50e+00, Power=4.39e+00
  [eval] val_mse=5.249e+00  (n=2997)
Epoch 00022: Time=   6.2s, Loss=3.09e+01, Inv=3.09e+01, For=5.56e+00, Power=3.99e+00
  [eval] val_mse=4.963e+00  (n=2997)
Epoch 00023: Time=   6.2s, Loss=2.83e+01, Inv=2.83e+01, For=5.62e+00, Power=3.62e+00
  [eval] val_mse=4.703e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=2.61e+01, Inv=2.61e+01, For=5.69e+00, Power=3.32e+00
  [eval] val_mse=4.469e+00  (n=2997)
Epoch 00025: Time=   6.3s, Loss=2.42e+01, Inv=2.42e+01, For=5.78e+00, Power=3.05e+00
  [eval] val_mse=4.260e+00  (n=2997)
Epoch 00026: Time=   6.3s, Loss=2.24e+01, Inv=2.24e+01, For=5.86e+00, Power=2.82e+00
  [eval] val_mse=4.066e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=2.08e+01, Inv=2.08e+01, For=5.95e+00, Power=2.62e+00
  [eval] val_mse=3.896e+00  (n=2997)
Epoch 00028: Time=   6.4s, Loss=1.95e+01, Inv=1.95e+01, For=6.06e+00, Power=2.44e+00
  [eval] val_mse=3.746e+00  (n=2997)
Epoch 00029: Time=   6.4s, Loss=1.82e+01, Inv=1.82e+01, For=6.15e+00, Power=2.27e+00
  [eval] val_mse=3.612e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=1.71e+01, Inv=1.71e+01, For=6.28e+00, Power=2.14e+00
  [eval] val_mse=3.484e+00  (n=2997)
Epoch 00031: Time=   6.5s, Loss=1.61e+01, Inv=1.61e+01, For=6.40e+00, Power=2.00e+00
  [eval] val_mse=3.373e+00  (n=2997)
Epoch 00032: Time=   6.5s, Loss=1.52e+01, Inv=1.52e+01, For=6.53e+00, Power=1.89e+00
  [eval] val_mse=3.276e+00  (n=2997)
Epoch 00033: Time=   6.6s, Loss=1.44e+01, Inv=1.44e+01, For=6.68e+00, Power=1.79e+00
  [eval] val_mse=3.188e+00  (n=2997)
Epoch 00034: Time=   6.6s, Loss=1.37e+01, Inv=1.37e+01, For=6.83e+00, Power=1.70e+00
  [eval] val_mse=3.108e+00  (n=2997)
Epoch 00035: Time=   6.6s, Loss=1.30e+01, Inv=1.30e+01, For=6.98e+00, Power=1.62e+00
  [eval] val_mse=3.042e+00  (n=2997)
Epoch 00036: Time=   6.7s, Loss=1.24e+01, Inv=1.24e+01, For=7.17e+00, Power=1.54e+00
  [eval] val_mse=2.980e+00  (n=2997)
Epoch 00037: Time=   6.7s, Loss=1.19e+01, Inv=1.19e+01, For=7.34e+00, Power=1.47e+00
  [eval] val_mse=2.922e+00  (n=2997)
Epoch 00038: Time=   6.7s, Loss=1.14e+01, Inv=1.14e+01, For=7.54e+00, Power=1.41e+00
  [eval] val_mse=2.875e+00  (n=2997)
Epoch 00039: Time=   6.8s, Loss=1.09e+01, Inv=1.09e+01, For=7.71e+00, Power=1.36e+00
  [eval] val_mse=2.828e+00  (n=2997)
Epoch 00040: Time=   6.8s, Loss=1.05e+01, Inv=1.05e+01, For=7.94e+00, Power=1.30e+00
  [eval] val_mse=2.785e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=1.01e+01, Inv=1.01e+01, For=8.14e+00, Power=1.26e+00
  [eval] val_mse=2.751e+00  (n=2997)
Epoch 00042: Time=   6.9s, Loss=9.77e+00, Inv=9.77e+00, For=8.35e+00, Power=1.21e+00
  [eval] val_mse=2.718e+00  (n=2997)
Epoch 00043: Time=   6.9s, Loss=9.43e+00, Inv=9.43e+00, For=8.56e+00, Power=1.17e+00
  [eval] val_mse=2.688e+00  (n=2997)
Epoch 00044: Time=   7.0s, Loss=9.13e+00, Inv=9.13e+00, For=8.82e+00, Power=1.14e+00
  [eval] val_mse=2.651e+00  (n=2997)
Epoch 00045: Time=   7.0s, Loss=8.84e+00, Inv=8.84e+00, For=9.02e+00, Power=1.10e+00
  [eval] val_mse=2.619e+00  (n=2997)
Epoch 00046: Time=   7.0s, Loss=8.58e+00, Inv=8.58e+00, For=9.27e+00, Power=1.07e+00
  [eval] val_mse=2.600e+00  (n=2997)
Epoch 00047: Time=   7.1s, Loss=8.33e+00, Inv=8.33e+00, For=9.48e+00, Power=1.04e+00
  [eval] val_mse=2.570e+00  (n=2997)
Epoch 00048: Time=   7.1s, Loss=8.10e+00, Inv=8.10e+00, For=9.73e+00, Power=1.02e+00
  [eval] val_mse=2.545e+00  (n=2997)
Epoch 00049: Time=   7.1s, Loss=7.88e+00, Inv=7.88e+00, For=9.95e+00, Power=9.95e-01
  [eval] val_mse=2.519e+00  (n=2997)
Epoch 00050: Time=   7.2s, Loss=7.68e+00, Inv=7.68e+00, For=1.03e+01, Power=9.71e-01
  [eval] val_mse=2.496e+00  (n=2997)
Epoch 00051: Time=   7.2s, Loss=7.50e+00, Inv=7.50e+00, For=1.05e+01, Power=9.51e-01
  [eval] val_mse=2.470e+00  (n=2997)
Epoch 00052: Time=   7.2s, Loss=7.32e+00, Inv=7.32e+00, For=1.07e+01, Power=9.31e-01
  [eval] val_mse=2.447e+00  (n=2997)
Epoch 00053: Time=   7.3s, Loss=7.15e+00, Inv=7.15e+00, For=1.10e+01, Power=9.12e-01
  [eval] val_mse=2.427e+00  (n=2997)
Epoch 00054: Time=   7.3s, Loss=6.99e+00, Inv=6.99e+00, For=1.12e+01, Power=8.96e-01
  [eval] val_mse=2.405e+00  (n=2997)
Epoch 00055: Time=   7.4s, Loss=6.84e+00, Inv=6.84e+00, For=1.15e+01, Power=8.79e-01
  [eval] val_mse=2.388e+00  (n=2997)
Epoch 00056: Time=   7.4s, Loss=6.70e+00, Inv=6.70e+00, For=1.18e+01, Power=8.64e-01
  [eval] val_mse=2.367e+00  (n=2997)
Epoch 00057: Time=   7.4s, Loss=6.57e+00, Inv=6.57e+00, For=1.20e+01, Power=8.50e-01
  [eval] val_mse=2.336e+00  (n=2997)
Epoch 00058: Time=   7.5s, Loss=6.44e+00, Inv=6.44e+00, For=1.23e+01, Power=8.37e-01
  [eval] val_mse=2.326e+00  (n=2997)
Epoch 00059: Time=   7.5s, Loss=6.33e+00, Inv=6.33e+00, For=1.26e+01, Power=8.26e-01
  [eval] val_mse=2.312e+00  (n=2997)
Epoch 00060: Time=   7.5s, Loss=6.21e+00, Inv=6.21e+00, For=1.29e+01, Power=8.12e-01
  [eval] val_mse=2.288e+00  (n=2997)
Epoch 00061: Time=   7.6s, Loss=6.10e+00, Inv=6.10e+00, For=1.31e+01, Power=8.02e-01
  [eval] val_mse=2.278e+00  (n=2997)
Epoch 00062: Time=   7.6s, Loss=6.00e+00, Inv=6.00e+00, For=1.34e+01, Power=7.92e-01
  [eval] val_mse=2.263e+00  (n=2997)
Epoch 00063: Time=   7.6s, Loss=5.90e+00, Inv=5.90e+00, For=1.37e+01, Power=7.83e-01
  [eval] val_mse=2.241e+00  (n=2997)
Epoch 00064: Time=   7.7s, Loss=5.81e+00, Inv=5.81e+00, For=1.39e+01, Power=7.73e-01
  [eval] val_mse=2.231e+00  (n=2997)
Epoch 00065: Time=   7.7s, Loss=5.72e+00, Inv=5.72e+00, For=1.42e+01, Power=7.66e-01
  [eval] val_mse=2.219e+00  (n=2997)
Epoch 00066: Time=   7.7s, Loss=5.64e+00, Inv=5.64e+00, For=1.45e+01, Power=7.57e-01
  [eval] val_mse=2.205e+00  (n=2997)
Epoch 00067: Time=   7.8s, Loss=5.56e+00, Inv=5.56e+00, For=1.48e+01, Power=7.49e-01
  [eval] val_mse=2.191e+00  (n=2997)
Epoch 00068: Time=   7.8s, Loss=5.49e+00, Inv=5.49e+00, For=1.51e+01, Power=7.42e-01
  [eval] val_mse=2.183e+00  (n=2997)
Epoch 00069: Time=   7.8s, Loss=5.41e+00, Inv=5.41e+00, For=1.54e+01, Power=7.35e-01
  [eval] val_mse=2.163e+00  (n=2997)
Epoch 00070: Time=   7.9s, Loss=5.34e+00, Inv=5.34e+00, For=1.57e+01, Power=7.29e-01
  [eval] val_mse=2.165e+00  (n=2997)
Epoch 00071: Time=   7.9s, Loss=5.28e+00, Inv=5.28e+00, For=1.59e+01, Power=7.23e-01
  [eval] val_mse=2.152e+00  (n=2997)
Epoch 00072: Time=   7.9s, Loss=5.21e+00, Inv=5.21e+00, For=1.61e+01, Power=7.16e-01
  [eval] val_mse=2.143e+00  (n=2997)
Epoch 00073: Time=   8.0s, Loss=5.15e+00, Inv=5.15e+00, For=1.65e+01, Power=7.11e-01
  [eval] val_mse=2.126e+00  (n=2997)
Epoch 00074: Time=   8.0s, Loss=5.10e+00, Inv=5.10e+00, For=1.67e+01, Power=7.05e-01
  [eval] val_mse=2.123e+00  (n=2997)
Epoch 00075: Time=   8.1s, Loss=5.04e+00, Inv=5.04e+00, For=1.72e+01, Power=7.00e-01
  [eval] val_mse=2.117e+00  (n=2997)
Epoch 00076: Time=   8.1s, Loss=4.99e+00, Inv=4.99e+00, For=1.73e+01, Power=6.95e-01
  [eval] val_mse=2.098e+00  (n=2997)
Epoch 00077: Time=   8.1s, Loss=4.94e+00, Inv=4.94e+00, For=1.76e+01, Power=6.92e-01
  [eval] val_mse=2.094e+00  (n=2997)
Epoch 00078: Time=   8.2s, Loss=4.89e+00, Inv=4.89e+00, For=1.80e+01, Power=6.86e-01
  [eval] val_mse=2.087e+00  (n=2997)
Epoch 00079: Time=   8.2s, Loss=4.84e+00, Inv=4.84e+00, For=1.82e+01, Power=6.82e-01
  [eval] val_mse=2.081e+00  (n=2997)
Epoch 00080: Time=   8.2s, Loss=4.80e+00, Inv=4.80e+00, For=1.85e+01, Power=6.78e-01
  [eval] val_mse=2.065e+00  (n=2997)
Epoch 00081: Time=   8.3s, Loss=4.75e+00, Inv=4.75e+00, For=1.88e+01, Power=6.74e-01
  [eval] val_mse=2.059e+00  (n=2997)
Epoch 00082: Time=   8.3s, Loss=4.71e+00, Inv=4.71e+00, For=1.91e+01, Power=6.71e-01
  [eval] val_mse=2.058e+00  (n=2997)
Epoch 00083: Time=   8.3s, Loss=4.67e+00, Inv=4.67e+00, For=1.93e+01, Power=6.68e-01
  [eval] val_mse=2.048e+00  (n=2997)
Epoch 00084: Time=   8.4s, Loss=4.63e+00, Inv=4.63e+00, For=1.97e+01, Power=6.64e-01
  [eval] val_mse=2.051e+00  (n=2997)
Epoch 00085: Time=   8.4s, Loss=4.59e+00, Inv=4.59e+00, For=1.99e+01, Power=6.61e-01
  [eval] val_mse=2.042e+00  (n=2997)
Epoch 00086: Time=   8.5s, Loss=4.55e+00, Inv=4.55e+00, For=2.02e+01, Power=6.58e-01
  [eval] val_mse=2.040e+00  (n=2997)
Epoch 00087: Time=   8.5s, Loss=4.52e+00, Inv=4.52e+00, For=2.05e+01, Power=6.55e-01
  [eval] val_mse=2.038e+00  (n=2997)
Epoch 00088: Time=   8.5s, Loss=4.49e+00, Inv=4.49e+00, For=2.06e+01, Power=6.52e-01
  [eval] val_mse=2.024e+00  (n=2997)
Epoch 00089: Time=   8.6s, Loss=4.46e+00, Inv=4.46e+00, For=2.12e+01, Power=6.49e-01
  [eval] val_mse=2.030e+00  (n=2997)
Epoch 00090: Time=   8.6s, Loss=4.43e+00, Inv=4.43e+00, For=2.14e+01, Power=6.47e-01
  [eval] val_mse=2.018e+00  (n=2997)
Epoch 00091: Time=   8.6s, Loss=4.40e+00, Inv=4.40e+00, For=2.16e+01, Power=6.45e-01
  [eval] val_mse=2.027e+00  (n=2997)
Epoch 00092: Time=   8.7s, Loss=4.37e+00, Inv=4.37e+00, For=2.20e+01, Power=6.42e-01
  [eval] val_mse=2.018e+00  (n=2997)
Epoch 00093: Time=   8.7s, Loss=4.34e+00, Inv=4.34e+00, For=2.22e+01, Power=6.39e-01
  [eval] val_mse=2.019e+00  (n=2997)
Epoch 00094: Time=   8.7s, Loss=4.31e+00, Inv=4.31e+00, For=2.24e+01, Power=6.38e-01
  [eval] val_mse=2.007e+00  (n=2997)
Epoch 00095: Time=   8.8s, Loss=4.29e+00, Inv=4.29e+00, For=2.28e+01, Power=6.35e-01
  [eval] val_mse=2.007e+00  (n=2997)
Epoch 00096: Time=   8.8s, Loss=4.26e+00, Inv=4.26e+00, For=2.31e+01, Power=6.33e-01
  [eval] val_mse=2.002e+00  (n=2997)
Epoch 00097: Time=   8.9s, Loss=4.24e+00, Inv=4.24e+00, For=2.32e+01, Power=6.31e-01
  [eval] val_mse=2.001e+00  (n=2997)
Epoch 00098: Time=   8.9s, Loss=4.21e+00, Inv=4.21e+00, For=2.37e+01, Power=6.29e-01
  [eval] val_mse=2.011e+00  (n=2997)
Epoch 00099: Time=   8.9s, Loss=4.19e+00, Inv=4.19e+00, For=2.37e+01, Power=6.28e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00100: Time=   9.0s, Loss=4.17e+00, Inv=4.17e+00, For=2.43e+01, Power=6.26e-01
  [eval] val_mse=1.987e+00  (n=2997)
Epoch 00101: Time=   9.0s, Loss=4.15e+00, Inv=4.15e+00, For=2.47e+01, Power=6.25e-01
  [eval] val_mse=1.996e+00  (n=2997)
Epoch 00102: Time=   9.1s, Loss=4.13e+00, Inv=4.13e+00, For=2.46e+01, Power=6.23e-01
  [eval] val_mse=1.990e+00  (n=2997)
Epoch 00103: Time=   9.1s, Loss=4.11e+00, Inv=4.11e+00, For=2.49e+01, Power=6.21e-01
  [eval] val_mse=1.993e+00  (n=2997)
Epoch 00104: Time=   9.1s, Loss=4.09e+00, Inv=4.09e+00, For=2.52e+01, Power=6.19e-01
  [eval] val_mse=1.994e+00  (n=2997)
Epoch 00105: Time=   9.2s, Loss=4.07e+00, Inv=4.07e+00, For=2.56e+01, Power=6.18e-01
  [eval] val_mse=1.993e+00  (n=2997)
Epoch 00106: Time=   9.2s, Loss=4.05e+00, Inv=4.05e+00, For=2.58e+01, Power=6.17e-01
  [eval] val_mse=1.990e+00  (n=2997)
Epoch 00107: Time=   9.2s, Loss=4.03e+00, Inv=4.03e+00, For=2.59e+01, Power=6.16e-01
  [eval] val_mse=2.002e+00  (n=2997)
Epoch 00108: Time=   9.3s, Loss=4.02e+00, Inv=4.02e+00, For=2.65e+01, Power=6.15e-01
  [eval] val_mse=1.979e+00  (n=2997)
Epoch 00109: Time=   9.3s, Loss=4.00e+00, Inv=4.00e+00, For=2.68e+01, Power=6.13e-01
  [eval] val_mse=1.998e+00  (n=2997)
Epoch 00110: Time=   9.3s, Loss=3.98e+00, Inv=3.98e+00, For=2.67e+01, Power=6.12e-01
  [eval] val_mse=1.993e+00  (n=2997)
Epoch 00111: Time=   9.4s, Loss=3.97e+00, Inv=3.97e+00, For=2.70e+01, Power=6.10e-01
  [eval] val_mse=1.985e+00  (n=2997)
Epoch 00112: Time=   9.4s, Loss=3.95e+00, Inv=3.95e+00, For=2.75e+01, Power=6.09e-01
  [eval] val_mse=2.000e+00  (n=2997)
Epoch 00113: Time=   9.5s, Loss=3.94e+00, Inv=3.94e+00, For=2.76e+01, Power=6.09e-01
  [eval] val_mse=1.989e+00  (n=2997)
Epoch 00114: Time=   9.5s, Loss=3.93e+00, Inv=3.93e+00, For=2.80e+01, Power=6.08e-01
  [eval] val_mse=1.990e+00  (n=2997)
Epoch 00115: Time=   9.5s, Loss=3.91e+00, Inv=3.91e+00, For=2.83e+01, Power=6.06e-01
  [eval] val_mse=1.988e+00  (n=2997)
Epoch 00116: Time=   9.6s, Loss=3.90e+00, Inv=3.90e+00, For=2.83e+01, Power=6.06e-01
  [eval] val_mse=1.987e+00  (n=2997)
Epoch 00117: Time=   9.6s, Loss=3.89e+00, Inv=3.89e+00, For=2.88e+01, Power=6.05e-01
  [eval] val_mse=1.989e+00  (n=2997)
Epoch 00118: Time=   9.6s, Loss=3.87e+00, Inv=3.87e+00, For=2.87e+01, Power=6.04e-01
  [eval] val_mse=1.990e+00  (n=2997)
  [early_stop] stop at epoch=118 (best_epoch=108, best_val_mse=1.979e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 5.743e-01
Torque MSE  = 1.296e-01
Torque RMSE = 3.600e-01
Per-joint MSE : 1.723e-01 2.741e-01 1.444e-01 6.770e-02 6.170e-02 5.755e-02
Per-joint RMSE: 4.152e-01 5.235e-01 3.800e-01 2.602e-01 2.484e-01 2.399e-01
Comp Time per Sample = 2.150e-04s / 4651.2Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256_lr5e5 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-znj6kbn3 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 5e-05, 'weight_decay': 1e-05, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7d754c5a68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_lr5e5
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 15:58:06.256804: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:58:08.189822: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.4s, Loss=3.20e+04, Inv=3.20e+04, For=5.82e+00, Power=1.90e+03
  [eval] val_mse=3.066e+02  (n=2997)
Epoch 00002: Time=   6.0s, Loss=5.95e+03, Inv=5.95e+03, For=5.73e+00, Power=4.18e+02
  [eval] val_mse=1.215e+02  (n=2997)
Epoch 00003: Time=   6.1s, Loss=2.40e+03, Inv=2.40e+03, For=5.63e+00, Power=1.89e+02
  [eval] val_mse=7.126e+01  (n=2997)
Epoch 00004: Time=   6.1s, Loss=1.30e+03, Inv=1.30e+03, For=5.56e+00, Power=1.09e+02
  [eval] val_mse=4.869e+01  (n=2997)
Epoch 00005: Time=   6.1s, Loss=8.16e+02, Inv=8.16e+02, For=5.49e+00, Power=7.00e+01
  [eval] val_mse=3.600e+01  (n=2997)
Epoch 00006: Time=   6.2s, Loss=5.56e+02, Inv=5.56e+02, For=5.42e+00, Power=4.83e+01
  [eval] val_mse=2.840e+01  (n=2997)
Epoch 00007: Time=   6.2s, Loss=4.03e+02, Inv=4.03e+02, For=5.36e+00, Power=3.55e+01
  [eval] val_mse=2.333e+01  (n=2997)
Epoch 00008: Time=   6.3s, Loss=3.05e+02, Inv=3.05e+02, For=5.31e+00, Power=2.69e+01
  [eval] val_mse=1.972e+01  (n=2997)
Epoch 00009: Time=   6.3s, Loss=2.39e+02, Inv=2.39e+02, For=5.27e+00, Power=2.11e+01
  [eval] val_mse=1.709e+01  (n=2997)
Epoch 00010: Time=   6.3s, Loss=1.91e+02, Inv=1.91e+02, For=5.21e+00, Power=1.69e+01
  [eval] val_mse=1.511e+01  (n=2997)
Epoch 00011: Time=   6.4s, Loss=1.58e+02, Inv=1.58e+02, For=5.19e+00, Power=1.38e+01
  [eval] val_mse=1.350e+01  (n=2997)
Epoch 00012: Time=   6.4s, Loss=1.32e+02, Inv=1.32e+02, For=5.17e+00, Power=1.15e+01
  [eval] val_mse=1.226e+01  (n=2997)
Epoch 00013: Time=   6.5s, Loss=1.12e+02, Inv=1.12e+02, For=5.15e+00, Power=9.71e+00
  [eval] val_mse=1.122e+01  (n=2997)
Epoch 00014: Time=   6.5s, Loss=9.63e+01, Inv=9.63e+01, For=5.15e+00, Power=8.30e+00
  [eval] val_mse=1.037e+01  (n=2997)
Epoch 00015: Time=   6.5s, Loss=8.39e+01, Inv=8.39e+01, For=5.14e+00, Power=7.18e+00
  [eval] val_mse=9.637e+00  (n=2997)
Epoch 00016: Time=   6.6s, Loss=7.38e+01, Inv=7.38e+01, For=5.15e+00, Power=6.27e+00
  [eval] val_mse=9.007e+00  (n=2997)
Epoch 00017: Time=   6.6s, Loss=6.53e+01, Inv=6.53e+01, For=5.15e+00, Power=5.53e+00
  [eval] val_mse=8.481e+00  (n=2997)
Epoch 00018: Time=   6.7s, Loss=5.84e+01, Inv=5.84e+01, For=5.17e+00, Power=4.91e+00
  [eval] val_mse=8.009e+00  (n=2997)
Epoch 00019: Time=   6.7s, Loss=5.25e+01, Inv=5.25e+01, For=5.19e+00, Power=4.39e+00
  [eval] val_mse=7.591e+00  (n=2997)
Epoch 00020: Time=   6.7s, Loss=4.75e+01, Inv=4.75e+01, For=5.21e+00, Power=3.96e+00
  [eval] val_mse=7.227e+00  (n=2997)
Epoch 00021: Time=   6.8s, Loss=4.33e+01, Inv=4.33e+01, For=5.23e+00, Power=3.59e+00
  [eval] val_mse=6.888e+00  (n=2997)
Epoch 00022: Time=   6.8s, Loss=3.95e+01, Inv=3.95e+01, For=5.25e+00, Power=3.28e+00
  [eval] val_mse=6.593e+00  (n=2997)
Epoch 00023: Time=   6.9s, Loss=3.63e+01, Inv=3.63e+01, For=5.28e+00, Power=3.00e+00
  [eval] val_mse=6.317e+00  (n=2997)
Epoch 00024: Time=   6.9s, Loss=3.35e+01, Inv=3.35e+01, For=5.31e+00, Power=2.76e+00
  [eval] val_mse=6.064e+00  (n=2997)
Epoch 00025: Time=   6.9s, Loss=3.10e+01, Inv=3.10e+01, For=5.34e+00, Power=2.56e+00
  [eval] val_mse=5.830e+00  (n=2997)
Epoch 00026: Time=   7.0s, Loss=2.88e+01, Inv=2.88e+01, For=5.38e+00, Power=2.38e+00
  [eval] val_mse=5.619e+00  (n=2997)
Epoch 00027: Time=   7.0s, Loss=2.68e+01, Inv=2.68e+01, For=5.42e+00, Power=2.21e+00
  [eval] val_mse=5.422e+00  (n=2997)
Epoch 00028: Time=   7.1s, Loss=2.51e+01, Inv=2.51e+01, For=5.46e+00, Power=2.07e+00
  [eval] val_mse=5.243e+00  (n=2997)
Epoch 00029: Time=   7.1s, Loss=2.35e+01, Inv=2.35e+01, For=5.50e+00, Power=1.95e+00
  [eval] val_mse=5.068e+00  (n=2997)
Epoch 00030: Time=   7.1s, Loss=2.21e+01, Inv=2.21e+01, For=5.55e+00, Power=1.84e+00
  [eval] val_mse=4.907e+00  (n=2997)
Epoch 00031: Time=   7.2s, Loss=2.08e+01, Inv=2.08e+01, For=5.59e+00, Power=1.73e+00
  [eval] val_mse=4.758e+00  (n=2997)
Epoch 00032: Time=   7.2s, Loss=1.96e+01, Inv=1.96e+01, For=5.64e+00, Power=1.64e+00
  [eval] val_mse=4.620e+00  (n=2997)
Epoch 00033: Time=   7.3s, Loss=1.86e+01, Inv=1.86e+01, For=5.69e+00, Power=1.56e+00
  [eval] val_mse=4.489e+00  (n=2997)
Epoch 00034: Time=   7.3s, Loss=1.76e+01, Inv=1.76e+01, For=5.75e+00, Power=1.49e+00
  [eval] val_mse=4.370e+00  (n=2997)
Epoch 00035: Time=   7.3s, Loss=1.67e+01, Inv=1.67e+01, For=5.81e+00, Power=1.42e+00
  [eval] val_mse=4.257e+00  (n=2997)
Epoch 00036: Time=   7.4s, Loss=1.60e+01, Inv=1.60e+01, For=5.88e+00, Power=1.36e+00
  [eval] val_mse=4.153e+00  (n=2997)
Epoch 00037: Time=   7.4s, Loss=1.52e+01, Inv=1.52e+01, For=5.95e+00, Power=1.30e+00
  [eval] val_mse=4.062e+00  (n=2997)
Epoch 00038: Time=   7.5s, Loss=1.45e+01, Inv=1.45e+01, For=6.02e+00, Power=1.25e+00
  [eval] val_mse=3.972e+00  (n=2997)
Epoch 00039: Time=   7.5s, Loss=1.39e+01, Inv=1.39e+01, For=6.11e+00, Power=1.21e+00
  [eval] val_mse=3.893e+00  (n=2997)
Epoch 00040: Time=   7.5s, Loss=1.34e+01, Inv=1.34e+01, For=6.19e+00, Power=1.16e+00
  [eval] val_mse=3.815e+00  (n=2997)
Epoch 00041: Time=   7.6s, Loss=1.28e+01, Inv=1.28e+01, For=6.28e+00, Power=1.13e+00
  [eval] val_mse=3.746e+00  (n=2997)
Epoch 00042: Time=   7.6s, Loss=1.24e+01, Inv=1.24e+01, For=6.39e+00, Power=1.09e+00
  [eval] val_mse=3.684e+00  (n=2997)
Epoch 00043: Time=   7.6s, Loss=1.19e+01, Inv=1.19e+01, For=6.49e+00, Power=1.06e+00
  [eval] val_mse=3.624e+00  (n=2997)
Epoch 00044: Time=   7.7s, Loss=1.15e+01, Inv=1.15e+01, For=6.60e+00, Power=1.03e+00
  [eval] val_mse=3.565e+00  (n=2997)
Epoch 00045: Time=   7.7s, Loss=1.11e+01, Inv=1.11e+01, For=6.71e+00, Power=1.00e+00
  [eval] val_mse=3.511e+00  (n=2997)
Epoch 00046: Time=   7.8s, Loss=1.07e+01, Inv=1.07e+01, For=6.84e+00, Power=9.76e-01
  [eval] val_mse=3.461e+00  (n=2997)
Epoch 00047: Time=   7.8s, Loss=1.04e+01, Inv=1.04e+01, For=6.97e+00, Power=9.53e-01
  [eval] val_mse=3.410e+00  (n=2997)
Epoch 00048: Time=   7.8s, Loss=1.01e+01, Inv=1.01e+01, For=7.11e+00, Power=9.32e-01
  [eval] val_mse=3.369e+00  (n=2997)
Epoch 00049: Time=   7.9s, Loss=9.81e+00, Inv=9.81e+00, For=7.25e+00, Power=9.13e-01
  [eval] val_mse=3.321e+00  (n=2997)
Epoch 00050: Time=   7.9s, Loss=9.53e+00, Inv=9.53e+00, For=7.39e+00, Power=8.93e-01
  [eval] val_mse=3.283e+00  (n=2997)
Epoch 00051: Time=   8.0s, Loss=9.28e+00, Inv=9.28e+00, For=7.56e+00, Power=8.76e-01
  [eval] val_mse=3.238e+00  (n=2997)
Epoch 00052: Time=   8.0s, Loss=9.05e+00, Inv=9.05e+00, For=7.72e+00, Power=8.62e-01
  [eval] val_mse=3.200e+00  (n=2997)
Epoch 00053: Time=   8.0s, Loss=8.81e+00, Inv=8.81e+00, For=7.88e+00, Power=8.47e-01
  [eval] val_mse=3.165e+00  (n=2997)
Epoch 00054: Time=   8.1s, Loss=8.60e+00, Inv=8.60e+00, For=8.04e+00, Power=8.33e-01
  [eval] val_mse=3.118e+00  (n=2997)
Epoch 00055: Time=   8.1s, Loss=8.41e+00, Inv=8.41e+00, For=8.22e+00, Power=8.21e-01
  [eval] val_mse=3.088e+00  (n=2997)
Epoch 00056: Time=   8.2s, Loss=8.21e+00, Inv=8.21e+00, For=8.39e+00, Power=8.09e-01
  [eval] val_mse=3.048e+00  (n=2997)
Epoch 00057: Time=   8.2s, Loss=8.04e+00, Inv=8.04e+00, For=8.58e+00, Power=7.99e-01
  [eval] val_mse=3.012e+00  (n=2997)
Epoch 00058: Time=   8.3s, Loss=7.86e+00, Inv=7.86e+00, For=8.75e+00, Power=7.87e-01
  [eval] val_mse=2.977e+00  (n=2997)
Epoch 00059: Time=   8.3s, Loss=7.70e+00, Inv=7.70e+00, For=8.92e+00, Power=7.76e-01
  [eval] val_mse=2.943e+00  (n=2997)
Epoch 00060: Time=   8.3s, Loss=7.55e+00, Inv=7.55e+00, For=9.13e+00, Power=7.68e-01
  [eval] val_mse=2.912e+00  (n=2997)
Epoch 00061: Time=   8.4s, Loss=7.40e+00, Inv=7.40e+00, For=9.32e+00, Power=7.59e-01
  [eval] val_mse=2.881e+00  (n=2997)
Epoch 00062: Time=   8.4s, Loss=7.26e+00, Inv=7.26e+00, For=9.53e+00, Power=7.52e-01
  [eval] val_mse=2.845e+00  (n=2997)
Epoch 00063: Time=   8.4s, Loss=7.13e+00, Inv=7.13e+00, For=9.73e+00, Power=7.43e-01
  [eval] val_mse=2.810e+00  (n=2997)
Epoch 00064: Time=   8.5s, Loss=7.00e+00, Inv=7.00e+00, For=9.93e+00, Power=7.37e-01
  [eval] val_mse=2.788e+00  (n=2997)
Epoch 00065: Time=   8.5s, Loss=6.88e+00, Inv=6.88e+00, For=1.01e+01, Power=7.30e-01
  [eval] val_mse=2.751e+00  (n=2997)
Epoch 00066: Time=   8.6s, Loss=6.76e+00, Inv=6.76e+00, For=1.04e+01, Power=7.24e-01
  [eval] val_mse=2.727e+00  (n=2997)
Epoch 00067: Time=   8.6s, Loss=6.66e+00, Inv=6.66e+00, For=1.06e+01, Power=7.19e-01
  [eval] val_mse=2.698e+00  (n=2997)
Epoch 00068: Time=   8.6s, Loss=6.55e+00, Inv=6.55e+00, For=1.08e+01, Power=7.12e-01
  [eval] val_mse=2.667e+00  (n=2997)
Epoch 00069: Time=   8.7s, Loss=6.45e+00, Inv=6.45e+00, For=1.10e+01, Power=7.08e-01
  [eval] val_mse=2.646e+00  (n=2997)
Epoch 00070: Time=   8.7s, Loss=6.35e+00, Inv=6.35e+00, For=1.12e+01, Power=7.02e-01
  [eval] val_mse=2.621e+00  (n=2997)
Epoch 00071: Time=   8.7s, Loss=6.26e+00, Inv=6.26e+00, For=1.15e+01, Power=6.97e-01
  [eval] val_mse=2.593e+00  (n=2997)
Epoch 00072: Time=   8.8s, Loss=6.16e+00, Inv=6.16e+00, For=1.17e+01, Power=6.93e-01
  [eval] val_mse=2.574e+00  (n=2997)
Epoch 00073: Time=   8.8s, Loss=6.08e+00, Inv=6.08e+00, For=1.19e+01, Power=6.88e-01
  [eval] val_mse=2.547e+00  (n=2997)
Epoch 00074: Time=   8.8s, Loss=6.00e+00, Inv=6.00e+00, For=1.22e+01, Power=6.83e-01
  [eval] val_mse=2.530e+00  (n=2997)
Epoch 00075: Time=   8.9s, Loss=5.91e+00, Inv=5.91e+00, For=1.24e+01, Power=6.80e-01
  [eval] val_mse=2.505e+00  (n=2997)
Epoch 00076: Time=   8.9s, Loss=5.84e+00, Inv=5.84e+00, For=1.27e+01, Power=6.77e-01
  [eval] val_mse=2.480e+00  (n=2997)
Epoch 00077: Time=   9.0s, Loss=5.76e+00, Inv=5.76e+00, For=1.29e+01, Power=6.72e-01
  [eval] val_mse=2.463e+00  (n=2997)
Epoch 00078: Time=   9.0s, Loss=5.69e+00, Inv=5.69e+00, For=1.32e+01, Power=6.68e-01
  [eval] val_mse=2.439e+00  (n=2997)
Epoch 00079: Time=   9.0s, Loss=5.63e+00, Inv=5.63e+00, For=1.35e+01, Power=6.66e-01
  [eval] val_mse=2.418e+00  (n=2997)
Epoch 00080: Time=   9.1s, Loss=5.56e+00, Inv=5.56e+00, For=1.37e+01, Power=6.63e-01
  [eval] val_mse=2.395e+00  (n=2997)
Epoch 00081: Time=   9.1s, Loss=5.50e+00, Inv=5.50e+00, For=1.40e+01, Power=6.59e-01
  [eval] val_mse=2.377e+00  (n=2997)
Epoch 00082: Time=   9.1s, Loss=5.44e+00, Inv=5.44e+00, For=1.43e+01, Power=6.56e-01
  [eval] val_mse=2.366e+00  (n=2997)
Epoch 00083: Time=   9.2s, Loss=5.38e+00, Inv=5.38e+00, For=1.46e+01, Power=6.54e-01
  [eval] val_mse=2.341e+00  (n=2997)
Epoch 00084: Time=   9.2s, Loss=5.32e+00, Inv=5.32e+00, For=1.49e+01, Power=6.52e-01
  [eval] val_mse=2.327e+00  (n=2997)
Epoch 00085: Time=   9.2s, Loss=5.26e+00, Inv=5.26e+00, For=1.51e+01, Power=6.48e-01
  [eval] val_mse=2.310e+00  (n=2997)
Epoch 00086: Time=   9.3s, Loss=5.21e+00, Inv=5.21e+00, For=1.55e+01, Power=6.46e-01
  [eval] val_mse=2.289e+00  (n=2997)
Epoch 00087: Time=   9.3s, Loss=5.16e+00, Inv=5.16e+00, For=1.58e+01, Power=6.43e-01
  [eval] val_mse=2.272e+00  (n=2997)
Epoch 00088: Time=   9.4s, Loss=5.11e+00, Inv=5.11e+00, For=1.61e+01, Power=6.41e-01
  [eval] val_mse=2.262e+00  (n=2997)
Epoch 00089: Time=   9.4s, Loss=5.06e+00, Inv=5.06e+00, For=1.63e+01, Power=6.40e-01
  [eval] val_mse=2.248e+00  (n=2997)
Epoch 00090: Time=   9.4s, Loss=5.02e+00, Inv=5.02e+00, For=1.67e+01, Power=6.37e-01
  [eval] val_mse=2.227e+00  (n=2997)
Epoch 00091: Time=   9.5s, Loss=4.97e+00, Inv=4.97e+00, For=1.70e+01, Power=6.34e-01
  [eval] val_mse=2.215e+00  (n=2997)
Epoch 00092: Time=   9.5s, Loss=4.93e+00, Inv=4.93e+00, For=1.73e+01, Power=6.32e-01
  [eval] val_mse=2.201e+00  (n=2997)
Epoch 00093: Time=   9.6s, Loss=4.89e+00, Inv=4.89e+00, For=1.77e+01, Power=6.31e-01
  [eval] val_mse=2.192e+00  (n=2997)
Epoch 00094: Time=   9.6s, Loss=4.85e+00, Inv=4.85e+00, For=1.80e+01, Power=6.30e-01
  [eval] val_mse=2.173e+00  (n=2997)
Epoch 00095: Time=   9.6s, Loss=4.80e+00, Inv=4.80e+00, For=1.83e+01, Power=6.26e-01
  [eval] val_mse=2.156e+00  (n=2997)
Epoch 00096: Time=   9.7s, Loss=4.77e+00, Inv=4.77e+00, For=1.87e+01, Power=6.26e-01
  [eval] val_mse=2.145e+00  (n=2997)
Epoch 00097: Time=   9.7s, Loss=4.73e+00, Inv=4.73e+00, For=1.91e+01, Power=6.24e-01
  [eval] val_mse=2.136e+00  (n=2997)
Epoch 00098: Time=   9.7s, Loss=4.70e+00, Inv=4.70e+00, For=1.94e+01, Power=6.23e-01
  [eval] val_mse=2.121e+00  (n=2997)
Epoch 00099: Time=   9.8s, Loss=4.66e+00, Inv=4.66e+00, For=1.98e+01, Power=6.21e-01
  [eval] val_mse=2.111e+00  (n=2997)
Epoch 00100: Time=   9.8s, Loss=4.63e+00, Inv=4.63e+00, For=2.01e+01, Power=6.19e-01
  [eval] val_mse=2.099e+00  (n=2997)
Epoch 00101: Time=   9.9s, Loss=4.59e+00, Inv=4.59e+00, For=2.05e+01, Power=6.18e-01
  [eval] val_mse=2.090e+00  (n=2997)
Epoch 00102: Time=   9.9s, Loss=4.56e+00, Inv=4.56e+00, For=2.08e+01, Power=6.16e-01
  [eval] val_mse=2.070e+00  (n=2997)
Epoch 00103: Time=   9.9s, Loss=4.53e+00, Inv=4.53e+00, For=2.12e+01, Power=6.14e-01
  [eval] val_mse=2.057e+00  (n=2997)
Epoch 00104: Time=  10.0s, Loss=4.50e+00, Inv=4.50e+00, For=2.16e+01, Power=6.13e-01
  [eval] val_mse=2.044e+00  (n=2997)
Epoch 00105: Time=  10.0s, Loss=4.48e+00, Inv=4.48e+00, For=2.20e+01, Power=6.13e-01
  [eval] val_mse=2.037e+00  (n=2997)
Epoch 00106: Time=  10.1s, Loss=4.45e+00, Inv=4.45e+00, For=2.23e+01, Power=6.12e-01
  [eval] val_mse=2.028e+00  (n=2997)
Epoch 00107: Time=  10.1s, Loss=4.42e+00, Inv=4.42e+00, For=2.28e+01, Power=6.10e-01
  [eval] val_mse=2.018e+00  (n=2997)
Epoch 00108: Time=  10.1s, Loss=4.40e+00, Inv=4.40e+00, For=2.31e+01, Power=6.10e-01
  [eval] val_mse=2.009e+00  (n=2997)
Epoch 00109: Time=  10.2s, Loss=4.37e+00, Inv=4.37e+00, For=2.36e+01, Power=6.09e-01
  [eval] val_mse=1.996e+00  (n=2997)
Epoch 00110: Time=  10.2s, Loss=4.34e+00, Inv=4.34e+00, For=2.39e+01, Power=6.08e-01
  [eval] val_mse=1.982e+00  (n=2997)
Epoch 00111: Time=  10.3s, Loss=4.32e+00, Inv=4.32e+00, For=2.43e+01, Power=6.07e-01
  [eval] val_mse=1.978e+00  (n=2997)
Epoch 00112: Time=  10.3s, Loss=4.30e+00, Inv=4.30e+00, For=2.47e+01, Power=6.05e-01
  [eval] val_mse=1.971e+00  (n=2997)
Epoch 00113: Time=  10.3s, Loss=4.28e+00, Inv=4.28e+00, For=2.52e+01, Power=6.04e-01
  [eval] val_mse=1.958e+00  (n=2997)
Epoch 00114: Time=  10.4s, Loss=4.25e+00, Inv=4.25e+00, For=2.56e+01, Power=6.03e-01
  [eval] val_mse=1.952e+00  (n=2997)
Epoch 00115: Time=  10.4s, Loss=4.23e+00, Inv=4.23e+00, For=2.60e+01, Power=6.04e-01
  [eval] val_mse=1.942e+00  (n=2997)
Epoch 00116: Time=  10.5s, Loss=4.21e+00, Inv=4.21e+00, For=2.64e+01, Power=6.03e-01
  [eval] val_mse=1.929e+00  (n=2997)
Epoch 00117: Time=  10.5s, Loss=4.19e+00, Inv=4.19e+00, For=2.68e+01, Power=6.01e-01
  [eval] val_mse=1.923e+00  (n=2997)
Epoch 00118: Time=  10.5s, Loss=4.17e+00, Inv=4.17e+00, For=2.73e+01, Power=6.01e-01
  [eval] val_mse=1.922e+00  (n=2997)
Epoch 00119: Time=  10.6s, Loss=4.15e+00, Inv=4.15e+00, For=2.76e+01, Power=6.00e-01
  [eval] val_mse=1.913e+00  (n=2997)
Epoch 00120: Time=  10.6s, Loss=4.13e+00, Inv=4.13e+00, For=2.81e+01, Power=5.99e-01
  [eval] val_mse=1.906e+00  (n=2997)
Epoch 00121: Time=  10.7s, Loss=4.12e+00, Inv=4.12e+00, For=2.85e+01, Power=5.99e-01
  [eval] val_mse=1.901e+00  (n=2997)
Epoch 00122: Time=  10.7s, Loss=4.10e+00, Inv=4.10e+00, For=2.89e+01, Power=5.98e-01
  [eval] val_mse=1.897e+00  (n=2997)
Epoch 00123: Time=  10.7s, Loss=4.09e+00, Inv=4.09e+00, For=2.93e+01, Power=5.98e-01
  [eval] val_mse=1.883e+00  (n=2997)
Epoch 00124: Time=  10.8s, Loss=4.07e+00, Inv=4.07e+00, For=2.99e+01, Power=5.97e-01
  [eval] val_mse=1.886e+00  (n=2997)
Epoch 00125: Time=  10.8s, Loss=4.05e+00, Inv=4.05e+00, For=3.02e+01, Power=5.95e-01
  [eval] val_mse=1.870e+00  (n=2997)
Epoch 00126: Time=  10.8s, Loss=4.04e+00, Inv=4.04e+00, For=3.07e+01, Power=5.95e-01
  [eval] val_mse=1.867e+00  (n=2997)
Epoch 00127: Time=  10.9s, Loss=4.02e+00, Inv=4.02e+00, For=3.11e+01, Power=5.95e-01
  [eval] val_mse=1.857e+00  (n=2997)
Epoch 00128: Time=  10.9s, Loss=4.01e+00, Inv=4.01e+00, For=3.15e+01, Power=5.94e-01
  [eval] val_mse=1.857e+00  (n=2997)
Epoch 00129: Time=  11.0s, Loss=4.00e+00, Inv=4.00e+00, For=3.20e+01, Power=5.93e-01
  [eval] val_mse=1.852e+00  (n=2997)
Epoch 00130: Time=  11.0s, Loss=3.98e+00, Inv=3.98e+00, For=3.25e+01, Power=5.94e-01
  [eval] val_mse=1.845e+00  (n=2997)
Epoch 00131: Time=  11.0s, Loss=3.97e+00, Inv=3.97e+00, For=3.29e+01, Power=5.92e-01
  [eval] val_mse=1.833e+00  (n=2997)
Epoch 00132: Time=  11.1s, Loss=3.95e+00, Inv=3.95e+00, For=3.34e+01, Power=5.92e-01
  [eval] val_mse=1.835e+00  (n=2997)
Epoch 00133: Time=  11.1s, Loss=3.94e+00, Inv=3.94e+00, For=3.37e+01, Power=5.91e-01
  [eval] val_mse=1.825e+00  (n=2997)
Epoch 00134: Time=  11.2s, Loss=3.93e+00, Inv=3.93e+00, For=3.42e+01, Power=5.92e-01
  [eval] val_mse=1.833e+00  (n=2997)
Epoch 00135: Time=  11.2s, Loss=3.92e+00, Inv=3.92e+00, For=3.47e+01, Power=5.91e-01
  [eval] val_mse=1.820e+00  (n=2997)
Epoch 00136: Time=  11.2s, Loss=3.91e+00, Inv=3.91e+00, For=3.51e+01, Power=5.91e-01
  [eval] val_mse=1.819e+00  (n=2997)
Epoch 00137: Time=  11.3s, Loss=3.90e+00, Inv=3.90e+00, For=3.57e+01, Power=5.92e-01
  [eval] val_mse=1.814e+00  (n=2997)
Epoch 00138: Time=  11.3s, Loss=3.89e+00, Inv=3.89e+00, For=3.61e+01, Power=5.90e-01
  [eval] val_mse=1.815e+00  (n=2997)
Epoch 00139: Time=  11.4s, Loss=3.88e+00, Inv=3.88e+00, For=3.65e+01, Power=5.90e-01
  [eval] val_mse=1.804e+00  (n=2997)
Epoch 00140: Time=  11.4s, Loss=3.87e+00, Inv=3.87e+00, For=3.70e+01, Power=5.90e-01
  [eval] val_mse=1.806e+00  (n=2997)
Epoch 00141: Time=  11.4s, Loss=3.86e+00, Inv=3.86e+00, For=3.74e+01, Power=5.89e-01
  [eval] val_mse=1.806e+00  (n=2997)
Epoch 00142: Time=  11.5s, Loss=3.85e+00, Inv=3.85e+00, For=3.80e+01, Power=5.88e-01
  [eval] val_mse=1.800e+00  (n=2997)
Epoch 00143: Time=  11.5s, Loss=3.84e+00, Inv=3.84e+00, For=3.84e+01, Power=5.90e-01
  [eval] val_mse=1.797e+00  (n=2997)
Epoch 00144: Time=  11.5s, Loss=3.83e+00, Inv=3.83e+00, For=3.90e+01, Power=5.88e-01
  [eval] val_mse=1.788e+00  (n=2997)
Epoch 00145: Time=  11.6s, Loss=3.82e+00, Inv=3.82e+00, For=3.95e+01, Power=5.89e-01
  [eval] val_mse=1.788e+00  (n=2997)
Epoch 00146: Time=  11.6s, Loss=3.81e+00, Inv=3.81e+00, For=3.98e+01, Power=5.87e-01
  [eval] val_mse=1.789e+00  (n=2997)
Epoch 00147: Time=  11.6s, Loss=3.80e+00, Inv=3.80e+00, For=4.03e+01, Power=5.88e-01
  [eval] val_mse=1.786e+00  (n=2997)
Epoch 00148: Time=  11.7s, Loss=3.80e+00, Inv=3.80e+00, For=4.08e+01, Power=5.88e-01
  [eval] val_mse=1.791e+00  (n=2997)
Epoch 00149: Time=  11.7s, Loss=3.79e+00, Inv=3.79e+00, For=4.13e+01, Power=5.88e-01
  [eval] val_mse=1.782e+00  (n=2997)
Epoch 00150: Time=  11.7s, Loss=3.78e+00, Inv=3.78e+00, For=4.18e+01, Power=5.87e-01
  [eval] val_mse=1.774e+00  (n=2997)
Epoch 00151: Time=  11.8s, Loss=3.77e+00, Inv=3.77e+00, For=4.23e+01, Power=5.87e-01
  [eval] val_mse=1.786e+00  (n=2997)
Epoch 00152: Time=  11.8s, Loss=3.76e+00, Inv=3.76e+00, For=4.27e+01, Power=5.87e-01
  [eval] val_mse=1.783e+00  (n=2997)
Epoch 00153: Time=  11.9s, Loss=3.76e+00, Inv=3.76e+00, For=4.32e+01, Power=5.87e-01
  [eval] val_mse=1.788e+00  (n=2997)
Epoch 00154: Time=  11.9s, Loss=3.75e+00, Inv=3.75e+00, For=4.37e+01, Power=5.87e-01
  [eval] val_mse=1.777e+00  (n=2997)
Epoch 00155: Time=  11.9s, Loss=3.74e+00, Inv=3.74e+00, For=4.40e+01, Power=5.87e-01
  [eval] val_mse=1.782e+00  (n=2997)
Epoch 00156: Time=  12.0s, Loss=3.74e+00, Inv=3.74e+00, For=4.46e+01, Power=5.87e-01
  [eval] val_mse=1.782e+00  (n=2997)
Epoch 00157: Time=  12.0s, Loss=3.73e+00, Inv=3.73e+00, For=4.51e+01, Power=5.86e-01
  [eval] val_mse=1.776e+00  (n=2997)
Epoch 00158: Time=  12.0s, Loss=3.72e+00, Inv=3.72e+00, For=4.57e+01, Power=5.87e-01
  [eval] val_mse=1.777e+00  (n=2997)
Epoch 00159: Time=  12.1s, Loss=3.72e+00, Inv=3.72e+00, For=4.60e+01, Power=5.87e-01
  [eval] val_mse=1.774e+00  (n=2997)
Epoch 00160: Time=  12.1s, Loss=3.71e+00, Inv=3.71e+00, For=4.67e+01, Power=5.86e-01
  [eval] val_mse=1.782e+00  (n=2997)
  [early_stop] stop at epoch=160 (best_epoch=150, best_val_mse=1.774e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2
  [val] Torque RMSE = 5.437e-01
Torque MSE  = 1.222e-01
Torque RMSE = 3.496e-01
Per-joint MSE : 1.700e-01 2.562e-01 1.396e-01 6.774e-02 4.880e-02 5.107e-02
Per-joint RMSE: 4.124e-01 5.061e-01 3.736e-01 2.603e-01 2.209e-01 2.260e-01
Comp Time per Sample = 2.077e-04s / 4814.3Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_lr5e5_actsoftplus_b1024_lr5e-5_wd1e-5_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 0 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-e_vijx3w because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x778cd39c68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:58:29.915939: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:58:31.774062: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.3s, Loss=8.94e+03, Inv=8.94e+03, For=5.90e+00, Power=1.70e+03
  [eval] val_mse=1.643e+02  (n=7000)
Epoch 00002: Time=   6.2s, Loss=5.96e+02, Inv=5.96e+02, For=5.66e+00, Power=1.25e+02
  [eval] val_mse=6.998e+01  (n=7000)
Epoch 00003: Time=   6.2s, Loss=2.52e+02, Inv=2.52e+02, For=5.58e+00, Power=5.00e+01
  [eval] val_mse=4.524e+01  (n=7000)
Epoch 00004: Time=   6.2s, Loss=1.48e+02, Inv=1.48e+02, For=5.65e+00, Power=3.00e+01
  [eval] val_mse=3.257e+01  (n=7000)
Epoch 00005: Time=   6.3s, Loss=9.82e+01, Inv=9.82e+01, For=5.80e+00, Power=1.99e+01
  [eval] val_mse=2.474e+01  (n=7000)
Epoch 00006: Time=   6.3s, Loss=6.97e+01, Inv=6.97e+01, For=6.01e+00, Power=1.41e+01
  [eval] val_mse=1.952e+01  (n=7000)
Epoch 00007: Time=   6.4s, Loss=5.24e+01, Inv=5.24e+01, For=6.22e+00, Power=1.03e+01
  [eval] val_mse=1.583e+01  (n=7000)
Epoch 00008: Time=   6.4s, Loss=4.13e+01, Inv=4.13e+01, For=6.51e+00, Power=7.97e+00
  [eval] val_mse=1.320e+01  (n=7000)
Epoch 00009: Time=   6.4s, Loss=3.37e+01, Inv=3.37e+01, For=6.86e+00, Power=6.41e+00
  [eval] val_mse=1.112e+01  (n=7000)
Epoch 00010: Time=   6.5s, Loss=2.80e+01, Inv=2.80e+01, For=7.15e+00, Power=5.18e+00
  [eval] val_mse=9.543e+00  (n=7000)
Epoch 00011: Time=   6.5s, Loss=2.40e+01, Inv=2.40e+01, For=7.51e+00, Power=4.35e+00
  [eval] val_mse=8.255e+00  (n=7000)
Epoch 00012: Time=   6.5s, Loss=2.07e+01, Inv=2.07e+01, For=7.84e+00, Power=3.68e+00
  [eval] val_mse=7.213e+00  (n=7000)
Epoch 00013: Time=   6.6s, Loss=1.83e+01, Inv=1.83e+01, For=8.26e+00, Power=3.18e+00
  [eval] val_mse=6.372e+00  (n=7000)
Epoch 00014: Time=   6.6s, Loss=1.63e+01, Inv=1.63e+01, For=8.57e+00, Power=2.78e+00
  [eval] val_mse=5.657e+00  (n=7000)
Epoch 00015: Time=   6.6s, Loss=1.47e+01, Inv=1.47e+01, For=8.97e+00, Power=2.47e+00
  [eval] val_mse=5.066e+00  (n=7000)
Epoch 00016: Time=   6.7s, Loss=1.34e+01, Inv=1.34e+01, For=9.34e+00, Power=2.23e+00
  [eval] val_mse=4.551e+00  (n=7000)
Epoch 00017: Time=   6.7s, Loss=1.23e+01, Inv=1.23e+01, For=9.74e+00, Power=2.01e+00
  [eval] val_mse=4.117e+00  (n=7000)
Epoch 00018: Time=   6.7s, Loss=1.14e+01, Inv=1.14e+01, For=1.01e+01, Power=1.84e+00
  [eval] val_mse=3.749e+00  (n=7000)
Epoch 00019: Time=   6.8s, Loss=1.06e+01, Inv=1.06e+01, For=1.05e+01, Power=1.69e+00
  [eval] val_mse=3.422e+00  (n=7000)
Epoch 00020: Time=   6.8s, Loss=9.89e+00, Inv=9.89e+00, For=1.08e+01, Power=1.58e+00
  [eval] val_mse=3.148e+00  (n=7000)
Epoch 00021: Time=   6.8s, Loss=9.28e+00, Inv=9.28e+00, For=1.13e+01, Power=1.48e+00
  [eval] val_mse=2.907e+00  (n=7000)
Epoch 00022: Time=   6.9s, Loss=8.76e+00, Inv=8.76e+00, For=1.17e+01, Power=1.38e+00
  [eval] val_mse=2.690e+00  (n=7000)
Epoch 00023: Time=   6.9s, Loss=8.30e+00, Inv=8.30e+00, For=1.22e+01, Power=1.30e+00
  [eval] val_mse=2.505e+00  (n=7000)
Epoch 00024: Time=   7.0s, Loss=7.91e+00, Inv=7.91e+00, For=1.27e+01, Power=1.24e+00
  [eval] val_mse=2.336e+00  (n=7000)
Epoch 00025: Time=   7.0s, Loss=7.56e+00, Inv=7.56e+00, For=1.33e+01, Power=1.18e+00
  [eval] val_mse=2.188e+00  (n=7000)
Epoch 00026: Time=   7.0s, Loss=7.23e+00, Inv=7.23e+00, For=1.38e+01, Power=1.13e+00
  [eval] val_mse=2.057e+00  (n=7000)
Epoch 00027: Time=   7.1s, Loss=6.96e+00, Inv=6.96e+00, For=1.46e+01, Power=1.09e+00
  [eval] val_mse=1.936e+00  (n=7000)
Epoch 00028: Time=   7.1s, Loss=6.73e+00, Inv=6.73e+00, For=1.52e+01, Power=1.06e+00
  [eval] val_mse=1.830e+00  (n=7000)
Epoch 00029: Time=   7.1s, Loss=6.51e+00, Inv=6.51e+00, For=1.59e+01, Power=1.02e+00
  [eval] val_mse=1.729e+00  (n=7000)
Epoch 00030: Time=   7.2s, Loss=6.29e+00, Inv=6.29e+00, For=1.67e+01, Power=9.87e-01
  [eval] val_mse=1.643e+00  (n=7000)
Epoch 00031: Time=   7.2s, Loss=6.11e+00, Inv=6.11e+00, For=1.75e+01, Power=9.60e-01
  [eval] val_mse=1.561e+00  (n=7000)
Epoch 00032: Time=   7.2s, Loss=5.94e+00, Inv=5.94e+00, For=1.83e+01, Power=9.35e-01
  [eval] val_mse=1.489e+00  (n=7000)
Epoch 00033: Time=   7.3s, Loss=5.78e+00, Inv=5.78e+00, For=1.92e+01, Power=9.15e-01
  [eval] val_mse=1.420e+00  (n=7000)
Epoch 00034: Time=   7.3s, Loss=5.65e+00, Inv=5.65e+00, For=2.02e+01, Power=8.99e-01
  [eval] val_mse=1.355e+00  (n=7000)
Epoch 00035: Time=   7.3s, Loss=5.53e+00, Inv=5.53e+00, For=2.11e+01, Power=8.81e-01
  [eval] val_mse=1.299e+00  (n=7000)
Epoch 00036: Time=   7.4s, Loss=5.41e+00, Inv=5.41e+00, For=2.22e+01, Power=8.66e-01
  [eval] val_mse=1.246e+00  (n=7000)
Epoch 00037: Time=   7.4s, Loss=5.30e+00, Inv=5.30e+00, For=2.30e+01, Power=8.49e-01
  [eval] val_mse=1.198e+00  (n=7000)
Epoch 00038: Time=   7.5s, Loss=5.20e+00, Inv=5.20e+00, For=2.42e+01, Power=8.33e-01
  [eval] val_mse=1.152e+00  (n=7000)
Epoch 00039: Time=   7.5s, Loss=5.10e+00, Inv=5.10e+00, For=2.53e+01, Power=8.25e-01
  [eval] val_mse=1.110e+00  (n=7000)
Epoch 00040: Time=   7.5s, Loss=5.02e+00, Inv=5.02e+00, For=2.65e+01, Power=8.14e-01
  [eval] val_mse=1.072e+00  (n=7000)
Epoch 00041: Time=   7.6s, Loss=4.93e+00, Inv=4.93e+00, For=2.76e+01, Power=8.05e-01
  [eval] val_mse=1.035e+00  (n=7000)
Epoch 00042: Time=   7.6s, Loss=4.86e+00, Inv=4.86e+00, For=2.89e+01, Power=7.98e-01
  [eval] val_mse=1.002e+00  (n=7000)
Epoch 00043: Time=   7.6s, Loss=4.79e+00, Inv=4.79e+00, For=3.00e+01, Power=7.89e-01
  [eval] val_mse=9.703e-01  (n=7000)
Epoch 00044: Time=   7.7s, Loss=4.72e+00, Inv=4.72e+00, For=3.13e+01, Power=7.78e-01
  [eval] val_mse=9.424e-01  (n=7000)
Epoch 00045: Time=   7.7s, Loss=4.66e+00, Inv=4.66e+00, For=3.29e+01, Power=7.75e-01
  [eval] val_mse=9.142e-01  (n=7000)
Epoch 00046: Time=   7.7s, Loss=4.59e+00, Inv=4.59e+00, For=3.41e+01, Power=7.65e-01
  [eval] val_mse=8.893e-01  (n=7000)
Epoch 00047: Time=   7.8s, Loss=4.53e+00, Inv=4.53e+00, For=3.54e+01, Power=7.61e-01
  [eval] val_mse=8.641e-01  (n=7000)
Epoch 00048: Time=   7.8s, Loss=4.47e+00, Inv=4.47e+00, For=3.70e+01, Power=7.55e-01
  [eval] val_mse=8.428e-01  (n=7000)
Epoch 00049: Time=   7.9s, Loss=4.42e+00, Inv=4.42e+00, For=3.85e+01, Power=7.48e-01
  [eval] val_mse=8.220e-01  (n=7000)
Epoch 00050: Time=   7.9s, Loss=4.38e+00, Inv=4.38e+00, For=4.00e+01, Power=7.46e-01
  [eval] val_mse=8.023e-01  (n=7000)
Epoch 00051: Time=   7.9s, Loss=4.32e+00, Inv=4.32e+00, For=4.14e+01, Power=7.39e-01
  [eval] val_mse=7.841e-01  (n=7000)
Epoch 00052: Time=   8.0s, Loss=4.28e+00, Inv=4.28e+00, For=4.31e+01, Power=7.35e-01
  [eval] val_mse=7.660e-01  (n=7000)
Epoch 00053: Time=   8.0s, Loss=4.24e+00, Inv=4.24e+00, For=4.49e+01, Power=7.35e-01
  [eval] val_mse=7.511e-01  (n=7000)
Epoch 00054: Time=   8.0s, Loss=4.20e+00, Inv=4.20e+00, For=4.67e+01, Power=7.30e-01
  [eval] val_mse=7.360e-01  (n=7000)
Epoch 00055: Time=   8.1s, Loss=4.16e+00, Inv=4.16e+00, For=4.85e+01, Power=7.27e-01
  [eval] val_mse=7.211e-01  (n=7000)
Epoch 00056: Time=   8.1s, Loss=4.11e+00, Inv=4.11e+00, For=5.01e+01, Power=7.25e-01
  [eval] val_mse=7.076e-01  (n=7000)
Epoch 00057: Time=   8.2s, Loss=4.08e+00, Inv=4.08e+00, For=5.20e+01, Power=7.21e-01
  [eval] val_mse=6.946e-01  (n=7000)
Epoch 00058: Time=   8.2s, Loss=4.05e+00, Inv=4.05e+00, For=5.41e+01, Power=7.16e-01
  [eval] val_mse=6.819e-01  (n=7000)
Epoch 00059: Time=   8.2s, Loss=4.01e+00, Inv=4.01e+00, For=5.60e+01, Power=7.12e-01
  [eval] val_mse=6.708e-01  (n=7000)
Epoch 00060: Time=   8.3s, Loss=3.98e+00, Inv=3.98e+00, For=5.82e+01, Power=7.14e-01
  [eval] val_mse=6.599e-01  (n=7000)
Epoch 00061: Time=   8.3s, Loss=3.95e+00, Inv=3.95e+00, For=6.01e+01, Power=7.14e-01
  [eval] val_mse=6.500e-01  (n=7000)
Epoch 00062: Time=   8.3s, Loss=3.92e+00, Inv=3.92e+00, For=6.25e+01, Power=7.09e-01
  [eval] val_mse=6.399e-01  (n=7000)
Epoch 00063: Time=   8.4s, Loss=3.89e+00, Inv=3.89e+00, For=6.44e+01, Power=7.09e-01
  [eval] val_mse=6.305e-01  (n=7000)
Epoch 00064: Time=   8.4s, Loss=3.87e+00, Inv=3.87e+00, For=6.63e+01, Power=7.05e-01
  [eval] val_mse=6.213e-01  (n=7000)
Epoch 00065: Time=   8.5s, Loss=3.84e+00, Inv=3.84e+00, For=6.90e+01, Power=7.06e-01
  [eval] val_mse=6.130e-01  (n=7000)
Epoch 00066: Time=   8.5s, Loss=3.81e+00, Inv=3.81e+00, For=7.08e+01, Power=7.02e-01
  [eval] val_mse=6.046e-01  (n=7000)
Epoch 00067: Time=   8.5s, Loss=3.79e+00, Inv=3.79e+00, For=7.37e+01, Power=7.01e-01
  [eval] val_mse=5.971e-01  (n=7000)
Epoch 00068: Time=   8.6s, Loss=3.76e+00, Inv=3.76e+00, For=7.54e+01, Power=6.98e-01
  [eval] val_mse=5.889e-01  (n=7000)
Epoch 00069: Time=   8.6s, Loss=3.74e+00, Inv=3.74e+00, For=7.81e+01, Power=6.95e-01
  [eval] val_mse=5.811e-01  (n=7000)
Epoch 00070: Time=   8.6s, Loss=3.72e+00, Inv=3.72e+00, For=8.08e+01, Power=6.99e-01
  [eval] val_mse=5.754e-01  (n=7000)
Epoch 00071: Time=   8.7s, Loss=3.70e+00, Inv=3.70e+00, For=8.34e+01, Power=6.94e-01
  [eval] val_mse=5.692e-01  (n=7000)
Epoch 00072: Time=   8.7s, Loss=3.69e+00, Inv=3.69e+00, For=8.53e+01, Power=6.96e-01
  [eval] val_mse=5.628e-01  (n=7000)
Epoch 00073: Time=   8.8s, Loss=3.66e+00, Inv=3.66e+00, For=8.80e+01, Power=6.94e-01
  [eval] val_mse=5.567e-01  (n=7000)
Epoch 00074: Time=   8.8s, Loss=3.65e+00, Inv=3.65e+00, For=9.11e+01, Power=6.93e-01
  [eval] val_mse=5.509e-01  (n=7000)
Epoch 00075: Time=   8.8s, Loss=3.63e+00, Inv=3.63e+00, For=9.34e+01, Power=6.95e-01
  [eval] val_mse=5.453e-01  (n=7000)
Epoch 00076: Time=   8.9s, Loss=3.61e+00, Inv=3.61e+00, For=9.64e+01, Power=6.93e-01
  [eval] val_mse=5.402e-01  (n=7000)
Epoch 00077: Time=   8.9s, Loss=3.59e+00, Inv=3.59e+00, For=9.87e+01, Power=6.89e-01
  [eval] val_mse=5.346e-01  (n=7000)
Epoch 00078: Time=   8.9s, Loss=3.58e+00, Inv=3.58e+00, For=1.02e+02, Power=6.91e-01
  [eval] val_mse=5.300e-01  (n=7000)
Epoch 00079: Time=   9.0s, Loss=3.56e+00, Inv=3.56e+00, For=1.04e+02, Power=6.88e-01
  [eval] val_mse=5.249e-01  (n=7000)
Epoch 00080: Time=   9.0s, Loss=3.55e+00, Inv=3.55e+00, For=1.08e+02, Power=6.89e-01
  [eval] val_mse=5.198e-01  (n=7000)
Epoch 00081: Time=   9.0s, Loss=3.54e+00, Inv=3.54e+00, For=1.10e+02, Power=6.91e-01
  [eval] val_mse=5.154e-01  (n=7000)
Epoch 00082: Time=   9.1s, Loss=3.53e+00, Inv=3.53e+00, For=1.14e+02, Power=6.91e-01
  [eval] val_mse=5.111e-01  (n=7000)
Epoch 00083: Time=   9.1s, Loss=3.52e+00, Inv=3.52e+00, For=1.17e+02, Power=6.91e-01
  [eval] val_mse=5.072e-01  (n=7000)
Epoch 00084: Time=   9.2s, Loss=3.51e+00, Inv=3.51e+00, For=1.20e+02, Power=6.88e-01
  [eval] val_mse=5.029e-01  (n=7000)
Epoch 00085: Time=   9.2s, Loss=3.49e+00, Inv=3.49e+00, For=1.23e+02, Power=6.89e-01
  [eval] val_mse=4.998e-01  (n=7000)
Epoch 00086: Time=   9.2s, Loss=3.48e+00, Inv=3.48e+00, For=1.26e+02, Power=6.88e-01
  [eval] val_mse=4.955e-01  (n=7000)
Epoch 00087: Time=   9.3s, Loss=3.47e+00, Inv=3.47e+00, For=1.29e+02, Power=6.87e-01
  [eval] val_mse=4.913e-01  (n=7000)
Epoch 00088: Time=   9.3s, Loss=3.46e+00, Inv=3.46e+00, For=1.32e+02, Power=6.87e-01
  [eval] val_mse=4.879e-01  (n=7000)
Epoch 00089: Time=   9.3s, Loss=3.45e+00, Inv=3.45e+00, For=1.36e+02, Power=6.88e-01
  [eval] val_mse=4.834e-01  (n=7000)
Epoch 00090: Time=   9.4s, Loss=3.44e+00, Inv=3.44e+00, For=1.39e+02, Power=6.88e-01
  [eval] val_mse=4.808e-01  (n=7000)
Epoch 00091: Time=   9.4s, Loss=3.43e+00, Inv=3.43e+00, For=1.42e+02, Power=6.86e-01
  [eval] val_mse=4.774e-01  (n=7000)
Epoch 00092: Time=   9.4s, Loss=3.42e+00, Inv=3.42e+00, For=1.45e+02, Power=6.86e-01
  [eval] val_mse=4.744e-01  (n=7000)
Epoch 00093: Time=   9.5s, Loss=3.40e+00, Inv=3.40e+00, For=1.49e+02, Power=6.84e-01
  [eval] val_mse=4.710e-01  (n=7000)
Epoch 00094: Time=   9.5s, Loss=3.40e+00, Inv=3.40e+00, For=1.53e+02, Power=6.88e-01
  [eval] val_mse=4.675e-01  (n=7000)
Epoch 00095: Time=   9.6s, Loss=3.39e+00, Inv=3.39e+00, For=1.56e+02, Power=6.83e-01
  [eval] val_mse=4.644e-01  (n=7000)
Epoch 00096: Time=   9.6s, Loss=3.38e+00, Inv=3.38e+00, For=1.61e+02, Power=6.84e-01
  [eval] val_mse=4.617e-01  (n=7000)
Epoch 00097: Time=   9.6s, Loss=3.37e+00, Inv=3.37e+00, For=1.62e+02, Power=6.84e-01
  [eval] val_mse=4.593e-01  (n=7000)
Epoch 00098: Time=   9.7s, Loss=3.37e+00, Inv=3.37e+00, For=1.67e+02, Power=6.86e-01
  [eval] val_mse=4.554e-01  (n=7000)
Epoch 00099: Time=   9.7s, Loss=3.36e+00, Inv=3.36e+00, For=1.72e+02, Power=6.87e-01
  [eval] val_mse=4.523e-01  (n=7000)
Epoch 00100: Time=   9.8s, Loss=3.36e+00, Inv=3.36e+00, For=1.75e+02, Power=6.88e-01
  [eval] val_mse=4.499e-01  (n=7000)
Epoch 00101: Time=   9.8s, Loss=3.35e+00, Inv=3.35e+00, For=1.78e+02, Power=6.85e-01
  [eval] val_mse=4.479e-01  (n=7000)
Epoch 00102: Time=   9.8s, Loss=3.34e+00, Inv=3.34e+00, For=1.81e+02, Power=6.82e-01
  [eval] val_mse=4.449e-01  (n=7000)
Epoch 00103: Time=   9.9s, Loss=3.33e+00, Inv=3.33e+00, For=1.86e+02, Power=6.82e-01
  [eval] val_mse=4.417e-01  (n=7000)
Epoch 00104: Time=   9.9s, Loss=3.32e+00, Inv=3.32e+00, For=1.90e+02, Power=6.84e-01
  [eval] val_mse=4.394e-01  (n=7000)
Epoch 00105: Time=  10.0s, Loss=3.32e+00, Inv=3.32e+00, For=1.91e+02, Power=6.85e-01
  [eval] val_mse=4.370e-01  (n=7000)
Epoch 00106: Time=  10.0s, Loss=3.30e+00, Inv=3.30e+00, For=1.98e+02, Power=6.83e-01
  [eval] val_mse=4.342e-01  (n=7000)
Epoch 00107: Time=  10.0s, Loss=3.30e+00, Inv=3.30e+00, For=2.00e+02, Power=6.82e-01
  [eval] val_mse=4.322e-01  (n=7000)
Epoch 00108: Time=  10.1s, Loss=3.30e+00, Inv=3.30e+00, For=2.07e+02, Power=6.83e-01
  [eval] val_mse=4.295e-01  (n=7000)
Epoch 00109: Time=  10.1s, Loss=3.29e+00, Inv=3.29e+00, For=2.09e+02, Power=6.83e-01
  [eval] val_mse=4.271e-01  (n=7000)
Epoch 00110: Time=  10.1s, Loss=3.28e+00, Inv=3.28e+00, For=2.13e+02, Power=6.79e-01
  [eval] val_mse=4.255e-01  (n=7000)
Epoch 00111: Time=  10.2s, Loss=3.28e+00, Inv=3.28e+00, For=2.16e+02, Power=6.83e-01
  [eval] val_mse=4.228e-01  (n=7000)
Epoch 00112: Time=  10.2s, Loss=3.27e+00, Inv=3.27e+00, For=2.22e+02, Power=6.85e-01
  [eval] val_mse=4.216e-01  (n=7000)
Epoch 00113: Time=  10.2s, Loss=3.27e+00, Inv=3.27e+00, For=2.24e+02, Power=6.86e-01
  [eval] val_mse=4.188e-01  (n=7000)
Epoch 00114: Time=  10.3s, Loss=3.26e+00, Inv=3.26e+00, For=2.30e+02, Power=6.83e-01
  [eval] val_mse=4.167e-01  (n=7000)
Epoch 00115: Time=  10.3s, Loss=3.26e+00, Inv=3.26e+00, For=2.30e+02, Power=6.81e-01
  [eval] val_mse=4.150e-01  (n=7000)
Epoch 00116: Time=  10.4s, Loss=3.25e+00, Inv=3.25e+00, For=2.38e+02, Power=6.81e-01
  [eval] val_mse=4.130e-01  (n=7000)
Epoch 00117: Time=  10.4s, Loss=3.24e+00, Inv=3.24e+00, For=2.41e+02, Power=6.81e-01
  [eval] val_mse=4.107e-01  (n=7000)
Epoch 00118: Time=  10.4s, Loss=3.24e+00, Inv=3.24e+00, For=2.46e+02, Power=6.80e-01
  [eval] val_mse=4.086e-01  (n=7000)
Epoch 00119: Time=  10.5s, Loss=3.23e+00, Inv=3.23e+00, For=2.51e+02, Power=6.80e-01
  [eval] val_mse=4.070e-01  (n=7000)
Epoch 00120: Time=  10.5s, Loss=3.23e+00, Inv=3.23e+00, For=2.51e+02, Power=6.82e-01
  [eval] val_mse=4.060e-01  (n=7000)
Epoch 00121: Time=  10.6s, Loss=3.22e+00, Inv=3.22e+00, For=2.57e+02, Power=6.83e-01
  [eval] val_mse=4.026e-01  (n=7000)
Epoch 00122: Time=  10.6s, Loss=3.22e+00, Inv=3.22e+00, For=2.65e+02, Power=6.82e-01
  [eval] val_mse=4.016e-01  (n=7000)
Epoch 00123: Time=  10.6s, Loss=3.21e+00, Inv=3.21e+00, For=2.66e+02, Power=6.81e-01
  [eval] val_mse=4.000e-01  (n=7000)
Epoch 00124: Time=  10.7s, Loss=3.21e+00, Inv=3.21e+00, For=2.66e+02, Power=6.83e-01
  [eval] val_mse=3.977e-01  (n=7000)
Epoch 00125: Time=  10.7s, Loss=3.21e+00, Inv=3.21e+00, For=2.73e+02, Power=6.82e-01
  [eval] val_mse=3.964e-01  (n=7000)
Epoch 00126: Time=  10.8s, Loss=3.20e+00, Inv=3.20e+00, For=2.80e+02, Power=6.84e-01
  [eval] val_mse=3.947e-01  (n=7000)
Epoch 00127: Time=  10.8s, Loss=3.20e+00, Inv=3.20e+00, For=2.84e+02, Power=6.81e-01
  [eval] val_mse=3.931e-01  (n=7000)
Epoch 00128: Time=  10.8s, Loss=3.19e+00, Inv=3.19e+00, For=2.87e+02, Power=6.80e-01
  [eval] val_mse=3.918e-01  (n=7000)
Epoch 00129: Time=  10.9s, Loss=3.19e+00, Inv=3.19e+00, For=2.94e+02, Power=6.80e-01
  [eval] val_mse=3.899e-01  (n=7000)
Epoch 00130: Time=  10.9s, Loss=3.19e+00, Inv=3.19e+00, For=2.99e+02, Power=6.80e-01
  [eval] val_mse=3.895e-01  (n=7000)
Epoch 00131: Time=  10.9s, Loss=3.18e+00, Inv=3.18e+00, For=2.95e+02, Power=6.83e-01
  [eval] val_mse=3.875e-01  (n=7000)
Epoch 00132: Time=  11.0s, Loss=3.18e+00, Inv=3.18e+00, For=3.09e+02, Power=6.80e-01
  [eval] val_mse=3.860e-01  (n=7000)
Epoch 00133: Time=  11.0s, Loss=3.17e+00, Inv=3.17e+00, For=3.05e+02, Power=6.82e-01
  [eval] val_mse=3.838e-01  (n=7000)
Epoch 00134: Time=  11.1s, Loss=3.17e+00, Inv=3.17e+00, For=3.11e+02, Power=6.81e-01
  [eval] val_mse=3.825e-01  (n=7000)
Epoch 00135: Time=  11.1s, Loss=3.16e+00, Inv=3.16e+00, For=3.15e+02, Power=6.79e-01
  [eval] val_mse=3.819e-01  (n=7000)
Epoch 00136: Time=  11.1s, Loss=3.16e+00, Inv=3.16e+00, For=3.27e+02, Power=6.81e-01
  [eval] val_mse=3.805e-01  (n=7000)
Epoch 00137: Time=  11.2s, Loss=3.16e+00, Inv=3.16e+00, For=3.17e+02, Power=6.82e-01
  [eval] val_mse=3.796e-01  (n=7000)
Epoch 00138: Time=  11.2s, Loss=3.16e+00, Inv=3.16e+00, For=3.35e+02, Power=6.78e-01
  [eval] val_mse=3.770e-01  (n=7000)
Epoch 00139: Time=  11.3s, Loss=3.15e+00, Inv=3.15e+00, For=3.31e+02, Power=6.81e-01
  [eval] val_mse=3.773e-01  (n=7000)
Epoch 00140: Time=  11.3s, Loss=3.15e+00, Inv=3.15e+00, For=3.39e+02, Power=6.81e-01
  [eval] val_mse=3.749e-01  (n=7000)
Epoch 00141: Time=  11.3s, Loss=3.15e+00, Inv=3.15e+00, For=3.45e+02, Power=6.81e-01
  [eval] val_mse=3.734e-01  (n=7000)
Epoch 00142: Time=  11.4s, Loss=3.15e+00, Inv=3.15e+00, For=3.45e+02, Power=6.81e-01
  [eval] val_mse=3.722e-01  (n=7000)
Epoch 00143: Time=  11.4s, Loss=3.14e+00, Inv=3.14e+00, For=3.49e+02, Power=6.80e-01
  [eval] val_mse=3.715e-01  (n=7000)
Epoch 00144: Time=  11.4s, Loss=3.14e+00, Inv=3.14e+00, For=3.57e+02, Power=6.81e-01
  [eval] val_mse=3.706e-01  (n=7000)
Epoch 00145: Time=  11.5s, Loss=3.13e+00, Inv=3.13e+00, For=3.55e+02, Power=6.80e-01
  [eval] val_mse=3.686e-01  (n=7000)
Epoch 00146: Time=  11.5s, Loss=3.13e+00, Inv=3.13e+00, For=3.62e+02, Power=6.80e-01
  [eval] val_mse=3.678e-01  (n=7000)
Epoch 00147: Time=  11.5s, Loss=3.12e+00, Inv=3.12e+00, For=3.66e+02, Power=6.79e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00148: Time=  11.6s, Loss=3.12e+00, Inv=3.12e+00, For=3.75e+02, Power=6.80e-01
  [eval] val_mse=3.662e-01  (n=7000)
Epoch 00149: Time=  11.6s, Loss=3.12e+00, Inv=3.12e+00, For=3.77e+02, Power=6.81e-01
  [eval] val_mse=3.649e-01  (n=7000)
Epoch 00150: Time=  11.7s, Loss=3.12e+00, Inv=3.12e+00, For=3.85e+02, Power=6.82e-01
  [eval] val_mse=3.649e-01  (n=7000)
Epoch 00151: Time=  11.7s, Loss=3.11e+00, Inv=3.11e+00, For=3.80e+02, Power=6.81e-01
  [eval] val_mse=3.624e-01  (n=7000)
Epoch 00152: Time=  11.7s, Loss=3.11e+00, Inv=3.11e+00, For=3.95e+02, Power=6.77e-01
  [eval] val_mse=3.617e-01  (n=7000)
Epoch 00153: Time=  11.8s, Loss=3.10e+00, Inv=3.10e+00, For=3.87e+02, Power=6.76e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00154: Time=  11.8s, Loss=3.10e+00, Inv=3.10e+00, For=4.04e+02, Power=6.79e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00155: Time=  11.9s, Loss=3.10e+00, Inv=3.10e+00, For=4.03e+02, Power=6.80e-01
  [eval] val_mse=3.589e-01  (n=7000)
Epoch 00156: Time=  11.9s, Loss=3.10e+00, Inv=3.10e+00, For=4.09e+02, Power=6.78e-01
  [eval] val_mse=3.588e-01  (n=7000)
Epoch 00157: Time=  11.9s, Loss=3.10e+00, Inv=3.10e+00, For=4.14e+02, Power=6.80e-01
  [eval] val_mse=3.576e-01  (n=7000)
Epoch 00158: Time=  12.0s, Loss=3.10e+00, Inv=3.10e+00, For=4.14e+02, Power=6.83e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00159: Time=  12.0s, Loss=3.09e+00, Inv=3.09e+00, For=4.18e+02, Power=6.83e-01
  [eval] val_mse=3.555e-01  (n=7000)
Epoch 00160: Time=  12.0s, Loss=3.09e+00, Inv=3.09e+00, For=4.30e+02, Power=6.81e-01
  [eval] val_mse=3.542e-01  (n=7000)
Epoch 00161: Time=  12.1s, Loss=3.09e+00, Inv=3.09e+00, For=4.25e+02, Power=6.81e-01
  [eval] val_mse=3.541e-01  (n=7000)
Epoch 00162: Time=  12.1s, Loss=3.09e+00, Inv=3.09e+00, For=4.41e+02, Power=6.81e-01
  [eval] val_mse=3.548e-01  (n=7000)
Epoch 00163: Time=  12.2s, Loss=3.08e+00, Inv=3.08e+00, For=4.34e+02, Power=6.79e-01
  [eval] val_mse=3.518e-01  (n=7000)
Epoch 00164: Time=  12.2s, Loss=3.08e+00, Inv=3.08e+00, For=4.52e+02, Power=6.82e-01
  [eval] val_mse=3.516e-01  (n=7000)
Epoch 00165: Time=  12.2s, Loss=3.08e+00, Inv=3.08e+00, For=4.53e+02, Power=6.82e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00166: Time=  12.3s, Loss=3.08e+00, Inv=3.08e+00, For=4.54e+02, Power=6.79e-01
  [eval] val_mse=3.504e-01  (n=7000)
Epoch 00167: Time=  12.3s, Loss=3.07e+00, Inv=3.07e+00, For=4.54e+02, Power=6.82e-01
  [eval] val_mse=3.497e-01  (n=7000)
Epoch 00168: Time=  12.4s, Loss=3.07e+00, Inv=3.07e+00, For=4.65e+02, Power=6.81e-01
  [eval] val_mse=3.481e-01  (n=7000)
Epoch 00169: Time=  12.4s, Loss=3.07e+00, Inv=3.07e+00, For=4.66e+02, Power=6.76e-01
  [eval] val_mse=3.476e-01  (n=7000)
Epoch 00170: Time=  12.4s, Loss=3.07e+00, Inv=3.07e+00, For=4.78e+02, Power=6.80e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00171: Time=  12.5s, Loss=3.07e+00, Inv=3.07e+00, For=4.82e+02, Power=6.81e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00172: Time=  12.5s, Loss=3.07e+00, Inv=3.07e+00, For=4.88e+02, Power=6.79e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00173: Time=  12.6s, Loss=3.06e+00, Inv=3.06e+00, For=4.85e+02, Power=6.76e-01
  [eval] val_mse=3.452e-01  (n=7000)
Epoch 00174: Time=  12.6s, Loss=3.06e+00, Inv=3.06e+00, For=4.93e+02, Power=6.81e-01
  [eval] val_mse=3.444e-01  (n=7000)
Epoch 00175: Time=  12.6s, Loss=3.06e+00, Inv=3.06e+00, For=5.04e+02, Power=6.83e-01
  [eval] val_mse=3.439e-01  (n=7000)
Epoch 00176: Time=  12.7s, Loss=3.06e+00, Inv=3.06e+00, For=4.98e+02, Power=6.83e-01
  [eval] val_mse=3.429e-01  (n=7000)
Epoch 00177: Time=  12.7s, Loss=3.05e+00, Inv=3.05e+00, For=5.09e+02, Power=6.80e-01
  [eval] val_mse=3.426e-01  (n=7000)
Epoch 00178: Time=  12.7s, Loss=3.05e+00, Inv=3.05e+00, For=5.24e+02, Power=6.80e-01
  [eval] val_mse=3.422e-01  (n=7000)
Epoch 00179: Time=  12.8s, Loss=3.05e+00, Inv=3.05e+00, For=5.27e+02, Power=6.81e-01
  [eval] val_mse=3.412e-01  (n=7000)
Epoch 00180: Time=  12.8s, Loss=3.05e+00, Inv=3.05e+00, For=5.25e+02, Power=6.82e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00181: Time=  12.9s, Loss=3.04e+00, Inv=3.04e+00, For=5.17e+02, Power=6.80e-01
  [eval] val_mse=3.399e-01  (n=7000)
Epoch 00182: Time=  12.9s, Loss=3.05e+00, Inv=3.05e+00, For=5.33e+02, Power=6.82e-01
  [eval] val_mse=3.399e-01  (n=7000)
Epoch 00183: Time=  13.0s, Loss=3.04e+00, Inv=3.04e+00, For=5.43e+02, Power=6.78e-01
  [eval] val_mse=3.389e-01  (n=7000)
Epoch 00184: Time=  13.0s, Loss=3.04e+00, Inv=3.04e+00, For=5.32e+02, Power=6.80e-01
  [eval] val_mse=3.385e-01  (n=7000)
Epoch 00185: Time=  13.0s, Loss=3.04e+00, Inv=3.04e+00, For=5.56e+02, Power=6.79e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00186: Time=  13.1s, Loss=3.03e+00, Inv=3.03e+00, For=5.71e+02, Power=6.81e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00187: Time=  13.1s, Loss=3.04e+00, Inv=3.04e+00, For=5.56e+02, Power=6.80e-01
  [eval] val_mse=3.377e-01  (n=7000)
Epoch 00188: Time=  13.1s, Loss=3.03e+00, Inv=3.03e+00, For=5.75e+02, Power=6.78e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00189: Time=  13.2s, Loss=3.03e+00, Inv=3.03e+00, For=5.73e+02, Power=6.77e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00190: Time=  13.2s, Loss=3.03e+00, Inv=3.03e+00, For=5.83e+02, Power=6.79e-01
  [eval] val_mse=3.355e-01  (n=7000)
Epoch 00191: Time=  13.3s, Loss=3.03e+00, Inv=3.03e+00, For=5.90e+02, Power=6.80e-01
  [eval] val_mse=3.352e-01  (n=7000)
Epoch 00192: Time=  13.3s, Loss=3.02e+00, Inv=3.02e+00, For=5.92e+02, Power=6.79e-01
  [eval] val_mse=3.355e-01  (n=7000)
Epoch 00193: Time=  13.3s, Loss=3.02e+00, Inv=3.02e+00, For=5.81e+02, Power=6.80e-01
  [eval] val_mse=3.346e-01  (n=7000)
Epoch 00194: Time=  13.4s, Loss=3.02e+00, Inv=3.02e+00, For=5.94e+02, Power=6.80e-01
  [eval] val_mse=3.343e-01  (n=7000)
Epoch 00195: Time=  13.4s, Loss=3.02e+00, Inv=3.02e+00, For=6.14e+02, Power=6.78e-01
  [eval] val_mse=3.336e-01  (n=7000)
Epoch 00196: Time=  13.5s, Loss=3.02e+00, Inv=3.02e+00, For=6.24e+02, Power=6.80e-01
  [eval] val_mse=3.328e-01  (n=7000)
Epoch 00197: Time=  13.5s, Loss=3.02e+00, Inv=3.02e+00, For=6.13e+02, Power=6.79e-01
  [eval] val_mse=3.335e-01  (n=7000)
Epoch 00198: Time=  13.5s, Loss=3.02e+00, Inv=3.02e+00, For=6.15e+02, Power=6.82e-01
  [eval] val_mse=3.318e-01  (n=7000)
Epoch 00199: Time=  13.6s, Loss=3.01e+00, Inv=3.01e+00, For=6.31e+02, Power=6.77e-01
  [eval] val_mse=3.323e-01  (n=7000)
Epoch 00200: Time=  13.6s, Loss=3.01e+00, Inv=3.01e+00, For=6.20e+02, Power=6.81e-01
  [eval] val_mse=3.315e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 2.351e-01
Torque MSE  = 6.816e-02
Torque RMSE = 2.611e-01
Per-joint MSE : 7.385e-02 1.637e-01 4.478e-02 2.100e-02 7.824e-02 2.741e-02
Per-joint RMSE: 2.718e-01 4.046e-01 2.116e-01 1.449e-01 2.797e-01 1.656e-01
Comp Time per Sample = 3.013e-04s / 3318.9Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-qpsks5yp because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x73384d6a28c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:58:53.934529: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:58:55.793883: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=2.38e+03, Inv=2.38e+03, For=5.71e+00, Power=4.63e+02
  [eval] val_mse=3.623e+01  (n=7000)
Epoch 00002: Time=   5.7s, Loss=1.37e+02, Inv=1.37e+02, For=5.32e+00, Power=2.88e+01
  [eval] val_mse=1.544e+01  (n=7000)
Epoch 00003: Time=   5.8s, Loss=6.78e+01, Inv=6.78e+01, For=5.12e+00, Power=1.31e+01
  [eval] val_mse=1.086e+01  (n=7000)
Epoch 00004: Time=   5.8s, Loss=4.54e+01, Inv=4.54e+01, For=5.12e+00, Power=8.05e+00
  [eval] val_mse=8.284e+00  (n=7000)
Epoch 00005: Time=   5.8s, Loss=3.34e+01, Inv=3.34e+01, For=5.25e+00, Power=5.62e+00
  [eval] val_mse=6.539e+00  (n=7000)
Epoch 00006: Time=   5.9s, Loss=2.57e+01, Inv=2.57e+01, For=5.41e+00, Power=4.15e+00
  [eval] val_mse=5.299e+00  (n=7000)
Epoch 00007: Time=   5.9s, Loss=2.08e+01, Inv=2.08e+01, For=5.68e+00, Power=3.23e+00
  [eval] val_mse=4.382e+00  (n=7000)
Epoch 00008: Time=   6.0s, Loss=1.73e+01, Inv=1.73e+01, For=6.03e+00, Power=2.63e+00
  [eval] val_mse=3.692e+00  (n=7000)
Epoch 00009: Time=   6.0s, Loss=1.47e+01, Inv=1.47e+01, For=6.47e+00, Power=2.19e+00
  [eval] val_mse=3.174e+00  (n=7000)
Epoch 00010: Time=   6.0s, Loss=1.29e+01, Inv=1.29e+01, For=6.95e+00, Power=1.89e+00
  [eval] val_mse=2.758e+00  (n=7000)
Epoch 00011: Time=   6.1s, Loss=1.14e+01, Inv=1.14e+01, For=7.45e+00, Power=1.67e+00
  [eval] val_mse=2.430e+00  (n=7000)
Epoch 00012: Time=   6.1s, Loss=1.03e+01, Inv=1.03e+01, For=8.00e+00, Power=1.50e+00
  [eval] val_mse=2.167e+00  (n=7000)
Epoch 00013: Time=   6.1s, Loss=9.36e+00, Inv=9.36e+00, For=8.61e+00, Power=1.36e+00
  [eval] val_mse=1.956e+00  (n=7000)
Epoch 00014: Time=   6.2s, Loss=8.63e+00, Inv=8.63e+00, For=9.15e+00, Power=1.26e+00
  [eval] val_mse=1.782e+00  (n=7000)
Epoch 00015: Time=   6.2s, Loss=8.02e+00, Inv=8.02e+00, For=9.71e+00, Power=1.18e+00
  [eval] val_mse=1.639e+00  (n=7000)
Epoch 00016: Time=   6.2s, Loss=7.52e+00, Inv=7.52e+00, For=1.03e+01, Power=1.11e+00
  [eval] val_mse=1.520e+00  (n=7000)
Epoch 00017: Time=   6.3s, Loss=7.08e+00, Inv=7.08e+00, For=1.08e+01, Power=1.05e+00
  [eval] val_mse=1.418e+00  (n=7000)
Epoch 00018: Time=   6.3s, Loss=6.72e+00, Inv=6.72e+00, For=1.13e+01, Power=1.01e+00
  [eval] val_mse=1.334e+00  (n=7000)
Epoch 00019: Time=   6.3s, Loss=6.43e+00, Inv=6.43e+00, For=1.19e+01, Power=9.77e-01
  [eval] val_mse=1.261e+00  (n=7000)
Epoch 00020: Time=   6.4s, Loss=6.15e+00, Inv=6.15e+00, For=1.24e+01, Power=9.46e-01
  [eval] val_mse=1.195e+00  (n=7000)
Epoch 00021: Time=   6.4s, Loss=5.92e+00, Inv=5.92e+00, For=1.30e+01, Power=9.16e-01
  [eval] val_mse=1.139e+00  (n=7000)
Epoch 00022: Time=   6.4s, Loss=5.73e+00, Inv=5.73e+00, For=1.36e+01, Power=8.96e-01
  [eval] val_mse=1.088e+00  (n=7000)
Epoch 00023: Time=   6.5s, Loss=5.55e+00, Inv=5.55e+00, For=1.41e+01, Power=8.76e-01
  [eval] val_mse=1.043e+00  (n=7000)
Epoch 00024: Time=   6.5s, Loss=5.41e+00, Inv=5.41e+00, For=1.47e+01, Power=8.62e-01
  [eval] val_mse=9.989e-01  (n=7000)
Epoch 00025: Time=   6.5s, Loss=5.25e+00, Inv=5.25e+00, For=1.54e+01, Power=8.46e-01
  [eval] val_mse=9.636e-01  (n=7000)
Epoch 00026: Time=   6.6s, Loss=5.13e+00, Inv=5.13e+00, For=1.59e+01, Power=8.29e-01
  [eval] val_mse=9.291e-01  (n=7000)
Epoch 00027: Time=   6.6s, Loss=5.01e+00, Inv=5.01e+00, For=1.64e+01, Power=8.17e-01
  [eval] val_mse=8.991e-01  (n=7000)
Epoch 00028: Time=   6.6s, Loss=4.91e+00, Inv=4.91e+00, For=1.73e+01, Power=8.11e-01
  [eval] val_mse=8.711e-01  (n=7000)
Epoch 00029: Time=   6.7s, Loss=4.82e+00, Inv=4.82e+00, For=1.79e+01, Power=8.02e-01
  [eval] val_mse=8.434e-01  (n=7000)
Epoch 00030: Time=   6.7s, Loss=4.73e+00, Inv=4.73e+00, For=1.86e+01, Power=7.94e-01
  [eval] val_mse=8.178e-01  (n=7000)
Epoch 00031: Time=   6.7s, Loss=4.65e+00, Inv=4.65e+00, For=1.93e+01, Power=7.86e-01
  [eval] val_mse=7.979e-01  (n=7000)
Epoch 00032: Time=   6.8s, Loss=4.58e+00, Inv=4.58e+00, For=1.99e+01, Power=7.85e-01
  [eval] val_mse=7.754e-01  (n=7000)
Epoch 00033: Time=   6.8s, Loss=4.51e+00, Inv=4.51e+00, For=2.05e+01, Power=7.76e-01
  [eval] val_mse=7.557e-01  (n=7000)
Epoch 00034: Time=   6.8s, Loss=4.43e+00, Inv=4.43e+00, For=2.12e+01, Power=7.64e-01
  [eval] val_mse=7.369e-01  (n=7000)
Epoch 00035: Time=   6.9s, Loss=4.38e+00, Inv=4.38e+00, For=2.22e+01, Power=7.69e-01
  [eval] val_mse=7.201e-01  (n=7000)
Epoch 00036: Time=   6.9s, Loss=4.31e+00, Inv=4.31e+00, For=2.26e+01, Power=7.59e-01
  [eval] val_mse=7.043e-01  (n=7000)
Epoch 00037: Time=   6.9s, Loss=4.27e+00, Inv=4.27e+00, For=2.35e+01, Power=7.58e-01
  [eval] val_mse=6.904e-01  (n=7000)
Epoch 00038: Time=   7.0s, Loss=4.21e+00, Inv=4.21e+00, For=2.42e+01, Power=7.54e-01
  [eval] val_mse=6.748e-01  (n=7000)
Epoch 00039: Time=   7.0s, Loss=4.17e+00, Inv=4.17e+00, For=2.51e+01, Power=7.49e-01
  [eval] val_mse=6.623e-01  (n=7000)
Epoch 00040: Time=   7.0s, Loss=4.12e+00, Inv=4.12e+00, For=2.58e+01, Power=7.48e-01
  [eval] val_mse=6.485e-01  (n=7000)
Epoch 00041: Time=   7.1s, Loss=4.08e+00, Inv=4.08e+00, For=2.66e+01, Power=7.45e-01
  [eval] val_mse=6.384e-01  (n=7000)
Epoch 00042: Time=   7.1s, Loss=4.04e+00, Inv=4.04e+00, For=2.74e+01, Power=7.42e-01
  [eval] val_mse=6.273e-01  (n=7000)
Epoch 00043: Time=   7.1s, Loss=4.00e+00, Inv=4.00e+00, For=2.80e+01, Power=7.40e-01
  [eval] val_mse=6.153e-01  (n=7000)
Epoch 00044: Time=   7.2s, Loss=3.96e+00, Inv=3.96e+00, For=2.92e+01, Power=7.33e-01
  [eval] val_mse=6.055e-01  (n=7000)
Epoch 00045: Time=   7.2s, Loss=3.93e+00, Inv=3.93e+00, For=2.97e+01, Power=7.34e-01
  [eval] val_mse=5.968e-01  (n=7000)
Epoch 00046: Time=   7.2s, Loss=3.89e+00, Inv=3.89e+00, For=3.08e+01, Power=7.30e-01
  [eval] val_mse=5.880e-01  (n=7000)
Epoch 00047: Time=   7.3s, Loss=3.86e+00, Inv=3.86e+00, For=3.18e+01, Power=7.28e-01
  [eval] val_mse=5.790e-01  (n=7000)
Epoch 00048: Time=   7.3s, Loss=3.83e+00, Inv=3.83e+00, For=3.22e+01, Power=7.29e-01
  [eval] val_mse=5.715e-01  (n=7000)
Epoch 00049: Time=   7.3s, Loss=3.81e+00, Inv=3.81e+00, For=3.36e+01, Power=7.26e-01
  [eval] val_mse=5.629e-01  (n=7000)
Epoch 00050: Time=   7.4s, Loss=3.78e+00, Inv=3.78e+00, For=3.40e+01, Power=7.25e-01
  [eval] val_mse=5.562e-01  (n=7000)
Epoch 00051: Time=   7.4s, Loss=3.76e+00, Inv=3.76e+00, For=3.49e+01, Power=7.20e-01
  [eval] val_mse=5.479e-01  (n=7000)
Epoch 00052: Time=   7.4s, Loss=3.73e+00, Inv=3.73e+00, For=3.61e+01, Power=7.22e-01
  [eval] val_mse=5.420e-01  (n=7000)
Epoch 00053: Time=   7.5s, Loss=3.71e+00, Inv=3.71e+00, For=3.63e+01, Power=7.19e-01
  [eval] val_mse=5.345e-01  (n=7000)
Epoch 00054: Time=   7.5s, Loss=3.69e+00, Inv=3.69e+00, For=3.81e+01, Power=7.17e-01
  [eval] val_mse=5.305e-01  (n=7000)
Epoch 00055: Time=   7.5s, Loss=3.67e+00, Inv=3.67e+00, For=3.89e+01, Power=7.19e-01
  [eval] val_mse=5.226e-01  (n=7000)
Epoch 00056: Time=   7.6s, Loss=3.65e+00, Inv=3.65e+00, For=3.96e+01, Power=7.13e-01
  [eval] val_mse=5.173e-01  (n=7000)
Epoch 00057: Time=   7.6s, Loss=3.63e+00, Inv=3.63e+00, For=4.00e+01, Power=7.15e-01
  [eval] val_mse=5.106e-01  (n=7000)
Epoch 00058: Time=   7.6s, Loss=3.61e+00, Inv=3.61e+00, For=4.17e+01, Power=7.11e-01
  [eval] val_mse=5.052e-01  (n=7000)
Epoch 00059: Time=   7.7s, Loss=3.59e+00, Inv=3.59e+00, For=4.10e+01, Power=7.09e-01
  [eval] val_mse=5.001e-01  (n=7000)
Epoch 00060: Time=   7.7s, Loss=3.58e+00, Inv=3.58e+00, For=4.31e+01, Power=7.10e-01
  [eval] val_mse=4.959e-01  (n=7000)
Epoch 00061: Time=   7.7s, Loss=3.57e+00, Inv=3.57e+00, For=4.43e+01, Power=7.05e-01
  [eval] val_mse=4.897e-01  (n=7000)
Epoch 00062: Time=   7.8s, Loss=3.55e+00, Inv=3.55e+00, For=4.48e+01, Power=7.06e-01
  [eval] val_mse=4.854e-01  (n=7000)
Epoch 00063: Time=   7.8s, Loss=3.54e+00, Inv=3.54e+00, For=4.56e+01, Power=7.08e-01
  [eval] val_mse=4.808e-01  (n=7000)
Epoch 00064: Time=   7.8s, Loss=3.52e+00, Inv=3.52e+00, For=4.64e+01, Power=7.04e-01
  [eval] val_mse=4.766e-01  (n=7000)
Epoch 00065: Time=   7.9s, Loss=3.51e+00, Inv=3.51e+00, For=4.75e+01, Power=7.05e-01
  [eval] val_mse=4.723e-01  (n=7000)
Epoch 00066: Time=   7.9s, Loss=3.50e+00, Inv=3.50e+00, For=4.78e+01, Power=7.06e-01
  [eval] val_mse=4.681e-01  (n=7000)
Epoch 00067: Time=   7.9s, Loss=3.48e+00, Inv=3.48e+00, For=4.84e+01, Power=7.01e-01
  [eval] val_mse=4.632e-01  (n=7000)
Epoch 00068: Time=   8.0s, Loss=3.48e+00, Inv=3.48e+00, For=4.97e+01, Power=7.03e-01
  [eval] val_mse=4.608e-01  (n=7000)
Epoch 00069: Time=   8.0s, Loss=3.46e+00, Inv=3.46e+00, For=5.08e+01, Power=7.00e-01
  [eval] val_mse=4.568e-01  (n=7000)
Epoch 00070: Time=   8.0s, Loss=3.45e+00, Inv=3.45e+00, For=5.12e+01, Power=6.98e-01
  [eval] val_mse=4.530e-01  (n=7000)
Epoch 00071: Time=   8.1s, Loss=3.44e+00, Inv=3.44e+00, For=5.22e+01, Power=7.00e-01
  [eval] val_mse=4.497e-01  (n=7000)
Epoch 00072: Time=   8.1s, Loss=3.43e+00, Inv=3.43e+00, For=5.33e+01, Power=6.97e-01
  [eval] val_mse=4.458e-01  (n=7000)
Epoch 00073: Time=   8.1s, Loss=3.42e+00, Inv=3.42e+00, For=5.42e+01, Power=7.00e-01
  [eval] val_mse=4.422e-01  (n=7000)
Epoch 00074: Time=   8.2s, Loss=3.41e+00, Inv=3.41e+00, For=5.46e+01, Power=6.96e-01
  [eval] val_mse=4.394e-01  (n=7000)
Epoch 00075: Time=   8.2s, Loss=3.40e+00, Inv=3.40e+00, For=5.48e+01, Power=6.96e-01
  [eval] val_mse=4.363e-01  (n=7000)
Epoch 00076: Time=   8.2s, Loss=3.39e+00, Inv=3.39e+00, For=5.81e+01, Power=6.96e-01
  [eval] val_mse=4.333e-01  (n=7000)
Epoch 00077: Time=   8.3s, Loss=3.38e+00, Inv=3.38e+00, For=5.74e+01, Power=6.93e-01
  [eval] val_mse=4.302e-01  (n=7000)
Epoch 00078: Time=   8.3s, Loss=3.38e+00, Inv=3.38e+00, For=5.79e+01, Power=6.96e-01
  [eval] val_mse=4.275e-01  (n=7000)
Epoch 00079: Time=   8.3s, Loss=3.37e+00, Inv=3.37e+00, For=5.97e+01, Power=6.96e-01
  [eval] val_mse=4.255e-01  (n=7000)
Epoch 00080: Time=   8.4s, Loss=3.36e+00, Inv=3.36e+00, For=5.88e+01, Power=6.96e-01
  [eval] val_mse=4.224e-01  (n=7000)
Epoch 00081: Time=   8.4s, Loss=3.36e+00, Inv=3.36e+00, For=6.18e+01, Power=6.94e-01
  [eval] val_mse=4.202e-01  (n=7000)
Epoch 00082: Time=   8.4s, Loss=3.34e+00, Inv=3.34e+00, For=6.20e+01, Power=6.91e-01
  [eval] val_mse=4.180e-01  (n=7000)
Epoch 00083: Time=   8.5s, Loss=3.33e+00, Inv=3.33e+00, For=6.15e+01, Power=6.88e-01
  [eval] val_mse=4.146e-01  (n=7000)
Epoch 00084: Time=   8.5s, Loss=3.33e+00, Inv=3.33e+00, For=6.42e+01, Power=6.91e-01
  [eval] val_mse=4.137e-01  (n=7000)
Epoch 00085: Time=   8.5s, Loss=3.32e+00, Inv=3.32e+00, For=6.49e+01, Power=6.90e-01
  [eval] val_mse=4.111e-01  (n=7000)
Epoch 00086: Time=   8.6s, Loss=3.32e+00, Inv=3.32e+00, For=6.48e+01, Power=6.90e-01
  [eval] val_mse=4.084e-01  (n=7000)
Epoch 00087: Time=   8.6s, Loss=3.31e+00, Inv=3.31e+00, For=6.54e+01, Power=6.91e-01
  [eval] val_mse=4.064e-01  (n=7000)
Epoch 00088: Time=   8.6s, Loss=3.30e+00, Inv=3.30e+00, For=6.64e+01, Power=6.88e-01
  [eval] val_mse=4.043e-01  (n=7000)
Epoch 00089: Time=   8.7s, Loss=3.30e+00, Inv=3.30e+00, For=6.88e+01, Power=6.89e-01
  [eval] val_mse=4.029e-01  (n=7000)
Epoch 00090: Time=   8.7s, Loss=3.28e+00, Inv=3.28e+00, For=6.86e+01, Power=6.90e-01
  [eval] val_mse=4.008e-01  (n=7000)
Epoch 00091: Time=   8.7s, Loss=3.28e+00, Inv=3.28e+00, For=6.99e+01, Power=6.91e-01
  [eval] val_mse=3.987e-01  (n=7000)
Epoch 00092: Time=   8.8s, Loss=3.28e+00, Inv=3.28e+00, For=7.16e+01, Power=6.87e-01
  [eval] val_mse=3.968e-01  (n=7000)
Epoch 00093: Time=   8.8s, Loss=3.27e+00, Inv=3.27e+00, For=7.12e+01, Power=6.88e-01
  [eval] val_mse=3.963e-01  (n=7000)
Epoch 00094: Time=   8.9s, Loss=3.27e+00, Inv=3.27e+00, For=7.29e+01, Power=6.89e-01
  [eval] val_mse=3.935e-01  (n=7000)
Epoch 00095: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=7.42e+01, Power=6.88e-01
  [eval] val_mse=3.934e-01  (n=7000)
Epoch 00096: Time=   8.9s, Loss=3.26e+00, Inv=3.26e+00, For=7.43e+01, Power=6.90e-01
  [eval] val_mse=3.915e-01  (n=7000)
Epoch 00097: Time=   9.0s, Loss=3.25e+00, Inv=3.25e+00, For=7.51e+01, Power=6.87e-01
  [eval] val_mse=3.894e-01  (n=7000)
Epoch 00098: Time=   9.0s, Loss=3.24e+00, Inv=3.24e+00, For=7.73e+01, Power=6.87e-01
  [eval] val_mse=3.879e-01  (n=7000)
Epoch 00099: Time=   9.0s, Loss=3.24e+00, Inv=3.24e+00, For=7.75e+01, Power=6.85e-01
  [eval] val_mse=3.868e-01  (n=7000)
Epoch 00100: Time=   9.1s, Loss=3.23e+00, Inv=3.23e+00, For=7.84e+01, Power=6.85e-01
  [eval] val_mse=3.853e-01  (n=7000)
Epoch 00101: Time=   9.1s, Loss=3.23e+00, Inv=3.23e+00, For=7.98e+01, Power=6.86e-01
  [eval] val_mse=3.841e-01  (n=7000)
Epoch 00102: Time=   9.1s, Loss=3.22e+00, Inv=3.22e+00, For=8.03e+01, Power=6.81e-01
  [eval] val_mse=3.826e-01  (n=7000)
Epoch 00103: Time=   9.2s, Loss=3.22e+00, Inv=3.22e+00, For=8.19e+01, Power=6.88e-01
  [eval] val_mse=3.817e-01  (n=7000)
Epoch 00104: Time=   9.2s, Loss=3.22e+00, Inv=3.22e+00, For=8.23e+01, Power=6.87e-01
  [eval] val_mse=3.812e-01  (n=7000)
Epoch 00105: Time=   9.2s, Loss=3.21e+00, Inv=3.21e+00, For=8.45e+01, Power=6.83e-01
  [eval] val_mse=3.795e-01  (n=7000)
Epoch 00106: Time=   9.3s, Loss=3.21e+00, Inv=3.21e+00, For=8.44e+01, Power=6.81e-01
  [eval] val_mse=3.783e-01  (n=7000)
Epoch 00107: Time=   9.3s, Loss=3.21e+00, Inv=3.21e+00, For=8.54e+01, Power=6.85e-01
  [eval] val_mse=3.775e-01  (n=7000)
Epoch 00108: Time=   9.3s, Loss=3.20e+00, Inv=3.20e+00, For=8.78e+01, Power=6.85e-01
  [eval] val_mse=3.760e-01  (n=7000)
Epoch 00109: Time=   9.4s, Loss=3.19e+00, Inv=3.19e+00, For=8.84e+01, Power=6.84e-01
  [eval] val_mse=3.750e-01  (n=7000)
Epoch 00110: Time=   9.4s, Loss=3.19e+00, Inv=3.19e+00, For=8.78e+01, Power=6.83e-01
  [eval] val_mse=3.743e-01  (n=7000)
Epoch 00111: Time=   9.4s, Loss=3.19e+00, Inv=3.19e+00, For=9.06e+01, Power=6.87e-01
  [eval] val_mse=3.732e-01  (n=7000)
Epoch 00112: Time=   9.5s, Loss=3.18e+00, Inv=3.18e+00, For=9.18e+01, Power=6.85e-01
  [eval] val_mse=3.725e-01  (n=7000)
Epoch 00113: Time=   9.5s, Loss=3.19e+00, Inv=3.19e+00, For=9.28e+01, Power=6.85e-01
  [eval] val_mse=3.718e-01  (n=7000)
Epoch 00114: Time=   9.5s, Loss=3.17e+00, Inv=3.17e+00, For=9.44e+01, Power=6.83e-01
  [eval] val_mse=3.710e-01  (n=7000)
Epoch 00115: Time=   9.6s, Loss=3.17e+00, Inv=3.17e+00, For=9.56e+01, Power=6.83e-01
  [eval] val_mse=3.705e-01  (n=7000)
Epoch 00116: Time=   9.6s, Loss=3.17e+00, Inv=3.17e+00, For=9.46e+01, Power=6.83e-01
  [eval] val_mse=3.691e-01  (n=7000)
Epoch 00117: Time=   9.6s, Loss=3.16e+00, Inv=3.16e+00, For=9.77e+01, Power=6.81e-01
  [eval] val_mse=3.684e-01  (n=7000)
Epoch 00118: Time=   9.7s, Loss=3.15e+00, Inv=3.15e+00, For=9.86e+01, Power=6.80e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00119: Time=   9.7s, Loss=3.15e+00, Inv=3.15e+00, For=9.93e+01, Power=6.81e-01
  [eval] val_mse=3.675e-01  (n=7000)
Epoch 00120: Time=   9.7s, Loss=3.15e+00, Inv=3.15e+00, For=1.00e+02, Power=6.79e-01
  [eval] val_mse=3.666e-01  (n=7000)
Epoch 00121: Time=   9.8s, Loss=3.15e+00, Inv=3.15e+00, For=1.04e+02, Power=6.81e-01
  [eval] val_mse=3.656e-01  (n=7000)
Epoch 00122: Time=   9.8s, Loss=3.15e+00, Inv=3.15e+00, For=1.03e+02, Power=6.84e-01
  [eval] val_mse=3.641e-01  (n=7000)
Epoch 00123: Time=   9.8s, Loss=3.14e+00, Inv=3.14e+00, For=1.04e+02, Power=6.84e-01
  [eval] val_mse=3.639e-01  (n=7000)
Epoch 00124: Time=   9.9s, Loss=3.14e+00, Inv=3.14e+00, For=1.06e+02, Power=6.82e-01
  [eval] val_mse=3.637e-01  (n=7000)
Epoch 00125: Time=   9.9s, Loss=3.13e+00, Inv=3.13e+00, For=1.08e+02, Power=6.83e-01
  [eval] val_mse=3.630e-01  (n=7000)
Epoch 00126: Time=   9.9s, Loss=3.13e+00, Inv=3.13e+00, For=1.08e+02, Power=6.82e-01
  [eval] val_mse=3.611e-01  (n=7000)
Epoch 00127: Time=  10.0s, Loss=3.12e+00, Inv=3.12e+00, For=1.10e+02, Power=6.80e-01
  [eval] val_mse=3.614e-01  (n=7000)
Epoch 00128: Time=  10.0s, Loss=3.12e+00, Inv=3.12e+00, For=1.12e+02, Power=6.80e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00129: Time=  10.0s, Loss=3.12e+00, Inv=3.12e+00, For=1.12e+02, Power=6.81e-01
  [eval] val_mse=3.591e-01  (n=7000)
Epoch 00130: Time=  10.1s, Loss=3.12e+00, Inv=3.12e+00, For=1.15e+02, Power=6.80e-01
  [eval] val_mse=3.591e-01  (n=7000)
Epoch 00131: Time=  10.1s, Loss=3.12e+00, Inv=3.12e+00, For=1.15e+02, Power=6.83e-01
  [eval] val_mse=3.578e-01  (n=7000)
Epoch 00132: Time=  10.1s, Loss=3.11e+00, Inv=3.11e+00, For=1.17e+02, Power=6.82e-01
  [eval] val_mse=3.573e-01  (n=7000)
Epoch 00133: Time=  10.2s, Loss=3.11e+00, Inv=3.11e+00, For=1.19e+02, Power=6.81e-01
  [eval] val_mse=3.571e-01  (n=7000)
Epoch 00134: Time=  10.2s, Loss=3.11e+00, Inv=3.11e+00, For=1.20e+02, Power=6.80e-01
  [eval] val_mse=3.570e-01  (n=7000)
Epoch 00135: Time=  10.2s, Loss=3.11e+00, Inv=3.11e+00, For=1.20e+02, Power=6.81e-01
  [eval] val_mse=3.558e-01  (n=7000)
Epoch 00136: Time=  10.3s, Loss=3.10e+00, Inv=3.10e+00, For=1.24e+02, Power=6.83e-01
  [eval] val_mse=3.556e-01  (n=7000)
Epoch 00137: Time=  10.3s, Loss=3.10e+00, Inv=3.10e+00, For=1.23e+02, Power=6.81e-01
  [eval] val_mse=3.548e-01  (n=7000)
Epoch 00138: Time=  10.3s, Loss=3.10e+00, Inv=3.10e+00, For=1.24e+02, Power=6.79e-01
  [eval] val_mse=3.539e-01  (n=7000)
Epoch 00139: Time=  10.4s, Loss=3.09e+00, Inv=3.09e+00, For=1.26e+02, Power=6.79e-01
  [eval] val_mse=3.538e-01  (n=7000)
Epoch 00140: Time=  10.4s, Loss=3.09e+00, Inv=3.09e+00, For=1.29e+02, Power=6.80e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00141: Time=  10.4s, Loss=3.09e+00, Inv=3.09e+00, For=1.29e+02, Power=6.81e-01
  [eval] val_mse=3.537e-01  (n=7000)
Epoch 00142: Time=  10.5s, Loss=3.09e+00, Inv=3.09e+00, For=1.31e+02, Power=6.83e-01
  [eval] val_mse=3.523e-01  (n=7000)
Epoch 00143: Time=  10.5s, Loss=3.08e+00, Inv=3.08e+00, For=1.31e+02, Power=6.82e-01
  [eval] val_mse=3.517e-01  (n=7000)
Epoch 00144: Time=  10.5s, Loss=3.08e+00, Inv=3.08e+00, For=1.34e+02, Power=6.82e-01
  [eval] val_mse=3.511e-01  (n=7000)
Epoch 00145: Time=  10.6s, Loss=3.08e+00, Inv=3.08e+00, For=1.34e+02, Power=6.85e-01
  [eval] val_mse=3.502e-01  (n=7000)
Epoch 00146: Time=  10.6s, Loss=3.07e+00, Inv=3.07e+00, For=1.38e+02, Power=6.78e-01
  [eval] val_mse=3.502e-01  (n=7000)
Epoch 00147: Time=  10.6s, Loss=3.07e+00, Inv=3.07e+00, For=1.38e+02, Power=6.82e-01
  [eval] val_mse=3.503e-01  (n=7000)
Epoch 00148: Time=  10.7s, Loss=3.07e+00, Inv=3.07e+00, For=1.40e+02, Power=6.81e-01
  [eval] val_mse=3.489e-01  (n=7000)
Epoch 00149: Time=  10.7s, Loss=3.08e+00, Inv=3.08e+00, For=1.40e+02, Power=6.80e-01
  [eval] val_mse=3.483e-01  (n=7000)
Epoch 00150: Time=  10.7s, Loss=3.07e+00, Inv=3.07e+00, For=1.45e+02, Power=6.80e-01
  [eval] val_mse=3.478e-01  (n=7000)
Epoch 00151: Time=  10.8s, Loss=3.07e+00, Inv=3.07e+00, For=1.44e+02, Power=6.81e-01
  [eval] val_mse=3.485e-01  (n=7000)
Epoch 00152: Time=  10.8s, Loss=3.06e+00, Inv=3.06e+00, For=1.45e+02, Power=6.80e-01
  [eval] val_mse=3.476e-01  (n=7000)
Epoch 00153: Time=  10.8s, Loss=3.06e+00, Inv=3.06e+00, For=1.44e+02, Power=6.79e-01
  [eval] val_mse=3.465e-01  (n=7000)
Epoch 00154: Time=  10.9s, Loss=3.06e+00, Inv=3.06e+00, For=1.48e+02, Power=6.82e-01
  [eval] val_mse=3.468e-01  (n=7000)
Epoch 00155: Time=  10.9s, Loss=3.06e+00, Inv=3.06e+00, For=1.49e+02, Power=6.80e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00156: Time=  11.0s, Loss=3.05e+00, Inv=3.05e+00, For=1.49e+02, Power=6.82e-01
  [eval] val_mse=3.455e-01  (n=7000)
Epoch 00157: Time=  11.0s, Loss=3.05e+00, Inv=3.05e+00, For=1.53e+02, Power=6.80e-01
  [eval] val_mse=3.461e-01  (n=7000)
Epoch 00158: Time=  11.0s, Loss=3.04e+00, Inv=3.04e+00, For=1.51e+02, Power=6.79e-01
  [eval] val_mse=3.449e-01  (n=7000)
Epoch 00159: Time=  11.1s, Loss=3.05e+00, Inv=3.05e+00, For=1.55e+02, Power=6.82e-01
  [eval] val_mse=3.442e-01  (n=7000)
Epoch 00160: Time=  11.1s, Loss=3.04e+00, Inv=3.04e+00, For=1.55e+02, Power=6.80e-01
  [eval] val_mse=3.435e-01  (n=7000)
Epoch 00161: Time=  11.1s, Loss=3.04e+00, Inv=3.04e+00, For=1.58e+02, Power=6.81e-01
  [eval] val_mse=3.432e-01  (n=7000)
Epoch 00162: Time=  11.2s, Loss=3.05e+00, Inv=3.05e+00, For=1.57e+02, Power=6.81e-01
  [eval] val_mse=3.439e-01  (n=7000)
Epoch 00163: Time=  11.2s, Loss=3.04e+00, Inv=3.04e+00, For=1.59e+02, Power=6.81e-01
  [eval] val_mse=3.431e-01  (n=7000)
Epoch 00164: Time=  11.2s, Loss=3.04e+00, Inv=3.04e+00, For=1.61e+02, Power=6.81e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00165: Time=  11.3s, Loss=3.04e+00, Inv=3.04e+00, For=1.60e+02, Power=6.82e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00166: Time=  11.3s, Loss=3.04e+00, Inv=3.04e+00, For=1.62e+02, Power=6.80e-01
  [eval] val_mse=3.417e-01  (n=7000)
Epoch 00167: Time=  11.3s, Loss=3.03e+00, Inv=3.03e+00, For=1.65e+02, Power=6.82e-01
  [eval] val_mse=3.407e-01  (n=7000)
Epoch 00168: Time=  11.4s, Loss=3.03e+00, Inv=3.03e+00, For=1.64e+02, Power=6.81e-01
  [eval] val_mse=3.415e-01  (n=7000)
Epoch 00169: Time=  11.4s, Loss=3.03e+00, Inv=3.03e+00, For=1.68e+02, Power=6.82e-01
  [eval] val_mse=3.403e-01  (n=7000)
Epoch 00170: Time=  11.4s, Loss=3.03e+00, Inv=3.03e+00, For=1.67e+02, Power=6.82e-01
  [eval] val_mse=3.423e-01  (n=7000)
Epoch 00171: Time=  11.5s, Loss=3.03e+00, Inv=3.03e+00, For=1.67e+02, Power=6.83e-01
  [eval] val_mse=3.404e-01  (n=7000)
Epoch 00172: Time=  11.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.70e+02, Power=6.82e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00173: Time=  11.5s, Loss=3.02e+00, Inv=3.02e+00, For=1.71e+02, Power=6.81e-01
  [eval] val_mse=3.390e-01  (n=7000)
Epoch 00174: Time=  11.6s, Loss=3.03e+00, Inv=3.03e+00, For=1.72e+02, Power=6.82e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00175: Time=  11.6s, Loss=3.02e+00, Inv=3.02e+00, For=1.71e+02, Power=6.80e-01
  [eval] val_mse=3.383e-01  (n=7000)
Epoch 00176: Time=  11.6s, Loss=3.02e+00, Inv=3.02e+00, For=1.75e+02, Power=6.82e-01
  [eval] val_mse=3.388e-01  (n=7000)
Epoch 00177: Time=  11.7s, Loss=3.02e+00, Inv=3.02e+00, For=1.75e+02, Power=6.79e-01
  [eval] val_mse=3.375e-01  (n=7000)
Epoch 00178: Time=  11.7s, Loss=3.01e+00, Inv=3.01e+00, For=1.74e+02, Power=6.82e-01
  [eval] val_mse=3.380e-01  (n=7000)
Epoch 00179: Time=  11.7s, Loss=3.01e+00, Inv=3.01e+00, For=1.76e+02, Power=6.79e-01
  [eval] val_mse=3.369e-01  (n=7000)
Epoch 00180: Time=  11.8s, Loss=3.01e+00, Inv=3.01e+00, For=1.77e+02, Power=6.79e-01
  [eval] val_mse=3.374e-01  (n=7000)
Epoch 00181: Time=  11.8s, Loss=3.01e+00, Inv=3.01e+00, For=1.77e+02, Power=6.80e-01
  [eval] val_mse=3.371e-01  (n=7000)
Epoch 00182: Time=  11.8s, Loss=3.01e+00, Inv=3.01e+00, For=1.80e+02, Power=6.77e-01
  [eval] val_mse=3.364e-01  (n=7000)
Epoch 00183: Time=  11.9s, Loss=3.01e+00, Inv=3.01e+00, For=1.80e+02, Power=6.76e-01
  [eval] val_mse=3.364e-01  (n=7000)
Epoch 00184: Time=  11.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.80e+02, Power=6.78e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00185: Time=  11.9s, Loss=3.00e+00, Inv=3.00e+00, For=1.82e+02, Power=6.80e-01
  [eval] val_mse=3.361e-01  (n=7000)
Epoch 00186: Time=  12.0s, Loss=3.01e+00, Inv=3.01e+00, For=1.85e+02, Power=6.84e-01
  [eval] val_mse=3.359e-01  (n=7000)
Epoch 00187: Time=  12.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.83e+02, Power=6.80e-01
  [eval] val_mse=3.354e-01  (n=7000)
Epoch 00188: Time=  12.0s, Loss=3.00e+00, Inv=3.00e+00, For=1.84e+02, Power=6.80e-01
  [eval] val_mse=3.363e-01  (n=7000)
Epoch 00189: Time=  12.1s, Loss=2.99e+00, Inv=2.99e+00, For=1.83e+02, Power=6.79e-01
  [eval] val_mse=3.342e-01  (n=7000)
Epoch 00190: Time=  12.1s, Loss=3.00e+00, Inv=3.00e+00, For=1.83e+02, Power=6.82e-01
  [eval] val_mse=3.341e-01  (n=7000)
Epoch 00191: Time=  12.1s, Loss=2.99e+00, Inv=2.99e+00, For=1.87e+02, Power=6.81e-01
  [eval] val_mse=3.339e-01  (n=7000)
Epoch 00192: Time=  12.2s, Loss=2.99e+00, Inv=2.99e+00, For=1.83e+02, Power=6.81e-01
  [eval] val_mse=3.334e-01  (n=7000)
Epoch 00193: Time=  12.2s, Loss=3.00e+00, Inv=3.00e+00, For=1.87e+02, Power=6.80e-01
  [eval] val_mse=3.335e-01  (n=7000)
Epoch 00194: Time=  12.3s, Loss=2.99e+00, Inv=2.99e+00, For=1.90e+02, Power=6.82e-01
  [eval] val_mse=3.329e-01  (n=7000)
Epoch 00195: Time=  12.3s, Loss=2.99e+00, Inv=2.99e+00, For=1.86e+02, Power=6.83e-01
  [eval] val_mse=3.332e-01  (n=7000)
Epoch 00196: Time=  12.3s, Loss=3.00e+00, Inv=3.00e+00, For=1.91e+02, Power=6.81e-01
  [eval] val_mse=3.324e-01  (n=7000)
Epoch 00197: Time=  12.4s, Loss=3.00e+00, Inv=3.00e+00, For=1.92e+02, Power=6.85e-01
  [eval] val_mse=3.326e-01  (n=7000)
Epoch 00198: Time=  12.4s, Loss=2.99e+00, Inv=2.99e+00, For=1.89e+02, Power=6.83e-01
  [eval] val_mse=3.321e-01  (n=7000)
Epoch 00199: Time=  12.4s, Loss=2.98e+00, Inv=2.98e+00, For=1.88e+02, Power=6.80e-01
  [eval] val_mse=3.316e-01  (n=7000)
Epoch 00200: Time=  12.5s, Loss=2.98e+00, Inv=2.98e+00, For=1.89e+02, Power=6.79e-01
  [eval] val_mse=3.314e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 2.350e-01
Torque MSE  = 1.207e-01
Torque RMSE = 3.474e-01
Per-joint MSE : 7.767e-02 4.428e-01 4.605e-02 2.727e-02 1.103e-01 2.003e-02
Per-joint RMSE: 2.787e-01 6.654e-01 2.146e-01 1.651e-01 3.321e-01 1.415e-01
Comp Time per Sample = 2.918e-04s / 3426.7Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-apj6mdlk because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x72ec342ae8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:59:16.403856: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:59:18.312761: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.0s, Loss=5.45e+03, Inv=5.45e+03, For=5.78e+00, Power=4.93e+02
  [eval] val_mse=1.264e+02  (n=7000)
Epoch 00002: Time=   5.6s, Loss=4.03e+02, Inv=4.03e+02, For=5.50e+00, Power=4.38e+01
  [eval] val_mse=5.171e+01  (n=7000)
Epoch 00003: Time=   5.6s, Loss=1.62e+02, Inv=1.62e+02, For=5.35e+00, Power=2.07e+01
  [eval] val_mse=3.232e+01  (n=7000)
Epoch 00004: Time=   5.7s, Loss=9.62e+01, Inv=9.62e+01, For=5.33e+00, Power=1.38e+01
  [eval] val_mse=2.349e+01  (n=7000)
Epoch 00005: Time=   5.7s, Loss=6.60e+01, Inv=6.60e+01, For=5.31e+00, Power=1.00e+01
  [eval] val_mse=1.814e+01  (n=7000)
Epoch 00006: Time=   5.7s, Loss=4.88e+01, Inv=4.88e+01, For=5.31e+00, Power=7.53e+00
  [eval] val_mse=1.457e+01  (n=7000)
Epoch 00007: Time=   5.8s, Loss=3.81e+01, Inv=3.81e+01, For=5.38e+00, Power=5.90e+00
  [eval] val_mse=1.200e+01  (n=7000)
Epoch 00008: Time=   5.8s, Loss=3.08e+01, Inv=3.08e+01, For=5.46e+00, Power=4.76e+00
  [eval] val_mse=1.008e+01  (n=7000)
Epoch 00009: Time=   5.8s, Loss=2.57e+01, Inv=2.57e+01, For=5.58e+00, Power=3.94e+00
  [eval] val_mse=8.597e+00  (n=7000)
Epoch 00010: Time=   5.9s, Loss=2.20e+01, Inv=2.20e+01, For=5.74e+00, Power=3.34e+00
  [eval] val_mse=7.422e+00  (n=7000)
Epoch 00011: Time=   5.9s, Loss=1.90e+01, Inv=1.90e+01, For=5.89e+00, Power=2.85e+00
  [eval] val_mse=6.487e+00  (n=7000)
Epoch 00012: Time=   6.0s, Loss=1.68e+01, Inv=1.68e+01, For=6.06e+00, Power=2.50e+00
  [eval] val_mse=5.735e+00  (n=7000)
Epoch 00013: Time=   6.0s, Loss=1.49e+01, Inv=1.49e+01, For=6.24e+00, Power=2.20e+00
  [eval] val_mse=5.111e+00  (n=7000)
Epoch 00014: Time=   6.0s, Loss=1.35e+01, Inv=1.35e+01, For=6.45e+00, Power=1.98e+00
  [eval] val_mse=4.596e+00  (n=7000)
Epoch 00015: Time=   6.1s, Loss=1.22e+01, Inv=1.22e+01, For=6.64e+00, Power=1.79e+00
  [eval] val_mse=4.166e+00  (n=7000)
Epoch 00016: Time=   6.1s, Loss=1.12e+01, Inv=1.12e+01, For=6.85e+00, Power=1.64e+00
  [eval] val_mse=3.800e+00  (n=7000)
Epoch 00017: Time=   6.1s, Loss=1.04e+01, Inv=1.04e+01, For=7.09e+00, Power=1.52e+00
  [eval] val_mse=3.485e+00  (n=7000)
Epoch 00018: Time=   6.2s, Loss=9.69e+00, Inv=9.69e+00, For=7.35e+00, Power=1.41e+00
  [eval] val_mse=3.216e+00  (n=7000)
Epoch 00019: Time=   6.2s, Loss=9.08e+00, Inv=9.08e+00, For=7.59e+00, Power=1.32e+00
  [eval] val_mse=2.985e+00  (n=7000)
Epoch 00020: Time=   6.3s, Loss=8.53e+00, Inv=8.53e+00, For=7.86e+00, Power=1.24e+00
  [eval] val_mse=2.789e+00  (n=7000)
Epoch 00021: Time=   6.3s, Loss=8.09e+00, Inv=8.09e+00, For=8.16e+00, Power=1.18e+00
  [eval] val_mse=2.610e+00  (n=7000)
Epoch 00022: Time=   6.3s, Loss=7.69e+00, Inv=7.69e+00, For=8.48e+00, Power=1.13e+00
  [eval] val_mse=2.461e+00  (n=7000)
Epoch 00023: Time=   6.4s, Loss=7.35e+00, Inv=7.35e+00, For=8.84e+00, Power=1.08e+00
  [eval] val_mse=2.320e+00  (n=7000)
Epoch 00024: Time=   6.4s, Loss=7.04e+00, Inv=7.04e+00, For=9.20e+00, Power=1.04e+00
  [eval] val_mse=2.200e+00  (n=7000)
Epoch 00025: Time=   6.4s, Loss=6.78e+00, Inv=6.78e+00, For=9.57e+00, Power=1.00e+00
  [eval] val_mse=2.089e+00  (n=7000)
Epoch 00026: Time=   6.5s, Loss=6.56e+00, Inv=6.56e+00, For=9.97e+00, Power=9.70e-01
  [eval] val_mse=1.987e+00  (n=7000)
Epoch 00027: Time=   6.5s, Loss=6.33e+00, Inv=6.33e+00, For=1.04e+01, Power=9.48e-01
  [eval] val_mse=1.900e+00  (n=7000)
Epoch 00028: Time=   6.5s, Loss=6.15e+00, Inv=6.15e+00, For=1.08e+01, Power=9.25e-01
  [eval] val_mse=1.818e+00  (n=7000)
Epoch 00029: Time=   6.6s, Loss=5.99e+00, Inv=5.99e+00, For=1.13e+01, Power=9.02e-01
  [eval] val_mse=1.740e+00  (n=7000)
Epoch 00030: Time=   6.6s, Loss=5.84e+00, Inv=5.84e+00, For=1.17e+01, Power=8.88e-01
  [eval] val_mse=1.670e+00  (n=7000)
Epoch 00031: Time=   6.6s, Loss=5.69e+00, Inv=5.69e+00, For=1.22e+01, Power=8.72e-01
  [eval] val_mse=1.606e+00  (n=7000)
Epoch 00032: Time=   6.7s, Loss=5.56e+00, Inv=5.56e+00, For=1.27e+01, Power=8.57e-01
  [eval] val_mse=1.547e+00  (n=7000)
Epoch 00033: Time=   6.7s, Loss=5.44e+00, Inv=5.44e+00, For=1.32e+01, Power=8.41e-01
  [eval] val_mse=1.491e+00  (n=7000)
Epoch 00034: Time=   6.8s, Loss=5.35e+00, Inv=5.35e+00, For=1.37e+01, Power=8.34e-01
  [eval] val_mse=1.440e+00  (n=7000)
Epoch 00035: Time=   6.8s, Loss=5.25e+00, Inv=5.25e+00, For=1.43e+01, Power=8.23e-01
  [eval] val_mse=1.391e+00  (n=7000)
Epoch 00036: Time=   6.8s, Loss=5.15e+00, Inv=5.15e+00, For=1.47e+01, Power=8.14e-01
  [eval] val_mse=1.346e+00  (n=7000)
Epoch 00037: Time=   6.9s, Loss=5.07e+00, Inv=5.07e+00, For=1.53e+01, Power=8.05e-01
  [eval] val_mse=1.302e+00  (n=7000)
Epoch 00038: Time=   6.9s, Loss=4.98e+00, Inv=4.98e+00, For=1.58e+01, Power=8.00e-01
  [eval] val_mse=1.265e+00  (n=7000)
Epoch 00039: Time=   6.9s, Loss=4.91e+00, Inv=4.91e+00, For=1.64e+01, Power=7.93e-01
  [eval] val_mse=1.226e+00  (n=7000)
Epoch 00040: Time=   7.0s, Loss=4.84e+00, Inv=4.84e+00, For=1.69e+01, Power=7.86e-01
  [eval] val_mse=1.190e+00  (n=7000)
Epoch 00041: Time=   7.0s, Loss=4.78e+00, Inv=4.78e+00, For=1.75e+01, Power=7.82e-01
  [eval] val_mse=1.157e+00  (n=7000)
Epoch 00042: Time=   7.0s, Loss=4.72e+00, Inv=4.72e+00, For=1.80e+01, Power=7.77e-01
  [eval] val_mse=1.126e+00  (n=7000)
Epoch 00043: Time=   7.1s, Loss=4.67e+00, Inv=4.67e+00, For=1.86e+01, Power=7.76e-01
  [eval] val_mse=1.096e+00  (n=7000)
Epoch 00044: Time=   7.1s, Loss=4.61e+00, Inv=4.61e+00, For=1.92e+01, Power=7.65e-01
  [eval] val_mse=1.067e+00  (n=7000)
Epoch 00045: Time=   7.2s, Loss=4.55e+00, Inv=4.55e+00, For=1.98e+01, Power=7.63e-01
  [eval] val_mse=1.040e+00  (n=7000)
Epoch 00046: Time=   7.2s, Loss=4.50e+00, Inv=4.50e+00, For=2.04e+01, Power=7.61e-01
  [eval] val_mse=1.014e+00  (n=7000)
Epoch 00047: Time=   7.2s, Loss=4.45e+00, Inv=4.45e+00, For=2.10e+01, Power=7.54e-01
  [eval] val_mse=9.900e-01  (n=7000)
Epoch 00048: Time=   7.3s, Loss=4.40e+00, Inv=4.40e+00, For=2.15e+01, Power=7.51e-01
  [eval] val_mse=9.684e-01  (n=7000)
Epoch 00049: Time=   7.3s, Loss=4.36e+00, Inv=4.36e+00, For=2.21e+01, Power=7.49e-01
  [eval] val_mse=9.439e-01  (n=7000)
Epoch 00050: Time=   7.3s, Loss=4.32e+00, Inv=4.32e+00, For=2.27e+01, Power=7.48e-01
  [eval] val_mse=9.240e-01  (n=7000)
Epoch 00051: Time=   7.4s, Loss=4.28e+00, Inv=4.28e+00, For=2.33e+01, Power=7.41e-01
  [eval] val_mse=9.059e-01  (n=7000)
Epoch 00052: Time=   7.4s, Loss=4.24e+00, Inv=4.24e+00, For=2.39e+01, Power=7.40e-01
  [eval] val_mse=8.861e-01  (n=7000)
Epoch 00053: Time=   7.4s, Loss=4.21e+00, Inv=4.21e+00, For=2.47e+01, Power=7.40e-01
  [eval] val_mse=8.683e-01  (n=7000)
Epoch 00054: Time=   7.5s, Loss=4.17e+00, Inv=4.17e+00, For=2.51e+01, Power=7.36e-01
  [eval] val_mse=8.510e-01  (n=7000)
Epoch 00055: Time=   7.5s, Loss=4.14e+00, Inv=4.14e+00, For=2.59e+01, Power=7.37e-01
  [eval] val_mse=8.344e-01  (n=7000)
Epoch 00056: Time=   7.5s, Loss=4.09e+00, Inv=4.09e+00, For=2.64e+01, Power=7.32e-01
  [eval] val_mse=8.185e-01  (n=7000)
Epoch 00057: Time=   7.6s, Loss=4.07e+00, Inv=4.07e+00, For=2.71e+01, Power=7.32e-01
  [eval] val_mse=8.040e-01  (n=7000)
Epoch 00058: Time=   7.6s, Loss=4.03e+00, Inv=4.03e+00, For=2.78e+01, Power=7.28e-01
  [eval] val_mse=7.897e-01  (n=7000)
Epoch 00059: Time=   7.6s, Loss=4.01e+00, Inv=4.01e+00, For=2.84e+01, Power=7.30e-01
  [eval] val_mse=7.753e-01  (n=7000)
Epoch 00060: Time=   7.7s, Loss=3.98e+00, Inv=3.98e+00, For=2.91e+01, Power=7.29e-01
  [eval] val_mse=7.631e-01  (n=7000)
Epoch 00061: Time=   7.7s, Loss=3.95e+00, Inv=3.95e+00, For=2.97e+01, Power=7.27e-01
  [eval] val_mse=7.503e-01  (n=7000)
Epoch 00062: Time=   7.8s, Loss=3.92e+00, Inv=3.92e+00, For=3.04e+01, Power=7.24e-01
  [eval] val_mse=7.375e-01  (n=7000)
Epoch 00063: Time=   7.8s, Loss=3.90e+00, Inv=3.90e+00, For=3.10e+01, Power=7.21e-01
  [eval] val_mse=7.252e-01  (n=7000)
Epoch 00064: Time=   7.8s, Loss=3.87e+00, Inv=3.87e+00, For=3.16e+01, Power=7.21e-01
  [eval] val_mse=7.143e-01  (n=7000)
Epoch 00065: Time=   7.9s, Loss=3.85e+00, Inv=3.85e+00, For=3.23e+01, Power=7.20e-01
  [eval] val_mse=7.033e-01  (n=7000)
Epoch 00066: Time=   7.9s, Loss=3.82e+00, Inv=3.82e+00, For=3.30e+01, Power=7.19e-01
  [eval] val_mse=6.931e-01  (n=7000)
Epoch 00067: Time=   7.9s, Loss=3.80e+00, Inv=3.80e+00, For=3.37e+01, Power=7.20e-01
  [eval] val_mse=6.831e-01  (n=7000)
Epoch 00068: Time=   8.0s, Loss=3.77e+00, Inv=3.77e+00, For=3.43e+01, Power=7.15e-01
  [eval] val_mse=6.741e-01  (n=7000)
Epoch 00069: Time=   8.0s, Loss=3.76e+00, Inv=3.76e+00, For=3.52e+01, Power=7.14e-01
  [eval] val_mse=6.631e-01  (n=7000)
Epoch 00070: Time=   8.0s, Loss=3.74e+00, Inv=3.74e+00, For=3.57e+01, Power=7.13e-01
  [eval] val_mse=6.533e-01  (n=7000)
Epoch 00071: Time=   8.1s, Loss=3.72e+00, Inv=3.72e+00, For=3.65e+01, Power=7.15e-01
  [eval] val_mse=6.450e-01  (n=7000)
Epoch 00072: Time=   8.1s, Loss=3.70e+00, Inv=3.70e+00, For=3.72e+01, Power=7.12e-01
  [eval] val_mse=6.365e-01  (n=7000)
Epoch 00073: Time=   8.1s, Loss=3.68e+00, Inv=3.68e+00, For=3.80e+01, Power=7.12e-01
  [eval] val_mse=6.282e-01  (n=7000)
Epoch 00074: Time=   8.2s, Loss=3.66e+00, Inv=3.66e+00, For=3.87e+01, Power=7.09e-01
  [eval] val_mse=6.205e-01  (n=7000)
Epoch 00075: Time=   8.2s, Loss=3.65e+00, Inv=3.65e+00, For=3.92e+01, Power=7.09e-01
  [eval] val_mse=6.123e-01  (n=7000)
Epoch 00076: Time=   8.2s, Loss=3.63e+00, Inv=3.63e+00, For=4.00e+01, Power=7.11e-01
  [eval] val_mse=6.043e-01  (n=7000)
Epoch 00077: Time=   8.3s, Loss=3.61e+00, Inv=3.61e+00, For=4.07e+01, Power=7.09e-01
  [eval] val_mse=5.973e-01  (n=7000)
Epoch 00078: Time=   8.3s, Loss=3.60e+00, Inv=3.60e+00, For=4.16e+01, Power=7.08e-01
  [eval] val_mse=5.906e-01  (n=7000)
Epoch 00079: Time=   8.4s, Loss=3.58e+00, Inv=3.58e+00, For=4.21e+01, Power=7.03e-01
  [eval] val_mse=5.832e-01  (n=7000)
Epoch 00080: Time=   8.4s, Loss=3.57e+00, Inv=3.57e+00, For=4.27e+01, Power=7.07e-01
  [eval] val_mse=5.760e-01  (n=7000)
Epoch 00081: Time=   8.4s, Loss=3.56e+00, Inv=3.56e+00, For=4.36e+01, Power=7.06e-01
  [eval] val_mse=5.690e-01  (n=7000)
Epoch 00082: Time=   8.5s, Loss=3.55e+00, Inv=3.55e+00, For=4.45e+01, Power=7.06e-01
  [eval] val_mse=5.640e-01  (n=7000)
Epoch 00083: Time=   8.5s, Loss=3.54e+00, Inv=3.54e+00, For=4.50e+01, Power=7.05e-01
  [eval] val_mse=5.559e-01  (n=7000)
Epoch 00084: Time=   8.6s, Loss=3.53e+00, Inv=3.53e+00, For=4.56e+01, Power=7.04e-01
  [eval] val_mse=5.504e-01  (n=7000)
Epoch 00085: Time=   8.6s, Loss=3.51e+00, Inv=3.51e+00, For=4.66e+01, Power=7.01e-01
  [eval] val_mse=5.439e-01  (n=7000)
Epoch 00086: Time=   8.6s, Loss=3.50e+00, Inv=3.50e+00, For=4.74e+01, Power=7.03e-01
  [eval] val_mse=5.382e-01  (n=7000)
Epoch 00087: Time=   8.7s, Loss=3.49e+00, Inv=3.49e+00, For=4.78e+01, Power=7.03e-01
  [eval] val_mse=5.329e-01  (n=7000)
Epoch 00088: Time=   8.7s, Loss=3.48e+00, Inv=3.48e+00, For=4.86e+01, Power=7.00e-01
  [eval] val_mse=5.268e-01  (n=7000)
Epoch 00089: Time=   8.7s, Loss=3.46e+00, Inv=3.46e+00, For=4.94e+01, Power=7.02e-01
  [eval] val_mse=5.205e-01  (n=7000)
Epoch 00090: Time=   8.8s, Loss=3.45e+00, Inv=3.45e+00, For=5.02e+01, Power=6.98e-01
  [eval] val_mse=5.151e-01  (n=7000)
Epoch 00091: Time=   8.8s, Loss=3.45e+00, Inv=3.45e+00, For=5.09e+01, Power=7.02e-01
  [eval] val_mse=5.103e-01  (n=7000)
Epoch 00092: Time=   8.8s, Loss=3.44e+00, Inv=3.44e+00, For=5.16e+01, Power=7.01e-01
  [eval] val_mse=5.053e-01  (n=7000)
Epoch 00093: Time=   8.9s, Loss=3.43e+00, Inv=3.43e+00, For=5.22e+01, Power=6.98e-01
  [eval] val_mse=5.010e-01  (n=7000)
Epoch 00094: Time=   8.9s, Loss=3.42e+00, Inv=3.42e+00, For=5.32e+01, Power=6.98e-01
  [eval] val_mse=4.956e-01  (n=7000)
Epoch 00095: Time=   8.9s, Loss=3.40e+00, Inv=3.40e+00, For=5.37e+01, Power=6.95e-01
  [eval] val_mse=4.905e-01  (n=7000)
Epoch 00096: Time=   9.0s, Loss=3.39e+00, Inv=3.39e+00, For=5.47e+01, Power=6.96e-01
  [eval] val_mse=4.862e-01  (n=7000)
Epoch 00097: Time=   9.0s, Loss=3.39e+00, Inv=3.39e+00, For=5.52e+01, Power=6.98e-01
  [eval] val_mse=4.821e-01  (n=7000)
Epoch 00098: Time=   9.0s, Loss=3.38e+00, Inv=3.38e+00, For=5.62e+01, Power=6.96e-01
  [eval] val_mse=4.785e-01  (n=7000)
Epoch 00099: Time=   9.1s, Loss=3.37e+00, Inv=3.37e+00, For=5.68e+01, Power=6.96e-01
  [eval] val_mse=4.738e-01  (n=7000)
Epoch 00100: Time=   9.1s, Loss=3.36e+00, Inv=3.36e+00, For=5.76e+01, Power=6.93e-01
  [eval] val_mse=4.689e-01  (n=7000)
Epoch 00101: Time=   9.2s, Loss=3.35e+00, Inv=3.35e+00, For=5.83e+01, Power=6.93e-01
  [eval] val_mse=4.662e-01  (n=7000)
Epoch 00102: Time=   9.2s, Loss=3.34e+00, Inv=3.34e+00, For=5.89e+01, Power=6.94e-01
  [eval] val_mse=4.618e-01  (n=7000)
Epoch 00103: Time=   9.2s, Loss=3.34e+00, Inv=3.34e+00, For=5.97e+01, Power=6.91e-01
  [eval] val_mse=4.583e-01  (n=7000)
Epoch 00104: Time=   9.3s, Loss=3.33e+00, Inv=3.33e+00, For=6.06e+01, Power=6.93e-01
  [eval] val_mse=4.558e-01  (n=7000)
Epoch 00105: Time=   9.3s, Loss=3.32e+00, Inv=3.32e+00, For=6.16e+01, Power=6.93e-01
  [eval] val_mse=4.523e-01  (n=7000)
Epoch 00106: Time=   9.3s, Loss=3.31e+00, Inv=3.31e+00, For=6.22e+01, Power=6.91e-01
  [eval] val_mse=4.483e-01  (n=7000)
Epoch 00107: Time=   9.4s, Loss=3.30e+00, Inv=3.30e+00, For=6.25e+01, Power=6.91e-01
  [eval] val_mse=4.446e-01  (n=7000)
Epoch 00108: Time=   9.4s, Loss=3.29e+00, Inv=3.29e+00, For=6.37e+01, Power=6.89e-01
  [eval] val_mse=4.413e-01  (n=7000)
Epoch 00109: Time=   9.4s, Loss=3.29e+00, Inv=3.29e+00, For=6.44e+01, Power=6.90e-01
  [eval] val_mse=4.384e-01  (n=7000)
Epoch 00110: Time=   9.5s, Loss=3.28e+00, Inv=3.28e+00, For=6.50e+01, Power=6.89e-01
  [eval] val_mse=4.355e-01  (n=7000)
Epoch 00111: Time=   9.5s, Loss=3.28e+00, Inv=3.28e+00, For=6.55e+01, Power=6.92e-01
  [eval] val_mse=4.333e-01  (n=7000)
Epoch 00112: Time=   9.5s, Loss=3.27e+00, Inv=3.27e+00, For=6.69e+01, Power=6.90e-01
  [eval] val_mse=4.294e-01  (n=7000)
Epoch 00113: Time=   9.6s, Loss=3.27e+00, Inv=3.27e+00, For=6.76e+01, Power=6.89e-01
  [eval] val_mse=4.271e-01  (n=7000)
Epoch 00114: Time=   9.6s, Loss=3.26e+00, Inv=3.26e+00, For=6.80e+01, Power=6.91e-01
  [eval] val_mse=4.249e-01  (n=7000)
Epoch 00115: Time=   9.6s, Loss=3.25e+00, Inv=3.25e+00, For=6.94e+01, Power=6.90e-01
  [eval] val_mse=4.216e-01  (n=7000)
Epoch 00116: Time=   9.7s, Loss=3.24e+00, Inv=3.24e+00, For=6.98e+01, Power=6.84e-01
  [eval] val_mse=4.196e-01  (n=7000)
Epoch 00117: Time=   9.7s, Loss=3.24e+00, Inv=3.24e+00, For=7.11e+01, Power=6.88e-01
  [eval] val_mse=4.161e-01  (n=7000)
Epoch 00118: Time=   9.7s, Loss=3.23e+00, Inv=3.23e+00, For=7.14e+01, Power=6.87e-01
  [eval] val_mse=4.139e-01  (n=7000)
Epoch 00119: Time=   9.8s, Loss=3.23e+00, Inv=3.23e+00, For=7.24e+01, Power=6.88e-01
  [eval] val_mse=4.122e-01  (n=7000)
Epoch 00120: Time=   9.8s, Loss=3.22e+00, Inv=3.22e+00, For=7.31e+01, Power=6.88e-01
  [eval] val_mse=4.097e-01  (n=7000)
Epoch 00121: Time=   9.8s, Loss=3.22e+00, Inv=3.22e+00, For=7.41e+01, Power=6.86e-01
  [eval] val_mse=4.083e-01  (n=7000)
Epoch 00122: Time=   9.9s, Loss=3.21e+00, Inv=3.21e+00, For=7.55e+01, Power=6.85e-01
  [eval] val_mse=4.060e-01  (n=7000)
Epoch 00123: Time=   9.9s, Loss=3.21e+00, Inv=3.21e+00, For=7.58e+01, Power=6.84e-01
  [eval] val_mse=4.035e-01  (n=7000)
Epoch 00124: Time=   9.9s, Loss=3.20e+00, Inv=3.20e+00, For=7.68e+01, Power=6.85e-01
  [eval] val_mse=4.015e-01  (n=7000)
Epoch 00125: Time=  10.0s, Loss=3.19e+00, Inv=3.19e+00, For=7.78e+01, Power=6.84e-01
  [eval] val_mse=3.993e-01  (n=7000)
Epoch 00126: Time=  10.0s, Loss=3.19e+00, Inv=3.19e+00, For=7.82e+01, Power=6.86e-01
  [eval] val_mse=3.977e-01  (n=7000)
Epoch 00127: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=7.97e+01, Power=6.86e-01
  [eval] val_mse=3.958e-01  (n=7000)
Epoch 00128: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=8.01e+01, Power=6.82e-01
  [eval] val_mse=3.938e-01  (n=7000)
Epoch 00129: Time=  10.1s, Loss=3.18e+00, Inv=3.18e+00, For=8.13e+01, Power=6.86e-01
  [eval] val_mse=3.925e-01  (n=7000)
Epoch 00130: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=8.17e+01, Power=6.84e-01
  [eval] val_mse=3.911e-01  (n=7000)
Epoch 00131: Time=  10.2s, Loss=3.17e+00, Inv=3.17e+00, For=8.31e+01, Power=6.87e-01
  [eval] val_mse=3.903e-01  (n=7000)
Epoch 00132: Time=  10.2s, Loss=3.16e+00, Inv=3.16e+00, For=8.42e+01, Power=6.86e-01
  [eval] val_mse=3.876e-01  (n=7000)
Epoch 00133: Time=  10.3s, Loss=3.16e+00, Inv=3.16e+00, For=8.50e+01, Power=6.85e-01
  [eval] val_mse=3.862e-01  (n=7000)
Epoch 00134: Time=  10.3s, Loss=3.15e+00, Inv=3.15e+00, For=8.58e+01, Power=6.82e-01
  [eval] val_mse=3.845e-01  (n=7000)
Epoch 00135: Time=  10.3s, Loss=3.15e+00, Inv=3.15e+00, For=8.72e+01, Power=6.83e-01
  [eval] val_mse=3.833e-01  (n=7000)
Epoch 00136: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=8.75e+01, Power=6.83e-01
  [eval] val_mse=3.825e-01  (n=7000)
Epoch 00137: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=8.88e+01, Power=6.82e-01
  [eval] val_mse=3.808e-01  (n=7000)
Epoch 00138: Time=  10.4s, Loss=3.14e+00, Inv=3.14e+00, For=9.03e+01, Power=6.82e-01
  [eval] val_mse=3.797e-01  (n=7000)
Epoch 00139: Time=  10.5s, Loss=3.13e+00, Inv=3.13e+00, For=9.13e+01, Power=6.81e-01
  [eval] val_mse=3.782e-01  (n=7000)
Epoch 00140: Time=  10.5s, Loss=3.13e+00, Inv=3.13e+00, For=9.13e+01, Power=6.83e-01
  [eval] val_mse=3.780e-01  (n=7000)
Epoch 00141: Time=  10.6s, Loss=3.12e+00, Inv=3.12e+00, For=9.34e+01, Power=6.82e-01
  [eval] val_mse=3.761e-01  (n=7000)
Epoch 00142: Time=  10.6s, Loss=3.12e+00, Inv=3.12e+00, For=9.37e+01, Power=6.82e-01
  [eval] val_mse=3.739e-01  (n=7000)
Epoch 00143: Time=  10.6s, Loss=3.12e+00, Inv=3.12e+00, For=9.52e+01, Power=6.84e-01
  [eval] val_mse=3.738e-01  (n=7000)
Epoch 00144: Time=  10.7s, Loss=3.11e+00, Inv=3.11e+00, For=9.59e+01, Power=6.80e-01
  [eval] val_mse=3.727e-01  (n=7000)
Epoch 00145: Time=  10.7s, Loss=3.11e+00, Inv=3.11e+00, For=9.72e+01, Power=6.82e-01
  [eval] val_mse=3.710e-01  (n=7000)
Epoch 00146: Time=  10.7s, Loss=3.11e+00, Inv=3.11e+00, For=9.85e+01, Power=6.81e-01
  [eval] val_mse=3.703e-01  (n=7000)
Epoch 00147: Time=  10.8s, Loss=3.10e+00, Inv=3.10e+00, For=1.00e+02, Power=6.81e-01
  [eval] val_mse=3.687e-01  (n=7000)
Epoch 00148: Time=  10.8s, Loss=3.10e+00, Inv=3.10e+00, For=1.01e+02, Power=6.84e-01
  [eval] val_mse=3.682e-01  (n=7000)
Epoch 00149: Time=  10.8s, Loss=3.09e+00, Inv=3.09e+00, For=1.02e+02, Power=6.81e-01
  [eval] val_mse=3.674e-01  (n=7000)
Epoch 00150: Time=  10.9s, Loss=3.09e+00, Inv=3.09e+00, For=1.03e+02, Power=6.83e-01
  [eval] val_mse=3.659e-01  (n=7000)
Epoch 00151: Time=  10.9s, Loss=3.09e+00, Inv=3.09e+00, For=1.04e+02, Power=6.83e-01
  [eval] val_mse=3.654e-01  (n=7000)
Epoch 00152: Time=  10.9s, Loss=3.09e+00, Inv=3.09e+00, For=1.05e+02, Power=6.80e-01
  [eval] val_mse=3.642e-01  (n=7000)
Epoch 00153: Time=  11.0s, Loss=3.08e+00, Inv=3.08e+00, For=1.06e+02, Power=6.80e-01
  [eval] val_mse=3.637e-01  (n=7000)
Epoch 00154: Time=  11.0s, Loss=3.08e+00, Inv=3.08e+00, For=1.08e+02, Power=6.80e-01
  [eval] val_mse=3.627e-01  (n=7000)
Epoch 00155: Time=  11.1s, Loss=3.08e+00, Inv=3.08e+00, For=1.09e+02, Power=6.83e-01
  [eval] val_mse=3.612e-01  (n=7000)
Epoch 00156: Time=  11.1s, Loss=3.07e+00, Inv=3.07e+00, For=1.10e+02, Power=6.80e-01
  [eval] val_mse=3.607e-01  (n=7000)
Epoch 00157: Time=  11.1s, Loss=3.07e+00, Inv=3.07e+00, For=1.11e+02, Power=6.79e-01
  [eval] val_mse=3.601e-01  (n=7000)
Epoch 00158: Time=  11.2s, Loss=3.06e+00, Inv=3.06e+00, For=1.12e+02, Power=6.81e-01
  [eval] val_mse=3.591e-01  (n=7000)
Epoch 00159: Time=  11.2s, Loss=3.07e+00, Inv=3.07e+00, For=1.13e+02, Power=6.81e-01
  [eval] val_mse=3.590e-01  (n=7000)
Epoch 00160: Time=  11.2s, Loss=3.07e+00, Inv=3.07e+00, For=1.16e+02, Power=6.79e-01
  [eval] val_mse=3.576e-01  (n=7000)
Epoch 00161: Time=  11.3s, Loss=3.06e+00, Inv=3.06e+00, For=1.17e+02, Power=6.81e-01
  [eval] val_mse=3.588e-01  (n=7000)
Epoch 00162: Time=  11.3s, Loss=3.06e+00, Inv=3.06e+00, For=1.17e+02, Power=6.83e-01
  [eval] val_mse=3.571e-01  (n=7000)
Epoch 00163: Time=  11.4s, Loss=3.06e+00, Inv=3.06e+00, For=1.19e+02, Power=6.82e-01
  [eval] val_mse=3.560e-01  (n=7000)
Epoch 00164: Time=  11.4s, Loss=3.05e+00, Inv=3.05e+00, For=1.21e+02, Power=6.80e-01
  [eval] val_mse=3.551e-01  (n=7000)
Epoch 00165: Time=  11.4s, Loss=3.05e+00, Inv=3.05e+00, For=1.22e+02, Power=6.80e-01
  [eval] val_mse=3.544e-01  (n=7000)
Epoch 00166: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=1.23e+02, Power=6.80e-01
  [eval] val_mse=3.539e-01  (n=7000)
Epoch 00167: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=1.26e+02, Power=6.80e-01
  [eval] val_mse=3.533e-01  (n=7000)
Epoch 00168: Time=  11.5s, Loss=3.05e+00, Inv=3.05e+00, For=1.25e+02, Power=6.81e-01
  [eval] val_mse=3.533e-01  (n=7000)
Epoch 00169: Time=  11.6s, Loss=3.04e+00, Inv=3.04e+00, For=1.26e+02, Power=6.77e-01
  [eval] val_mse=3.525e-01  (n=7000)
Epoch 00170: Time=  11.6s, Loss=3.04e+00, Inv=3.04e+00, For=1.29e+02, Power=6.77e-01
  [eval] val_mse=3.507e-01  (n=7000)
Epoch 00171: Time=  11.6s, Loss=3.04e+00, Inv=3.04e+00, For=1.30e+02, Power=6.81e-01
  [eval] val_mse=3.505e-01  (n=7000)
Epoch 00172: Time=  11.7s, Loss=3.04e+00, Inv=3.04e+00, For=1.32e+02, Power=6.82e-01
  [eval] val_mse=3.509e-01  (n=7000)
Epoch 00173: Time=  11.7s, Loss=3.04e+00, Inv=3.04e+00, For=1.33e+02, Power=6.81e-01
  [eval] val_mse=3.510e-01  (n=7000)
Epoch 00174: Time=  11.7s, Loss=3.03e+00, Inv=3.03e+00, For=1.34e+02, Power=6.80e-01
  [eval] val_mse=3.491e-01  (n=7000)
Epoch 00175: Time=  11.8s, Loss=3.03e+00, Inv=3.03e+00, For=1.36e+02, Power=6.76e-01
  [eval] val_mse=3.482e-01  (n=7000)
Epoch 00176: Time=  11.8s, Loss=3.03e+00, Inv=3.03e+00, For=1.38e+02, Power=6.79e-01
  [eval] val_mse=3.474e-01  (n=7000)
Epoch 00177: Time=  11.8s, Loss=3.03e+00, Inv=3.03e+00, For=1.38e+02, Power=6.79e-01
  [eval] val_mse=3.479e-01  (n=7000)
Epoch 00178: Time=  11.9s, Loss=3.02e+00, Inv=3.02e+00, For=1.41e+02, Power=6.80e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00179: Time=  11.9s, Loss=3.02e+00, Inv=3.02e+00, For=1.42e+02, Power=6.77e-01
  [eval] val_mse=3.467e-01  (n=7000)
Epoch 00180: Time=  12.0s, Loss=3.02e+00, Inv=3.02e+00, For=1.44e+02, Power=6.81e-01
  [eval] val_mse=3.459e-01  (n=7000)
Epoch 00181: Time=  12.0s, Loss=3.02e+00, Inv=3.02e+00, For=1.44e+02, Power=6.80e-01
  [eval] val_mse=3.455e-01  (n=7000)
Epoch 00182: Time=  12.0s, Loss=3.02e+00, Inv=3.02e+00, For=1.47e+02, Power=6.80e-01
  [eval] val_mse=3.457e-01  (n=7000)
Epoch 00183: Time=  12.1s, Loss=3.02e+00, Inv=3.02e+00, For=1.48e+02, Power=6.79e-01
  [eval] val_mse=3.447e-01  (n=7000)
Epoch 00184: Time=  12.1s, Loss=3.01e+00, Inv=3.01e+00, For=1.50e+02, Power=6.79e-01
  [eval] val_mse=3.450e-01  (n=7000)
Epoch 00185: Time=  12.1s, Loss=3.02e+00, Inv=3.02e+00, For=1.52e+02, Power=6.81e-01
  [eval] val_mse=3.444e-01  (n=7000)
Epoch 00186: Time=  12.2s, Loss=3.01e+00, Inv=3.01e+00, For=1.53e+02, Power=6.79e-01
  [eval] val_mse=3.442e-01  (n=7000)
Epoch 00187: Time=  12.2s, Loss=3.01e+00, Inv=3.01e+00, For=1.55e+02, Power=6.78e-01
  [eval] val_mse=3.441e-01  (n=7000)
Epoch 00188: Time=  12.2s, Loss=3.01e+00, Inv=3.01e+00, For=1.57e+02, Power=6.79e-01
  [eval] val_mse=3.427e-01  (n=7000)
Epoch 00189: Time=  12.3s, Loss=3.01e+00, Inv=3.01e+00, For=1.58e+02, Power=6.79e-01
  [eval] val_mse=3.425e-01  (n=7000)
Epoch 00190: Time=  12.3s, Loss=3.00e+00, Inv=3.00e+00, For=1.59e+02, Power=6.77e-01
  [eval] val_mse=3.422e-01  (n=7000)
Epoch 00191: Time=  12.3s, Loss=3.01e+00, Inv=3.01e+00, For=1.63e+02, Power=6.78e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00192: Time=  12.4s, Loss=3.00e+00, Inv=3.00e+00, For=1.62e+02, Power=6.78e-01
  [eval] val_mse=3.418e-01  (n=7000)
Epoch 00193: Time=  12.4s, Loss=3.00e+00, Inv=3.00e+00, For=1.64e+02, Power=6.80e-01
  [eval] val_mse=3.404e-01  (n=7000)
Epoch 00194: Time=  12.4s, Loss=3.00e+00, Inv=3.00e+00, For=1.66e+02, Power=6.79e-01
  [eval] val_mse=3.413e-01  (n=7000)
Epoch 00195: Time=  12.5s, Loss=3.00e+00, Inv=3.00e+00, For=1.67e+02, Power=6.80e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00196: Time=  12.5s, Loss=2.99e+00, Inv=2.99e+00, For=1.68e+02, Power=6.79e-01
  [eval] val_mse=3.395e-01  (n=7000)
Epoch 00197: Time=  12.5s, Loss=2.99e+00, Inv=2.99e+00, For=1.72e+02, Power=6.80e-01
  [eval] val_mse=3.394e-01  (n=7000)
Epoch 00198: Time=  12.6s, Loss=2.99e+00, Inv=2.99e+00, For=1.71e+02, Power=6.79e-01
  [eval] val_mse=3.399e-01  (n=7000)
Epoch 00199: Time=  12.6s, Loss=2.99e+00, Inv=2.99e+00, For=1.75e+02, Power=6.79e-01
  [eval] val_mse=3.384e-01  (n=7000)
Epoch 00200: Time=  12.7s, Loss=2.99e+00, Inv=2.99e+00, For=1.76e+02, Power=6.81e-01
  [eval] val_mse=3.389e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 2.375e-01
Torque MSE  = 7.984e-02
Torque RMSE = 2.826e-01
Per-joint MSE : 7.447e-02 1.549e-01 6.316e-02 1.821e-02 1.515e-01 1.682e-02
Per-joint RMSE: 2.729e-01 3.936e-01 2.513e-01 1.349e-01 3.892e-01 1.297e-01
Comp Time per Sample = 2.980e-04s / 3356.3Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-e1dji5my because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7c25e31268c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 15:59:39.312845: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 15:59:41.165065: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.2s, Loss=5.15e+03, Inv=5.15e+03, For=5.77e+00, Power=8.86e+02
  [eval] val_mse=1.832e+02  (n=7000)
Epoch 00002: Time=   5.9s, Loss=4.51e+02, Inv=4.51e+02, For=5.58e+00, Power=9.04e+01
  [eval] val_mse=7.297e+01  (n=7000)
Epoch 00003: Time=   5.9s, Loss=1.89e+02, Inv=1.89e+02, For=5.48e+00, Power=4.07e+01
  [eval] val_mse=4.714e+01  (n=7000)
Epoch 00004: Time=   5.9s, Loss=1.15e+02, Inv=1.15e+02, For=5.43e+00, Power=2.45e+01
  [eval] val_mse=3.209e+01  (n=7000)
Epoch 00005: Time=   6.0s, Loss=7.87e+01, Inv=7.87e+01, For=5.41e+00, Power=1.60e+01
  [eval] val_mse=2.309e+01  (n=7000)
Epoch 00006: Time=   6.0s, Loss=5.71e+01, Inv=5.71e+01, For=5.39e+00, Power=1.12e+01
  [eval] val_mse=1.738e+01  (n=7000)
Epoch 00007: Time=   6.0s, Loss=4.34e+01, Inv=4.34e+01, For=5.40e+00, Power=8.17e+00
  [eval] val_mse=1.352e+01  (n=7000)
Epoch 00008: Time=   6.1s, Loss=3.43e+01, Inv=3.43e+01, For=5.46e+00, Power=6.23e+00
  [eval] val_mse=1.088e+01  (n=7000)
Epoch 00009: Time=   6.1s, Loss=2.80e+01, Inv=2.80e+01, For=5.56e+00, Power=4.96e+00
  [eval] val_mse=8.938e+00  (n=7000)
Epoch 00010: Time=   6.2s, Loss=2.35e+01, Inv=2.35e+01, For=5.69e+00, Power=4.05e+00
  [eval] val_mse=7.491e+00  (n=7000)
Epoch 00011: Time=   6.2s, Loss=2.00e+01, Inv=2.00e+01, For=5.82e+00, Power=3.38e+00
  [eval] val_mse=6.373e+00  (n=7000)
Epoch 00012: Time=   6.2s, Loss=1.74e+01, Inv=1.74e+01, For=5.98e+00, Power=2.86e+00
  [eval] val_mse=5.516e+00  (n=7000)
Epoch 00013: Time=   6.3s, Loss=1.54e+01, Inv=1.54e+01, For=6.17e+00, Power=2.48e+00
  [eval] val_mse=4.824e+00  (n=7000)
Epoch 00014: Time=   6.3s, Loss=1.37e+01, Inv=1.37e+01, For=6.36e+00, Power=2.19e+00
  [eval] val_mse=4.272e+00  (n=7000)
Epoch 00015: Time=   6.3s, Loss=1.24e+01, Inv=1.24e+01, For=6.58e+00, Power=1.96e+00
  [eval] val_mse=3.820e+00  (n=7000)
Epoch 00016: Time=   6.4s, Loss=1.13e+01, Inv=1.13e+01, For=6.82e+00, Power=1.77e+00
  [eval] val_mse=3.438e+00  (n=7000)
Epoch 00017: Time=   6.4s, Loss=1.05e+01, Inv=1.05e+01, For=7.12e+00, Power=1.61e+00
  [eval] val_mse=3.120e+00  (n=7000)
Epoch 00018: Time=   6.5s, Loss=9.71e+00, Inv=9.71e+00, For=7.41e+00, Power=1.48e+00
  [eval] val_mse=2.846e+00  (n=7000)
Epoch 00019: Time=   6.5s, Loss=9.07e+00, Inv=9.07e+00, For=7.70e+00, Power=1.38e+00
  [eval] val_mse=2.615e+00  (n=7000)
Epoch 00020: Time=   6.5s, Loss=8.54e+00, Inv=8.54e+00, For=8.03e+00, Power=1.30e+00
  [eval] val_mse=2.411e+00  (n=7000)
Epoch 00021: Time=   6.6s, Loss=8.09e+00, Inv=8.09e+00, For=8.42e+00, Power=1.22e+00
  [eval] val_mse=2.241e+00  (n=7000)
Epoch 00022: Time=   6.6s, Loss=7.68e+00, Inv=7.68e+00, For=8.78e+00, Power=1.17e+00
  [eval] val_mse=2.089e+00  (n=7000)
Epoch 00023: Time=   6.6s, Loss=7.33e+00, Inv=7.33e+00, For=9.23e+00, Power=1.11e+00
  [eval] val_mse=1.956e+00  (n=7000)
Epoch 00024: Time=   6.7s, Loss=7.01e+00, Inv=7.01e+00, For=9.64e+00, Power=1.07e+00
  [eval] val_mse=1.837e+00  (n=7000)
Epoch 00025: Time=   6.7s, Loss=6.75e+00, Inv=6.75e+00, For=1.01e+01, Power=1.03e+00
  [eval] val_mse=1.733e+00  (n=7000)
Epoch 00026: Time=   6.8s, Loss=6.52e+00, Inv=6.52e+00, For=1.05e+01, Power=9.95e-01
  [eval] val_mse=1.633e+00  (n=7000)
Epoch 00027: Time=   6.8s, Loss=6.30e+00, Inv=6.30e+00, For=1.10e+01, Power=9.65e-01
  [eval] val_mse=1.548e+00  (n=7000)
Epoch 00028: Time=   6.8s, Loss=6.10e+00, Inv=6.10e+00, For=1.15e+01, Power=9.42e-01
  [eval] val_mse=1.471e+00  (n=7000)
Epoch 00029: Time=   6.9s, Loss=5.93e+00, Inv=5.93e+00, For=1.21e+01, Power=9.19e-01
  [eval] val_mse=1.400e+00  (n=7000)
Epoch 00030: Time=   6.9s, Loss=5.77e+00, Inv=5.77e+00, For=1.25e+01, Power=8.97e-01
  [eval] val_mse=1.335e+00  (n=7000)
Epoch 00031: Time=   6.9s, Loss=5.62e+00, Inv=5.62e+00, For=1.30e+01, Power=8.81e-01
  [eval] val_mse=1.274e+00  (n=7000)
Epoch 00032: Time=   7.0s, Loss=5.49e+00, Inv=5.49e+00, For=1.36e+01, Power=8.67e-01
  [eval] val_mse=1.221e+00  (n=7000)
Epoch 00033: Time=   7.0s, Loss=5.36e+00, Inv=5.36e+00, For=1.39e+01, Power=8.50e-01
  [eval] val_mse=1.168e+00  (n=7000)
Epoch 00034: Time=   7.1s, Loss=5.25e+00, Inv=5.25e+00, For=1.45e+01, Power=8.37e-01
  [eval] val_mse=1.122e+00  (n=7000)
Epoch 00035: Time=   7.1s, Loss=5.14e+00, Inv=5.14e+00, For=1.50e+01, Power=8.24e-01
  [eval] val_mse=1.082e+00  (n=7000)
Epoch 00036: Time=   7.1s, Loss=5.05e+00, Inv=5.05e+00, For=1.57e+01, Power=8.16e-01
  [eval] val_mse=1.041e+00  (n=7000)
Epoch 00037: Time=   7.2s, Loss=4.95e+00, Inv=4.95e+00, For=1.61e+01, Power=8.06e-01
  [eval] val_mse=1.003e+00  (n=7000)
Epoch 00038: Time=   7.2s, Loss=4.87e+00, Inv=4.87e+00, For=1.68e+01, Power=8.02e-01
  [eval] val_mse=9.687e-01  (n=7000)
Epoch 00039: Time=   7.2s, Loss=4.79e+00, Inv=4.79e+00, For=1.71e+01, Power=7.94e-01
  [eval] val_mse=9.367e-01  (n=7000)
Epoch 00040: Time=   7.3s, Loss=4.71e+00, Inv=4.71e+00, For=1.77e+01, Power=7.85e-01
  [eval] val_mse=9.067e-01  (n=7000)
Epoch 00041: Time=   7.3s, Loss=4.64e+00, Inv=4.64e+00, For=1.82e+01, Power=7.81e-01
  [eval] val_mse=8.795e-01  (n=7000)
Epoch 00042: Time=   7.4s, Loss=4.57e+00, Inv=4.57e+00, For=1.86e+01, Power=7.73e-01
  [eval] val_mse=8.519e-01  (n=7000)
Epoch 00043: Time=   7.4s, Loss=4.51e+00, Inv=4.51e+00, For=1.93e+01, Power=7.66e-01
  [eval] val_mse=8.302e-01  (n=7000)
Epoch 00044: Time=   7.4s, Loss=4.45e+00, Inv=4.45e+00, For=1.97e+01, Power=7.61e-01
  [eval] val_mse=8.057e-01  (n=7000)
Epoch 00045: Time=   7.5s, Loss=4.39e+00, Inv=4.39e+00, For=2.02e+01, Power=7.58e-01
  [eval] val_mse=7.857e-01  (n=7000)
Epoch 00046: Time=   7.5s, Loss=4.34e+00, Inv=4.34e+00, For=2.08e+01, Power=7.52e-01
  [eval] val_mse=7.652e-01  (n=7000)
Epoch 00047: Time=   7.5s, Loss=4.29e+00, Inv=4.29e+00, For=2.13e+01, Power=7.53e-01
  [eval] val_mse=7.461e-01  (n=7000)
Epoch 00048: Time=   7.6s, Loss=4.23e+00, Inv=4.23e+00, For=2.17e+01, Power=7.43e-01
  [eval] val_mse=7.281e-01  (n=7000)
Epoch 00049: Time=   7.6s, Loss=4.19e+00, Inv=4.19e+00, For=2.23e+01, Power=7.46e-01
  [eval] val_mse=7.117e-01  (n=7000)
Epoch 00050: Time=   7.7s, Loss=4.15e+00, Inv=4.15e+00, For=2.28e+01, Power=7.42e-01
  [eval] val_mse=6.950e-01  (n=7000)
Epoch 00051: Time=   7.7s, Loss=4.11e+00, Inv=4.11e+00, For=2.32e+01, Power=7.38e-01
  [eval] val_mse=6.810e-01  (n=7000)
Epoch 00052: Time=   7.7s, Loss=4.07e+00, Inv=4.07e+00, For=2.40e+01, Power=7.36e-01
  [eval] val_mse=6.674e-01  (n=7000)
Epoch 00053: Time=   7.8s, Loss=4.03e+00, Inv=4.03e+00, For=2.43e+01, Power=7.35e-01
  [eval] val_mse=6.545e-01  (n=7000)
Epoch 00054: Time=   7.8s, Loss=3.99e+00, Inv=3.99e+00, For=2.49e+01, Power=7.30e-01
  [eval] val_mse=6.410e-01  (n=7000)
Epoch 00055: Time=   7.8s, Loss=3.96e+00, Inv=3.96e+00, For=2.52e+01, Power=7.29e-01
  [eval] val_mse=6.299e-01  (n=7000)
Epoch 00056: Time=   7.9s, Loss=3.92e+00, Inv=3.92e+00, For=2.60e+01, Power=7.22e-01
  [eval] val_mse=6.185e-01  (n=7000)
Epoch 00057: Time=   7.9s, Loss=3.90e+00, Inv=3.90e+00, For=2.65e+01, Power=7.24e-01
  [eval] val_mse=6.082e-01  (n=7000)
Epoch 00058: Time=   8.0s, Loss=3.87e+00, Inv=3.87e+00, For=2.69e+01, Power=7.25e-01
  [eval] val_mse=5.974e-01  (n=7000)
Epoch 00059: Time=   8.0s, Loss=3.84e+00, Inv=3.84e+00, For=2.76e+01, Power=7.21e-01
  [eval] val_mse=5.882e-01  (n=7000)
Epoch 00060: Time=   8.0s, Loss=3.81e+00, Inv=3.81e+00, For=2.80e+01, Power=7.21e-01
  [eval] val_mse=5.786e-01  (n=7000)
Epoch 00061: Time=   8.1s, Loss=3.78e+00, Inv=3.78e+00, For=2.87e+01, Power=7.16e-01
  [eval] val_mse=5.704e-01  (n=7000)
Epoch 00062: Time=   8.1s, Loss=3.77e+00, Inv=3.77e+00, For=2.92e+01, Power=7.16e-01
  [eval] val_mse=5.623e-01  (n=7000)
Epoch 00063: Time=   8.1s, Loss=3.74e+00, Inv=3.74e+00, For=2.99e+01, Power=7.17e-01
  [eval] val_mse=5.540e-01  (n=7000)
Epoch 00064: Time=   8.2s, Loss=3.72e+00, Inv=3.72e+00, For=3.00e+01, Power=7.15e-01
  [eval] val_mse=5.464e-01  (n=7000)
Epoch 00065: Time=   8.2s, Loss=3.70e+00, Inv=3.70e+00, For=3.10e+01, Power=7.12e-01
  [eval] val_mse=5.398e-01  (n=7000)
Epoch 00066: Time=   8.3s, Loss=3.68e+00, Inv=3.68e+00, For=3.15e+01, Power=7.14e-01
  [eval] val_mse=5.322e-01  (n=7000)
Epoch 00067: Time=   8.3s, Loss=3.66e+00, Inv=3.66e+00, For=3.17e+01, Power=7.12e-01
  [eval] val_mse=5.256e-01  (n=7000)
Epoch 00068: Time=   8.3s, Loss=3.64e+00, Inv=3.64e+00, For=3.24e+01, Power=7.09e-01
  [eval] val_mse=5.197e-01  (n=7000)
Epoch 00069: Time=   8.4s, Loss=3.62e+00, Inv=3.62e+00, For=3.30e+01, Power=7.08e-01
  [eval] val_mse=5.132e-01  (n=7000)
Epoch 00070: Time=   8.4s, Loss=3.60e+00, Inv=3.60e+00, For=3.32e+01, Power=7.08e-01
  [eval] val_mse=5.076e-01  (n=7000)
Epoch 00071: Time=   8.5s, Loss=3.59e+00, Inv=3.59e+00, For=3.43e+01, Power=7.06e-01
  [eval] val_mse=5.015e-01  (n=7000)
Epoch 00072: Time=   8.5s, Loss=3.56e+00, Inv=3.56e+00, For=3.44e+01, Power=7.02e-01
  [eval] val_mse=4.957e-01  (n=7000)
Epoch 00073: Time=   8.5s, Loss=3.55e+00, Inv=3.55e+00, For=3.52e+01, Power=7.06e-01
  [eval] val_mse=4.909e-01  (n=7000)
Epoch 00074: Time=   8.6s, Loss=3.54e+00, Inv=3.54e+00, For=3.57e+01, Power=7.02e-01
  [eval] val_mse=4.878e-01  (n=7000)
Epoch 00075: Time=   8.6s, Loss=3.53e+00, Inv=3.53e+00, For=3.63e+01, Power=7.04e-01
  [eval] val_mse=4.809e-01  (n=7000)
Epoch 00076: Time=   8.7s, Loss=3.51e+00, Inv=3.51e+00, For=3.69e+01, Power=7.05e-01
  [eval] val_mse=4.764e-01  (n=7000)
Epoch 00077: Time=   8.7s, Loss=3.49e+00, Inv=3.49e+00, For=3.72e+01, Power=6.97e-01
  [eval] val_mse=4.722e-01  (n=7000)
Epoch 00078: Time=   8.7s, Loss=3.49e+00, Inv=3.49e+00, For=3.83e+01, Power=7.03e-01
  [eval] val_mse=4.689e-01  (n=7000)
Epoch 00079: Time=   8.8s, Loss=3.47e+00, Inv=3.47e+00, For=3.79e+01, Power=7.00e-01
  [eval] val_mse=4.638e-01  (n=7000)
Epoch 00080: Time=   8.8s, Loss=3.46e+00, Inv=3.46e+00, For=3.97e+01, Power=7.01e-01
  [eval] val_mse=4.597e-01  (n=7000)
Epoch 00081: Time=   8.8s, Loss=3.45e+00, Inv=3.45e+00, For=3.97e+01, Power=6.99e-01
  [eval] val_mse=4.558e-01  (n=7000)
Epoch 00082: Time=   8.9s, Loss=3.44e+00, Inv=3.44e+00, For=4.01e+01, Power=7.00e-01
  [eval] val_mse=4.523e-01  (n=7000)
Epoch 00083: Time=   8.9s, Loss=3.43e+00, Inv=3.43e+00, For=4.11e+01, Power=7.01e-01
  [eval] val_mse=4.507e-01  (n=7000)
Epoch 00084: Time=   9.0s, Loss=3.42e+00, Inv=3.42e+00, For=4.18e+01, Power=6.99e-01
  [eval] val_mse=4.466e-01  (n=7000)
Epoch 00085: Time=   9.0s, Loss=3.41e+00, Inv=3.41e+00, For=4.20e+01, Power=6.99e-01
  [eval] val_mse=4.436e-01  (n=7000)
Epoch 00086: Time=   9.0s, Loss=3.39e+00, Inv=3.39e+00, For=4.23e+01, Power=6.98e-01
  [eval] val_mse=4.402e-01  (n=7000)
Epoch 00087: Time=   9.1s, Loss=3.39e+00, Inv=3.39e+00, For=4.39e+01, Power=6.97e-01
  [eval] val_mse=4.377e-01  (n=7000)
Epoch 00088: Time=   9.1s, Loss=3.38e+00, Inv=3.38e+00, For=4.34e+01, Power=6.97e-01
  [eval] val_mse=4.351e-01  (n=7000)
Epoch 00089: Time=   9.1s, Loss=3.37e+00, Inv=3.37e+00, For=4.50e+01, Power=6.97e-01
  [eval] val_mse=4.308e-01  (n=7000)
Epoch 00090: Time=   9.2s, Loss=3.36e+00, Inv=3.36e+00, For=4.50e+01, Power=6.97e-01
  [eval] val_mse=4.281e-01  (n=7000)
Epoch 00091: Time=   9.2s, Loss=3.35e+00, Inv=3.35e+00, For=4.54e+01, Power=6.93e-01
  [eval] val_mse=4.261e-01  (n=7000)
Epoch 00092: Time=   9.3s, Loss=3.35e+00, Inv=3.35e+00, For=4.63e+01, Power=6.96e-01
  [eval] val_mse=4.235e-01  (n=7000)
Epoch 00093: Time=   9.3s, Loss=3.33e+00, Inv=3.33e+00, For=4.72e+01, Power=6.91e-01
  [eval] val_mse=4.210e-01  (n=7000)
Epoch 00094: Time=   9.3s, Loss=3.32e+00, Inv=3.32e+00, For=4.71e+01, Power=6.92e-01
  [eval] val_mse=4.183e-01  (n=7000)
Epoch 00095: Time=   9.4s, Loss=3.32e+00, Inv=3.32e+00, For=4.79e+01, Power=6.94e-01
  [eval] val_mse=4.157e-01  (n=7000)
Epoch 00096: Time=   9.4s, Loss=3.31e+00, Inv=3.31e+00, For=4.90e+01, Power=6.94e-01
  [eval] val_mse=4.142e-01  (n=7000)
Epoch 00097: Time=   9.4s, Loss=3.30e+00, Inv=3.30e+00, For=4.93e+01, Power=6.93e-01
  [eval] val_mse=4.117e-01  (n=7000)
Epoch 00098: Time=   9.5s, Loss=3.30e+00, Inv=3.30e+00, For=5.01e+01, Power=6.95e-01
  [eval] val_mse=4.100e-01  (n=7000)
Epoch 00099: Time=   9.5s, Loss=3.29e+00, Inv=3.29e+00, For=5.06e+01, Power=6.88e-01
  [eval] val_mse=4.073e-01  (n=7000)
Epoch 00100: Time=   9.6s, Loss=3.29e+00, Inv=3.29e+00, For=5.17e+01, Power=6.93e-01
  [eval] val_mse=4.063e-01  (n=7000)
Epoch 00101: Time=   9.6s, Loss=3.28e+00, Inv=3.28e+00, For=5.14e+01, Power=6.89e-01
  [eval] val_mse=4.034e-01  (n=7000)
Epoch 00102: Time=   9.6s, Loss=3.27e+00, Inv=3.27e+00, For=5.23e+01, Power=6.93e-01
  [eval] val_mse=4.021e-01  (n=7000)
Epoch 00103: Time=   9.7s, Loss=3.26e+00, Inv=3.26e+00, For=5.30e+01, Power=6.90e-01
  [eval] val_mse=4.005e-01  (n=7000)
Epoch 00104: Time=   9.7s, Loss=3.26e+00, Inv=3.26e+00, For=5.38e+01, Power=6.92e-01
  [eval] val_mse=3.997e-01  (n=7000)
Epoch 00105: Time=   9.7s, Loss=3.25e+00, Inv=3.25e+00, For=5.44e+01, Power=6.90e-01
  [eval] val_mse=3.968e-01  (n=7000)
Epoch 00106: Time=   9.8s, Loss=3.25e+00, Inv=3.25e+00, For=5.49e+01, Power=6.91e-01
  [eval] val_mse=3.960e-01  (n=7000)
Epoch 00107: Time=   9.8s, Loss=3.24e+00, Inv=3.24e+00, For=5.55e+01, Power=6.89e-01
  [eval] val_mse=3.949e-01  (n=7000)
Epoch 00108: Time=   9.9s, Loss=3.24e+00, Inv=3.24e+00, For=5.63e+01, Power=6.92e-01
  [eval] val_mse=3.922e-01  (n=7000)
Epoch 00109: Time=   9.9s, Loss=3.23e+00, Inv=3.23e+00, For=5.67e+01, Power=6.90e-01
  [eval] val_mse=3.902e-01  (n=7000)
Epoch 00110: Time=   9.9s, Loss=3.22e+00, Inv=3.22e+00, For=5.78e+01, Power=6.88e-01
  [eval] val_mse=3.889e-01  (n=7000)
Epoch 00111: Time=  10.0s, Loss=3.22e+00, Inv=3.22e+00, For=5.78e+01, Power=6.91e-01
  [eval] val_mse=3.865e-01  (n=7000)
Epoch 00112: Time=  10.0s, Loss=3.21e+00, Inv=3.21e+00, For=5.90e+01, Power=6.86e-01
  [eval] val_mse=3.866e-01  (n=7000)
Epoch 00113: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=5.96e+01, Power=6.88e-01
  [eval] val_mse=3.865e-01  (n=7000)
Epoch 00114: Time=  10.1s, Loss=3.21e+00, Inv=3.21e+00, For=6.02e+01, Power=6.88e-01
  [eval] val_mse=3.831e-01  (n=7000)
Epoch 00115: Time=  10.1s, Loss=3.20e+00, Inv=3.20e+00, For=6.09e+01, Power=6.88e-01
  [eval] val_mse=3.823e-01  (n=7000)
Epoch 00116: Time=  10.2s, Loss=3.20e+00, Inv=3.20e+00, For=6.13e+01, Power=6.89e-01
  [eval] val_mse=3.806e-01  (n=7000)
Epoch 00117: Time=  10.2s, Loss=3.19e+00, Inv=3.19e+00, For=6.24e+01, Power=6.89e-01
  [eval] val_mse=3.806e-01  (n=7000)
Epoch 00118: Time=  10.3s, Loss=3.18e+00, Inv=3.18e+00, For=6.17e+01, Power=6.83e-01
  [eval] val_mse=3.780e-01  (n=7000)
Epoch 00119: Time=  10.3s, Loss=3.18e+00, Inv=3.18e+00, For=6.37e+01, Power=6.87e-01
  [eval] val_mse=3.776e-01  (n=7000)
Epoch 00120: Time=  10.3s, Loss=3.17e+00, Inv=3.17e+00, For=6.42e+01, Power=6.85e-01
  [eval] val_mse=3.762e-01  (n=7000)
Epoch 00121: Time=  10.4s, Loss=3.18e+00, Inv=3.18e+00, For=6.48e+01, Power=6.87e-01
  [eval] val_mse=3.752e-01  (n=7000)
Epoch 00122: Time=  10.4s, Loss=3.17e+00, Inv=3.17e+00, For=6.58e+01, Power=6.86e-01
  [eval] val_mse=3.742e-01  (n=7000)
Epoch 00123: Time=  10.4s, Loss=3.16e+00, Inv=3.16e+00, For=6.53e+01, Power=6.84e-01
  [eval] val_mse=3.736e-01  (n=7000)
Epoch 00124: Time=  10.5s, Loss=3.16e+00, Inv=3.16e+00, For=6.69e+01, Power=6.87e-01
  [eval] val_mse=3.718e-01  (n=7000)
Epoch 00125: Time=  10.5s, Loss=3.15e+00, Inv=3.15e+00, For=6.66e+01, Power=6.85e-01
  [eval] val_mse=3.711e-01  (n=7000)
Epoch 00126: Time=  10.6s, Loss=3.15e+00, Inv=3.15e+00, For=6.83e+01, Power=6.85e-01
  [eval] val_mse=3.698e-01  (n=7000)
Epoch 00127: Time=  10.6s, Loss=3.15e+00, Inv=3.15e+00, For=6.88e+01, Power=6.85e-01
  [eval] val_mse=3.701e-01  (n=7000)
Epoch 00128: Time=  10.6s, Loss=3.14e+00, Inv=3.14e+00, For=6.89e+01, Power=6.85e-01
  [eval] val_mse=3.683e-01  (n=7000)
Epoch 00129: Time=  10.7s, Loss=3.14e+00, Inv=3.14e+00, For=6.94e+01, Power=6.86e-01
  [eval] val_mse=3.671e-01  (n=7000)
Epoch 00130: Time=  10.7s, Loss=3.13e+00, Inv=3.13e+00, For=7.10e+01, Power=6.84e-01
  [eval] val_mse=3.660e-01  (n=7000)
Epoch 00131: Time=  10.7s, Loss=3.13e+00, Inv=3.13e+00, For=7.08e+01, Power=6.85e-01
  [eval] val_mse=3.662e-01  (n=7000)
Epoch 00132: Time=  10.8s, Loss=3.13e+00, Inv=3.13e+00, For=7.18e+01, Power=6.85e-01
  [eval] val_mse=3.645e-01  (n=7000)
Epoch 00133: Time=  10.8s, Loss=3.13e+00, Inv=3.13e+00, For=7.18e+01, Power=6.86e-01
  [eval] val_mse=3.644e-01  (n=7000)
Epoch 00134: Time=  10.9s, Loss=3.13e+00, Inv=3.13e+00, For=7.29e+01, Power=6.88e-01
  [eval] val_mse=3.630e-01  (n=7000)
Epoch 00135: Time=  10.9s, Loss=3.12e+00, Inv=3.12e+00, For=7.35e+01, Power=6.85e-01
  [eval] val_mse=3.626e-01  (n=7000)
Epoch 00136: Time=  10.9s, Loss=3.12e+00, Inv=3.12e+00, For=7.41e+01, Power=6.82e-01
  [eval] val_mse=3.617e-01  (n=7000)
Epoch 00137: Time=  11.0s, Loss=3.12e+00, Inv=3.12e+00, For=7.48e+01, Power=6.86e-01
  [eval] val_mse=3.605e-01  (n=7000)
Epoch 00138: Time=  11.0s, Loss=3.11e+00, Inv=3.11e+00, For=7.59e+01, Power=6.85e-01
  [eval] val_mse=3.606e-01  (n=7000)
Epoch 00139: Time=  11.0s, Loss=3.11e+00, Inv=3.11e+00, For=7.58e+01, Power=6.84e-01
  [eval] val_mse=3.602e-01  (n=7000)
Epoch 00140: Time=  11.1s, Loss=3.10e+00, Inv=3.10e+00, For=7.69e+01, Power=6.81e-01
  [eval] val_mse=3.598e-01  (n=7000)
Epoch 00141: Time=  11.1s, Loss=3.10e+00, Inv=3.10e+00, For=7.72e+01, Power=6.84e-01
  [eval] val_mse=3.579e-01  (n=7000)
Epoch 00142: Time=  11.2s, Loss=3.10e+00, Inv=3.10e+00, For=7.79e+01, Power=6.82e-01
  [eval] val_mse=3.570e-01  (n=7000)
Epoch 00143: Time=  11.2s, Loss=3.09e+00, Inv=3.09e+00, For=7.79e+01, Power=6.81e-01
  [eval] val_mse=3.566e-01  (n=7000)
Epoch 00144: Time=  11.2s, Loss=3.09e+00, Inv=3.09e+00, For=7.98e+01, Power=6.80e-01
  [eval] val_mse=3.567e-01  (n=7000)
Epoch 00145: Time=  11.3s, Loss=3.09e+00, Inv=3.09e+00, For=7.91e+01, Power=6.83e-01
  [eval] val_mse=3.552e-01  (n=7000)
Epoch 00146: Time=  11.3s, Loss=3.09e+00, Inv=3.09e+00, For=8.08e+01, Power=6.84e-01
  [eval] val_mse=3.555e-01  (n=7000)
Epoch 00147: Time=  11.3s, Loss=3.08e+00, Inv=3.08e+00, For=8.03e+01, Power=6.82e-01
  [eval] val_mse=3.544e-01  (n=7000)
Epoch 00148: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=8.18e+01, Power=6.80e-01
  [eval] val_mse=3.545e-01  (n=7000)
Epoch 00149: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=8.19e+01, Power=6.81e-01
  [eval] val_mse=3.546e-01  (n=7000)
Epoch 00150: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=8.27e+01, Power=6.82e-01
  [eval] val_mse=3.527e-01  (n=7000)
Epoch 00151: Time=  11.5s, Loss=3.08e+00, Inv=3.08e+00, For=8.30e+01, Power=6.82e-01
  [eval] val_mse=3.525e-01  (n=7000)
Epoch 00152: Time=  11.5s, Loss=3.07e+00, Inv=3.07e+00, For=8.32e+01, Power=6.82e-01
  [eval] val_mse=3.530e-01  (n=7000)
Epoch 00153: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=8.42e+01, Power=6.81e-01
  [eval] val_mse=3.511e-01  (n=7000)
Epoch 00154: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=8.50e+01, Power=6.83e-01
  [eval] val_mse=3.511e-01  (n=7000)
Epoch 00155: Time=  11.6s, Loss=3.06e+00, Inv=3.06e+00, For=8.56e+01, Power=6.82e-01
  [eval] val_mse=3.510e-01  (n=7000)
Epoch 00156: Time=  11.7s, Loss=3.06e+00, Inv=3.06e+00, For=8.53e+01, Power=6.82e-01
  [eval] val_mse=3.493e-01  (n=7000)
Epoch 00157: Time=  11.7s, Loss=3.06e+00, Inv=3.06e+00, For=8.65e+01, Power=6.80e-01
  [eval] val_mse=3.496e-01  (n=7000)
Epoch 00158: Time=  11.8s, Loss=3.06e+00, Inv=3.06e+00, For=8.71e+01, Power=6.80e-01
  [eval] val_mse=3.494e-01  (n=7000)
Epoch 00159: Time=  11.8s, Loss=3.06e+00, Inv=3.06e+00, For=8.75e+01, Power=6.81e-01
  [eval] val_mse=3.492e-01  (n=7000)
Epoch 00160: Time=  11.8s, Loss=3.05e+00, Inv=3.05e+00, For=8.75e+01, Power=6.80e-01
  [eval] val_mse=3.477e-01  (n=7000)
Epoch 00161: Time=  11.9s, Loss=3.05e+00, Inv=3.05e+00, For=8.79e+01, Power=6.80e-01
  [eval] val_mse=3.475e-01  (n=7000)
Epoch 00162: Time=  11.9s, Loss=3.05e+00, Inv=3.05e+00, For=8.93e+01, Power=6.83e-01
  [eval] val_mse=3.471e-01  (n=7000)
Epoch 00163: Time=  12.0s, Loss=3.05e+00, Inv=3.05e+00, For=8.93e+01, Power=6.81e-01
  [eval] val_mse=3.477e-01  (n=7000)
Epoch 00164: Time=  12.0s, Loss=3.04e+00, Inv=3.04e+00, For=8.86e+01, Power=6.81e-01
  [eval] val_mse=3.463e-01  (n=7000)
Epoch 00165: Time=  12.1s, Loss=3.04e+00, Inv=3.04e+00, For=9.06e+01, Power=6.81e-01
  [eval] val_mse=3.457e-01  (n=7000)
Epoch 00166: Time=  12.1s, Loss=3.04e+00, Inv=3.04e+00, For=9.02e+01, Power=6.81e-01
  [eval] val_mse=3.464e-01  (n=7000)
Epoch 00167: Time=  12.1s, Loss=3.04e+00, Inv=3.04e+00, For=9.17e+01, Power=6.81e-01
  [eval] val_mse=3.457e-01  (n=7000)
Epoch 00168: Time=  12.2s, Loss=3.04e+00, Inv=3.04e+00, For=9.17e+01, Power=6.82e-01
  [eval] val_mse=3.460e-01  (n=7000)
Epoch 00169: Time=  12.2s, Loss=3.03e+00, Inv=3.03e+00, For=9.18e+01, Power=6.82e-01
  [eval] val_mse=3.445e-01  (n=7000)
Epoch 00170: Time=  12.2s, Loss=3.03e+00, Inv=3.03e+00, For=9.19e+01, Power=6.81e-01
  [eval] val_mse=3.433e-01  (n=7000)
Epoch 00171: Time=  12.3s, Loss=3.03e+00, Inv=3.03e+00, For=9.26e+01, Power=6.78e-01
  [eval] val_mse=3.441e-01  (n=7000)
Epoch 00172: Time=  12.3s, Loss=3.03e+00, Inv=3.03e+00, For=9.36e+01, Power=6.84e-01
  [eval] val_mse=3.439e-01  (n=7000)
Epoch 00173: Time=  12.4s, Loss=3.02e+00, Inv=3.02e+00, For=9.34e+01, Power=6.79e-01
  [eval] val_mse=3.436e-01  (n=7000)
Epoch 00174: Time=  12.4s, Loss=3.03e+00, Inv=3.03e+00, For=9.42e+01, Power=6.81e-01
  [eval] val_mse=3.423e-01  (n=7000)
Epoch 00175: Time=  12.4s, Loss=3.03e+00, Inv=3.03e+00, For=9.53e+01, Power=6.84e-01
  [eval] val_mse=3.439e-01  (n=7000)
Epoch 00176: Time=  12.5s, Loss=3.02e+00, Inv=3.02e+00, For=9.46e+01, Power=6.79e-01
  [eval] val_mse=3.424e-01  (n=7000)
Epoch 00177: Time=  12.5s, Loss=3.01e+00, Inv=3.01e+00, For=9.48e+01, Power=6.79e-01
  [eval] val_mse=3.421e-01  (n=7000)
Epoch 00178: Time=  12.5s, Loss=3.01e+00, Inv=3.01e+00, For=9.47e+01, Power=6.79e-01
  [eval] val_mse=3.416e-01  (n=7000)
Epoch 00179: Time=  12.6s, Loss=3.01e+00, Inv=3.01e+00, For=9.67e+01, Power=6.76e-01
  [eval] val_mse=3.414e-01  (n=7000)
Epoch 00180: Time=  12.6s, Loss=3.01e+00, Inv=3.01e+00, For=9.61e+01, Power=6.79e-01
  [eval] val_mse=3.411e-01  (n=7000)
Epoch 00181: Time=  12.6s, Loss=3.01e+00, Inv=3.01e+00, For=9.61e+01, Power=6.79e-01
  [eval] val_mse=3.406e-01  (n=7000)
Epoch 00182: Time=  12.7s, Loss=3.01e+00, Inv=3.01e+00, For=9.70e+01, Power=6.79e-01
  [eval] val_mse=3.412e-01  (n=7000)
Epoch 00183: Time=  12.7s, Loss=3.01e+00, Inv=3.01e+00, For=9.69e+01, Power=6.78e-01
  [eval] val_mse=3.406e-01  (n=7000)
Epoch 00184: Time=  12.8s, Loss=3.00e+00, Inv=3.00e+00, For=9.71e+01, Power=6.81e-01
  [eval] val_mse=3.405e-01  (n=7000)
Epoch 00185: Time=  12.8s, Loss=3.00e+00, Inv=3.00e+00, For=9.80e+01, Power=6.79e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00186: Time=  12.8s, Loss=3.00e+00, Inv=3.00e+00, For=9.83e+01, Power=6.80e-01
  [eval] val_mse=3.415e-01  (n=7000)
Epoch 00187: Time=  12.9s, Loss=3.00e+00, Inv=3.00e+00, For=9.76e+01, Power=6.78e-01
  [eval] val_mse=3.393e-01  (n=7000)
Epoch 00188: Time=  12.9s, Loss=3.00e+00, Inv=3.00e+00, For=9.82e+01, Power=6.79e-01
  [eval] val_mse=3.389e-01  (n=7000)
Epoch 00189: Time=  12.9s, Loss=2.99e+00, Inv=2.99e+00, For=9.85e+01, Power=6.79e-01
  [eval] val_mse=3.384e-01  (n=7000)
Epoch 00190: Time=  13.0s, Loss=2.99e+00, Inv=2.99e+00, For=9.96e+01, Power=6.77e-01
  [eval] val_mse=3.391e-01  (n=7000)
Epoch 00191: Time=  13.0s, Loss=2.99e+00, Inv=2.99e+00, For=9.87e+01, Power=6.78e-01
  [eval] val_mse=3.382e-01  (n=7000)
Epoch 00192: Time=  13.0s, Loss=2.99e+00, Inv=2.99e+00, For=1.00e+02, Power=6.79e-01
  [eval] val_mse=3.396e-01  (n=7000)
Epoch 00193: Time=  13.1s, Loss=2.99e+00, Inv=2.99e+00, For=9.88e+01, Power=6.79e-01
  [eval] val_mse=3.378e-01  (n=7000)
Epoch 00194: Time=  13.1s, Loss=2.99e+00, Inv=2.99e+00, For=1.00e+02, Power=6.81e-01
  [eval] val_mse=3.380e-01  (n=7000)
Epoch 00195: Time=  13.1s, Loss=2.98e+00, Inv=2.98e+00, For=1.00e+02, Power=6.79e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00196: Time=  13.2s, Loss=2.99e+00, Inv=2.99e+00, For=1.00e+02, Power=6.81e-01
  [eval] val_mse=3.373e-01  (n=7000)
Epoch 00197: Time=  13.2s, Loss=2.98e+00, Inv=2.98e+00, For=1.01e+02, Power=6.79e-01
  [eval] val_mse=3.370e-01  (n=7000)
Epoch 00198: Time=  13.2s, Loss=2.97e+00, Inv=2.97e+00, For=1.00e+02, Power=6.78e-01
  [eval] val_mse=3.381e-01  (n=7000)
Epoch 00199: Time=  13.3s, Loss=2.98e+00, Inv=2.98e+00, For=1.00e+02, Power=6.80e-01
  [eval] val_mse=3.362e-01  (n=7000)
Epoch 00200: Time=  13.3s, Loss=2.98e+00, Inv=2.98e+00, For=1.01e+02, Power=6.78e-01
  [eval] val_mse=3.367e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 2.367e-01
Torque MSE  = 1.084e-01
Torque RMSE = 3.292e-01
Per-joint MSE : 7.266e-02 3.518e-01 5.318e-02 2.038e-02 1.366e-01 1.586e-02
Per-joint RMSE: 2.695e-01 5.931e-01 2.306e-01 1.428e-01 3.696e-01 1.259e-01
Comp Time per Sample = 3.242e-04s / 3084.1Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-hshdjbu_ because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7911b42228c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
   dt ≈ 0.013911611423806564
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 35497
  Test samples  = 5500
################################################

2026-01-30 16:00:03.162369: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 16:00:05.036663: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.2s, Loss=1.12e+04, Inv=1.12e+04, For=5.76e+00, Power=1.01e+03
  [eval] val_mse=2.198e+02  (n=7000)
Epoch 00002: Time=   5.8s, Loss=8.23e+02, Inv=8.23e+02, For=5.64e+00, Power=7.28e+01
  [eval] val_mse=8.858e+01  (n=7000)
Epoch 00003: Time=   5.8s, Loss=3.40e+02, Inv=3.40e+02, For=5.72e+00, Power=3.22e+01
  [eval] val_mse=4.974e+01  (n=7000)
Epoch 00004: Time=   5.8s, Loss=2.03e+02, Inv=2.03e+02, For=5.80e+00, Power=1.99e+01
  [eval] val_mse=3.172e+01  (n=7000)
Epoch 00005: Time=   5.9s, Loss=1.36e+02, Inv=1.36e+02, For=5.93e+00, Power=1.34e+01
  [eval] val_mse=2.184e+01  (n=7000)
Epoch 00006: Time=   5.9s, Loss=9.71e+01, Inv=9.71e+01, For=6.06e+00, Power=9.72e+00
  [eval] val_mse=1.598e+01  (n=7000)
Epoch 00007: Time=   5.9s, Loss=7.31e+01, Inv=7.31e+01, For=6.27e+00, Power=7.32e+00
  [eval] val_mse=1.225e+01  (n=7000)
Epoch 00008: Time=   6.0s, Loss=5.73e+01, Inv=5.73e+01, For=6.53e+00, Power=5.81e+00
  [eval] val_mse=9.755e+00  (n=7000)
Epoch 00009: Time=   6.0s, Loss=4.65e+01, Inv=4.65e+01, For=6.81e+00, Power=4.70e+00
  [eval] val_mse=7.943e+00  (n=7000)
Epoch 00010: Time=   6.1s, Loss=3.84e+01, Inv=3.84e+01, For=7.08e+00, Power=3.92e+00
  [eval] val_mse=6.623e+00  (n=7000)
Epoch 00011: Time=   6.1s, Loss=3.24e+01, Inv=3.24e+01, For=7.37e+00, Power=3.34e+00
  [eval] val_mse=5.608e+00  (n=7000)
Epoch 00012: Time=   6.1s, Loss=2.78e+01, Inv=2.78e+01, For=7.59e+00, Power=2.88e+00
  [eval] val_mse=4.823e+00  (n=7000)
Epoch 00013: Time=   6.2s, Loss=2.42e+01, Inv=2.42e+01, For=7.82e+00, Power=2.54e+00
  [eval] val_mse=4.204e+00  (n=7000)
Epoch 00014: Time=   6.2s, Loss=2.13e+01, Inv=2.13e+01, For=8.01e+00, Power=2.24e+00
  [eval] val_mse=3.716e+00  (n=7000)
Epoch 00015: Time=   6.2s, Loss=1.90e+01, Inv=1.90e+01, For=8.19e+00, Power=2.03e+00
  [eval] val_mse=3.317e+00  (n=7000)
Epoch 00016: Time=   6.3s, Loss=1.72e+01, Inv=1.72e+01, For=8.38e+00, Power=1.85e+00
  [eval] val_mse=2.989e+00  (n=7000)
Epoch 00017: Time=   6.3s, Loss=1.56e+01, Inv=1.56e+01, For=8.55e+00, Power=1.71e+00
  [eval] val_mse=2.710e+00  (n=7000)
Epoch 00018: Time=   6.3s, Loss=1.43e+01, Inv=1.43e+01, For=8.72e+00, Power=1.58e+00
  [eval] val_mse=2.484e+00  (n=7000)
Epoch 00019: Time=   6.4s, Loss=1.31e+01, Inv=1.31e+01, For=8.87e+00, Power=1.48e+00
  [eval] val_mse=2.290e+00  (n=7000)
Epoch 00020: Time=   6.4s, Loss=1.22e+01, Inv=1.22e+01, For=9.11e+00, Power=1.39e+00
  [eval] val_mse=2.128e+00  (n=7000)
Epoch 00021: Time=   6.4s, Loss=1.14e+01, Inv=1.14e+01, For=9.29e+00, Power=1.30e+00
  [eval] val_mse=1.986e+00  (n=7000)
Epoch 00022: Time=   6.5s, Loss=1.07e+01, Inv=1.07e+01, For=9.56e+00, Power=1.25e+00
  [eval] val_mse=1.865e+00  (n=7000)
Epoch 00023: Time=   6.5s, Loss=1.01e+01, Inv=1.01e+01, For=9.87e+00, Power=1.19e+00
  [eval] val_mse=1.763e+00  (n=7000)
Epoch 00024: Time=   6.5s, Loss=9.51e+00, Inv=9.51e+00, For=1.02e+01, Power=1.14e+00
  [eval] val_mse=1.671e+00  (n=7000)
Epoch 00025: Time=   6.6s, Loss=9.07e+00, Inv=9.07e+00, For=1.05e+01, Power=1.10e+00
  [eval] val_mse=1.587e+00  (n=7000)
Epoch 00026: Time=   6.6s, Loss=8.62e+00, Inv=8.62e+00, For=1.09e+01, Power=1.06e+00
  [eval] val_mse=1.518e+00  (n=7000)
Epoch 00027: Time=   6.6s, Loss=8.24e+00, Inv=8.24e+00, For=1.13e+01, Power=1.03e+00
  [eval] val_mse=1.452e+00  (n=7000)
Epoch 00028: Time=   6.7s, Loss=7.90e+00, Inv=7.90e+00, For=1.17e+01, Power=9.97e-01
  [eval] val_mse=1.393e+00  (n=7000)
Epoch 00029: Time=   6.7s, Loss=7.59e+00, Inv=7.59e+00, For=1.21e+01, Power=9.72e-01
  [eval] val_mse=1.341e+00  (n=7000)
Epoch 00030: Time=   6.7s, Loss=7.34e+00, Inv=7.34e+00, For=1.26e+01, Power=9.47e-01
  [eval] val_mse=1.293e+00  (n=7000)
Epoch 00031: Time=   6.8s, Loss=7.08e+00, Inv=7.08e+00, For=1.31e+01, Power=9.27e-01
  [eval] val_mse=1.247e+00  (n=7000)
Epoch 00032: Time=   6.8s, Loss=6.86e+00, Inv=6.86e+00, For=1.36e+01, Power=9.12e-01
  [eval] val_mse=1.208e+00  (n=7000)
Epoch 00033: Time=   6.8s, Loss=6.66e+00, Inv=6.66e+00, For=1.41e+01, Power=8.91e-01
  [eval] val_mse=1.171e+00  (n=7000)
Epoch 00034: Time=   6.9s, Loss=6.47e+00, Inv=6.47e+00, For=1.46e+01, Power=8.77e-01
  [eval] val_mse=1.135e+00  (n=7000)
Epoch 00035: Time=   6.9s, Loss=6.30e+00, Inv=6.30e+00, For=1.52e+01, Power=8.66e-01
  [eval] val_mse=1.103e+00  (n=7000)
Epoch 00036: Time=   6.9s, Loss=6.14e+00, Inv=6.14e+00, For=1.57e+01, Power=8.54e-01
  [eval] val_mse=1.072e+00  (n=7000)
Epoch 00037: Time=   7.0s, Loss=5.99e+00, Inv=5.99e+00, For=1.62e+01, Power=8.42e-01
  [eval] val_mse=1.043e+00  (n=7000)
Epoch 00038: Time=   7.0s, Loss=5.86e+00, Inv=5.86e+00, For=1.67e+01, Power=8.30e-01
  [eval] val_mse=1.017e+00  (n=7000)
Epoch 00039: Time=   7.0s, Loss=5.73e+00, Inv=5.73e+00, For=1.74e+01, Power=8.23e-01
  [eval] val_mse=9.915e-01  (n=7000)
Epoch 00040: Time=   7.1s, Loss=5.61e+00, Inv=5.61e+00, For=1.79e+01, Power=8.15e-01
  [eval] val_mse=9.698e-01  (n=7000)
Epoch 00041: Time=   7.1s, Loss=5.51e+00, Inv=5.51e+00, For=1.85e+01, Power=8.04e-01
  [eval] val_mse=9.478e-01  (n=7000)
Epoch 00042: Time=   7.1s, Loss=5.40e+00, Inv=5.40e+00, For=1.91e+01, Power=7.95e-01
  [eval] val_mse=9.270e-01  (n=7000)
Epoch 00043: Time=   7.2s, Loss=5.30e+00, Inv=5.30e+00, For=1.97e+01, Power=7.91e-01
  [eval] val_mse=9.079e-01  (n=7000)
Epoch 00044: Time=   7.2s, Loss=5.21e+00, Inv=5.21e+00, For=2.04e+01, Power=7.85e-01
  [eval] val_mse=8.908e-01  (n=7000)
Epoch 00045: Time=   7.2s, Loss=5.13e+00, Inv=5.13e+00, For=2.10e+01, Power=7.79e-01
  [eval] val_mse=8.728e-01  (n=7000)
Epoch 00046: Time=   7.3s, Loss=5.05e+00, Inv=5.05e+00, For=2.17e+01, Power=7.74e-01
  [eval] val_mse=8.566e-01  (n=7000)
Epoch 00047: Time=   7.3s, Loss=4.98e+00, Inv=4.98e+00, For=2.24e+01, Power=7.67e-01
  [eval] val_mse=8.414e-01  (n=7000)
Epoch 00048: Time=   7.3s, Loss=4.91e+00, Inv=4.91e+00, For=2.31e+01, Power=7.65e-01
  [eval] val_mse=8.277e-01  (n=7000)
Epoch 00049: Time=   7.4s, Loss=4.84e+00, Inv=4.84e+00, For=2.38e+01, Power=7.59e-01
  [eval] val_mse=8.131e-01  (n=7000)
Epoch 00050: Time=   7.4s, Loss=4.77e+00, Inv=4.77e+00, For=2.44e+01, Power=7.54e-01
  [eval] val_mse=8.007e-01  (n=7000)
Epoch 00051: Time=   7.4s, Loss=4.70e+00, Inv=4.70e+00, For=2.52e+01, Power=7.51e-01
  [eval] val_mse=7.886e-01  (n=7000)
Epoch 00052: Time=   7.5s, Loss=4.64e+00, Inv=4.64e+00, For=2.60e+01, Power=7.47e-01
  [eval] val_mse=7.768e-01  (n=7000)
Epoch 00053: Time=   7.5s, Loss=4.59e+00, Inv=4.59e+00, For=2.69e+01, Power=7.42e-01
  [eval] val_mse=7.664e-01  (n=7000)
Epoch 00054: Time=   7.5s, Loss=4.53e+00, Inv=4.53e+00, For=2.75e+01, Power=7.38e-01
  [eval] val_mse=7.555e-01  (n=7000)
Epoch 00055: Time=   7.6s, Loss=4.49e+00, Inv=4.49e+00, For=2.85e+01, Power=7.37e-01
  [eval] val_mse=7.473e-01  (n=7000)
Epoch 00056: Time=   7.6s, Loss=4.44e+00, Inv=4.44e+00, For=2.92e+01, Power=7.36e-01
  [eval] val_mse=7.370e-01  (n=7000)
Epoch 00057: Time=   7.6s, Loss=4.39e+00, Inv=4.39e+00, For=3.02e+01, Power=7.33e-01
  [eval] val_mse=7.285e-01  (n=7000)
Epoch 00058: Time=   7.7s, Loss=4.35e+00, Inv=4.35e+00, For=3.10e+01, Power=7.29e-01
  [eval] val_mse=7.198e-01  (n=7000)
Epoch 00059: Time=   7.7s, Loss=4.30e+00, Inv=4.30e+00, For=3.19e+01, Power=7.29e-01
  [eval] val_mse=7.121e-01  (n=7000)
Epoch 00060: Time=   7.7s, Loss=4.27e+00, Inv=4.27e+00, For=3.27e+01, Power=7.26e-01
  [eval] val_mse=7.045e-01  (n=7000)
Epoch 00061: Time=   7.8s, Loss=4.22e+00, Inv=4.22e+00, For=3.39e+01, Power=7.22e-01
  [eval] val_mse=6.966e-01  (n=7000)
Epoch 00062: Time=   7.8s, Loss=4.19e+00, Inv=4.19e+00, For=3.48e+01, Power=7.23e-01
  [eval] val_mse=6.904e-01  (n=7000)
Epoch 00063: Time=   7.8s, Loss=4.15e+00, Inv=4.15e+00, For=3.58e+01, Power=7.15e-01
  [eval] val_mse=6.830e-01  (n=7000)
Epoch 00064: Time=   7.9s, Loss=4.12e+00, Inv=4.12e+00, For=3.66e+01, Power=7.18e-01
  [eval] val_mse=6.762e-01  (n=7000)
Epoch 00065: Time=   7.9s, Loss=4.09e+00, Inv=4.09e+00, For=3.81e+01, Power=7.15e-01
  [eval] val_mse=6.712e-01  (n=7000)
Epoch 00066: Time=   7.9s, Loss=4.06e+00, Inv=4.06e+00, For=3.90e+01, Power=7.16e-01
  [eval] val_mse=6.639e-01  (n=7000)
Epoch 00067: Time=   8.0s, Loss=4.03e+00, Inv=4.03e+00, For=4.01e+01, Power=7.13e-01
  [eval] val_mse=6.578e-01  (n=7000)
Epoch 00068: Time=   8.0s, Loss=4.00e+00, Inv=4.00e+00, For=4.13e+01, Power=7.12e-01
  [eval] val_mse=6.525e-01  (n=7000)
Epoch 00069: Time=   8.1s, Loss=3.97e+00, Inv=3.97e+00, For=4.23e+01, Power=7.08e-01
  [eval] val_mse=6.467e-01  (n=7000)
Epoch 00070: Time=   8.1s, Loss=3.94e+00, Inv=3.94e+00, For=4.35e+01, Power=7.13e-01
  [eval] val_mse=6.420e-01  (n=7000)
Epoch 00071: Time=   8.1s, Loss=3.92e+00, Inv=3.92e+00, For=4.49e+01, Power=7.10e-01
  [eval] val_mse=6.361e-01  (n=7000)
Epoch 00072: Time=   8.2s, Loss=3.89e+00, Inv=3.89e+00, For=4.62e+01, Power=7.08e-01
  [eval] val_mse=6.321e-01  (n=7000)
Epoch 00073: Time=   8.2s, Loss=3.87e+00, Inv=3.87e+00, For=4.76e+01, Power=7.09e-01
  [eval] val_mse=6.269e-01  (n=7000)
Epoch 00074: Time=   8.2s, Loss=3.85e+00, Inv=3.85e+00, For=4.85e+01, Power=7.07e-01
  [eval] val_mse=6.219e-01  (n=7000)
Epoch 00075: Time=   8.2s, Loss=3.83e+00, Inv=3.83e+00, For=5.01e+01, Power=7.08e-01
  [eval] val_mse=6.166e-01  (n=7000)
Epoch 00076: Time=   8.3s, Loss=3.81e+00, Inv=3.81e+00, For=5.14e+01, Power=7.04e-01
  [eval] val_mse=6.115e-01  (n=7000)
Epoch 00077: Time=   8.3s, Loss=3.79e+00, Inv=3.79e+00, For=5.28e+01, Power=7.06e-01
  [eval] val_mse=6.079e-01  (n=7000)
Epoch 00078: Time=   8.4s, Loss=3.77e+00, Inv=3.77e+00, For=5.43e+01, Power=7.03e-01
  [eval] val_mse=6.022e-01  (n=7000)
Epoch 00079: Time=   8.4s, Loss=3.75e+00, Inv=3.75e+00, For=5.54e+01, Power=7.03e-01
  [eval] val_mse=5.976e-01  (n=7000)
Epoch 00080: Time=   8.4s, Loss=3.73e+00, Inv=3.73e+00, For=5.69e+01, Power=7.00e-01
  [eval] val_mse=5.946e-01  (n=7000)
Epoch 00081: Time=   8.5s, Loss=3.71e+00, Inv=3.71e+00, For=5.87e+01, Power=7.04e-01
  [eval] val_mse=5.894e-01  (n=7000)
Epoch 00082: Time=   8.5s, Loss=3.69e+00, Inv=3.69e+00, For=5.98e+01, Power=7.00e-01
  [eval] val_mse=5.873e-01  (n=7000)
Epoch 00083: Time=   8.5s, Loss=3.68e+00, Inv=3.68e+00, For=6.19e+01, Power=6.98e-01
  [eval] val_mse=5.827e-01  (n=7000)
Epoch 00084: Time=   8.6s, Loss=3.66e+00, Inv=3.66e+00, For=6.29e+01, Power=6.98e-01
  [eval] val_mse=5.794e-01  (n=7000)
Epoch 00085: Time=   8.6s, Loss=3.65e+00, Inv=3.65e+00, For=6.51e+01, Power=6.98e-01
  [eval] val_mse=5.747e-01  (n=7000)
Epoch 00086: Time=   8.6s, Loss=3.63e+00, Inv=3.63e+00, For=6.62e+01, Power=6.99e-01
  [eval] val_mse=5.714e-01  (n=7000)
Epoch 00087: Time=   8.7s, Loss=3.62e+00, Inv=3.62e+00, For=6.84e+01, Power=6.94e-01
  [eval] val_mse=5.670e-01  (n=7000)
Epoch 00088: Time=   8.7s, Loss=3.60e+00, Inv=3.60e+00, For=6.98e+01, Power=6.98e-01
  [eval] val_mse=5.635e-01  (n=7000)
Epoch 00089: Time=   8.7s, Loss=3.59e+00, Inv=3.59e+00, For=7.14e+01, Power=6.96e-01
  [eval] val_mse=5.597e-01  (n=7000)
Epoch 00090: Time=   8.8s, Loss=3.58e+00, Inv=3.58e+00, For=7.32e+01, Power=6.94e-01
  [eval] val_mse=5.557e-01  (n=7000)
Epoch 00091: Time=   8.8s, Loss=3.56e+00, Inv=3.56e+00, For=7.49e+01, Power=6.96e-01
  [eval] val_mse=5.523e-01  (n=7000)
Epoch 00092: Time=   8.8s, Loss=3.55e+00, Inv=3.55e+00, For=7.65e+01, Power=6.96e-01
  [eval] val_mse=5.499e-01  (n=7000)
Epoch 00093: Time=   8.9s, Loss=3.53e+00, Inv=3.53e+00, For=7.89e+01, Power=6.93e-01
  [eval] val_mse=5.465e-01  (n=7000)
Epoch 00094: Time=   8.9s, Loss=3.52e+00, Inv=3.52e+00, For=8.02e+01, Power=6.94e-01
  [eval] val_mse=5.434e-01  (n=7000)
Epoch 00095: Time=   8.9s, Loss=3.52e+00, Inv=3.52e+00, For=8.27e+01, Power=6.96e-01
  [eval] val_mse=5.393e-01  (n=7000)
Epoch 00096: Time=   9.0s, Loss=3.50e+00, Inv=3.50e+00, For=8.41e+01, Power=6.95e-01
  [eval] val_mse=5.371e-01  (n=7000)
Epoch 00097: Time=   9.0s, Loss=3.49e+00, Inv=3.49e+00, For=8.59e+01, Power=6.92e-01
  [eval] val_mse=5.343e-01  (n=7000)
Epoch 00098: Time=   9.0s, Loss=3.48e+00, Inv=3.48e+00, For=8.83e+01, Power=6.92e-01
  [eval] val_mse=5.318e-01  (n=7000)
Epoch 00099: Time=   9.1s, Loss=3.47e+00, Inv=3.47e+00, For=9.12e+01, Power=6.93e-01
  [eval] val_mse=5.275e-01  (n=7000)
Epoch 00100: Time=   9.1s, Loss=3.46e+00, Inv=3.46e+00, For=9.20e+01, Power=6.93e-01
  [eval] val_mse=5.254e-01  (n=7000)
Epoch 00101: Time=   9.1s, Loss=3.45e+00, Inv=3.45e+00, For=9.43e+01, Power=6.92e-01
  [eval] val_mse=5.231e-01  (n=7000)
Epoch 00102: Time=   9.2s, Loss=3.44e+00, Inv=3.44e+00, For=9.61e+01, Power=6.90e-01
  [eval] val_mse=5.207e-01  (n=7000)
Epoch 00103: Time=   9.2s, Loss=3.43e+00, Inv=3.43e+00, For=9.84e+01, Power=6.91e-01
  [eval] val_mse=5.164e-01  (n=7000)
Epoch 00104: Time=   9.2s, Loss=3.42e+00, Inv=3.42e+00, For=1.01e+02, Power=6.91e-01
  [eval] val_mse=5.142e-01  (n=7000)
Epoch 00105: Time=   9.3s, Loss=3.41e+00, Inv=3.41e+00, For=1.03e+02, Power=6.91e-01
  [eval] val_mse=5.119e-01  (n=7000)
Epoch 00106: Time=   9.3s, Loss=3.40e+00, Inv=3.40e+00, For=1.05e+02, Power=6.87e-01
  [eval] val_mse=5.099e-01  (n=7000)
Epoch 00107: Time=   9.3s, Loss=3.39e+00, Inv=3.39e+00, For=1.07e+02, Power=6.89e-01
  [eval] val_mse=5.075e-01  (n=7000)
Epoch 00108: Time=   9.4s, Loss=3.38e+00, Inv=3.38e+00, For=1.09e+02, Power=6.88e-01
  [eval] val_mse=5.047e-01  (n=7000)
Epoch 00109: Time=   9.4s, Loss=3.38e+00, Inv=3.38e+00, For=1.13e+02, Power=6.90e-01
  [eval] val_mse=5.010e-01  (n=7000)
Epoch 00110: Time=   9.4s, Loss=3.36e+00, Inv=3.36e+00, For=1.13e+02, Power=6.89e-01
  [eval] val_mse=5.002e-01  (n=7000)
Epoch 00111: Time=   9.5s, Loss=3.36e+00, Inv=3.36e+00, For=1.16e+02, Power=6.89e-01
  [eval] val_mse=4.968e-01  (n=7000)
Epoch 00112: Time=   9.5s, Loss=3.35e+00, Inv=3.35e+00, For=1.19e+02, Power=6.89e-01
  [eval] val_mse=4.939e-01  (n=7000)
Epoch 00113: Time=   9.5s, Loss=3.34e+00, Inv=3.34e+00, For=1.21e+02, Power=6.88e-01
  [eval] val_mse=4.922e-01  (n=7000)
Epoch 00114: Time=   9.6s, Loss=3.34e+00, Inv=3.34e+00, For=1.23e+02, Power=6.88e-01
  [eval] val_mse=4.896e-01  (n=7000)
Epoch 00115: Time=   9.6s, Loss=3.33e+00, Inv=3.33e+00, For=1.26e+02, Power=6.87e-01
  [eval] val_mse=4.879e-01  (n=7000)
Epoch 00116: Time=   9.6s, Loss=3.32e+00, Inv=3.32e+00, For=1.28e+02, Power=6.88e-01
  [eval] val_mse=4.867e-01  (n=7000)
Epoch 00117: Time=   9.7s, Loss=3.31e+00, Inv=3.31e+00, For=1.32e+02, Power=6.85e-01
  [eval] val_mse=4.842e-01  (n=7000)
Epoch 00118: Time=   9.7s, Loss=3.30e+00, Inv=3.30e+00, For=1.33e+02, Power=6.85e-01
  [eval] val_mse=4.828e-01  (n=7000)
Epoch 00119: Time=   9.7s, Loss=3.30e+00, Inv=3.30e+00, For=1.35e+02, Power=6.86e-01
  [eval] val_mse=4.802e-01  (n=7000)
Epoch 00120: Time=   9.8s, Loss=3.29e+00, Inv=3.29e+00, For=1.37e+02, Power=6.84e-01
  [eval] val_mse=4.797e-01  (n=7000)
Epoch 00121: Time=   9.8s, Loss=3.29e+00, Inv=3.29e+00, For=1.41e+02, Power=6.88e-01
  [eval] val_mse=4.765e-01  (n=7000)
Epoch 00122: Time=   9.8s, Loss=3.28e+00, Inv=3.28e+00, For=1.42e+02, Power=6.88e-01
  [eval] val_mse=4.758e-01  (n=7000)
Epoch 00123: Time=   9.9s, Loss=3.27e+00, Inv=3.27e+00, For=1.47e+02, Power=6.86e-01
  [eval] val_mse=4.725e-01  (n=7000)
Epoch 00124: Time=   9.9s, Loss=3.27e+00, Inv=3.27e+00, For=1.49e+02, Power=6.87e-01
  [eval] val_mse=4.706e-01  (n=7000)
Epoch 00125: Time=   9.9s, Loss=3.26e+00, Inv=3.26e+00, For=1.50e+02, Power=6.84e-01
  [eval] val_mse=4.701e-01  (n=7000)
Epoch 00126: Time=  10.0s, Loss=3.26e+00, Inv=3.26e+00, For=1.54e+02, Power=6.88e-01
  [eval] val_mse=4.678e-01  (n=7000)
Epoch 00127: Time=  10.0s, Loss=3.25e+00, Inv=3.25e+00, For=1.57e+02, Power=6.86e-01
  [eval] val_mse=4.656e-01  (n=7000)
Epoch 00128: Time=  10.0s, Loss=3.24e+00, Inv=3.24e+00, For=1.59e+02, Power=6.85e-01
  [eval] val_mse=4.644e-01  (n=7000)
Epoch 00129: Time=  10.1s, Loss=3.24e+00, Inv=3.24e+00, For=1.62e+02, Power=6.85e-01
  [eval] val_mse=4.637e-01  (n=7000)
Epoch 00130: Time=  10.1s, Loss=3.24e+00, Inv=3.24e+00, For=1.66e+02, Power=6.84e-01
  [eval] val_mse=4.611e-01  (n=7000)
Epoch 00131: Time=  10.1s, Loss=3.23e+00, Inv=3.23e+00, For=1.68e+02, Power=6.84e-01
  [eval] val_mse=4.602e-01  (n=7000)
Epoch 00132: Time=  10.2s, Loss=3.22e+00, Inv=3.22e+00, For=1.69e+02, Power=6.84e-01
  [eval] val_mse=4.588e-01  (n=7000)
Epoch 00133: Time=  10.2s, Loss=3.22e+00, Inv=3.22e+00, For=1.75e+02, Power=6.84e-01
  [eval] val_mse=4.567e-01  (n=7000)
Epoch 00134: Time=  10.2s, Loss=3.21e+00, Inv=3.21e+00, For=1.75e+02, Power=6.83e-01
  [eval] val_mse=4.553e-01  (n=7000)
Epoch 00135: Time=  10.3s, Loss=3.21e+00, Inv=3.21e+00, For=1.80e+02, Power=6.84e-01
  [eval] val_mse=4.521e-01  (n=7000)
Epoch 00136: Time=  10.3s, Loss=3.20e+00, Inv=3.20e+00, For=1.81e+02, Power=6.82e-01
  [eval] val_mse=4.534e-01  (n=7000)
Epoch 00137: Time=  10.3s, Loss=3.20e+00, Inv=3.20e+00, For=1.86e+02, Power=6.84e-01
  [eval] val_mse=4.508e-01  (n=7000)
Epoch 00138: Time=  10.4s, Loss=3.19e+00, Inv=3.19e+00, For=1.88e+02, Power=6.84e-01
  [eval] val_mse=4.500e-01  (n=7000)
Epoch 00139: Time=  10.4s, Loss=3.19e+00, Inv=3.19e+00, For=1.91e+02, Power=6.84e-01
  [eval] val_mse=4.481e-01  (n=7000)
Epoch 00140: Time=  10.4s, Loss=3.18e+00, Inv=3.18e+00, For=1.93e+02, Power=6.80e-01
  [eval] val_mse=4.465e-01  (n=7000)
Epoch 00141: Time=  10.5s, Loss=3.18e+00, Inv=3.18e+00, For=1.96e+02, Power=6.84e-01
  [eval] val_mse=4.458e-01  (n=7000)
Epoch 00142: Time=  10.5s, Loss=3.17e+00, Inv=3.17e+00, For=1.99e+02, Power=6.83e-01
  [eval] val_mse=4.439e-01  (n=7000)
Epoch 00143: Time=  10.5s, Loss=3.17e+00, Inv=3.17e+00, For=2.02e+02, Power=6.85e-01
  [eval] val_mse=4.426e-01  (n=7000)
Epoch 00144: Time=  10.6s, Loss=3.17e+00, Inv=3.17e+00, For=2.03e+02, Power=6.82e-01
  [eval] val_mse=4.420e-01  (n=7000)
Epoch 00145: Time=  10.6s, Loss=3.17e+00, Inv=3.17e+00, For=2.10e+02, Power=6.85e-01
  [eval] val_mse=4.406e-01  (n=7000)
Epoch 00146: Time=  10.6s, Loss=3.16e+00, Inv=3.16e+00, For=2.12e+02, Power=6.84e-01
  [eval] val_mse=4.397e-01  (n=7000)
Epoch 00147: Time=  10.7s, Loss=3.16e+00, Inv=3.16e+00, For=2.15e+02, Power=6.82e-01
  [eval] val_mse=4.384e-01  (n=7000)
Epoch 00148: Time=  10.7s, Loss=3.15e+00, Inv=3.15e+00, For=2.17e+02, Power=6.80e-01
  [eval] val_mse=4.386e-01  (n=7000)
Epoch 00149: Time=  10.7s, Loss=3.15e+00, Inv=3.15e+00, For=2.20e+02, Power=6.81e-01
  [eval] val_mse=4.359e-01  (n=7000)
Epoch 00150: Time=  10.8s, Loss=3.15e+00, Inv=3.15e+00, For=2.23e+02, Power=6.82e-01
  [eval] val_mse=4.353e-01  (n=7000)
Epoch 00151: Time=  10.8s, Loss=3.14e+00, Inv=3.14e+00, For=2.27e+02, Power=6.81e-01
  [eval] val_mse=4.331e-01  (n=7000)
Epoch 00152: Time=  10.8s, Loss=3.13e+00, Inv=3.13e+00, For=2.28e+02, Power=6.81e-01
  [eval] val_mse=4.328e-01  (n=7000)
Epoch 00153: Time=  10.9s, Loss=3.13e+00, Inv=3.13e+00, For=2.34e+02, Power=6.82e-01
  [eval] val_mse=4.304e-01  (n=7000)
Epoch 00154: Time=  10.9s, Loss=3.13e+00, Inv=3.13e+00, For=2.33e+02, Power=6.82e-01
  [eval] val_mse=4.321e-01  (n=7000)
Epoch 00155: Time=  10.9s, Loss=3.13e+00, Inv=3.13e+00, For=2.39e+02, Power=6.83e-01
  [eval] val_mse=4.304e-01  (n=7000)
Epoch 00156: Time=  11.0s, Loss=3.12e+00, Inv=3.12e+00, For=2.41e+02, Power=6.83e-01
  [eval] val_mse=4.278e-01  (n=7000)
Epoch 00157: Time=  11.0s, Loss=3.12e+00, Inv=3.12e+00, For=2.39e+02, Power=6.84e-01
  [eval] val_mse=4.275e-01  (n=7000)
Epoch 00158: Time=  11.0s, Loss=3.12e+00, Inv=3.12e+00, For=2.49e+02, Power=6.81e-01
  [eval] val_mse=4.259e-01  (n=7000)
Epoch 00159: Time=  11.1s, Loss=3.11e+00, Inv=3.11e+00, For=2.48e+02, Power=6.81e-01
  [eval] val_mse=4.244e-01  (n=7000)
Epoch 00160: Time=  11.1s, Loss=3.11e+00, Inv=3.11e+00, For=2.53e+02, Power=6.83e-01
  [eval] val_mse=4.238e-01  (n=7000)
Epoch 00161: Time=  11.1s, Loss=3.10e+00, Inv=3.10e+00, For=2.56e+02, Power=6.82e-01
  [eval] val_mse=4.227e-01  (n=7000)
Epoch 00162: Time=  11.2s, Loss=3.10e+00, Inv=3.10e+00, For=2.58e+02, Power=6.81e-01
  [eval] val_mse=4.216e-01  (n=7000)
Epoch 00163: Time=  11.2s, Loss=3.10e+00, Inv=3.10e+00, For=2.60e+02, Power=6.83e-01
  [eval] val_mse=4.209e-01  (n=7000)
Epoch 00164: Time=  11.2s, Loss=3.09e+00, Inv=3.09e+00, For=2.61e+02, Power=6.80e-01
  [eval] val_mse=4.193e-01  (n=7000)
Epoch 00165: Time=  11.3s, Loss=3.09e+00, Inv=3.09e+00, For=2.64e+02, Power=6.83e-01
  [eval] val_mse=4.197e-01  (n=7000)
Epoch 00166: Time=  11.3s, Loss=3.09e+00, Inv=3.09e+00, For=2.63e+02, Power=6.82e-01
  [eval] val_mse=4.194e-01  (n=7000)
Epoch 00167: Time=  11.3s, Loss=3.09e+00, Inv=3.09e+00, For=2.72e+02, Power=6.82e-01
  [eval] val_mse=4.179e-01  (n=7000)
Epoch 00168: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=2.73e+02, Power=6.83e-01
  [eval] val_mse=4.173e-01  (n=7000)
Epoch 00169: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=2.76e+02, Power=6.78e-01
  [eval] val_mse=4.168e-01  (n=7000)
Epoch 00170: Time=  11.4s, Loss=3.08e+00, Inv=3.08e+00, For=2.78e+02, Power=6.81e-01
  [eval] val_mse=4.148e-01  (n=7000)
Epoch 00171: Time=  11.5s, Loss=3.08e+00, Inv=3.08e+00, For=2.83e+02, Power=6.82e-01
  [eval] val_mse=4.141e-01  (n=7000)
Epoch 00172: Time=  11.5s, Loss=3.07e+00, Inv=3.07e+00, For=2.82e+02, Power=6.81e-01
  [eval] val_mse=4.126e-01  (n=7000)
Epoch 00173: Time=  11.5s, Loss=3.07e+00, Inv=3.07e+00, For=2.83e+02, Power=6.83e-01
  [eval] val_mse=4.124e-01  (n=7000)
Epoch 00174: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=2.89e+02, Power=6.82e-01
  [eval] val_mse=4.115e-01  (n=7000)
Epoch 00175: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=2.86e+02, Power=6.80e-01
  [eval] val_mse=4.129e-01  (n=7000)
Epoch 00176: Time=  11.6s, Loss=3.07e+00, Inv=3.07e+00, For=2.95e+02, Power=6.84e-01
  [eval] val_mse=4.092e-01  (n=7000)
Epoch 00177: Time=  11.7s, Loss=3.06e+00, Inv=3.06e+00, For=2.89e+02, Power=6.78e-01
  [eval] val_mse=4.092e-01  (n=7000)
Epoch 00178: Time=  11.7s, Loss=3.05e+00, Inv=3.05e+00, For=2.96e+02, Power=6.79e-01
  [eval] val_mse=4.076e-01  (n=7000)
Epoch 00179: Time=  11.7s, Loss=3.06e+00, Inv=3.06e+00, For=2.97e+02, Power=6.83e-01
  [eval] val_mse=4.087e-01  (n=7000)
Epoch 00180: Time=  11.8s, Loss=3.05e+00, Inv=3.05e+00, For=3.00e+02, Power=6.80e-01
  [eval] val_mse=4.069e-01  (n=7000)
Epoch 00181: Time=  11.8s, Loss=3.05e+00, Inv=3.05e+00, For=3.06e+02, Power=6.82e-01
  [eval] val_mse=4.056e-01  (n=7000)
Epoch 00182: Time=  11.8s, Loss=3.04e+00, Inv=3.04e+00, For=3.02e+02, Power=6.77e-01
  [eval] val_mse=4.057e-01  (n=7000)
Epoch 00183: Time=  11.9s, Loss=3.05e+00, Inv=3.05e+00, For=3.05e+02, Power=6.84e-01
  [eval] val_mse=4.064e-01  (n=7000)
Epoch 00184: Time=  11.9s, Loss=3.04e+00, Inv=3.04e+00, For=3.09e+02, Power=6.79e-01
  [eval] val_mse=4.043e-01  (n=7000)
Epoch 00185: Time=  11.9s, Loss=3.04e+00, Inv=3.04e+00, For=3.09e+02, Power=6.81e-01
  [eval] val_mse=4.034e-01  (n=7000)
Epoch 00186: Time=  12.0s, Loss=3.04e+00, Inv=3.04e+00, For=3.11e+02, Power=6.77e-01
  [eval] val_mse=4.018e-01  (n=7000)
Epoch 00187: Time=  12.0s, Loss=3.04e+00, Inv=3.04e+00, For=3.16e+02, Power=6.80e-01
  [eval] val_mse=4.030e-01  (n=7000)
Epoch 00188: Time=  12.0s, Loss=3.04e+00, Inv=3.04e+00, For=3.11e+02, Power=6.80e-01
  [eval] val_mse=4.016e-01  (n=7000)
Epoch 00189: Time=  12.1s, Loss=3.03e+00, Inv=3.03e+00, For=3.11e+02, Power=6.80e-01
  [eval] val_mse=4.012e-01  (n=7000)
Epoch 00190: Time=  12.1s, Loss=3.03e+00, Inv=3.03e+00, For=3.17e+02, Power=6.78e-01
  [eval] val_mse=4.022e-01  (n=7000)
Epoch 00191: Time=  12.1s, Loss=3.03e+00, Inv=3.03e+00, For=3.23e+02, Power=6.81e-01
  [eval] val_mse=3.989e-01  (n=7000)
Epoch 00192: Time=  12.2s, Loss=3.03e+00, Inv=3.03e+00, For=3.19e+02, Power=6.80e-01
  [eval] val_mse=3.995e-01  (n=7000)
Epoch 00193: Time=  12.2s, Loss=3.02e+00, Inv=3.02e+00, For=3.19e+02, Power=6.80e-01
  [eval] val_mse=3.979e-01  (n=7000)
Epoch 00194: Time=  12.2s, Loss=3.02e+00, Inv=3.02e+00, For=3.23e+02, Power=6.80e-01
  [eval] val_mse=3.979e-01  (n=7000)
Epoch 00195: Time=  12.3s, Loss=3.02e+00, Inv=3.02e+00, For=3.24e+02, Power=6.80e-01
  [eval] val_mse=3.988e-01  (n=7000)
Epoch 00196: Time=  12.3s, Loss=3.02e+00, Inv=3.02e+00, For=3.31e+02, Power=6.80e-01
  [eval] val_mse=3.970e-01  (n=7000)
Epoch 00197: Time=  12.3s, Loss=3.02e+00, Inv=3.02e+00, For=3.23e+02, Power=6.78e-01
  [eval] val_mse=3.957e-01  (n=7000)
Epoch 00198: Time=  12.4s, Loss=3.02e+00, Inv=3.02e+00, For=3.27e+02, Power=6.81e-01
  [eval] val_mse=3.942e-01  (n=7000)
Epoch 00199: Time=  12.4s, Loss=3.02e+00, Inv=3.02e+00, For=3.31e+02, Power=6.81e-01
  [eval] val_mse=3.938e-01  (n=7000)
Epoch 00200: Time=  12.4s, Loss=3.01e+00, Inv=3.01e+00, For=3.26e+02, Power=6.80e-01
  [eval] val_mse=3.946e-01  (n=7000)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 2.562e-01
Torque MSE  = 8.270e-02
Torque RMSE = 2.876e-01
Per-joint MSE : 8.884e-02 1.631e-01 6.580e-02 2.082e-02 1.413e-01 1.631e-02
Per-joint RMSE: 2.981e-01 4.038e-01 2.565e-01 1.443e-01 3.760e-01 1.277e-01
Comp Time per Sample = 2.564e-04s / 3899.4Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 1 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 0 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-1v9awdoc because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7f22542aa8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 16:00:26.981021: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 16:00:28.824313: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   3.9s, Loss=1.16e+04, Inv=1.16e+04, For=5.81e+00, Power=1.65e+03
  [eval] val_mse=1.246e+02  (n=2997)
Epoch 00002: Time=   5.3s, Loss=7.32e+02, Inv=7.32e+02, For=5.51e+00, Power=1.10e+02
  [eval] val_mse=4.840e+01  (n=2997)
Epoch 00003: Time=   5.3s, Loss=3.17e+02, Inv=3.17e+02, For=5.32e+00, Power=5.03e+01
  [eval] val_mse=2.867e+01  (n=2997)
Epoch 00004: Time=   5.4s, Loss=1.88e+02, Inv=1.88e+02, For=5.19e+00, Power=3.08e+01
  [eval] val_mse=1.954e+01  (n=2997)
Epoch 00005: Time=   5.4s, Loss=1.25e+02, Inv=1.25e+02, For=5.11e+00, Power=2.06e+01
  [eval] val_mse=1.448e+01  (n=2997)
Epoch 00006: Time=   5.5s, Loss=8.87e+01, Inv=8.87e+01, For=5.05e+00, Power=1.46e+01
  [eval] val_mse=1.142e+01  (n=2997)
Epoch 00007: Time=   5.5s, Loss=6.61e+01, Inv=6.61e+01, For=5.04e+00, Power=1.08e+01
  [eval] val_mse=9.469e+00  (n=2997)
Epoch 00008: Time=   5.5s, Loss=5.13e+01, Inv=5.13e+01, For=5.06e+00, Power=8.27e+00
  [eval] val_mse=8.124e+00  (n=2997)
Epoch 00009: Time=   5.6s, Loss=4.11e+01, Inv=4.11e+01, For=5.11e+00, Power=6.57e+00
  [eval] val_mse=7.137e+00  (n=2997)
Epoch 00010: Time=   5.6s, Loss=3.37e+01, Inv=3.37e+01, For=5.18e+00, Power=5.32e+00
  [eval] val_mse=6.412e+00  (n=2997)
Epoch 00011: Time=   5.6s, Loss=2.83e+01, Inv=2.83e+01, For=5.28e+00, Power=4.38e+00
  [eval] val_mse=5.839e+00  (n=2997)
Epoch 00012: Time=   5.7s, Loss=2.41e+01, Inv=2.41e+01, For=5.41e+00, Power=3.69e+00
  [eval] val_mse=5.388e+00  (n=2997)
Epoch 00013: Time=   5.7s, Loss=2.09e+01, Inv=2.09e+01, For=5.57e+00, Power=3.15e+00
  [eval] val_mse=4.982e+00  (n=2997)
Epoch 00014: Time=   5.7s, Loss=1.84e+01, Inv=1.84e+01, For=5.77e+00, Power=2.73e+00
  [eval] val_mse=4.655e+00  (n=2997)
Epoch 00015: Time=   5.8s, Loss=1.63e+01, Inv=1.63e+01, For=6.01e+00, Power=2.40e+00
  [eval] val_mse=4.358e+00  (n=2997)
Epoch 00016: Time=   5.8s, Loss=1.47e+01, Inv=1.47e+01, For=6.31e+00, Power=2.12e+00
  [eval] val_mse=4.107e+00  (n=2997)
Epoch 00017: Time=   5.8s, Loss=1.33e+01, Inv=1.33e+01, For=6.63e+00, Power=1.90e+00
  [eval] val_mse=3.879e+00  (n=2997)
Epoch 00018: Time=   5.9s, Loss=1.22e+01, Inv=1.22e+01, For=7.02e+00, Power=1.72e+00
  [eval] val_mse=3.674e+00  (n=2997)
Epoch 00019: Time=   5.9s, Loss=1.12e+01, Inv=1.12e+01, For=7.45e+00, Power=1.57e+00
  [eval] val_mse=3.502e+00  (n=2997)
Epoch 00020: Time=   5.9s, Loss=1.04e+01, Inv=1.04e+01, For=7.91e+00, Power=1.44e+00
  [eval] val_mse=3.352e+00  (n=2997)
Epoch 00021: Time=   6.0s, Loss=9.77e+00, Inv=9.77e+00, For=8.47e+00, Power=1.34e+00
  [eval] val_mse=3.221e+00  (n=2997)
Epoch 00022: Time=   6.0s, Loss=9.18e+00, Inv=9.18e+00, For=9.02e+00, Power=1.25e+00
  [eval] val_mse=3.096e+00  (n=2997)
Epoch 00023: Time=   6.1s, Loss=8.69e+00, Inv=8.69e+00, For=9.62e+00, Power=1.17e+00
  [eval] val_mse=2.982e+00  (n=2997)
Epoch 00024: Time=   6.1s, Loss=8.26e+00, Inv=8.26e+00, For=1.03e+01, Power=1.10e+00
  [eval] val_mse=2.887e+00  (n=2997)
Epoch 00025: Time=   6.1s, Loss=7.88e+00, Inv=7.88e+00, For=1.09e+01, Power=1.05e+00
  [eval] val_mse=2.792e+00  (n=2997)
Epoch 00026: Time=   6.2s, Loss=7.55e+00, Inv=7.55e+00, For=1.16e+01, Power=9.99e-01
  [eval] val_mse=2.721e+00  (n=2997)
Epoch 00027: Time=   6.2s, Loss=7.25e+00, Inv=7.25e+00, For=1.24e+01, Power=9.57e-01
  [eval] val_mse=2.637e+00  (n=2997)
Epoch 00028: Time=   6.2s, Loss=7.00e+00, Inv=7.00e+00, For=1.32e+01, Power=9.22e-01
  [eval] val_mse=2.570e+00  (n=2997)
Epoch 00029: Time=   6.3s, Loss=6.76e+00, Inv=6.76e+00, For=1.40e+01, Power=8.88e-01
  [eval] val_mse=2.498e+00  (n=2997)
Epoch 00030: Time=   6.3s, Loss=6.55e+00, Inv=6.55e+00, For=1.48e+01, Power=8.58e-01
  [eval] val_mse=2.441e+00  (n=2997)
Epoch 00031: Time=   6.3s, Loss=6.36e+00, Inv=6.36e+00, For=1.57e+01, Power=8.34e-01
  [eval] val_mse=2.379e+00  (n=2997)
Epoch 00032: Time=   6.4s, Loss=6.18e+00, Inv=6.18e+00, For=1.66e+01, Power=8.12e-01
  [eval] val_mse=2.337e+00  (n=2997)
Epoch 00033: Time=   6.4s, Loss=6.02e+00, Inv=6.02e+00, For=1.75e+01, Power=7.90e-01
  [eval] val_mse=2.295e+00  (n=2997)
Epoch 00034: Time=   6.4s, Loss=5.88e+00, Inv=5.88e+00, For=1.85e+01, Power=7.73e-01
  [eval] val_mse=2.254e+00  (n=2997)
Epoch 00035: Time=   6.5s, Loss=5.75e+00, Inv=5.75e+00, For=1.94e+01, Power=7.58e-01
  [eval] val_mse=2.206e+00  (n=2997)
Epoch 00036: Time=   6.5s, Loss=5.63e+00, Inv=5.63e+00, For=2.05e+01, Power=7.43e-01
  [eval] val_mse=2.160e+00  (n=2997)
Epoch 00037: Time=   6.5s, Loss=5.51e+00, Inv=5.51e+00, For=2.15e+01, Power=7.28e-01
  [eval] val_mse=2.139e+00  (n=2997)
Epoch 00038: Time=   6.6s, Loss=5.41e+00, Inv=5.41e+00, For=2.25e+01, Power=7.18e-01
  [eval] val_mse=2.101e+00  (n=2997)
Epoch 00039: Time=   6.6s, Loss=5.31e+00, Inv=5.31e+00, For=2.37e+01, Power=7.07e-01
  [eval] val_mse=2.069e+00  (n=2997)
Epoch 00040: Time=   6.6s, Loss=5.23e+00, Inv=5.23e+00, For=2.47e+01, Power=6.98e-01
  [eval] val_mse=2.034e+00  (n=2997)
Epoch 00041: Time=   6.7s, Loss=5.14e+00, Inv=5.14e+00, For=2.58e+01, Power=6.88e-01
  [eval] val_mse=2.020e+00  (n=2997)
Epoch 00042: Time=   6.7s, Loss=5.06e+00, Inv=5.06e+00, For=2.69e+01, Power=6.78e-01
  [eval] val_mse=1.986e+00  (n=2997)
Epoch 00043: Time=   6.7s, Loss=4.99e+00, Inv=4.99e+00, For=2.82e+01, Power=6.72e-01
  [eval] val_mse=1.960e+00  (n=2997)
Epoch 00044: Time=   6.8s, Loss=4.93e+00, Inv=4.93e+00, For=2.93e+01, Power=6.66e-01
  [eval] val_mse=1.933e+00  (n=2997)
Epoch 00045: Time=   6.8s, Loss=4.86e+00, Inv=4.86e+00, For=3.05e+01, Power=6.60e-01
  [eval] val_mse=1.913e+00  (n=2997)
Epoch 00046: Time=   6.8s, Loss=4.80e+00, Inv=4.80e+00, For=3.17e+01, Power=6.55e-01
  [eval] val_mse=1.903e+00  (n=2997)
Epoch 00047: Time=   6.9s, Loss=4.74e+00, Inv=4.74e+00, For=3.28e+01, Power=6.49e-01
  [eval] val_mse=1.870e+00  (n=2997)
Epoch 00048: Time=   6.9s, Loss=4.69e+00, Inv=4.69e+00, For=3.41e+01, Power=6.44e-01
  [eval] val_mse=1.857e+00  (n=2997)
Epoch 00049: Time=   7.0s, Loss=4.64e+00, Inv=4.64e+00, For=3.53e+01, Power=6.39e-01
  [eval] val_mse=1.847e+00  (n=2997)
Epoch 00050: Time=   7.0s, Loss=4.59e+00, Inv=4.59e+00, For=3.65e+01, Power=6.36e-01
  [eval] val_mse=1.818e+00  (n=2997)
Epoch 00051: Time=   7.0s, Loss=4.55e+00, Inv=4.55e+00, For=3.79e+01, Power=6.32e-01
  [eval] val_mse=1.800e+00  (n=2997)
Epoch 00052: Time=   7.1s, Loss=4.51e+00, Inv=4.51e+00, For=3.89e+01, Power=6.29e-01
  [eval] val_mse=1.785e+00  (n=2997)
Epoch 00053: Time=   7.1s, Loss=4.47e+00, Inv=4.47e+00, For=4.03e+01, Power=6.25e-01
  [eval] val_mse=1.767e+00  (n=2997)
Epoch 00054: Time=   7.1s, Loss=4.42e+00, Inv=4.42e+00, For=4.13e+01, Power=6.22e-01
  [eval] val_mse=1.763e+00  (n=2997)
Epoch 00055: Time=   7.2s, Loss=4.39e+00, Inv=4.39e+00, For=4.28e+01, Power=6.19e-01
  [eval] val_mse=1.741e+00  (n=2997)
Epoch 00056: Time=   7.2s, Loss=4.36e+00, Inv=4.36e+00, For=4.39e+01, Power=6.17e-01
  [eval] val_mse=1.728e+00  (n=2997)
Epoch 00057: Time=   7.2s, Loss=4.32e+00, Inv=4.32e+00, For=4.52e+01, Power=6.14e-01
  [eval] val_mse=1.711e+00  (n=2997)
Epoch 00058: Time=   7.3s, Loss=4.29e+00, Inv=4.29e+00, For=4.64e+01, Power=6.12e-01
  [eval] val_mse=1.691e+00  (n=2997)
Epoch 00059: Time=   7.3s, Loss=4.26e+00, Inv=4.26e+00, For=4.73e+01, Power=6.10e-01
  [eval] val_mse=1.693e+00  (n=2997)
Epoch 00060: Time=   7.3s, Loss=4.23e+00, Inv=4.23e+00, For=4.86e+01, Power=6.08e-01
  [eval] val_mse=1.683e+00  (n=2997)
Epoch 00061: Time=   7.4s, Loss=4.20e+00, Inv=4.20e+00, For=4.98e+01, Power=6.06e-01
  [eval] val_mse=1.667e+00  (n=2997)
Epoch 00062: Time=   7.4s, Loss=4.17e+00, Inv=4.17e+00, For=5.07e+01, Power=6.05e-01
  [eval] val_mse=1.664e+00  (n=2997)
Epoch 00063: Time=   7.4s, Loss=4.15e+00, Inv=4.15e+00, For=5.21e+01, Power=6.02e-01
  [eval] val_mse=1.643e+00  (n=2997)
Epoch 00064: Time=   7.5s, Loss=4.12e+00, Inv=4.12e+00, For=5.31e+01, Power=6.01e-01
  [eval] val_mse=1.653e+00  (n=2997)
Epoch 00065: Time=   7.5s, Loss=4.10e+00, Inv=4.10e+00, For=5.42e+01, Power=6.00e-01
  [eval] val_mse=1.634e+00  (n=2997)
Epoch 00066: Time=   7.5s, Loss=4.08e+00, Inv=4.08e+00, For=5.52e+01, Power=5.98e-01
  [eval] val_mse=1.618e+00  (n=2997)
Epoch 00067: Time=   7.6s, Loss=4.06e+00, Inv=4.06e+00, For=5.62e+01, Power=5.96e-01
  [eval] val_mse=1.626e+00  (n=2997)
Epoch 00068: Time=   7.6s, Loss=4.03e+00, Inv=4.03e+00, For=5.72e+01, Power=5.97e-01
  [eval] val_mse=1.612e+00  (n=2997)
Epoch 00069: Time=   7.6s, Loss=4.01e+00, Inv=4.01e+00, For=5.84e+01, Power=5.95e-01
  [eval] val_mse=1.603e+00  (n=2997)
Epoch 00070: Time=   7.7s, Loss=3.99e+00, Inv=3.99e+00, For=5.94e+01, Power=5.94e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00071: Time=   7.7s, Loss=3.98e+00, Inv=3.98e+00, For=6.01e+01, Power=5.93e-01
  [eval] val_mse=1.601e+00  (n=2997)
Epoch 00072: Time=   7.8s, Loss=3.96e+00, Inv=3.96e+00, For=6.11e+01, Power=5.91e-01
  [eval] val_mse=1.609e+00  (n=2997)
Epoch 00073: Time=   7.8s, Loss=3.94e+00, Inv=3.94e+00, For=6.18e+01, Power=5.91e-01
  [eval] val_mse=1.589e+00  (n=2997)
Epoch 00074: Time=   7.8s, Loss=3.92e+00, Inv=3.92e+00, For=6.26e+01, Power=5.90e-01
  [eval] val_mse=1.590e+00  (n=2997)
Epoch 00075: Time=   7.9s, Loss=3.91e+00, Inv=3.91e+00, For=6.34e+01, Power=5.90e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00076: Time=   7.9s, Loss=3.89e+00, Inv=3.89e+00, For=6.44e+01, Power=5.89e-01
  [eval] val_mse=1.588e+00  (n=2997)
Epoch 00077: Time=   7.9s, Loss=3.88e+00, Inv=3.88e+00, For=6.49e+01, Power=5.88e-01
  [eval] val_mse=1.585e+00  (n=2997)
Epoch 00078: Time=   8.0s, Loss=3.86e+00, Inv=3.86e+00, For=6.59e+01, Power=5.87e-01
  [eval] val_mse=1.582e+00  (n=2997)
Epoch 00079: Time=   8.0s, Loss=3.85e+00, Inv=3.85e+00, For=6.66e+01, Power=5.88e-01
  [eval] val_mse=1.587e+00  (n=2997)
Epoch 00080: Time=   8.0s, Loss=3.83e+00, Inv=3.83e+00, For=6.74e+01, Power=5.85e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00081: Time=   8.1s, Loss=3.82e+00, Inv=3.82e+00, For=6.80e+01, Power=5.86e-01
  [eval] val_mse=1.614e+00  (n=2997)
Epoch 00082: Time=   8.1s, Loss=3.81e+00, Inv=3.81e+00, For=6.83e+01, Power=5.86e-01
  [eval] val_mse=1.597e+00  (n=2997)
Epoch 00083: Time=   8.1s, Loss=3.79e+00, Inv=3.79e+00, For=6.89e+01, Power=5.85e-01
  [eval] val_mse=1.606e+00  (n=2997)
Epoch 00084: Time=   8.2s, Loss=3.79e+00, Inv=3.79e+00, For=7.00e+01, Power=5.85e-01
  [eval] val_mse=1.602e+00  (n=2997)
Epoch 00085: Time=   8.2s, Loss=3.77e+00, Inv=3.77e+00, For=7.05e+01, Power=5.85e-01
  [eval] val_mse=1.594e+00  (n=2997)
Epoch 00086: Time=   8.2s, Loss=3.76e+00, Inv=3.76e+00, For=7.05e+01, Power=5.83e-01
  [eval] val_mse=1.618e+00  (n=2997)
Epoch 00087: Time=   8.3s, Loss=3.75e+00, Inv=3.75e+00, For=7.12e+01, Power=5.84e-01
  [eval] val_mse=1.616e+00  (n=2997)
Epoch 00088: Time=   8.3s, Loss=3.74e+00, Inv=3.74e+00, For=7.15e+01, Power=5.82e-01
  [eval] val_mse=1.612e+00  (n=2997)
  [early_stop] stop at epoch=88 (best_epoch=78, best_val_mse=1.582e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 5.135e-01
Torque MSE  = 1.283e-01
Torque RMSE = 3.582e-01
Per-joint MSE : 1.702e-01 2.866e-01 1.444e-01 5.921e-02 5.355e-02 5.595e-02
Per-joint RMSE: 4.126e-01 5.353e-01 3.800e-01 2.433e-01 2.314e-01 2.365e-01
Comp Time per Sample = 2.249e-04s / 4446.0Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 1 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-iyflbppo because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x72aa656868c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 16:00:45.354387: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 16:00:47.225299: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=3.85e+03, Inv=3.85e+03, For=5.67e+00, Power=4.92e+02
  [eval] val_mse=6.448e+01  (n=2997)
Epoch 00002: Time=   5.5s, Loss=2.43e+02, Inv=2.43e+02, For=5.29e+00, Power=4.15e+01
  [eval] val_mse=2.554e+01  (n=2997)
Epoch 00003: Time=   5.5s, Loss=1.13e+02, Inv=1.13e+02, For=5.10e+00, Power=1.86e+01
  [eval] val_mse=1.652e+01  (n=2997)
Epoch 00004: Time=   5.5s, Loss=6.96e+01, Inv=6.96e+01, For=5.02e+00, Power=1.11e+01
  [eval] val_mse=1.220e+01  (n=2997)
Epoch 00005: Time=   5.6s, Loss=4.79e+01, Inv=4.79e+01, For=5.02e+00, Power=7.40e+00
  [eval] val_mse=9.735e+00  (n=2997)
Epoch 00006: Time=   5.6s, Loss=3.55e+01, Inv=3.55e+01, For=5.12e+00, Power=5.26e+00
  [eval] val_mse=8.178e+00  (n=2997)
Epoch 00007: Time=   5.6s, Loss=2.76e+01, Inv=2.76e+01, For=5.31e+00, Power=3.97e+00
  [eval] val_mse=7.084e+00  (n=2997)
Epoch 00008: Time=   5.7s, Loss=2.24e+01, Inv=2.24e+01, For=5.58e+00, Power=3.13e+00
  [eval] val_mse=6.278e+00  (n=2997)
Epoch 00009: Time=   5.7s, Loss=1.86e+01, Inv=1.86e+01, For=5.90e+00, Power=2.55e+00
  [eval] val_mse=5.661e+00  (n=2997)
Epoch 00010: Time=   5.7s, Loss=1.59e+01, Inv=1.59e+01, For=6.25e+00, Power=2.14e+00
  [eval] val_mse=5.165e+00  (n=2997)
Epoch 00011: Time=   5.8s, Loss=1.38e+01, Inv=1.38e+01, For=6.64e+00, Power=1.85e+00
  [eval] val_mse=4.751e+00  (n=2997)
Epoch 00012: Time=   5.8s, Loss=1.22e+01, Inv=1.22e+01, For=7.08e+00, Power=1.63e+00
  [eval] val_mse=4.403e+00  (n=2997)
Epoch 00013: Time=   5.8s, Loss=1.09e+01, Inv=1.09e+01, For=7.54e+00, Power=1.46e+00
  [eval] val_mse=4.106e+00  (n=2997)
Epoch 00014: Time=   5.9s, Loss=9.91e+00, Inv=9.91e+00, For=7.98e+00, Power=1.32e+00
  [eval] val_mse=3.862e+00  (n=2997)
Epoch 00015: Time=   5.9s, Loss=9.10e+00, Inv=9.10e+00, For=8.47e+00, Power=1.21e+00
  [eval] val_mse=3.648e+00  (n=2997)
Epoch 00016: Time=   5.9s, Loss=8.42e+00, Inv=8.42e+00, For=8.95e+00, Power=1.12e+00
  [eval] val_mse=3.474e+00  (n=2997)
Epoch 00017: Time=   6.0s, Loss=7.86e+00, Inv=7.86e+00, For=9.50e+00, Power=1.05e+00
  [eval] val_mse=3.315e+00  (n=2997)
Epoch 00018: Time=   6.0s, Loss=7.40e+00, Inv=7.40e+00, For=9.91e+00, Power=9.95e-01
  [eval] val_mse=3.197e+00  (n=2997)
Epoch 00019: Time=   6.1s, Loss=7.00e+00, Inv=7.00e+00, For=1.04e+01, Power=9.43e-01
  [eval] val_mse=3.084e+00  (n=2997)
Epoch 00020: Time=   6.1s, Loss=6.68e+00, Inv=6.68e+00, For=1.09e+01, Power=9.05e-01
  [eval] val_mse=2.979e+00  (n=2997)
Epoch 00021: Time=   6.1s, Loss=6.39e+00, Inv=6.39e+00, For=1.14e+01, Power=8.72e-01
  [eval] val_mse=2.888e+00  (n=2997)
Epoch 00022: Time=   6.2s, Loss=6.15e+00, Inv=6.15e+00, For=1.19e+01, Power=8.41e-01
  [eval] val_mse=2.806e+00  (n=2997)
Epoch 00023: Time=   6.2s, Loss=5.93e+00, Inv=5.93e+00, For=1.23e+01, Power=8.16e-01
  [eval] val_mse=2.731e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=5.75e+00, Inv=5.75e+00, For=1.27e+01, Power=7.96e-01
  [eval] val_mse=2.653e+00  (n=2997)
Epoch 00025: Time=   6.3s, Loss=5.58e+00, Inv=5.58e+00, For=1.31e+01, Power=7.77e-01
  [eval] val_mse=2.603e+00  (n=2997)
Epoch 00026: Time=   6.3s, Loss=5.43e+00, Inv=5.43e+00, For=1.35e+01, Power=7.60e-01
  [eval] val_mse=2.541e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=5.30e+00, Inv=5.30e+00, For=1.39e+01, Power=7.45e-01
  [eval] val_mse=2.486e+00  (n=2997)
Epoch 00028: Time=   6.4s, Loss=5.18e+00, Inv=5.18e+00, For=1.42e+01, Power=7.31e-01
  [eval] val_mse=2.425e+00  (n=2997)
Epoch 00029: Time=   6.4s, Loss=5.07e+00, Inv=5.07e+00, For=1.46e+01, Power=7.22e-01
  [eval] val_mse=2.377e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=4.98e+00, Inv=4.98e+00, For=1.51e+01, Power=7.11e-01
  [eval] val_mse=2.354e+00  (n=2997)
Epoch 00031: Time=   6.5s, Loss=4.89e+00, Inv=4.89e+00, For=1.53e+01, Power=7.02e-01
  [eval] val_mse=2.299e+00  (n=2997)
Epoch 00032: Time=   6.5s, Loss=4.80e+00, Inv=4.80e+00, For=1.59e+01, Power=6.93e-01
  [eval] val_mse=2.261e+00  (n=2997)
Epoch 00033: Time=   6.5s, Loss=4.73e+00, Inv=4.73e+00, For=1.61e+01, Power=6.87e-01
  [eval] val_mse=2.226e+00  (n=2997)
Epoch 00034: Time=   6.6s, Loss=4.66e+00, Inv=4.66e+00, For=1.65e+01, Power=6.79e-01
  [eval] val_mse=2.193e+00  (n=2997)
Epoch 00035: Time=   6.6s, Loss=4.60e+00, Inv=4.60e+00, For=1.68e+01, Power=6.73e-01
  [eval] val_mse=2.158e+00  (n=2997)
Epoch 00036: Time=   6.6s, Loss=4.54e+00, Inv=4.54e+00, For=1.72e+01, Power=6.69e-01
  [eval] val_mse=2.133e+00  (n=2997)
Epoch 00037: Time=   6.7s, Loss=4.49e+00, Inv=4.49e+00, For=1.74e+01, Power=6.63e-01
  [eval] val_mse=2.094e+00  (n=2997)
Epoch 00038: Time=   6.7s, Loss=4.44e+00, Inv=4.44e+00, For=1.79e+01, Power=6.58e-01
  [eval] val_mse=2.074e+00  (n=2997)
Epoch 00039: Time=   6.8s, Loss=4.39e+00, Inv=4.39e+00, For=1.83e+01, Power=6.53e-01
  [eval] val_mse=2.049e+00  (n=2997)
Epoch 00040: Time=   6.8s, Loss=4.35e+00, Inv=4.35e+00, For=1.84e+01, Power=6.49e-01
  [eval] val_mse=2.032e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=4.31e+00, Inv=4.31e+00, For=1.90e+01, Power=6.46e-01
  [eval] val_mse=2.010e+00  (n=2997)
Epoch 00042: Time=   6.9s, Loss=4.27e+00, Inv=4.27e+00, For=1.92e+01, Power=6.42e-01
  [eval] val_mse=1.980e+00  (n=2997)
Epoch 00043: Time=   6.9s, Loss=4.23e+00, Inv=4.23e+00, For=1.96e+01, Power=6.39e-01
  [eval] val_mse=1.960e+00  (n=2997)
Epoch 00044: Time=   6.9s, Loss=4.20e+00, Inv=4.20e+00, For=2.01e+01, Power=6.36e-01
  [eval] val_mse=1.939e+00  (n=2997)
Epoch 00045: Time=   7.0s, Loss=4.17e+00, Inv=4.17e+00, For=2.04e+01, Power=6.33e-01
  [eval] val_mse=1.920e+00  (n=2997)
Epoch 00046: Time=   7.0s, Loss=4.14e+00, Inv=4.14e+00, For=2.08e+01, Power=6.31e-01
  [eval] val_mse=1.915e+00  (n=2997)
Epoch 00047: Time=   7.0s, Loss=4.11e+00, Inv=4.11e+00, For=2.12e+01, Power=6.28e-01
  [eval] val_mse=1.892e+00  (n=2997)
Epoch 00048: Time=   7.1s, Loss=4.08e+00, Inv=4.08e+00, For=2.17e+01, Power=6.26e-01
  [eval] val_mse=1.867e+00  (n=2997)
Epoch 00049: Time=   7.1s, Loss=4.06e+00, Inv=4.06e+00, For=2.19e+01, Power=6.23e-01
  [eval] val_mse=1.849e+00  (n=2997)
Epoch 00050: Time=   7.1s, Loss=4.03e+00, Inv=4.03e+00, For=2.24e+01, Power=6.21e-01
  [eval] val_mse=1.834e+00  (n=2997)
Epoch 00051: Time=   7.2s, Loss=4.01e+00, Inv=4.01e+00, For=2.28e+01, Power=6.19e-01
  [eval] val_mse=1.821e+00  (n=2997)
Epoch 00052: Time=   7.2s, Loss=3.99e+00, Inv=3.99e+00, For=2.32e+01, Power=6.17e-01
  [eval] val_mse=1.815e+00  (n=2997)
Epoch 00053: Time=   7.2s, Loss=3.96e+00, Inv=3.96e+00, For=2.36e+01, Power=6.15e-01
  [eval] val_mse=1.812e+00  (n=2997)
Epoch 00054: Time=   7.3s, Loss=3.94e+00, Inv=3.94e+00, For=2.42e+01, Power=6.14e-01
  [eval] val_mse=1.787e+00  (n=2997)
Epoch 00055: Time=   7.3s, Loss=3.92e+00, Inv=3.92e+00, For=2.44e+01, Power=6.11e-01
  [eval] val_mse=1.777e+00  (n=2997)
Epoch 00056: Time=   7.3s, Loss=3.91e+00, Inv=3.91e+00, For=2.49e+01, Power=6.10e-01
  [eval] val_mse=1.752e+00  (n=2997)
Epoch 00057: Time=   7.4s, Loss=3.89e+00, Inv=3.89e+00, For=2.53e+01, Power=6.10e-01
  [eval] val_mse=1.760e+00  (n=2997)
Epoch 00058: Time=   7.4s, Loss=3.87e+00, Inv=3.87e+00, For=2.57e+01, Power=6.08e-01
  [eval] val_mse=1.742e+00  (n=2997)
Epoch 00059: Time=   7.5s, Loss=3.85e+00, Inv=3.85e+00, For=2.62e+01, Power=6.05e-01
  [eval] val_mse=1.730e+00  (n=2997)
Epoch 00060: Time=   7.5s, Loss=3.83e+00, Inv=3.83e+00, For=2.65e+01, Power=6.04e-01
  [eval] val_mse=1.731e+00  (n=2997)
Epoch 00061: Time=   7.5s, Loss=3.82e+00, Inv=3.82e+00, For=2.71e+01, Power=6.04e-01
  [eval] val_mse=1.700e+00  (n=2997)
Epoch 00062: Time=   7.6s, Loss=3.81e+00, Inv=3.81e+00, For=2.76e+01, Power=6.03e-01
  [eval] val_mse=1.699e+00  (n=2997)
Epoch 00063: Time=   7.6s, Loss=3.79e+00, Inv=3.79e+00, For=2.78e+01, Power=6.01e-01
  [eval] val_mse=1.694e+00  (n=2997)
Epoch 00064: Time=   7.6s, Loss=3.78e+00, Inv=3.78e+00, For=2.83e+01, Power=6.00e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00065: Time=   7.7s, Loss=3.77e+00, Inv=3.77e+00, For=2.90e+01, Power=6.00e-01
  [eval] val_mse=1.682e+00  (n=2997)
Epoch 00066: Time=   7.7s, Loss=3.75e+00, Inv=3.75e+00, For=2.92e+01, Power=5.98e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00067: Time=   7.7s, Loss=3.74e+00, Inv=3.74e+00, For=2.96e+01, Power=5.98e-01
  [eval] val_mse=1.682e+00  (n=2997)
Epoch 00068: Time=   7.8s, Loss=3.73e+00, Inv=3.73e+00, For=3.00e+01, Power=5.96e-01
  [eval] val_mse=1.677e+00  (n=2997)
Epoch 00069: Time=   7.8s, Loss=3.71e+00, Inv=3.71e+00, For=3.07e+01, Power=5.95e-01
  [eval] val_mse=1.683e+00  (n=2997)
Epoch 00070: Time=   7.8s, Loss=3.70e+00, Inv=3.70e+00, For=3.08e+01, Power=5.95e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00071: Time=   7.9s, Loss=3.69e+00, Inv=3.69e+00, For=3.16e+01, Power=5.94e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00072: Time=   7.9s, Loss=3.68e+00, Inv=3.68e+00, For=3.18e+01, Power=5.92e-01
  [eval] val_mse=1.692e+00  (n=2997)
Epoch 00073: Time=   7.9s, Loss=3.67e+00, Inv=3.67e+00, For=3.22e+01, Power=5.93e-01
  [eval] val_mse=1.678e+00  (n=2997)
Epoch 00074: Time=   8.0s, Loss=3.66e+00, Inv=3.66e+00, For=3.29e+01, Power=5.92e-01
  [eval] val_mse=1.692e+00  (n=2997)
Epoch 00075: Time=   8.0s, Loss=3.65e+00, Inv=3.65e+00, For=3.29e+01, Power=5.91e-01
  [eval] val_mse=1.697e+00  (n=2997)
Epoch 00076: Time=   8.1s, Loss=3.64e+00, Inv=3.64e+00, For=3.37e+01, Power=5.91e-01
  [eval] val_mse=1.705e+00  (n=2997)
Epoch 00077: Time=   8.1s, Loss=3.63e+00, Inv=3.63e+00, For=3.37e+01, Power=5.90e-01
  [eval] val_mse=1.705e+00  (n=2997)
Epoch 00078: Time=   8.1s, Loss=3.62e+00, Inv=3.62e+00, For=3.44e+01, Power=5.89e-01
  [eval] val_mse=1.704e+00  (n=2997)
Epoch 00079: Time=   8.2s, Loss=3.61e+00, Inv=3.61e+00, For=3.50e+01, Power=5.88e-01
  [eval] val_mse=1.723e+00  (n=2997)
Epoch 00080: Time=   8.2s, Loss=3.61e+00, Inv=3.61e+00, For=3.53e+01, Power=5.88e-01
  [eval] val_mse=1.733e+00  (n=2997)
Epoch 00081: Time=   8.2s, Loss=3.60e+00, Inv=3.60e+00, For=3.55e+01, Power=5.86e-01
  [eval] val_mse=1.717e+00  (n=2997)
  [early_stop] stop at epoch=81 (best_epoch=71, best_val_mse=1.675e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 5.283e-01
Torque MSE  = 1.285e-01
Torque RMSE = 3.585e-01
Per-joint MSE : 1.543e-01 3.275e-01 1.304e-01 6.378e-02 4.818e-02 4.697e-02
Per-joint RMSE: 3.928e-01 5.723e-01 3.611e-01 2.525e-01 2.195e-01 2.167e-01
Comp Time per Sample = 2.162e-04s / 4624.8Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 2 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-o05bha6q because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7ee3b4d268c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 16:01:03.638702: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 16:01:05.488143: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=9.66e+03, Inv=9.66e+03, For=5.72e+00, Power=5.75e+02
  [eval] val_mse=8.012e+01  (n=2997)
Epoch 00002: Time=   5.7s, Loss=6.01e+02, Inv=6.01e+02, For=5.48e+00, Power=6.50e+01
  [eval] val_mse=3.316e+01  (n=2997)
Epoch 00003: Time=   5.7s, Loss=2.59e+02, Inv=2.59e+02, For=5.31e+00, Power=3.08e+01
  [eval] val_mse=2.130e+01  (n=2997)
Epoch 00004: Time=   5.8s, Loss=1.55e+02, Inv=1.55e+02, For=5.17e+00, Power=1.89e+01
  [eval] val_mse=1.527e+01  (n=2997)
Epoch 00005: Time=   5.8s, Loss=1.04e+02, Inv=1.04e+02, For=5.07e+00, Power=1.26e+01
  [eval] val_mse=1.187e+01  (n=2997)
Epoch 00006: Time=   5.8s, Loss=7.54e+01, Inv=7.54e+01, For=4.98e+00, Power=8.90e+00
  [eval] val_mse=9.760e+00  (n=2997)
Epoch 00007: Time=   5.9s, Loss=5.74e+01, Inv=5.74e+01, For=4.95e+00, Power=6.62e+00
  [eval] val_mse=8.319e+00  (n=2997)
Epoch 00008: Time=   5.9s, Loss=4.55e+01, Inv=4.55e+01, For=4.93e+00, Power=5.10e+00
  [eval] val_mse=7.309e+00  (n=2997)
Epoch 00009: Time=   5.9s, Loss=3.71e+01, Inv=3.71e+01, For=4.96e+00, Power=4.08e+00
  [eval] val_mse=6.528e+00  (n=2997)
Epoch 00010: Time=   6.0s, Loss=3.11e+01, Inv=3.11e+01, For=5.02e+00, Power=3.35e+00
  [eval] val_mse=5.928e+00  (n=2997)
Epoch 00011: Time=   6.0s, Loss=2.65e+01, Inv=2.65e+01, For=5.08e+00, Power=2.81e+00
  [eval] val_mse=5.439e+00  (n=2997)
Epoch 00012: Time=   6.0s, Loss=2.29e+01, Inv=2.29e+01, For=5.16e+00, Power=2.40e+00
  [eval] val_mse=5.028e+00  (n=2997)
Epoch 00013: Time=   6.1s, Loss=2.01e+01, Inv=2.01e+01, For=5.25e+00, Power=2.09e+00
  [eval] val_mse=4.666e+00  (n=2997)
Epoch 00014: Time=   6.1s, Loss=1.78e+01, Inv=1.78e+01, For=5.35e+00, Power=1.85e+00
  [eval] val_mse=4.354e+00  (n=2997)
Epoch 00015: Time=   6.2s, Loss=1.59e+01, Inv=1.59e+01, For=5.45e+00, Power=1.66e+00
  [eval] val_mse=4.078e+00  (n=2997)
Epoch 00016: Time=   6.2s, Loss=1.44e+01, Inv=1.44e+01, For=5.56e+00, Power=1.50e+00
  [eval] val_mse=3.835e+00  (n=2997)
Epoch 00017: Time=   6.2s, Loss=1.32e+01, Inv=1.32e+01, For=5.66e+00, Power=1.38e+00
  [eval] val_mse=3.624e+00  (n=2997)
Epoch 00018: Time=   6.3s, Loss=1.21e+01, Inv=1.21e+01, For=5.78e+00, Power=1.27e+00
  [eval] val_mse=3.440e+00  (n=2997)
Epoch 00019: Time=   6.3s, Loss=1.12e+01, Inv=1.12e+01, For=5.89e+00, Power=1.18e+00
  [eval] val_mse=3.288e+00  (n=2997)
Epoch 00020: Time=   6.3s, Loss=1.04e+01, Inv=1.04e+01, For=6.03e+00, Power=1.11e+00
  [eval] val_mse=3.158e+00  (n=2997)
Epoch 00021: Time=   6.4s, Loss=9.75e+00, Inv=9.75e+00, For=6.18e+00, Power=1.05e+00
  [eval] val_mse=3.046e+00  (n=2997)
Epoch 00022: Time=   6.4s, Loss=9.20e+00, Inv=9.20e+00, For=6.35e+00, Power=9.96e-01
  [eval] val_mse=2.945e+00  (n=2997)
Epoch 00023: Time=   6.4s, Loss=8.72e+00, Inv=8.72e+00, For=6.53e+00, Power=9.54e-01
  [eval] val_mse=2.867e+00  (n=2997)
Epoch 00024: Time=   6.5s, Loss=8.30e+00, Inv=8.30e+00, For=6.74e+00, Power=9.16e-01
  [eval] val_mse=2.791e+00  (n=2997)
Epoch 00025: Time=   6.5s, Loss=7.93e+00, Inv=7.93e+00, For=6.94e+00, Power=8.84e-01
  [eval] val_mse=2.724e+00  (n=2997)
Epoch 00026: Time=   6.5s, Loss=7.61e+00, Inv=7.61e+00, For=7.19e+00, Power=8.57e-01
  [eval] val_mse=2.663e+00  (n=2997)
Epoch 00027: Time=   6.6s, Loss=7.31e+00, Inv=7.31e+00, For=7.39e+00, Power=8.33e-01
  [eval] val_mse=2.607e+00  (n=2997)
Epoch 00028: Time=   6.6s, Loss=7.06e+00, Inv=7.06e+00, For=7.65e+00, Power=8.12e-01
  [eval] val_mse=2.553e+00  (n=2997)
Epoch 00029: Time=   6.6s, Loss=6.83e+00, Inv=6.83e+00, For=7.89e+00, Power=7.93e-01
  [eval] val_mse=2.492e+00  (n=2997)
Epoch 00030: Time=   6.7s, Loss=6.62e+00, Inv=6.62e+00, For=8.15e+00, Power=7.78e-01
  [eval] val_mse=2.443e+00  (n=2997)
Epoch 00031: Time=   6.7s, Loss=6.43e+00, Inv=6.43e+00, For=8.41e+00, Power=7.63e-01
  [eval] val_mse=2.389e+00  (n=2997)
Epoch 00032: Time=   6.7s, Loss=6.26e+00, Inv=6.26e+00, For=8.69e+00, Power=7.51e-01
  [eval] val_mse=2.345e+00  (n=2997)
Epoch 00033: Time=   6.8s, Loss=6.10e+00, Inv=6.10e+00, For=8.97e+00, Power=7.40e-01
  [eval] val_mse=2.296e+00  (n=2997)
Epoch 00034: Time=   6.8s, Loss=5.96e+00, Inv=5.96e+00, For=9.24e+00, Power=7.29e-01
  [eval] val_mse=2.258e+00  (n=2997)
Epoch 00035: Time=   6.8s, Loss=5.83e+00, Inv=5.83e+00, For=9.53e+00, Power=7.21e-01
  [eval] val_mse=2.219e+00  (n=2997)
Epoch 00036: Time=   6.9s, Loss=5.70e+00, Inv=5.70e+00, For=9.81e+00, Power=7.13e-01
  [eval] val_mse=2.179e+00  (n=2997)
Epoch 00037: Time=   6.9s, Loss=5.59e+00, Inv=5.59e+00, For=1.01e+01, Power=7.05e-01
  [eval] val_mse=2.136e+00  (n=2997)
Epoch 00038: Time=   7.0s, Loss=5.49e+00, Inv=5.49e+00, For=1.04e+01, Power=6.98e-01
  [eval] val_mse=2.106e+00  (n=2997)
Epoch 00039: Time=   7.0s, Loss=5.38e+00, Inv=5.38e+00, For=1.07e+01, Power=6.92e-01
  [eval] val_mse=2.067e+00  (n=2997)
Epoch 00040: Time=   7.0s, Loss=5.29e+00, Inv=5.29e+00, For=1.10e+01, Power=6.86e-01
  [eval] val_mse=2.037e+00  (n=2997)
Epoch 00041: Time=   7.1s, Loss=5.21e+00, Inv=5.21e+00, For=1.13e+01, Power=6.81e-01
  [eval] val_mse=2.017e+00  (n=2997)
Epoch 00042: Time=   7.1s, Loss=5.13e+00, Inv=5.13e+00, For=1.16e+01, Power=6.74e-01
  [eval] val_mse=1.979e+00  (n=2997)
Epoch 00043: Time=   7.1s, Loss=5.05e+00, Inv=5.05e+00, For=1.18e+01, Power=6.71e-01
  [eval] val_mse=1.956e+00  (n=2997)
Epoch 00044: Time=   7.2s, Loss=4.98e+00, Inv=4.98e+00, For=1.21e+01, Power=6.67e-01
  [eval] val_mse=1.933e+00  (n=2997)
Epoch 00045: Time=   7.2s, Loss=4.91e+00, Inv=4.91e+00, For=1.24e+01, Power=6.62e-01
  [eval] val_mse=1.907e+00  (n=2997)
Epoch 00046: Time=   7.2s, Loss=4.85e+00, Inv=4.85e+00, For=1.27e+01, Power=6.59e-01
  [eval] val_mse=1.876e+00  (n=2997)
Epoch 00047: Time=   7.3s, Loss=4.79e+00, Inv=4.79e+00, For=1.30e+01, Power=6.56e-01
  [eval] val_mse=1.862e+00  (n=2997)
Epoch 00048: Time=   7.3s, Loss=4.73e+00, Inv=4.73e+00, For=1.33e+01, Power=6.52e-01
  [eval] val_mse=1.841e+00  (n=2997)
Epoch 00049: Time=   7.3s, Loss=4.68e+00, Inv=4.68e+00, For=1.36e+01, Power=6.50e-01
  [eval] val_mse=1.826e+00  (n=2997)
Epoch 00050: Time=   7.4s, Loss=4.63e+00, Inv=4.63e+00, For=1.39e+01, Power=6.45e-01
  [eval] val_mse=1.798e+00  (n=2997)
Epoch 00051: Time=   7.4s, Loss=4.58e+00, Inv=4.58e+00, For=1.42e+01, Power=6.43e-01
  [eval] val_mse=1.781e+00  (n=2997)
Epoch 00052: Time=   7.4s, Loss=4.54e+00, Inv=4.54e+00, For=1.45e+01, Power=6.41e-01
  [eval] val_mse=1.769e+00  (n=2997)
Epoch 00053: Time=   7.5s, Loss=4.49e+00, Inv=4.49e+00, For=1.48e+01, Power=6.39e-01
  [eval] val_mse=1.755e+00  (n=2997)
Epoch 00054: Time=   7.5s, Loss=4.45e+00, Inv=4.45e+00, For=1.50e+01, Power=6.35e-01
  [eval] val_mse=1.743e+00  (n=2997)
Epoch 00055: Time=   7.6s, Loss=4.41e+00, Inv=4.41e+00, For=1.53e+01, Power=6.33e-01
  [eval] val_mse=1.732e+00  (n=2997)
Epoch 00056: Time=   7.6s, Loss=4.37e+00, Inv=4.37e+00, For=1.56e+01, Power=6.32e-01
  [eval] val_mse=1.715e+00  (n=2997)
Epoch 00057: Time=   7.6s, Loss=4.33e+00, Inv=4.33e+00, For=1.59e+01, Power=6.29e-01
  [eval] val_mse=1.695e+00  (n=2997)
Epoch 00058: Time=   7.7s, Loss=4.30e+00, Inv=4.30e+00, For=1.62e+01, Power=6.28e-01
  [eval] val_mse=1.702e+00  (n=2997)
Epoch 00059: Time=   7.7s, Loss=4.26e+00, Inv=4.26e+00, For=1.65e+01, Power=6.26e-01
  [eval] val_mse=1.686e+00  (n=2997)
Epoch 00060: Time=   7.7s, Loss=4.23e+00, Inv=4.23e+00, For=1.68e+01, Power=6.24e-01
  [eval] val_mse=1.680e+00  (n=2997)
Epoch 00061: Time=   7.8s, Loss=4.20e+00, Inv=4.20e+00, For=1.70e+01, Power=6.23e-01
  [eval] val_mse=1.681e+00  (n=2997)
Epoch 00062: Time=   7.8s, Loss=4.17e+00, Inv=4.17e+00, For=1.73e+01, Power=6.21e-01
  [eval] val_mse=1.670e+00  (n=2997)
Epoch 00063: Time=   7.8s, Loss=4.14e+00, Inv=4.14e+00, For=1.76e+01, Power=6.19e-01
  [eval] val_mse=1.661e+00  (n=2997)
Epoch 00064: Time=   7.9s, Loss=4.12e+00, Inv=4.12e+00, For=1.79e+01, Power=6.18e-01
  [eval] val_mse=1.653e+00  (n=2997)
Epoch 00065: Time=   7.9s, Loss=4.09e+00, Inv=4.09e+00, For=1.82e+01, Power=6.16e-01
  [eval] val_mse=1.667e+00  (n=2997)
Epoch 00066: Time=   7.9s, Loss=4.06e+00, Inv=4.06e+00, For=1.84e+01, Power=6.14e-01
  [eval] val_mse=1.656e+00  (n=2997)
Epoch 00067: Time=   8.0s, Loss=4.04e+00, Inv=4.04e+00, For=1.87e+01, Power=6.13e-01
  [eval] val_mse=1.654e+00  (n=2997)
Epoch 00068: Time=   8.0s, Loss=4.02e+00, Inv=4.02e+00, For=1.89e+01, Power=6.12e-01
  [eval] val_mse=1.671e+00  (n=2997)
Epoch 00069: Time=   8.0s, Loss=4.00e+00, Inv=4.00e+00, For=1.93e+01, Power=6.11e-01
  [eval] val_mse=1.649e+00  (n=2997)
Epoch 00070: Time=   8.1s, Loss=3.98e+00, Inv=3.98e+00, For=1.95e+01, Power=6.10e-01
  [eval] val_mse=1.665e+00  (n=2997)
Epoch 00071: Time=   8.1s, Loss=3.95e+00, Inv=3.95e+00, For=1.98e+01, Power=6.09e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00072: Time=   8.1s, Loss=3.94e+00, Inv=3.94e+00, For=2.01e+01, Power=6.08e-01
  [eval] val_mse=1.675e+00  (n=2997)
Epoch 00073: Time=   8.2s, Loss=3.92e+00, Inv=3.92e+00, For=2.03e+01, Power=6.07e-01
  [eval] val_mse=1.680e+00  (n=2997)
Epoch 00074: Time=   8.2s, Loss=3.90e+00, Inv=3.90e+00, For=2.06e+01, Power=6.05e-01
  [eval] val_mse=1.674e+00  (n=2997)
Epoch 00075: Time=   8.2s, Loss=3.88e+00, Inv=3.88e+00, For=2.08e+01, Power=6.03e-01
  [eval] val_mse=1.696e+00  (n=2997)
Epoch 00076: Time=   8.3s, Loss=3.87e+00, Inv=3.87e+00, For=2.11e+01, Power=6.04e-01
  [eval] val_mse=1.690e+00  (n=2997)
Epoch 00077: Time=   8.3s, Loss=3.85e+00, Inv=3.85e+00, For=2.13e+01, Power=6.02e-01
  [eval] val_mse=1.697e+00  (n=2997)
Epoch 00078: Time=   8.3s, Loss=3.84e+00, Inv=3.84e+00, For=2.16e+01, Power=6.02e-01
  [eval] val_mse=1.708e+00  (n=2997)
Epoch 00079: Time=   8.4s, Loss=3.82e+00, Inv=3.82e+00, For=2.19e+01, Power=6.00e-01
  [eval] val_mse=1.706e+00  (n=2997)
  [early_stop] stop at epoch=79 (best_epoch=69, best_val_mse=1.649e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 5.243e-01
Torque MSE  = 1.269e-01
Torque RMSE = 3.563e-01
Per-joint MSE : 1.700e-01 2.706e-01 1.401e-01 7.326e-02 5.533e-02 5.215e-02
Per-joint RMSE: 4.124e-01 5.202e-01 3.743e-01 2.707e-01 2.352e-01 2.284e-01
Comp Time per Sample = 2.136e-04s / 4682.5Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s2_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 3 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-6ulbpfyk because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x780db551e8c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 16:01:21.860143: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 16:01:23.705073: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.1s, Loss=1.21e+04, Inv=1.21e+04, For=5.80e+00, Power=1.20e+03
  [eval] val_mse=1.756e+02  (n=2997)
Epoch 00002: Time=   5.5s, Loss=1.01e+03, Inv=1.01e+03, For=5.64e+00, Power=1.51e+02
  [eval] val_mse=5.672e+01  (n=2997)
Epoch 00003: Time=   5.6s, Loss=4.09e+02, Inv=4.09e+02, For=5.53e+00, Power=6.48e+01
  [eval] val_mse=3.048e+01  (n=2997)
Epoch 00004: Time=   5.6s, Loss=2.35e+02, Inv=2.35e+02, For=5.44e+00, Power=3.66e+01
  [eval] val_mse=1.974e+01  (n=2997)
Epoch 00005: Time=   5.7s, Loss=1.52e+02, Inv=1.52e+02, For=5.36e+00, Power=2.30e+01
  [eval] val_mse=1.415e+01  (n=2997)
Epoch 00006: Time=   5.7s, Loss=1.06e+02, Inv=1.06e+02, For=5.29e+00, Power=1.55e+01
  [eval] val_mse=1.090e+01  (n=2997)
Epoch 00007: Time=   5.7s, Loss=7.89e+01, Inv=7.89e+01, For=5.28e+00, Power=1.12e+01
  [eval] val_mse=8.820e+00  (n=2997)
Epoch 00008: Time=   5.8s, Loss=6.10e+01, Inv=6.10e+01, For=5.29e+00, Power=8.41e+00
  [eval] val_mse=7.441e+00  (n=2997)
Epoch 00009: Time=   5.8s, Loss=4.87e+01, Inv=4.87e+01, For=5.34e+00, Power=6.55e+00
  [eval] val_mse=6.454e+00  (n=2997)
Epoch 00010: Time=   5.8s, Loss=4.00e+01, Inv=4.00e+01, For=5.41e+00, Power=5.25e+00
  [eval] val_mse=5.695e+00  (n=2997)
Epoch 00011: Time=   5.9s, Loss=3.34e+01, Inv=3.34e+01, For=5.47e+00, Power=4.33e+00
  [eval] val_mse=5.102e+00  (n=2997)
Epoch 00012: Time=   5.9s, Loss=2.84e+01, Inv=2.84e+01, For=5.59e+00, Power=3.63e+00
  [eval] val_mse=4.616e+00  (n=2997)
Epoch 00013: Time=   5.9s, Loss=2.45e+01, Inv=2.45e+01, For=5.72e+00, Power=3.11e+00
  [eval] val_mse=4.230e+00  (n=2997)
Epoch 00014: Time=   6.0s, Loss=2.15e+01, Inv=2.15e+01, For=5.86e+00, Power=2.70e+00
  [eval] val_mse=3.908e+00  (n=2997)
Epoch 00015: Time=   6.0s, Loss=1.90e+01, Inv=1.90e+01, For=6.04e+00, Power=2.38e+00
  [eval] val_mse=3.643e+00  (n=2997)
Epoch 00016: Time=   6.0s, Loss=1.70e+01, Inv=1.70e+01, For=6.25e+00, Power=2.12e+00
  [eval] val_mse=3.437e+00  (n=2997)
Epoch 00017: Time=   6.1s, Loss=1.53e+01, Inv=1.53e+01, For=6.44e+00, Power=1.90e+00
  [eval] val_mse=3.258e+00  (n=2997)
Epoch 00018: Time=   6.1s, Loss=1.40e+01, Inv=1.40e+01, For=6.73e+00, Power=1.73e+00
  [eval] val_mse=3.130e+00  (n=2997)
Epoch 00019: Time=   6.2s, Loss=1.28e+01, Inv=1.28e+01, For=7.01e+00, Power=1.58e+00
  [eval] val_mse=3.023e+00  (n=2997)
Epoch 00020: Time=   6.2s, Loss=1.19e+01, Inv=1.19e+01, For=7.32e+00, Power=1.46e+00
  [eval] val_mse=2.935e+00  (n=2997)
Epoch 00021: Time=   6.2s, Loss=1.10e+01, Inv=1.10e+01, For=7.63e+00, Power=1.36e+00
  [eval] val_mse=2.863e+00  (n=2997)
Epoch 00022: Time=   6.3s, Loss=1.03e+01, Inv=1.03e+01, For=7.97e+00, Power=1.28e+00
  [eval] val_mse=2.806e+00  (n=2997)
Epoch 00023: Time=   6.3s, Loss=9.72e+00, Inv=9.72e+00, For=8.36e+00, Power=1.20e+00
  [eval] val_mse=2.754e+00  (n=2997)
Epoch 00024: Time=   6.3s, Loss=9.18e+00, Inv=9.18e+00, For=8.70e+00, Power=1.14e+00
  [eval] val_mse=2.705e+00  (n=2997)
Epoch 00025: Time=   6.4s, Loss=8.72e+00, Inv=8.72e+00, For=9.11e+00, Power=1.08e+00
  [eval] val_mse=2.654e+00  (n=2997)
Epoch 00026: Time=   6.4s, Loss=8.30e+00, Inv=8.30e+00, For=9.47e+00, Power=1.04e+00
  [eval] val_mse=2.600e+00  (n=2997)
Epoch 00027: Time=   6.5s, Loss=7.93e+00, Inv=7.93e+00, For=9.86e+00, Power=9.96e-01
  [eval] val_mse=2.565e+00  (n=2997)
Epoch 00028: Time=   6.5s, Loss=7.60e+00, Inv=7.60e+00, For=1.03e+01, Power=9.58e-01
  [eval] val_mse=2.526e+00  (n=2997)
Epoch 00029: Time=   6.5s, Loss=7.30e+00, Inv=7.30e+00, For=1.06e+01, Power=9.24e-01
  [eval] val_mse=2.479e+00  (n=2997)
Epoch 00030: Time=   6.6s, Loss=7.04e+00, Inv=7.04e+00, For=1.11e+01, Power=8.99e-01
  [eval] val_mse=2.449e+00  (n=2997)
Epoch 00031: Time=   6.6s, Loss=6.79e+00, Inv=6.79e+00, For=1.14e+01, Power=8.71e-01
  [eval] val_mse=2.423e+00  (n=2997)
Epoch 00032: Time=   6.6s, Loss=6.57e+00, Inv=6.57e+00, For=1.19e+01, Power=8.50e-01
  [eval] val_mse=2.395e+00  (n=2997)
Epoch 00033: Time=   6.7s, Loss=6.38e+00, Inv=6.38e+00, For=1.23e+01, Power=8.29e-01
  [eval] val_mse=2.360e+00  (n=2997)
Epoch 00034: Time=   6.7s, Loss=6.19e+00, Inv=6.19e+00, For=1.27e+01, Power=8.11e-01
  [eval] val_mse=2.340e+00  (n=2997)
Epoch 00035: Time=   6.7s, Loss=6.02e+00, Inv=6.02e+00, For=1.31e+01, Power=7.94e-01
  [eval] val_mse=2.310e+00  (n=2997)
Epoch 00036: Time=   6.8s, Loss=5.87e+00, Inv=5.87e+00, For=1.35e+01, Power=7.80e-01
  [eval] val_mse=2.295e+00  (n=2997)
Epoch 00037: Time=   6.8s, Loss=5.73e+00, Inv=5.73e+00, For=1.39e+01, Power=7.65e-01
  [eval] val_mse=2.270e+00  (n=2997)
Epoch 00038: Time=   6.8s, Loss=5.60e+00, Inv=5.60e+00, For=1.44e+01, Power=7.52e-01
  [eval] val_mse=2.256e+00  (n=2997)
Epoch 00039: Time=   6.9s, Loss=5.48e+00, Inv=5.48e+00, For=1.46e+01, Power=7.42e-01
  [eval] val_mse=2.246e+00  (n=2997)
Epoch 00040: Time=   6.9s, Loss=5.36e+00, Inv=5.36e+00, For=1.52e+01, Power=7.30e-01
  [eval] val_mse=2.228e+00  (n=2997)
Epoch 00041: Time=   6.9s, Loss=5.26e+00, Inv=5.26e+00, For=1.56e+01, Power=7.21e-01
  [eval] val_mse=2.212e+00  (n=2997)
Epoch 00042: Time=   7.0s, Loss=5.16e+00, Inv=5.16e+00, For=1.60e+01, Power=7.11e-01
  [eval] val_mse=2.199e+00  (n=2997)
Epoch 00043: Time=   7.0s, Loss=5.07e+00, Inv=5.07e+00, For=1.63e+01, Power=7.03e-01
  [eval] val_mse=2.196e+00  (n=2997)
Epoch 00044: Time=   7.1s, Loss=4.99e+00, Inv=4.99e+00, For=1.69e+01, Power=6.96e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00045: Time=   7.1s, Loss=4.91e+00, Inv=4.91e+00, For=1.71e+01, Power=6.89e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00046: Time=   7.1s, Loss=4.84e+00, Inv=4.84e+00, For=1.76e+01, Power=6.83e-01
  [eval] val_mse=2.166e+00  (n=2997)
Epoch 00047: Time=   7.2s, Loss=4.76e+00, Inv=4.76e+00, For=1.79e+01, Power=6.76e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00048: Time=   7.2s, Loss=4.70e+00, Inv=4.70e+00, For=1.83e+01, Power=6.71e-01
  [eval] val_mse=2.178e+00  (n=2997)
Epoch 00049: Time=   7.2s, Loss=4.64e+00, Inv=4.64e+00, For=1.86e+01, Power=6.66e-01
  [eval] val_mse=2.164e+00  (n=2997)
Epoch 00050: Time=   7.3s, Loss=4.58e+00, Inv=4.58e+00, For=1.93e+01, Power=6.60e-01
  [eval] val_mse=2.157e+00  (n=2997)
Epoch 00051: Time=   7.3s, Loss=4.53e+00, Inv=4.53e+00, For=1.95e+01, Power=6.57e-01
  [eval] val_mse=2.169e+00  (n=2997)
Epoch 00052: Time=   7.3s, Loss=4.47e+00, Inv=4.47e+00, For=1.98e+01, Power=6.52e-01
  [eval] val_mse=2.150e+00  (n=2997)
Epoch 00053: Time=   7.4s, Loss=4.43e+00, Inv=4.43e+00, For=2.04e+01, Power=6.48e-01
  [eval] val_mse=2.164e+00  (n=2997)
Epoch 00054: Time=   7.4s, Loss=4.38e+00, Inv=4.38e+00, For=2.07e+01, Power=6.45e-01
  [eval] val_mse=2.158e+00  (n=2997)
Epoch 00055: Time=   7.4s, Loss=4.34e+00, Inv=4.34e+00, For=2.08e+01, Power=6.40e-01
  [eval] val_mse=2.157e+00  (n=2997)
Epoch 00056: Time=   7.5s, Loss=4.30e+00, Inv=4.30e+00, For=2.13e+01, Power=6.38e-01
  [eval] val_mse=2.165e+00  (n=2997)
Epoch 00057: Time=   7.5s, Loss=4.25e+00, Inv=4.25e+00, For=2.16e+01, Power=6.33e-01
  [eval] val_mse=2.157e+00  (n=2997)
Epoch 00058: Time=   7.5s, Loss=4.22e+00, Inv=4.22e+00, For=2.21e+01, Power=6.31e-01
  [eval] val_mse=2.173e+00  (n=2997)
Epoch 00059: Time=   7.6s, Loss=4.19e+00, Inv=4.19e+00, For=2.23e+01, Power=6.29e-01
  [eval] val_mse=2.180e+00  (n=2997)
Epoch 00060: Time=   7.6s, Loss=4.15e+00, Inv=4.15e+00, For=2.29e+01, Power=6.25e-01
  [eval] val_mse=2.174e+00  (n=2997)
Epoch 00061: Time=   7.7s, Loss=4.12e+00, Inv=4.12e+00, For=2.29e+01, Power=6.23e-01
  [eval] val_mse=2.177e+00  (n=2997)
Epoch 00062: Time=   7.7s, Loss=4.09e+00, Inv=4.09e+00, For=2.33e+01, Power=6.21e-01
  [eval] val_mse=2.198e+00  (n=2997)
  [early_stop] stop at epoch=62 (best_epoch=52, best_val_mse=2.150e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 5.987e-01
Torque MSE  = 1.424e-01
Torque RMSE = 3.774e-01
Per-joint MSE : 1.794e-01 2.917e-01 1.718e-01 7.717e-02 7.313e-02 6.138e-02
Per-joint RMSE: 4.235e-01 5.401e-01 4.145e-01 2.778e-01 2.704e-01 2.478e-01
Comp Time per Sample = 2.022e-04s / 4945.6Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s3_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/rbyt_train_delan_jax.py --npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz -t structured -s 4 -r 0 --hp_preset lutter_like_256_wd1e4 --epochs 200 --eval_every 1 --log_every 1 --early_stop True --early_stop_patience 10 --early_stop_min_delta 0.0 --early_stop_warmup_evals 0 --save_path /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax'
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-y2hu36yr because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Final hyper: {'dataset': 'UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2', 'n_width': 256, 'n_depth': 2, 'n_minibatch': 1024, 'diagonal_epsilon': 0.1, 'diagonal_shift': 2.0, 'activation': 'softplus', 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'max_epoch': 200, 'lagrangian_type': <function structured_lagrangian_fn at 0x7eaeb28d68c0>}


################################################
DeLaN run: UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  model_dir = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  ckpt_path = /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
  type = structured
  hp_preset = lutter_like_256_wd1e4
################################################


################################################
Dataset: delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
  npz = /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
   dt ≈ 0.01391161142380656
  dof = 6
  Train trajectories = 19
  Val trajectories   = 3
  Test trajectories  = 5
  Train samples = 38000
  Test samples  = 7000
################################################

2026-01-30 16:01:39.468427: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
2026-01-30 16:01:41.332670: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.
################################################
Training DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2 | type=structured | dof=6
################################################
Epoch 00001: Time=   4.0s, Loss=1.89e+04, Inv=1.89e+04, For=5.77e+00, Power=1.15e+03
  [eval] val_mse=9.676e+01  (n=2997)
Epoch 00002: Time=   5.4s, Loss=1.30e+03, Inv=1.30e+03, For=5.57e+00, Power=1.13e+02
  [eval] val_mse=4.089e+01  (n=2997)
Epoch 00003: Time=   5.4s, Loss=5.23e+02, Inv=5.23e+02, For=5.42e+00, Power=4.64e+01
  [eval] val_mse=2.549e+01  (n=2997)
Epoch 00004: Time=   5.5s, Loss=2.99e+02, Inv=2.99e+02, For=5.33e+00, Power=2.68e+01
  [eval] val_mse=1.863e+01  (n=2997)
Epoch 00005: Time=   5.5s, Loss=1.94e+02, Inv=1.94e+02, For=5.25e+00, Power=1.73e+01
  [eval] val_mse=1.463e+01  (n=2997)
Epoch 00006: Time=   5.5s, Loss=1.36e+02, Inv=1.36e+02, For=5.19e+00, Power=1.20e+01
  [eval] val_mse=1.212e+01  (n=2997)
Epoch 00007: Time=   5.6s, Loss=1.01e+02, Inv=1.01e+02, For=5.15e+00, Power=8.82e+00
  [eval] val_mse=1.035e+01  (n=2997)
Epoch 00008: Time=   5.6s, Loss=7.85e+01, Inv=7.85e+01, For=5.15e+00, Power=6.72e+00
  [eval] val_mse=9.099e+00  (n=2997)
Epoch 00009: Time=   5.6s, Loss=6.28e+01, Inv=6.28e+01, For=5.17e+00, Power=5.32e+00
  [eval] val_mse=8.144e+00  (n=2997)
Epoch 00010: Time=   5.7s, Loss=5.16e+01, Inv=5.16e+01, For=5.17e+00, Power=4.32e+00
  [eval] val_mse=7.411e+00  (n=2997)
Epoch 00011: Time=   5.7s, Loss=4.33e+01, Inv=4.33e+01, For=5.21e+00, Power=3.60e+00
  [eval] val_mse=6.789e+00  (n=2997)
Epoch 00012: Time=   5.7s, Loss=3.70e+01, Inv=3.70e+01, For=5.26e+00, Power=3.06e+00
  [eval] val_mse=6.283e+00  (n=2997)
Epoch 00013: Time=   5.8s, Loss=3.20e+01, Inv=3.20e+01, For=5.29e+00, Power=2.64e+00
  [eval] val_mse=5.848e+00  (n=2997)
Epoch 00014: Time=   5.8s, Loss=2.80e+01, Inv=2.80e+01, For=5.35e+00, Power=2.31e+00
  [eval] val_mse=5.476e+00  (n=2997)
Epoch 00015: Time=   5.9s, Loss=2.49e+01, Inv=2.49e+01, For=5.41e+00, Power=2.05e+00
  [eval] val_mse=5.153e+00  (n=2997)
Epoch 00016: Time=   5.9s, Loss=2.22e+01, Inv=2.22e+01, For=5.47e+00, Power=1.84e+00
  [eval] val_mse=4.866e+00  (n=2997)
Epoch 00017: Time=   5.9s, Loss=2.00e+01, Inv=2.00e+01, For=5.53e+00, Power=1.67e+00
  [eval] val_mse=4.619e+00  (n=2997)
Epoch 00018: Time=   6.0s, Loss=1.82e+01, Inv=1.82e+01, For=5.62e+00, Power=1.53e+00
  [eval] val_mse=4.404e+00  (n=2997)
Epoch 00019: Time=   6.0s, Loss=1.67e+01, Inv=1.67e+01, For=5.72e+00, Power=1.41e+00
  [eval] val_mse=4.213e+00  (n=2997)
Epoch 00020: Time=   6.0s, Loss=1.53e+01, Inv=1.53e+01, For=5.82e+00, Power=1.31e+00
  [eval] val_mse=4.059e+00  (n=2997)
Epoch 00021: Time=   6.1s, Loss=1.42e+01, Inv=1.42e+01, For=5.94e+00, Power=1.22e+00
  [eval] val_mse=3.923e+00  (n=2997)
Epoch 00022: Time=   6.1s, Loss=1.32e+01, Inv=1.32e+01, For=6.08e+00, Power=1.15e+00
  [eval] val_mse=3.803e+00  (n=2997)
Epoch 00023: Time=   6.2s, Loss=1.24e+01, Inv=1.24e+01, For=6.23e+00, Power=1.09e+00
  [eval] val_mse=3.697e+00  (n=2997)
Epoch 00024: Time=   6.2s, Loss=1.17e+01, Inv=1.17e+01, For=6.41e+00, Power=1.04e+00
  [eval] val_mse=3.611e+00  (n=2997)
Epoch 00025: Time=   6.2s, Loss=1.10e+01, Inv=1.10e+01, For=6.59e+00, Power=9.93e-01
  [eval] val_mse=3.529e+00  (n=2997)
Epoch 00026: Time=   6.3s, Loss=1.05e+01, Inv=1.05e+01, For=6.81e+00, Power=9.54e-01
  [eval] val_mse=3.452e+00  (n=2997)
Epoch 00027: Time=   6.3s, Loss=9.96e+00, Inv=9.96e+00, For=7.03e+00, Power=9.19e-01
  [eval] val_mse=3.375e+00  (n=2997)
Epoch 00028: Time=   6.3s, Loss=9.51e+00, Inv=9.51e+00, For=7.25e+00, Power=8.90e-01
  [eval] val_mse=3.308e+00  (n=2997)
Epoch 00029: Time=   6.4s, Loss=9.12e+00, Inv=9.12e+00, For=7.49e+00, Power=8.65e-01
  [eval] val_mse=3.241e+00  (n=2997)
Epoch 00030: Time=   6.4s, Loss=8.76e+00, Inv=8.76e+00, For=7.75e+00, Power=8.41e-01
  [eval] val_mse=3.179e+00  (n=2997)
Epoch 00031: Time=   6.4s, Loss=8.42e+00, Inv=8.42e+00, For=8.00e+00, Power=8.19e-01
  [eval] val_mse=3.118e+00  (n=2997)
Epoch 00032: Time=   6.5s, Loss=8.13e+00, Inv=8.13e+00, For=8.26e+00, Power=8.02e-01
  [eval] val_mse=3.049e+00  (n=2997)
Epoch 00033: Time=   6.5s, Loss=7.85e+00, Inv=7.85e+00, For=8.53e+00, Power=7.84e-01
  [eval] val_mse=2.989e+00  (n=2997)
Epoch 00034: Time=   6.5s, Loss=7.60e+00, Inv=7.60e+00, For=8.81e+00, Power=7.70e-01
  [eval] val_mse=2.934e+00  (n=2997)
Epoch 00035: Time=   6.6s, Loss=7.37e+00, Inv=7.37e+00, For=9.08e+00, Power=7.58e-01
  [eval] val_mse=2.884e+00  (n=2997)
Epoch 00036: Time=   6.6s, Loss=7.16e+00, Inv=7.16e+00, For=9.41e+00, Power=7.46e-01
  [eval] val_mse=2.836e+00  (n=2997)
Epoch 00037: Time=   6.7s, Loss=6.96e+00, Inv=6.96e+00, For=9.67e+00, Power=7.34e-01
  [eval] val_mse=2.791e+00  (n=2997)
Epoch 00038: Time=   6.7s, Loss=6.77e+00, Inv=6.77e+00, For=9.98e+00, Power=7.24e-01
  [eval] val_mse=2.741e+00  (n=2997)
Epoch 00039: Time=   6.8s, Loss=6.60e+00, Inv=6.60e+00, For=1.03e+01, Power=7.14e-01
  [eval] val_mse=2.698e+00  (n=2997)
Epoch 00040: Time=   6.8s, Loss=6.45e+00, Inv=6.45e+00, For=1.06e+01, Power=7.06e-01
  [eval] val_mse=2.652e+00  (n=2997)
Epoch 00041: Time=   6.8s, Loss=6.30e+00, Inv=6.30e+00, For=1.09e+01, Power=6.99e-01
  [eval] val_mse=2.629e+00  (n=2997)
Epoch 00042: Time=   6.9s, Loss=6.16e+00, Inv=6.16e+00, For=1.12e+01, Power=6.92e-01
  [eval] val_mse=2.584e+00  (n=2997)
Epoch 00043: Time=   6.9s, Loss=6.03e+00, Inv=6.03e+00, For=1.15e+01, Power=6.86e-01
  [eval] val_mse=2.564e+00  (n=2997)
Epoch 00044: Time=   6.9s, Loss=5.91e+00, Inv=5.91e+00, For=1.19e+01, Power=6.79e-01
  [eval] val_mse=2.523e+00  (n=2997)
Epoch 00045: Time=   7.0s, Loss=5.79e+00, Inv=5.79e+00, For=1.22e+01, Power=6.73e-01
  [eval] val_mse=2.502e+00  (n=2997)
Epoch 00046: Time=   7.0s, Loss=5.68e+00, Inv=5.68e+00, For=1.26e+01, Power=6.68e-01
  [eval] val_mse=2.459e+00  (n=2997)
Epoch 00047: Time=   7.0s, Loss=5.58e+00, Inv=5.58e+00, For=1.29e+01, Power=6.63e-01
  [eval] val_mse=2.431e+00  (n=2997)
Epoch 00048: Time=   7.1s, Loss=5.48e+00, Inv=5.48e+00, For=1.33e+01, Power=6.58e-01
  [eval] val_mse=2.408e+00  (n=2997)
Epoch 00049: Time=   7.1s, Loss=5.39e+00, Inv=5.39e+00, For=1.36e+01, Power=6.54e-01
  [eval] val_mse=2.377e+00  (n=2997)
Epoch 00050: Time=   7.2s, Loss=5.31e+00, Inv=5.31e+00, For=1.40e+01, Power=6.49e-01
  [eval] val_mse=2.359e+00  (n=2997)
Epoch 00051: Time=   7.2s, Loss=5.22e+00, Inv=5.22e+00, For=1.44e+01, Power=6.46e-01
  [eval] val_mse=2.340e+00  (n=2997)
Epoch 00052: Time=   7.2s, Loss=5.15e+00, Inv=5.15e+00, For=1.47e+01, Power=6.42e-01
  [eval] val_mse=2.319e+00  (n=2997)
Epoch 00053: Time=   7.3s, Loss=5.07e+00, Inv=5.07e+00, For=1.51e+01, Power=6.39e-01
  [eval] val_mse=2.295e+00  (n=2997)
Epoch 00054: Time=   7.3s, Loss=5.00e+00, Inv=5.00e+00, For=1.55e+01, Power=6.35e-01
  [eval] val_mse=2.270e+00  (n=2997)
Epoch 00055: Time=   7.3s, Loss=4.94e+00, Inv=4.94e+00, For=1.59e+01, Power=6.33e-01
  [eval] val_mse=2.257e+00  (n=2997)
Epoch 00056: Time=   7.4s, Loss=4.88e+00, Inv=4.88e+00, For=1.63e+01, Power=6.30e-01
  [eval] val_mse=2.228e+00  (n=2997)
Epoch 00057: Time=   7.4s, Loss=4.82e+00, Inv=4.82e+00, For=1.67e+01, Power=6.27e-01
  [eval] val_mse=2.226e+00  (n=2997)
Epoch 00058: Time=   7.4s, Loss=4.76e+00, Inv=4.76e+00, For=1.70e+01, Power=6.24e-01
  [eval] val_mse=2.208e+00  (n=2997)
Epoch 00059: Time=   7.5s, Loss=4.71e+00, Inv=4.71e+00, For=1.75e+01, Power=6.20e-01
  [eval] val_mse=2.188e+00  (n=2997)
Epoch 00060: Time=   7.5s, Loss=4.66e+00, Inv=4.66e+00, For=1.79e+01, Power=6.19e-01
  [eval] val_mse=2.176e+00  (n=2997)
Epoch 00061: Time=   7.6s, Loss=4.61e+00, Inv=4.61e+00, For=1.83e+01, Power=6.16e-01
  [eval] val_mse=2.153e+00  (n=2997)
Epoch 00062: Time=   7.6s, Loss=4.56e+00, Inv=4.56e+00, For=1.87e+01, Power=6.15e-01
  [eval] val_mse=2.154e+00  (n=2997)
Epoch 00063: Time=   7.6s, Loss=4.52e+00, Inv=4.52e+00, For=1.91e+01, Power=6.13e-01
  [eval] val_mse=2.129e+00  (n=2997)
Epoch 00064: Time=   7.7s, Loss=4.48e+00, Inv=4.48e+00, For=1.95e+01, Power=6.11e-01
  [eval] val_mse=2.119e+00  (n=2997)
Epoch 00065: Time=   7.7s, Loss=4.44e+00, Inv=4.44e+00, For=1.99e+01, Power=6.09e-01
  [eval] val_mse=2.103e+00  (n=2997)
Epoch 00066: Time=   7.7s, Loss=4.40e+00, Inv=4.40e+00, For=2.03e+01, Power=6.08e-01
  [eval] val_mse=2.084e+00  (n=2997)
Epoch 00067: Time=   7.8s, Loss=4.37e+00, Inv=4.37e+00, For=2.07e+01, Power=6.07e-01
  [eval] val_mse=2.086e+00  (n=2997)
Epoch 00068: Time=   7.8s, Loss=4.33e+00, Inv=4.33e+00, For=2.11e+01, Power=6.04e-01
  [eval] val_mse=2.064e+00  (n=2997)
Epoch 00069: Time=   7.8s, Loss=4.30e+00, Inv=4.30e+00, For=2.15e+01, Power=6.04e-01
  [eval] val_mse=2.063e+00  (n=2997)
Epoch 00070: Time=   7.9s, Loss=4.27e+00, Inv=4.27e+00, For=2.19e+01, Power=6.03e-01
  [eval] val_mse=2.058e+00  (n=2997)
Epoch 00071: Time=   7.9s, Loss=4.24e+00, Inv=4.24e+00, For=2.23e+01, Power=6.02e-01
  [eval] val_mse=2.033e+00  (n=2997)
Epoch 00072: Time=   8.0s, Loss=4.21e+00, Inv=4.21e+00, For=2.28e+01, Power=6.00e-01
  [eval] val_mse=2.043e+00  (n=2997)
Epoch 00073: Time=   8.0s, Loss=4.19e+00, Inv=4.19e+00, For=2.32e+01, Power=5.99e-01
  [eval] val_mse=2.009e+00  (n=2997)
Epoch 00074: Time=   8.0s, Loss=4.16e+00, Inv=4.16e+00, For=2.36e+01, Power=5.98e-01
  [eval] val_mse=2.005e+00  (n=2997)
Epoch 00075: Time=   8.1s, Loss=4.13e+00, Inv=4.13e+00, For=2.40e+01, Power=5.97e-01
  [eval] val_mse=2.000e+00  (n=2997)
Epoch 00076: Time=   8.1s, Loss=4.11e+00, Inv=4.11e+00, For=2.44e+01, Power=5.97e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00077: Time=   8.1s, Loss=4.09e+00, Inv=4.09e+00, For=2.48e+01, Power=5.95e-01
  [eval] val_mse=1.995e+00  (n=2997)
Epoch 00078: Time=   8.2s, Loss=4.07e+00, Inv=4.07e+00, For=2.52e+01, Power=5.94e-01
  [eval] val_mse=1.980e+00  (n=2997)
Epoch 00079: Time=   8.2s, Loss=4.05e+00, Inv=4.05e+00, For=2.56e+01, Power=5.94e-01
  [eval] val_mse=1.982e+00  (n=2997)
Epoch 00080: Time=   8.2s, Loss=4.03e+00, Inv=4.03e+00, For=2.61e+01, Power=5.94e-01
  [eval] val_mse=1.974e+00  (n=2997)
Epoch 00081: Time=   8.3s, Loss=4.01e+00, Inv=4.01e+00, For=2.65e+01, Power=5.93e-01
  [eval] val_mse=1.964e+00  (n=2997)
Epoch 00082: Time=   8.3s, Loss=3.99e+00, Inv=3.99e+00, For=2.68e+01, Power=5.93e-01
  [eval] val_mse=1.959e+00  (n=2997)
Epoch 00083: Time=   8.4s, Loss=3.98e+00, Inv=3.98e+00, For=2.73e+01, Power=5.92e-01
  [eval] val_mse=1.944e+00  (n=2997)
Epoch 00084: Time=   8.4s, Loss=3.97e+00, Inv=3.97e+00, For=2.77e+01, Power=5.92e-01
  [eval] val_mse=1.950e+00  (n=2997)
Epoch 00085: Time=   8.4s, Loss=3.95e+00, Inv=3.95e+00, For=2.81e+01, Power=5.91e-01
  [eval] val_mse=1.938e+00  (n=2997)
Epoch 00086: Time=   8.5s, Loss=3.93e+00, Inv=3.93e+00, For=2.86e+01, Power=5.91e-01
  [eval] val_mse=1.941e+00  (n=2997)
Epoch 00087: Time=   8.5s, Loss=3.92e+00, Inv=3.92e+00, For=2.90e+01, Power=5.90e-01
  [eval] val_mse=1.935e+00  (n=2997)
Epoch 00088: Time=   8.5s, Loss=3.90e+00, Inv=3.90e+00, For=2.94e+01, Power=5.90e-01
  [eval] val_mse=1.936e+00  (n=2997)
Epoch 00089: Time=   8.6s, Loss=3.89e+00, Inv=3.89e+00, For=2.98e+01, Power=5.90e-01
  [eval] val_mse=1.935e+00  (n=2997)
Epoch 00090: Time=   8.6s, Loss=3.88e+00, Inv=3.88e+00, For=3.03e+01, Power=5.89e-01
  [eval] val_mse=1.935e+00  (n=2997)
Epoch 00091: Time=   8.6s, Loss=3.87e+00, Inv=3.87e+00, For=3.06e+01, Power=5.88e-01
  [eval] val_mse=1.930e+00  (n=2997)
Epoch 00092: Time=   8.7s, Loss=3.85e+00, Inv=3.85e+00, For=3.11e+01, Power=5.88e-01
  [eval] val_mse=1.940e+00  (n=2997)
Epoch 00093: Time=   8.7s, Loss=3.85e+00, Inv=3.85e+00, For=3.16e+01, Power=5.89e-01
  [eval] val_mse=1.925e+00  (n=2997)
Epoch 00094: Time=   8.8s, Loss=3.83e+00, Inv=3.83e+00, For=3.21e+01, Power=5.89e-01
  [eval] val_mse=1.924e+00  (n=2997)
Epoch 00095: Time=   8.8s, Loss=3.82e+00, Inv=3.82e+00, For=3.23e+01, Power=5.87e-01
  [eval] val_mse=1.927e+00  (n=2997)
Epoch 00096: Time=   8.8s, Loss=3.81e+00, Inv=3.81e+00, For=3.29e+01, Power=5.88e-01
  [eval] val_mse=1.927e+00  (n=2997)
Epoch 00097: Time=   8.9s, Loss=3.80e+00, Inv=3.80e+00, For=3.34e+01, Power=5.87e-01
  [eval] val_mse=1.922e+00  (n=2997)
Epoch 00098: Time=   8.9s, Loss=3.79e+00, Inv=3.79e+00, For=3.36e+01, Power=5.88e-01
  [eval] val_mse=1.929e+00  (n=2997)
Epoch 00099: Time=   8.9s, Loss=3.78e+00, Inv=3.78e+00, For=3.41e+01, Power=5.87e-01
  [eval] val_mse=1.917e+00  (n=2997)
Epoch 00100: Time=   9.0s, Loss=3.77e+00, Inv=3.77e+00, For=3.46e+01, Power=5.86e-01
  [eval] val_mse=1.927e+00  (n=2997)
Epoch 00101: Time=   9.0s, Loss=3.76e+00, Inv=3.76e+00, For=3.50e+01, Power=5.87e-01
  [eval] val_mse=1.936e+00  (n=2997)
Epoch 00102: Time=   9.0s, Loss=3.75e+00, Inv=3.75e+00, For=3.54e+01, Power=5.86e-01
  [eval] val_mse=1.932e+00  (n=2997)
Epoch 00103: Time=   9.1s, Loss=3.74e+00, Inv=3.74e+00, For=3.59e+01, Power=5.85e-01
  [eval] val_mse=1.931e+00  (n=2997)
Epoch 00104: Time=   9.1s, Loss=3.73e+00, Inv=3.73e+00, For=3.63e+01, Power=5.85e-01
  [eval] val_mse=1.933e+00  (n=2997)
Epoch 00105: Time=   9.1s, Loss=3.72e+00, Inv=3.72e+00, For=3.67e+01, Power=5.86e-01
  [eval] val_mse=1.915e+00  (n=2997)
Epoch 00106: Time=   9.2s, Loss=3.71e+00, Inv=3.71e+00, For=3.72e+01, Power=5.86e-01
  [eval] val_mse=1.938e+00  (n=2997)
Epoch 00107: Time=   9.2s, Loss=3.70e+00, Inv=3.70e+00, For=3.76e+01, Power=5.85e-01
  [eval] val_mse=1.938e+00  (n=2997)
Epoch 00108: Time=   9.2s, Loss=3.70e+00, Inv=3.70e+00, For=3.81e+01, Power=5.86e-01
  [eval] val_mse=1.942e+00  (n=2997)
Epoch 00109: Time=   9.3s, Loss=3.69e+00, Inv=3.69e+00, For=3.86e+01, Power=5.85e-01
  [eval] val_mse=1.950e+00  (n=2997)
Epoch 00110: Time=   9.3s, Loss=3.69e+00, Inv=3.69e+00, For=3.88e+01, Power=5.86e-01
  [eval] val_mse=1.939e+00  (n=2997)
Epoch 00111: Time=   9.4s, Loss=3.67e+00, Inv=3.67e+00, For=3.94e+01, Power=5.85e-01
  [eval] val_mse=1.947e+00  (n=2997)
Epoch 00112: Time=   9.4s, Loss=3.67e+00, Inv=3.67e+00, For=3.98e+01, Power=5.85e-01
  [eval] val_mse=1.948e+00  (n=2997)
Epoch 00113: Time=   9.4s, Loss=3.66e+00, Inv=3.66e+00, For=4.02e+01, Power=5.85e-01
  [eval] val_mse=1.955e+00  (n=2997)
Epoch 00114: Time=   9.5s, Loss=3.66e+00, Inv=3.66e+00, For=4.06e+01, Power=5.85e-01
  [eval] val_mse=1.965e+00  (n=2997)
Epoch 00115: Time=   9.5s, Loss=3.65e+00, Inv=3.65e+00, For=4.11e+01, Power=5.86e-01
  [eval] val_mse=1.965e+00  (n=2997)
  [early_stop] stop at epoch=115 (best_epoch=105, best_val_mse=1.915e+00)
Saved DeLaN checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Saved training history: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__train_history.csv

################################################
Evaluating DeLaN | run=UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2
  [val] Torque RMSE = 5.649e-01
Torque MSE  = 1.228e-01
Torque RMSE = 3.504e-01
Per-joint MSE : 1.702e-01 2.795e-01 1.353e-01 5.895e-02 4.495e-02 4.785e-02
Per-joint RMSE: 4.126e-01 5.286e-01 3.678e-01 2.428e-01 2.120e-01 2.187e-01
Comp Time per Sample = 2.096e-04s / 4772.0Hz
Saved metrics TXT: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics_test.txt
Saved metrics JSON: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s4_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/metrics.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/delan_best_fold_plots.py --summary_jsonl /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/shared/evaluation/summary_delan_best_runs_best5x10L0_20260130_164430.jsonl --out_dir /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-8w5hxnm1 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
[info] summary_jsonl=/workspace/shared/evaluation/summary_delan_best_runs_best5x10L0_20260130_164430.jsonl rows=50
[info] out_dir=/workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds MPLCONFIGDIR=/tmp/matplotlib-8w5hxnm1
[info] groups=10
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_128__d0.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_128__d1.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256__d0.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256__d1.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256_d3__d0.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256_d3__d1.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256_lr5e5__d0.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256_lr5e5__d1.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256_wd1e4__d0.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/folds/delan_best_fold_K84__hp_lutter_like_256_wd1e4__d1.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/delan_best_hp_curves.py --summary_jsonl /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/shared/evaluation/summary_delan_best_runs_best5x10L0_20260130_164430.jsonl --out_dir /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/curves --hp_presets lutter_like_128,lutter_like_256 '
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-ttgtvdvp because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
[info] summary_jsonl=/workspace/shared/evaluation/summary_delan_best_runs_best5x10L0_20260130_164430.jsonl rows=50
[info] out_dir=/workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/curves MPLCONFIGDIR=/tmp/matplotlib-ttgtvdvp
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/curves/delan_best_train_val_curves_by_hp.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/delan_best_hyper_scatter.py --summary_jsonl /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/shared/evaluation/summary_delan_best_hypers_best5x10L0_20260130_164430.jsonl --out_dir /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/hypers'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-r333_ovx because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
[info] summary_jsonl=/workspace/shared/evaluation/summary_delan_best_hypers_best5x10L0_20260130_164430.jsonl rows=5 run_tag=n/a
[info] out_dir=/workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/hypers MPLCONFIGDIR=/tmp/matplotlib-r333_ovx
[info] points_a=5 points_b=5
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/hypers/scatter_accuracy_vs_stability.png
[info] saved /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/hypers/scatter_val_vs_test.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/delan_best_torque_rmse_aggregate.py --summary_jsonl /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/shared/evaluation/summary_delan_best_runs_best5x10L0_20260130_164430.jsonl --out_dir /workspace/shared/evaluation/delan_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_164430/torque --bins 200 --split test --hp_presets lutter_like_128,lutter_like_256 '
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-5cl_5zan because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.


MASTER LOG: /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/shared/logs/delan_best_UR3_Load0_5x10^4_under_best5x10L0_20260130_164430/delan_best_UR3_Load0_5x10^4_under_best5x10L0_20260130_164430.log
Done.

[2026-01-30 17:02:00] END best_delan (5x10^4_under): exit_code=0
[2026-01-30 17:02:00] LSTM handshake paths (5x10^4_under):
[2026-01-30 17:02:00]   LSTM_BEST_DELAN_HYPERS_JSONL=/workspace/shared/evaluation/summary_delan_best_hypers_best5x10L0.jsonl
[2026-01-30 17:02:00]   LSTM_BEST_DELAN_FOLDS_JSONL=/workspace/shared/evaluation/summary_delan_best_folds_best5x10L0.jsonl
[2026-01-30 17:02:00]   LSTM_BEST_DELAN_MODEL_JSON=/workspace/shared/evaluation/delan_best_model_best5x10L0.json
[2026-01-30 17:02:00] START best_lstm (5x10^4_under): /home/robat/.venv/ape_sweep/bin/python3 /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/services/sweep/scripts/run_sweep_lstm.py
docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 0 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/export_delan_residuals_jax.py --npz_in /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz --ckpt /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax --out /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz'
Loading dataset: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset/delan_UR3_Load0_5x10^4_under_K84_seed0_dataset.npz
Loading checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Detected n_dof=6 (seed=1)
2026-01-30 16:02:03.417380: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.

Exporting split=train: 19 trajectories
  done 19/19

Exporting split=test: 5 trajectories
  done 5/5

Saved residual trajectory dataset: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Keys: ['test_labels', 'test_q', 'test_qd', 'test_qdd', 'test_r_tau', 'test_t', 'test_tau', 'test_tau_hat', 'train_labels', 'train_q', 'train_qd', 'train_qdd', 'train_r_tau', 'train_t', 'train_tau', 'train_tau_hat']
Saved export JSON: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 50 --features full'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 50
  feature_mode= full
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=50, n_dof=6, feature_dim=24
X_train: (34566, 50, 24)  Y_train: (34566, 6)
X_test : (5255, 50, 24)  Y_test : (5255, 6)
feature_mode=full

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:02:12.085681: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:02:12.316126: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-0ew_ta6a because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 24
 dout = 6
  X_train = (34566, 50, 24), Y_train = (34566, 6)
  X_test  = (5255, 50, 24),  Y_test  = (5255, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:02:14.307016: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.340681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.342029: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.343717: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.344711: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.347436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.434555: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.435541: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.436389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:02:14.437389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8964 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:02:15.585524: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
487/487 - 3s - 6ms/step - loss: 0.0966 - val_loss: 0.1397
Epoch 2/120
487/487 - 1s - 3ms/step - loss: 0.0485 - val_loss: 0.1445
Epoch 3/120
487/487 - 1s - 3ms/step - loss: 0.0403 - val_loss: 0.1374
Epoch 4/120
487/487 - 1s - 3ms/step - loss: 0.0365 - val_loss: 0.1651
Epoch 5/120
487/487 - 1s - 3ms/step - loss: 0.0335 - val_loss: 0.1852
Epoch 6/120
487/487 - 1s - 3ms/step - loss: 0.0329 - val_loss: 0.1541
Epoch 7/120
487/487 - 1s - 3ms/step - loss: 0.0310 - val_loss: 0.1708
Epoch 8/120
487/487 - 1s - 3ms/step - loss: 0.0303 - val_loss: 0.1701
Epoch 9/120
487/487 - 1s - 3ms/step - loss: 0.0290 - val_loss: 0.1637
Epoch 10/120
487/487 - 1s - 3ms/step - loss: 0.0289 - val_loss: 0.1755
Epoch 11/120
487/487 - 1s - 3ms/step - loss: 0.0279 - val_loss: 0.1575
Epoch 12/120
487/487 - 1s - 3ms/step - loss: 0.0272 - val_loss: 0.1913
Epoch 13/120
487/487 - 1s - 3ms/step - loss: 0.0266 - val_loss: 0.1706
Epoch 14/120
487/487 - 1s - 3ms/step - loss: 0.0265 - val_loss: 0.1651
Epoch 15/120
487/487 - 1s - 3ms/step - loss: 0.0258 - val_loss: 0.1715
Epoch 16/120
487/487 - 1s - 3ms/step - loss: 0.0256 - val_loss: 0.1808
Epoch 17/120
487/487 - 1s - 3ms/step - loss: 0.0256 - val_loss: 0.1864
Epoch 18/120
487/487 - 1s - 3ms/step - loss: 0.0251 - val_loss: 0.1924
Epoch 19/120
487/487 - 1s - 3ms/step - loss: 0.0246 - val_loss: 0.1808
Epoch 20/120
487/487 - 1s - 3ms/step - loss: 0.0244 - val_loss: 0.1831
Epoch 21/120
487/487 - 1s - 3ms/step - loss: 0.0241 - val_loss: 0.1765
Epoch 22/120
487/487 - 1s - 3ms/step - loss: 0.0236 - val_loss: 0.1721
Epoch 23/120
487/487 - 1s - 3ms/step - loss: 0.0234 - val_loss: 0.1709
Epoch 24/120
487/487 - 1s - 3ms/step - loss: 0.0235 - val_loss: 0.1666
Epoch 25/120
487/487 - 1s - 3ms/step - loss: 0.0234 - val_loss: 0.1825
Epoch 26/120
487/487 - 1s - 3ms/step - loss: 0.0229 - val_loss: 0.1817
Epoch 27/120
487/487 - 1s - 3ms/step - loss: 0.0235 - val_loss: 0.1676
Epoch 28/120
487/487 - 1s - 3ms/step - loss: 0.0227 - val_loss: 0.1791
Epoch 29/120
487/487 - 1s - 3ms/step - loss: 0.0222 - val_loss: 0.1665
Epoch 30/120
487/487 - 1s - 3ms/step - loss: 0.0221 - val_loss: 0.1887
Epoch 31/120
487/487 - 1s - 3ms/step - loss: 0.0221 - val_loss: 0.1766
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2553
Per-joint RMSE: 0.1724 0.5019 0.1789 0.1724 0.2059 0.0724
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2 --H 50 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:03:02.262907: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:03:02.288834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-bqja6rkx because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:03:03.398261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.403328: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.404210: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.405850: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.406718: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.407456: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.488399: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.489330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.490081: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:03.490817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9131 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:03:03.797373: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.232794e-01  RMSE=3.511117e-01
  per-joint RMSE: 0.2735 0.6770 0.2133 0.1655 0.3373 0.1411
Residual LSTM:  MSE=6.358586e-02      RMSE=2.521624e-01
  per-joint RMSE: 0.1941 0.4721 0.2031 0.1687 0.2061 0.0933
Combined torque MSE=6.358586e-02     RMSE=2.521624e-01
  per-joint RMSE: 0.1941 0.4721 0.2031 0.1687 0.2061 0.0933
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:03:05.671371: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:03:05.697049: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-5e35pi30 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 24
 dout = 6
  X_train = (34566, 50, 24), Y_train = (34566, 6)
  X_test  = (5255, 50, 24),  Y_test  = (5255, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:03:07.025056: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.029674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.030517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.032033: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.032813: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.033549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.107940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.108847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.109588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:03:07.110407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9124 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:03:08.168306: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
487/487 - 3s - 6ms/step - loss: 0.0927 - val_loss: 0.1321
Epoch 2/120
487/487 - 1s - 3ms/step - loss: 0.0507 - val_loss: 0.1605
Epoch 3/120
487/487 - 1s - 3ms/step - loss: 0.0402 - val_loss: 0.1796
Epoch 4/120
487/487 - 1s - 3ms/step - loss: 0.0366 - val_loss: 0.1667
Epoch 5/120
487/487 - 1s - 3ms/step - loss: 0.0362 - val_loss: 0.1983
Epoch 6/120
487/487 - 1s - 3ms/step - loss: 0.0320 - val_loss: 0.1972
Epoch 7/120
487/487 - 1s - 3ms/step - loss: 0.0305 - val_loss: 0.2101
Epoch 8/120
487/487 - 1s - 3ms/step - loss: 0.0298 - val_loss: 0.2083
Epoch 9/120
487/487 - 1s - 3ms/step - loss: 0.0290 - val_loss: 0.1842
Epoch 10/120
487/487 - 1s - 3ms/step - loss: 0.0284 - val_loss: 0.1788
Epoch 11/120
487/487 - 1s - 3ms/step - loss: 0.0275 - val_loss: 0.1730
Epoch 12/120
487/487 - 1s - 3ms/step - loss: 0.0276 - val_loss: 0.1707
Epoch 13/120
487/487 - 1s - 3ms/step - loss: 0.0269 - val_loss: 0.1664
Epoch 14/120
487/487 - 1s - 3ms/step - loss: 0.0264 - val_loss: 0.1530
Epoch 15/120
487/487 - 1s - 3ms/step - loss: 0.0259 - val_loss: 0.1606
Epoch 16/120
487/487 - 1s - 3ms/step - loss: 0.0261 - val_loss: 0.1638
Epoch 17/120
487/487 - 1s - 3ms/step - loss: 0.0251 - val_loss: 0.1525
Epoch 18/120
487/487 - 1s - 3ms/step - loss: 0.0248 - val_loss: 0.1543
Epoch 19/120
487/487 - 1s - 3ms/step - loss: 0.0247 - val_loss: 0.1358
Epoch 20/120
487/487 - 1s - 3ms/step - loss: 0.0246 - val_loss: 0.1286
Epoch 21/120
487/487 - 1s - 3ms/step - loss: 0.0242 - val_loss: 0.1381
Epoch 22/120
487/487 - 1s - 3ms/step - loss: 0.0235 - val_loss: 0.1317
Epoch 23/120
487/487 - 1s - 3ms/step - loss: 0.0237 - val_loss: 0.1513
Epoch 24/120
487/487 - 1s - 3ms/step - loss: 0.0236 - val_loss: 0.1536
Epoch 25/120
487/487 - 1s - 3ms/step - loss: 0.0231 - val_loss: 0.1332
Epoch 26/120
487/487 - 1s - 3ms/step - loss: 0.0228 - val_loss: 0.1353
Epoch 27/120
487/487 - 1s - 3ms/step - loss: 0.0226 - val_loss: 0.1377
Epoch 28/120
487/487 - 1s - 3ms/step - loss: 0.0225 - val_loss: 0.1414
Epoch 29/120
487/487 - 1s - 3ms/step - loss: 0.0226 - val_loss: 0.1388
Epoch 30/120
487/487 - 1s - 3ms/step - loss: 0.0225 - val_loss: 0.1543
Epoch 31/120
487/487 - 1s - 3ms/step - loss: 0.0220 - val_loss: 0.1527
Epoch 32/120
487/487 - 1s - 3ms/step - loss: 0.0219 - val_loss: 0.1517
Epoch 33/120
487/487 - 1s - 3ms/step - loss: 0.0216 - val_loss: 0.1447
Epoch 34/120
487/487 - 1s - 3ms/step - loss: 0.0215 - val_loss: 0.1497
Epoch 35/120
487/487 - 1s - 3ms/step - loss: 0.0215 - val_loss: 0.1522
Epoch 36/120
487/487 - 1s - 3ms/step - loss: 0.0213 - val_loss: 0.1476
Epoch 37/120
487/487 - 1s - 3ms/step - loss: 0.0237 - val_loss: 0.1537
Epoch 38/120
487/487 - 1s - 3ms/step - loss: 0.0215 - val_loss: 0.1393
Epoch 39/120
487/487 - 1s - 3ms/step - loss: 0.0209 - val_loss: 0.1529
Epoch 40/120
487/487 - 1s - 3ms/step - loss: 0.0208 - val_loss: 0.1593
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2487
Per-joint RMSE: 0.2019 0.4653 0.2001 0.1562 0.2089 0.0762
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2 --H 50 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:04:07.359749: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:04:07.385810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-6ey_h9bn because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:04:08.386611: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.395067: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.395870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.397896: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.398690: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.399432: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.479693: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.480530: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.481283: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:08.482012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:04:08.788241: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.232794e-01  RMSE=3.511117e-01
  per-joint RMSE: 0.2735 0.6770 0.2133 0.1655 0.3373 0.1411
Residual LSTM:  MSE=6.185230e-02      RMSE=2.487012e-01
  per-joint RMSE: 0.2019 0.4653 0.2001 0.1562 0.2089 0.0763
Combined torque MSE=6.185230e-02     RMSE=2.487012e-01
  per-joint RMSE: 0.2019 0.4653 0.2001 0.1562 0.2089 0.0763
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 100 --features full'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 100
  feature_mode= full
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=100, n_dof=6, feature_dim=24
X_train: (33616, 100, 24)  Y_train: (33616, 6)
X_test : (5005, 100, 24)  Y_test : (5005, 6)
feature_mode=full

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:04:11.285322: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:04:11.310599: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-2_txxz1q because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 24
 dout = 6
  X_train = (33616, 100, 24), Y_train = (33616, 6)
  X_test  = (5005, 100, 24),  Y_test  = (5005, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:04:12.901970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.907042: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.907972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.909774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.910688: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.911630: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.998354: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:12.999350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:13.000162: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:04:13.000952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9185 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:04:14.148460: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
473/473 - 3s - 7ms/step - loss: 0.0972 - val_loss: 0.1613
Epoch 2/120
473/473 - 2s - 4ms/step - loss: 0.0469 - val_loss: 0.1536
Epoch 3/120
473/473 - 2s - 4ms/step - loss: 0.0407 - val_loss: 0.1586
Epoch 4/120
473/473 - 2s - 4ms/step - loss: 0.0351 - val_loss: 0.1479
Epoch 5/120
473/473 - 2s - 4ms/step - loss: 0.0332 - val_loss: 0.1425
Epoch 6/120
473/473 - 2s - 4ms/step - loss: 0.0320 - val_loss: 0.1564
Epoch 7/120
473/473 - 2s - 4ms/step - loss: 0.0302 - val_loss: 0.1512
Epoch 8/120
473/473 - 2s - 4ms/step - loss: 0.0294 - val_loss: 0.1620
Epoch 9/120
473/473 - 2s - 4ms/step - loss: 0.0284 - val_loss: 0.1673
Epoch 10/120
473/473 - 2s - 4ms/step - loss: 0.0281 - val_loss: 0.1559
Epoch 11/120
473/473 - 2s - 4ms/step - loss: 0.0274 - val_loss: 0.1481
Epoch 12/120
473/473 - 2s - 4ms/step - loss: 0.0271 - val_loss: 0.1553
Epoch 13/120
473/473 - 2s - 4ms/step - loss: 0.0267 - val_loss: 0.1570
Epoch 14/120
473/473 - 2s - 4ms/step - loss: 0.0263 - val_loss: 0.1583
Epoch 15/120
473/473 - 2s - 4ms/step - loss: 0.0256 - val_loss: 0.1563
Epoch 16/120
473/473 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.1602
Epoch 17/120
473/473 - 2s - 4ms/step - loss: 0.0247 - val_loss: 0.1567
Epoch 18/120
473/473 - 2s - 4ms/step - loss: 0.0244 - val_loss: 0.1613
Epoch 19/120
473/473 - 2s - 4ms/step - loss: 0.0244 - val_loss: 0.1555
Epoch 20/120
473/473 - 2s - 4ms/step - loss: 0.0243 - val_loss: 0.1477
Epoch 21/120
473/473 - 2s - 4ms/step - loss: 0.0235 - val_loss: 0.1619
Epoch 22/120
473/473 - 2s - 4ms/step - loss: 0.0234 - val_loss: 0.1738
Epoch 23/120
473/473 - 2s - 4ms/step - loss: 0.0236 - val_loss: 0.1620
Epoch 24/120
473/473 - 2s - 4ms/step - loss: 0.0232 - val_loss: 0.1725
Epoch 25/120
473/473 - 2s - 4ms/step - loss: 0.0228 - val_loss: 0.1638
Epoch 26/120
473/473 - 2s - 4ms/step - loss: 0.0226 - val_loss: 0.1623
Epoch 27/120
473/473 - 2s - 4ms/step - loss: 0.0223 - val_loss: 0.1750
Epoch 28/120
473/473 - 2s - 4ms/step - loss: 0.0222 - val_loss: 0.1754
Epoch 29/120
473/473 - 2s - 4ms/step - loss: 0.0221 - val_loss: 0.1732
Epoch 30/120
473/473 - 2s - 4ms/step - loss: 0.0219 - val_loss: 0.1933
Epoch 31/120
473/473 - 2s - 4ms/step - loss: 0.0217 - val_loss: 0.1785
Epoch 32/120
473/473 - 2s - 4ms/step - loss: 0.0217 - val_loss: 0.1719
Epoch 33/120
473/473 - 2s - 4ms/step - loss: 0.0213 - val_loss: 0.1673
Epoch 34/120
473/473 - 2s - 4ms/step - loss: 0.0213 - val_loss: 0.1813
Epoch 35/120
473/473 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1650
Epoch 36/120
473/473 - 2s - 4ms/step - loss: 0.0212 - val_loss: 0.1837
Epoch 37/120
473/473 - 2s - 4ms/step - loss: 0.0209 - val_loss: 0.1679
Epoch 38/120
473/473 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1705
Epoch 39/120
473/473 - 2s - 4ms/step - loss: 0.0207 - val_loss: 0.1715
Epoch 40/120
473/473 - 2s - 4ms/step - loss: 0.0205 - val_loss: 0.1671
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2736
Per-joint RMSE: 0.2023 0.5354 0.1997 0.1816 0.2034 0.0848
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2 --H 100 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:05:40.240349: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:05:40.266453: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-nm69swhq because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:05:41.260462: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.265268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.266193: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.267792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.268637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.269421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.348028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.348955: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.349704: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:41.350440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9206 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:05:41.652735: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.258905e-01  RMSE=3.548106e-01
  per-joint RMSE: 0.2690 0.6907 0.2073 0.1624 0.3421 0.1398
Residual LSTM:  MSE=7.447244e-02      RMSE=2.728964e-01
  per-joint RMSE: 0.2157 0.5079 0.2209 0.1907 0.2165 0.1016
Combined torque MSE=7.447244e-02     RMSE=2.728964e-01
  per-joint RMSE: 0.2157 0.5079 0.2209 0.1907 0.2165 0.1016
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:05:43.567998: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:05:43.593203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-1sy7o022 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_full__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 24
 dout = 6
  X_train = (33616, 100, 24), Y_train = (33616, 6)
  X_test  = (5005, 100, 24),  Y_test  = (5005, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:05:45.195192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.200128: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.200997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.202776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.203567: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.204307: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.286230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.287155: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.287949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:05:45.288744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9201 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:05:46.422254: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
473/473 - 3s - 7ms/step - loss: 0.0959 - val_loss: 0.1684
Epoch 2/120
473/473 - 2s - 4ms/step - loss: 0.0479 - val_loss: 0.1748
Epoch 3/120
473/473 - 2s - 4ms/step - loss: 0.0396 - val_loss: 0.1835
Epoch 4/120
473/473 - 2s - 4ms/step - loss: 0.0358 - val_loss: 0.1759
Epoch 5/120
473/473 - 2s - 4ms/step - loss: 0.0337 - val_loss: 0.1707
Epoch 6/120
473/473 - 2s - 4ms/step - loss: 0.0324 - val_loss: 0.1619
Epoch 7/120
473/473 - 2s - 4ms/step - loss: 0.0309 - val_loss: 0.1774
Epoch 8/120
473/473 - 2s - 4ms/step - loss: 0.0295 - val_loss: 0.1625
Epoch 9/120
473/473 - 2s - 4ms/step - loss: 0.0286 - val_loss: 0.1833
Epoch 10/120
473/473 - 2s - 4ms/step - loss: 0.0278 - val_loss: 0.1709
Epoch 11/120
473/473 - 2s - 4ms/step - loss: 0.0284 - val_loss: 0.1449
Epoch 12/120
473/473 - 2s - 4ms/step - loss: 0.0276 - val_loss: 0.1439
Epoch 13/120
473/473 - 2s - 4ms/step - loss: 0.0264 - val_loss: 0.1492
Epoch 14/120
473/473 - 2s - 4ms/step - loss: 0.0256 - val_loss: 0.1513
Epoch 15/120
473/473 - 2s - 4ms/step - loss: 0.0257 - val_loss: 0.1500
Epoch 16/120
473/473 - 2s - 4ms/step - loss: 0.0252 - val_loss: 0.1436
Epoch 17/120
473/473 - 2s - 4ms/step - loss: 0.0250 - val_loss: 0.1484
Epoch 18/120
473/473 - 2s - 4ms/step - loss: 0.0249 - val_loss: 0.1441
Epoch 19/120
473/473 - 2s - 4ms/step - loss: 0.0242 - val_loss: 0.1539
Epoch 20/120
473/473 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.1350
Epoch 21/120
473/473 - 2s - 4ms/step - loss: 0.0238 - val_loss: 0.1652
Epoch 22/120
473/473 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.1437
Epoch 23/120
473/473 - 2s - 4ms/step - loss: 0.0233 - val_loss: 0.1471
Epoch 24/120
473/473 - 2s - 4ms/step - loss: 0.0236 - val_loss: 0.1471
Epoch 25/120
473/473 - 2s - 4ms/step - loss: 0.0230 - val_loss: 0.1381
Epoch 26/120
473/473 - 2s - 4ms/step - loss: 0.0226 - val_loss: 0.1431
Epoch 27/120
473/473 - 2s - 4ms/step - loss: 0.0226 - val_loss: 0.1420
Epoch 28/120
473/473 - 2s - 4ms/step - loss: 0.0221 - val_loss: 0.1473
Epoch 29/120
473/473 - 2s - 4ms/step - loss: 0.0222 - val_loss: 0.1593
Epoch 30/120
473/473 - 2s - 4ms/step - loss: 0.0219 - val_loss: 0.1609
Epoch 31/120
473/473 - 2s - 4ms/step - loss: 0.0219 - val_loss: 0.1708
Epoch 32/120
473/473 - 2s - 4ms/step - loss: 0.0217 - val_loss: 0.1877
Epoch 33/120
473/473 - 2s - 4ms/step - loss: 0.0218 - val_loss: 0.1858
Epoch 34/120
473/473 - 2s - 4ms/step - loss: 0.0223 - val_loss: 0.1684
Epoch 35/120
473/473 - 2s - 4ms/step - loss: 0.0213 - val_loss: 0.1854
Epoch 36/120
473/473 - 2s - 4ms/step - loss: 0.0214 - val_loss: 0.1780
Epoch 37/120
473/473 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1736
Epoch 38/120
473/473 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1715
Epoch 39/120
473/473 - 2s - 4ms/step - loss: 0.0209 - val_loss: 0.1557
Epoch 40/120
473/473 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1560
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2531
Per-joint RMSE: 0.1879 0.4965 0.1707 0.1513 0.2112 0.0766
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2 --H 100 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:07:12.185513: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:07:12.211485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-xgw1s4cp because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:07:13.208295: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.213183: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.214167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.215762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.216625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.217361: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.291445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.292293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.293125: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:13.293858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9210 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:07:13.599393: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.258905e-01  RMSE=3.548106e-01
  per-joint RMSE: 0.2690 0.6907 0.2073 0.1624 0.3421 0.1398
Residual LSTM:  MSE=6.404889e-02      RMSE=2.530788e-01
  per-joint RMSE: 0.1879 0.4965 0.1707 0.1513 0.2112 0.0766
Combined torque MSE=6.404889e-02     RMSE=2.530788e-01
  per-joint RMSE: 0.1879 0.4965 0.1707 0.1513 0.2112 0.0766
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 50 --features state'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 50
  feature_mode= state
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=50, n_dof=6, feature_dim=18
X_train: (34566, 50, 18)  Y_train: (34566, 6)
X_test : (5255, 50, 18)  Y_test : (5255, 6)
feature_mode=state

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:07:15.913434: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:07:15.938573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-v08918cp because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 18
 dout = 6
  X_train = (34566, 50, 18), Y_train = (34566, 6)
  X_test  = (5255, 50, 18),  Y_test  = (5255, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:07:17.221964: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.226600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.227395: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.228909: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.229700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.230432: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.320228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.321129: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.322119: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:07:17.322898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:07:18.317942: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
487/487 - 3s - 6ms/step - loss: 0.0964 - val_loss: 0.1542
Epoch 2/120
487/487 - 1s - 3ms/step - loss: 0.0517 - val_loss: 0.1660
Epoch 3/120
487/487 - 1s - 3ms/step - loss: 0.0418 - val_loss: 0.1805
Epoch 4/120
487/487 - 1s - 3ms/step - loss: 0.0374 - val_loss: 0.1844
Epoch 5/120
487/487 - 1s - 3ms/step - loss: 0.0346 - val_loss: 0.1833
Epoch 6/120
487/487 - 1s - 3ms/step - loss: 0.0327 - val_loss: 0.1782
Epoch 7/120
487/487 - 1s - 3ms/step - loss: 0.0326 - val_loss: 0.2050
Epoch 8/120
487/487 - 1s - 3ms/step - loss: 0.0313 - val_loss: 0.1640
Epoch 9/120
487/487 - 1s - 3ms/step - loss: 0.0297 - val_loss: 0.1701
Epoch 10/120
487/487 - 1s - 3ms/step - loss: 0.0290 - val_loss: 0.1588
Epoch 11/120
487/487 - 1s - 3ms/step - loss: 0.0290 - val_loss: 0.1561
Epoch 12/120
487/487 - 1s - 3ms/step - loss: 0.0281 - val_loss: 0.1438
Epoch 13/120
487/487 - 1s - 3ms/step - loss: 0.0271 - val_loss: 0.1652
Epoch 14/120
487/487 - 1s - 3ms/step - loss: 0.0271 - val_loss: 0.1500
Epoch 15/120
487/487 - 1s - 3ms/step - loss: 0.0268 - val_loss: 0.1426
Epoch 16/120
487/487 - 1s - 3ms/step - loss: 0.0264 - val_loss: 0.1473
Epoch 17/120
487/487 - 1s - 3ms/step - loss: 0.0259 - val_loss: 0.1403
Epoch 18/120
487/487 - 1s - 3ms/step - loss: 0.0258 - val_loss: 0.1497
Epoch 19/120
487/487 - 1s - 3ms/step - loss: 0.0255 - val_loss: 0.1406
Epoch 20/120
487/487 - 1s - 3ms/step - loss: 0.0250 - val_loss: 0.1325
Epoch 21/120
487/487 - 1s - 3ms/step - loss: 0.0251 - val_loss: 0.1504
Epoch 22/120
487/487 - 1s - 3ms/step - loss: 0.0245 - val_loss: 0.1269
Epoch 23/120
487/487 - 1s - 3ms/step - loss: 0.0242 - val_loss: 0.1228
Epoch 24/120
487/487 - 1s - 3ms/step - loss: 0.0238 - val_loss: 0.1289
Epoch 25/120
487/487 - 1s - 3ms/step - loss: 0.0239 - val_loss: 0.1235
Epoch 26/120
487/487 - 1s - 3ms/step - loss: 0.0234 - val_loss: 0.1230
Epoch 27/120
487/487 - 1s - 3ms/step - loss: 0.0235 - val_loss: 0.1290
Epoch 28/120
487/487 - 1s - 3ms/step - loss: 0.0231 - val_loss: 0.1292
Epoch 29/120
487/487 - 1s - 3ms/step - loss: 0.0251 - val_loss: 0.1198
Epoch 30/120
487/487 - 1s - 3ms/step - loss: 0.0229 - val_loss: 0.1177
Epoch 31/120
487/487 - 1s - 3ms/step - loss: 0.0227 - val_loss: 0.1310
Epoch 32/120
487/487 - 1s - 3ms/step - loss: 0.0226 - val_loss: 0.1252
Epoch 33/120
487/487 - 1s - 3ms/step - loss: 0.0225 - val_loss: 0.1302
Epoch 34/120
487/487 - 1s - 3ms/step - loss: 0.0222 - val_loss: 0.1203
Epoch 35/120
487/487 - 1s - 3ms/step - loss: 0.0221 - val_loss: 0.1295
Epoch 36/120
487/487 - 1s - 3ms/step - loss: 0.0222 - val_loss: 0.1330
Epoch 37/120
487/487 - 1s - 3ms/step - loss: 0.0221 - val_loss: 0.1285
Epoch 38/120
487/487 - 1s - 3ms/step - loss: 0.0216 - val_loss: 0.1375
Epoch 39/120
487/487 - 1s - 3ms/step - loss: 0.0216 - val_loss: 0.1250
Epoch 40/120
487/487 - 1s - 3ms/step - loss: 0.0213 - val_loss: 0.1361
Epoch 41/120
487/487 - 1s - 3ms/step - loss: 0.0214 - val_loss: 0.1389
Epoch 42/120
487/487 - 1s - 3ms/step - loss: 0.0213 - val_loss: 0.1604
Epoch 43/120
487/487 - 1s - 3ms/step - loss: 0.0210 - val_loss: 0.1372
Epoch 44/120
487/487 - 1s - 3ms/step - loss: 0.0210 - val_loss: 0.1404
Epoch 45/120
487/487 - 1s - 3ms/step - loss: 0.0208 - val_loss: 0.1395
Epoch 46/120
487/487 - 1s - 3ms/step - loss: 0.0210 - val_loss: 0.1456
Epoch 47/120
487/487 - 1s - 3ms/step - loss: 0.0206 - val_loss: 0.1447
Epoch 48/120
487/487 - 1s - 3ms/step - loss: 0.0206 - val_loss: 0.1480
Epoch 49/120
487/487 - 1s - 3ms/step - loss: 0.0206 - val_loss: 0.1392
Epoch 50/120
487/487 - 1s - 3ms/step - loss: 0.0204 - val_loss: 0.1379
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2675
Per-joint RMSE: 0.1643 0.5051 0.2060 0.1729 0.2558 0.0971
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2 --H 50 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:08:31.420595: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:08:31.447798: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-9gaogpp3 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:08:32.443566: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.448288: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.449136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.450791: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.451583: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.452319: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.533780: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.534617: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.535386: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:32.536114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:08:32.835295: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.232794e-01  RMSE=3.511117e-01
  per-joint RMSE: 0.2735 0.6770 0.2133 0.1655 0.3373 0.1411
Residual LSTM:  MSE=7.155088e-02      RMSE=2.674899e-01
  per-joint RMSE: 0.1643 0.5051 0.2060 0.1729 0.2558 0.0971
Combined torque MSE=7.155088e-02     RMSE=2.674899e-01
  per-joint RMSE: 0.1643 0.5051 0.2060 0.1729 0.2558 0.0971
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:08:34.715537: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:08:34.740727: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-u5rc9s7b because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H50__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 18
 dout = 6
  X_train = (34566, 50, 18), Y_train = (34566, 6)
  X_test  = (5255, 50, 18),  Y_test  = (5255, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:08:36.014473: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.019037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.019822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.021355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.022146: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.022893: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.093296: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.094150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.094896: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:08:36.095717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:08:37.110226: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
487/487 - 3s - 6ms/step - loss: 0.0952 - val_loss: 0.1717
Epoch 2/120
487/487 - 1s - 3ms/step - loss: 0.0512 - val_loss: 0.1975
Epoch 3/120
487/487 - 1s - 3ms/step - loss: 0.0421 - val_loss: 0.2368
Epoch 4/120
487/487 - 1s - 3ms/step - loss: 0.0382 - val_loss: 0.2374
Epoch 5/120
487/487 - 1s - 3ms/step - loss: 0.0358 - val_loss: 0.2369
Epoch 6/120
487/487 - 1s - 3ms/step - loss: 0.0334 - val_loss: 0.2219
Epoch 7/120
487/487 - 1s - 3ms/step - loss: 0.0317 - val_loss: 0.2204
Epoch 8/120
487/487 - 1s - 3ms/step - loss: 0.0310 - val_loss: 0.2225
Epoch 9/120
487/487 - 1s - 3ms/step - loss: 0.0296 - val_loss: 0.2059
Epoch 10/120
487/487 - 1s - 3ms/step - loss: 0.0288 - val_loss: 0.2140
Epoch 11/120
487/487 - 1s - 3ms/step - loss: 0.0283 - val_loss: 0.2019
Epoch 12/120
487/487 - 1s - 3ms/step - loss: 0.0278 - val_loss: 0.2033
Epoch 13/120
487/487 - 1s - 3ms/step - loss: 0.0273 - val_loss: 0.1880
Epoch 14/120
487/487 - 1s - 3ms/step - loss: 0.0268 - val_loss: 0.1802
Epoch 15/120
487/487 - 1s - 3ms/step - loss: 0.0270 - val_loss: 0.1739
Epoch 16/120
487/487 - 1s - 3ms/step - loss: 0.0263 - val_loss: 0.1788
Epoch 17/120
487/487 - 1s - 3ms/step - loss: 0.0258 - val_loss: 0.1844
Epoch 18/120
487/487 - 1s - 3ms/step - loss: 0.0252 - val_loss: 0.1718
Epoch 19/120
487/487 - 1s - 3ms/step - loss: 0.0250 - val_loss: 0.1691
Epoch 20/120
487/487 - 1s - 3ms/step - loss: 0.0250 - val_loss: 0.1858
Epoch 21/120
487/487 - 1s - 3ms/step - loss: 0.0244 - val_loss: 0.1800
Epoch 22/120
487/487 - 1s - 3ms/step - loss: 0.0245 - val_loss: 0.1783
Epoch 23/120
487/487 - 1s - 3ms/step - loss: 0.0240 - val_loss: 0.2023
Epoch 24/120
487/487 - 1s - 3ms/step - loss: 0.0240 - val_loss: 0.1849
Epoch 25/120
487/487 - 1s - 3ms/step - loss: 0.0236 - val_loss: 0.1903
Epoch 26/120
487/487 - 1s - 3ms/step - loss: 0.0234 - val_loss: 0.2038
Epoch 27/120
487/487 - 1s - 3ms/step - loss: 0.0232 - val_loss: 0.2017
Epoch 28/120
487/487 - 1s - 3ms/step - loss: 0.0233 - val_loss: 0.1984
Epoch 29/120
487/487 - 1s - 3ms/step - loss: 0.0228 - val_loss: 0.2043
Epoch 30/120
487/487 - 1s - 3ms/step - loss: 0.0227 - val_loss: 0.2105
Epoch 31/120
487/487 - 1s - 3ms/step - loss: 0.0226 - val_loss: 0.2134
Epoch 32/120
487/487 - 1s - 3ms/step - loss: 0.0222 - val_loss: 0.2252
Epoch 33/120
487/487 - 1s - 3ms/step - loss: 0.0222 - val_loss: 0.2375
Epoch 34/120
487/487 - 1s - 3ms/step - loss: 0.0221 - val_loss: 0.2208
Epoch 35/120
487/487 - 1s - 3ms/step - loss: 0.0219 - val_loss: 0.2144
Epoch 36/120
487/487 - 1s - 3ms/step - loss: 0.0217 - val_loss: 0.2319
Epoch 37/120
487/487 - 1s - 3ms/step - loss: 0.0219 - val_loss: 0.2088
Epoch 38/120
487/487 - 1s - 3ms/step - loss: 0.0225 - val_loss: 0.2507
Epoch 39/120
487/487 - 1s - 3ms/step - loss: 0.0221 - val_loss: 0.2132
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2754
Per-joint RMSE: 0.1842 0.5558 0.1434 0.1632 0.2390 0.0892
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2 --H 50 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:09:34.839639: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:09:34.865219: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-9d4p3dea because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:09:35.829846: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.834435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.835223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.836878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.837658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.838395: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.914728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.915558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.916300: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:35.917028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:09:36.218199: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.232794e-01  RMSE=3.511117e-01
  per-joint RMSE: 0.2735 0.6770 0.2133 0.1655 0.3373 0.1411
Residual LSTM:  MSE=7.584986e-02      RMSE=2.754085e-01
  per-joint RMSE: 0.1842 0.5558 0.1434 0.1632 0.2390 0.0892
Combined torque MSE=7.584987e-02     RMSE=2.754085e-01
  per-joint RMSE: 0.1842 0.5558 0.1434 0.1632 0.2390 0.0892
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 100 --features state'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 100
  feature_mode= state
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=100, n_dof=6, feature_dim=18
X_train: (33616, 100, 18)  Y_train: (33616, 6)
X_test : (5005, 100, 18)  Y_test : (5005, 6)
feature_mode=state

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:09:38.624936: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:09:38.652327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-jzdz6hbx because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 18
 dout = 6
  X_train = (33616, 100, 18), Y_train = (33616, 6)
  X_test  = (5005, 100, 18),  Y_test  = (5005, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:09:40.158807: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.163702: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.165006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.167702: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.168632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.169398: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.254533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.255462: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.256261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:09:40.257059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9268 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:09:41.356902: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
473/473 - 3s - 7ms/step - loss: 0.0997 - val_loss: 0.1577
Epoch 2/120
473/473 - 2s - 4ms/step - loss: 0.0501 - val_loss: 0.1584
Epoch 3/120
473/473 - 2s - 4ms/step - loss: 0.0411 - val_loss: 0.1624
Epoch 4/120
473/473 - 2s - 4ms/step - loss: 0.0366 - val_loss: 0.1655
Epoch 5/120
473/473 - 2s - 4ms/step - loss: 0.0342 - val_loss: 0.1764
Epoch 6/120
473/473 - 2s - 4ms/step - loss: 0.0321 - val_loss: 0.1730
Epoch 7/120
473/473 - 2s - 4ms/step - loss: 0.0313 - val_loss: 0.1495
Epoch 8/120
473/473 - 2s - 4ms/step - loss: 0.0297 - val_loss: 0.1477
Epoch 9/120
473/473 - 2s - 4ms/step - loss: 0.0296 - val_loss: 0.1540
Epoch 10/120
473/473 - 2s - 5ms/step - loss: 0.0285 - val_loss: 0.1289
Epoch 11/120
473/473 - 2s - 4ms/step - loss: 0.0281 - val_loss: 0.1323
Epoch 12/120
473/473 - 2s - 4ms/step - loss: 0.0320 - val_loss: 0.1699
Epoch 13/120
473/473 - 2s - 4ms/step - loss: 0.0279 - val_loss: 0.1733
Epoch 14/120
473/473 - 2s - 4ms/step - loss: 0.0267 - val_loss: 0.1518
Epoch 15/120
473/473 - 2s - 4ms/step - loss: 0.0262 - val_loss: 0.1438
Epoch 16/120
473/473 - 2s - 4ms/step - loss: 0.0261 - val_loss: 0.1537
Epoch 17/120
473/473 - 2s - 4ms/step - loss: 0.0257 - val_loss: 0.1403
Epoch 18/120
473/473 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.1471
Epoch 19/120
473/473 - 2s - 4ms/step - loss: 0.0248 - val_loss: 0.1539
Epoch 20/120
473/473 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.1436
Epoch 21/120
473/473 - 2s - 4ms/step - loss: 0.0246 - val_loss: 0.1493
Epoch 22/120
473/473 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.1552
Epoch 23/120
473/473 - 2s - 4ms/step - loss: 0.0240 - val_loss: 0.1502
Epoch 24/120
473/473 - 2s - 4ms/step - loss: 0.0238 - val_loss: 0.1418
Epoch 25/120
473/473 - 2s - 4ms/step - loss: 0.0235 - val_loss: 0.1507
Epoch 26/120
473/473 - 2s - 4ms/step - loss: 0.0234 - val_loss: 0.1409
Epoch 27/120
473/473 - 2s - 4ms/step - loss: 0.0230 - val_loss: 0.1402
Epoch 28/120
473/473 - 2s - 4ms/step - loss: 0.0229 - val_loss: 0.1433
Epoch 29/120
473/473 - 2s - 4ms/step - loss: 0.0228 - val_loss: 0.1408
Epoch 30/120
473/473 - 2s - 4ms/step - loss: 0.0223 - val_loss: 0.1505
Epoch 31/120
473/473 - 2s - 4ms/step - loss: 0.0225 - val_loss: 0.1459
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2698
Per-joint RMSE: 0.1753 0.5406 0.1831 0.1605 0.2134 0.0956
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2 --H 100 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:10:48.558090: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:10:48.584105: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-99ry3c5u because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:10:49.559770: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.564418: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.565237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.566943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.567721: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.568458: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.648422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.649284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.650037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:49.650771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:10:49.950697: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.258905e-01  RMSE=3.548106e-01
  per-joint RMSE: 0.2690 0.6907 0.2073 0.1624 0.3421 0.1398
Residual LSTM:  MSE=7.344804e-02      RMSE=2.710130e-01
  per-joint RMSE: 0.1887 0.5374 0.1865 0.1620 0.2150 0.0950
Combined torque MSE=7.344804e-02     RMSE=2.710130e-01
  per-joint RMSE: 0.1887 0.5374 0.1865 0.1620 0.2150 0.0950
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:10:51.844254: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:10:51.869906: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-39x_g5sq because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__lstm_windows_H100__feat_state__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 18
 dout = 6
  X_train = (33616, 100, 18), Y_train = (33616, 6)
  X_test  = (5005, 100, 18),  Y_test  = (5005, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:10:53.374143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.378749: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.379537: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.381242: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.382051: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.382780: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.456557: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.457751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.458559: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:10:53.459293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:10:54.508916: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
473/473 - 3s - 7ms/step - loss: 0.0992 - val_loss: 0.1040
Epoch 2/120
473/473 - 2s - 4ms/step - loss: 0.0504 - val_loss: 0.1194
Epoch 3/120
473/473 - 2s - 4ms/step - loss: 0.0419 - val_loss: 0.1251
Epoch 4/120
473/473 - 2s - 4ms/step - loss: 0.0372 - val_loss: 0.1420
Epoch 5/120
473/473 - 2s - 4ms/step - loss: 0.0344 - val_loss: 0.1380
Epoch 6/120
473/473 - 2s - 4ms/step - loss: 0.0326 - val_loss: 0.1414
Epoch 7/120
473/473 - 2s - 4ms/step - loss: 0.0309 - val_loss: 0.1525
Epoch 8/120
473/473 - 2s - 4ms/step - loss: 0.0301 - val_loss: 0.1459
Epoch 9/120
473/473 - 2s - 5ms/step - loss: 0.0294 - val_loss: 0.1592
Epoch 10/120
473/473 - 2s - 5ms/step - loss: 0.0328 - val_loss: 0.1426
Epoch 11/120
473/473 - 2s - 5ms/step - loss: 0.0284 - val_loss: 0.1640
Epoch 12/120
473/473 - 2s - 5ms/step - loss: 0.0274 - val_loss: 0.1986
Epoch 13/120
473/473 - 2s - 4ms/step - loss: 0.0271 - val_loss: 0.1913
Epoch 14/120
473/473 - 2s - 4ms/step - loss: 0.0264 - val_loss: 0.1522
Epoch 15/120
473/473 - 2s - 4ms/step - loss: 0.0263 - val_loss: 0.1517
Epoch 16/120
473/473 - 2s - 4ms/step - loss: 0.0256 - val_loss: 0.1457
Epoch 17/120
473/473 - 2s - 4ms/step - loss: 0.0254 - val_loss: 0.1770
Epoch 18/120
473/473 - 2s - 4ms/step - loss: 0.0253 - val_loss: 0.1618
Epoch 19/120
473/473 - 2s - 4ms/step - loss: 0.0249 - val_loss: 0.1720
Epoch 20/120
473/473 - 2s - 4ms/step - loss: 0.0248 - val_loss: 0.1347
Epoch 21/120
473/473 - 2s - 4ms/step - loss: 0.0243 - val_loss: 0.1580
Epoch 22/120
473/473 - 2s - 4ms/step - loss: 0.0240 - val_loss: 0.1683
Epoch 23/120
473/473 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.1450
Epoch 24/120
473/473 - 2s - 4ms/step - loss: 0.0232 - val_loss: 0.1367
Epoch 25/120
473/473 - 2s - 4ms/step - loss: 0.0234 - val_loss: 0.1445
Epoch 26/120
473/473 - 2s - 4ms/step - loss: 0.0235 - val_loss: 0.1514
Epoch 27/120
473/473 - 2s - 4ms/step - loss: 0.0229 - val_loss: 0.1538
Epoch 28/120
473/473 - 2s - 4ms/step - loss: 0.0229 - val_loss: 0.1446
Epoch 29/120
473/473 - 2s - 4ms/step - loss: 0.0227 - val_loss: 0.1758
Epoch 30/120
473/473 - 2s - 4ms/step - loss: 0.0227 - val_loss: 0.1498
Epoch 31/120
473/473 - 2s - 4ms/step - loss: 0.0225 - val_loss: 0.1274
Epoch 32/120
473/473 - 2s - 4ms/step - loss: 0.0221 - val_loss: 0.1223
Epoch 33/120
473/473 - 2s - 4ms/step - loss: 0.0217 - val_loss: 0.1300
Epoch 34/120
473/473 - 2s - 4ms/step - loss: 0.0218 - val_loss: 0.1318
Epoch 35/120
473/473 - 2s - 4ms/step - loss: 0.0217 - val_loss: 0.1295
Epoch 36/120
473/473 - 2s - 4ms/step - loss: 0.0226 - val_loss: 0.1576
Epoch 37/120
473/473 - 2s - 5ms/step - loss: 0.0215 - val_loss: 0.1313
Epoch 38/120
473/473 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.1600
Epoch 39/120
473/473 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.1298
Epoch 40/120
473/473 - 2s - 4ms/step - loss: 0.0209 - val_loss: 0.1657
Epoch 41/120
473/473 - 2s - 4ms/step - loss: 0.0209 - val_loss: 0.1643
Epoch 42/120
473/473 - 2s - 4ms/step - loss: 0.0208 - val_loss: 0.1394
Epoch 43/120
473/473 - 2s - 4ms/step - loss: 0.0205 - val_loss: 0.1507
Epoch 44/120
473/473 - 2s - 4ms/step - loss: 0.0206 - val_loss: 0.1439
Epoch 45/120
473/473 - 2s - 4ms/step - loss: 0.0204 - val_loss: 0.1316
Epoch 46/120
473/473 - 2s - 4ms/step - loss: 0.0203 - val_loss: 0.1606
Epoch 47/120
473/473 - 2s - 4ms/step - loss: 0.0203 - val_loss: 0.1681
Epoch 48/120
473/473 - 2s - 4ms/step - loss: 0.0201 - val_loss: 0.1572
Epoch 49/120
473/473 - 2s - 4ms/step - loss: 0.0203 - val_loss: 0.1605
Epoch 50/120
473/473 - 2s - 4ms/step - loss: 0.0199 - val_loss: 0.1757
Epoch 51/120
473/473 - 2s - 4ms/step - loss: 0.0197 - val_loss: 0.1596
Epoch 52/120
473/473 - 2s - 4ms/step - loss: 0.0196 - val_loss: 0.1720
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.2786
Per-joint RMSE: 0.1832 0.5664 0.1420 0.1588 0.2418 0.0868
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2 --H 100 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 0 --delan_seed 1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.23502598002565936 --delan_rmse_test 0.34739817995520866'
2026-01-30 16:12:45.243255: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:12:45.268889: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-7gi3v9fx because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:12:46.267698: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.272525: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.273312: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.274933: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.275724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.276519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.356480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.357379: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.358136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:46.358885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9236 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:12:46.667270: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.258905e-01  RMSE=3.548106e-01
  per-joint RMSE: 0.2690 0.6907 0.2073 0.1624 0.3421 0.1398
Residual LSTM:  MSE=8.097427e-02      RMSE=2.845598e-01
  per-joint RMSE: 0.1810 0.5907 0.1322 0.1595 0.2303 0.0904
Combined torque MSE=8.097427e-02     RMSE=2.845598e-01
  per-joint RMSE: 0.1810 0.5907 0.1322 0.1595 0.2303 0.0904
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d0__delan_jax_struct_s1_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_delan_dataset.py --derive_qdd_from_qd True --col_format wide --trajectory_amount 84 --test_fraction 0.2 --val_fraction 0.1 --seed 1 --lowpass_signals True --lowpass_cutoff_hz 10.0 --lowpass_order 4 --lowpass_qdd False --raw_csv /workspace/shared/data/raw/UR3_Load0_5x10^4_under.csv --out_npz /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz'
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Saved: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.json
Trajectories: train=19 val=3 test=5
Exists: True

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T delan_jax bash -lc 'python3 /workspace/delan_jax/scripts/export_delan_residuals_jax.py --npz_in /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz --ckpt /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax --out /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz'
Loading dataset: /workspace/shared/data/preprocessed/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset/delan_UR3_Load0_5x10^4_under_K84_seed1_dataset.npz
Loading checkpoint: /workspace/shared/models/delan/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__seed1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.jax
Detected n_dof=6 (seed=0)
2026-01-30 16:12:51.192641: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.

Exporting split=train: 19 trajectories
  done 19/19

Exporting split=test: 5 trajectories
  done 5/5

Saved residual trajectory dataset: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Keys: ['test_labels', 'test_q', 'test_qd', 'test_qdd', 'test_r_tau', 'test_t', 'test_tau', 'test_tau_hat', 'train_labels', 'train_q', 'train_qd', 'train_qdd', 'train_r_tau', 'train_t', 'train_tau', 'train_tau_hat']
Saved export JSON: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 50 --features full'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 50
  feature_mode= full
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=50, n_dof=6, feature_dim=24
X_train: (37069, 50, 24)  Y_train: (37069, 6)
X_test : (6755, 50, 24)  Y_test : (6755, 6)
feature_mode=full

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:12:58.165581: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:12:58.191130: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-mxqtrsuq because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 24
 dout = 6
  X_train = (37069, 50, 24), Y_train = (37069, 6)
  X_test  = (6755, 50, 24),  Y_test  = (6755, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:12:59.547577: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.553198: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.554529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.556294: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.557359: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.558213: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.639373: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.640321: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.641135: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:12:59.641921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8915 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:13:00.708454: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
522/522 - 3s - 6ms/step - loss: 0.1051 - val_loss: 0.1122
Epoch 2/120
522/522 - 2s - 3ms/step - loss: 0.0556 - val_loss: 0.1224
Epoch 3/120
522/522 - 2s - 3ms/step - loss: 0.0466 - val_loss: 0.1259
Epoch 4/120
522/522 - 2s - 3ms/step - loss: 0.0415 - val_loss: 0.1271
Epoch 5/120
522/522 - 2s - 3ms/step - loss: 0.0384 - val_loss: 0.1265
Epoch 6/120
522/522 - 2s - 3ms/step - loss: 0.0361 - val_loss: 0.1275
Epoch 7/120
522/522 - 2s - 3ms/step - loss: 0.0347 - val_loss: 0.1229
Epoch 8/120
522/522 - 2s - 3ms/step - loss: 0.0329 - val_loss: 0.1191
Epoch 9/120
522/522 - 2s - 3ms/step - loss: 0.0320 - val_loss: 0.1109
Epoch 10/120
522/522 - 2s - 3ms/step - loss: 0.0306 - val_loss: 0.1082
Epoch 11/120
522/522 - 2s - 3ms/step - loss: 0.0303 - val_loss: 0.1072
Epoch 12/120
522/522 - 2s - 3ms/step - loss: 0.0293 - val_loss: 0.1068
Epoch 13/120
522/522 - 2s - 3ms/step - loss: 0.0288 - val_loss: 0.1059
Epoch 14/120
522/522 - 2s - 3ms/step - loss: 0.0278 - val_loss: 0.1106
Epoch 15/120
522/522 - 2s - 3ms/step - loss: 0.0273 - val_loss: 0.1101
Epoch 16/120
522/522 - 2s - 3ms/step - loss: 0.0271 - val_loss: 0.1050
Epoch 17/120
522/522 - 2s - 3ms/step - loss: 0.0270 - val_loss: 0.1104
Epoch 18/120
522/522 - 2s - 3ms/step - loss: 0.0267 - val_loss: 0.1136
Epoch 19/120
522/522 - 2s - 3ms/step - loss: 0.0260 - val_loss: 0.1066
Epoch 20/120
522/522 - 2s - 3ms/step - loss: 0.0258 - val_loss: 0.1101
Epoch 21/120
522/522 - 2s - 3ms/step - loss: 0.0256 - val_loss: 0.1119
Epoch 22/120
522/522 - 2s - 3ms/step - loss: 0.0253 - val_loss: 0.1105
Epoch 23/120
522/522 - 2s - 3ms/step - loss: 0.0254 - val_loss: 0.1090
Epoch 24/120
522/522 - 2s - 3ms/step - loss: 0.0248 - val_loss: 0.1146
Epoch 25/120
522/522 - 2s - 3ms/step - loss: 0.0245 - val_loss: 0.1093
Epoch 26/120
522/522 - 2s - 3ms/step - loss: 0.0249 - val_loss: 0.1154
Epoch 27/120
522/522 - 2s - 3ms/step - loss: 0.0244 - val_loss: 0.1058
Epoch 28/120
522/522 - 2s - 3ms/step - loss: 0.0242 - val_loss: 0.1146
Epoch 29/120
522/522 - 2s - 3ms/step - loss: 0.0241 - val_loss: 0.1181
Epoch 30/120
522/522 - 2s - 3ms/step - loss: 0.0239 - val_loss: 0.1096
Epoch 31/120
522/522 - 2s - 3ms/step - loss: 0.0239 - val_loss: 0.1113
Epoch 32/120
522/522 - 2s - 3ms/step - loss: 0.0239 - val_loss: 0.1062
Epoch 33/120
522/522 - 2s - 3ms/step - loss: 0.0237 - val_loss: 0.1090
Epoch 34/120
522/522 - 2s - 3ms/step - loss: 0.0235 - val_loss: 0.1122
Epoch 35/120
522/522 - 2s - 3ms/step - loss: 0.0232 - val_loss: 0.1092
Epoch 36/120
522/522 - 2s - 3ms/step - loss: 0.0232 - val_loss: 0.1083
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0517
Per-joint RMSE: 0.0505 0.0528 0.0726 0.0419 0.0486 0.0365
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2 --H 50 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:13:58.396258: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:13:58.422540: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-p4w37sx5 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:13:59.422630: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.427389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.428268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.429891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.430683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.431423: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.518369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.519260: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.520019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:13:59.520774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:13:59.820121: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294841e-01  RMSE=3.598391e-01
  per-joint RMSE: 0.4098 0.5424 0.3822 0.2443 0.2329 0.2341
Residual LSTM:  MSE=2.676729e-03      RMSE=5.173711e-02
  per-joint RMSE: 0.0505 0.0528 0.0726 0.0419 0.0486 0.0365
Combined torque MSE=2.676729e-03     RMSE=5.173712e-02
  per-joint RMSE: 0.0505 0.0528 0.0726 0.0419 0.0486 0.0365
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:14:01.756029: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:14:01.781553: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-y1vu8byf because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 24
 dout = 6
  X_train = (37069, 50, 24), Y_train = (37069, 6)
  X_test  = (6755, 50, 24),  Y_test  = (6755, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:14:03.118777: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.123367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.124163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.125728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.126514: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.127247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.195272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.196102: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.196849: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:14:03.197666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9117 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:14:04.229088: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
522/522 - 3s - 6ms/step - loss: 0.1054 - val_loss: 0.1305
Epoch 2/120
522/522 - 2s - 3ms/step - loss: 0.0554 - val_loss: 0.1184
Epoch 3/120
522/522 - 1s - 3ms/step - loss: 0.0459 - val_loss: 0.1229
Epoch 4/120
522/522 - 2s - 3ms/step - loss: 0.0408 - val_loss: 0.1161
Epoch 5/120
522/522 - 2s - 3ms/step - loss: 0.0381 - val_loss: 0.1227
Epoch 6/120
522/522 - 2s - 3ms/step - loss: 0.0356 - val_loss: 0.1134
Epoch 7/120
522/522 - 2s - 3ms/step - loss: 0.0341 - val_loss: 0.1044
Epoch 8/120
522/522 - 2s - 3ms/step - loss: 0.0329 - val_loss: 0.1144
Epoch 9/120
522/522 - 2s - 3ms/step - loss: 0.0320 - val_loss: 0.1063
Epoch 10/120
522/522 - 2s - 3ms/step - loss: 0.0301 - val_loss: 0.1152
Epoch 11/120
522/522 - 2s - 3ms/step - loss: 0.0299 - val_loss: 0.1082
Epoch 12/120
522/522 - 2s - 3ms/step - loss: 0.0294 - val_loss: 0.1058
Epoch 13/120
522/522 - 2s - 3ms/step - loss: 0.0283 - val_loss: 0.1121
Epoch 14/120
522/522 - 2s - 3ms/step - loss: 0.0282 - val_loss: 0.1031
Epoch 15/120
522/522 - 2s - 3ms/step - loss: 0.0274 - val_loss: 0.1003
Epoch 16/120
522/522 - 2s - 3ms/step - loss: 0.0271 - val_loss: 0.1017
Epoch 17/120
522/522 - 2s - 3ms/step - loss: 0.0276 - val_loss: 0.1036
Epoch 18/120
522/522 - 2s - 3ms/step - loss: 0.0265 - val_loss: 0.1049
Epoch 19/120
522/522 - 2s - 3ms/step - loss: 0.0261 - val_loss: 0.1140
Epoch 20/120
522/522 - 1s - 3ms/step - loss: 0.0258 - val_loss: 0.1076
Epoch 21/120
522/522 - 2s - 3ms/step - loss: 0.0256 - val_loss: 0.1109
Epoch 22/120
522/522 - 2s - 3ms/step - loss: 0.0254 - val_loss: 0.1031
Epoch 23/120
522/522 - 2s - 3ms/step - loss: 0.0250 - val_loss: 0.1050
Epoch 24/120
522/522 - 2s - 3ms/step - loss: 0.0248 - val_loss: 0.1072
Epoch 25/120
522/522 - 2s - 3ms/step - loss: 0.0246 - val_loss: 0.1129
Epoch 26/120
522/522 - 1s - 3ms/step - loss: 0.0245 - val_loss: 0.1070
Epoch 27/120
522/522 - 2s - 3ms/step - loss: 0.0247 - val_loss: 0.1052
Epoch 28/120
522/522 - 2s - 3ms/step - loss: 0.0242 - val_loss: 0.1050
Epoch 29/120
522/522 - 1s - 3ms/step - loss: 0.0242 - val_loss: 0.1058
Epoch 30/120
522/522 - 1s - 3ms/step - loss: 0.0252 - val_loss: 0.1083
Epoch 31/120
522/522 - 2s - 3ms/step - loss: 0.0240 - val_loss: 0.1056
Epoch 32/120
522/522 - 2s - 3ms/step - loss: 0.0236 - val_loss: 0.1026
Epoch 33/120
522/522 - 2s - 3ms/step - loss: 0.0234 - val_loss: 0.1074
Epoch 34/120
522/522 - 2s - 3ms/step - loss: 0.0235 - val_loss: 0.1065
Epoch 35/120
522/522 - 2s - 3ms/step - loss: 0.0235 - val_loss: 0.1087
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0519
Per-joint RMSE: 0.0510 0.0535 0.0738 0.0398 0.0484 0.0362
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2 --H 50 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:14:59.717901: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:14:59.745067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-qou1w8k2 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:15:00.762434: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.767166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.768104: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.769858: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.770648: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.771383: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.850331: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.851188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.851944: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:00.852772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9126 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:15:01.153497: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294841e-01  RMSE=3.598391e-01
  per-joint RMSE: 0.4098 0.5424 0.3822 0.2443 0.2329 0.2341
Residual LSTM:  MSE=2.690446e-03      RMSE=5.186951e-02
  per-joint RMSE: 0.0510 0.0535 0.0738 0.0398 0.0484 0.0362
Combined torque MSE=2.690446e-03     RMSE=5.186951e-02
  per-joint RMSE: 0.0510 0.0535 0.0738 0.0398 0.0484 0.0362
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 100 --features full'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 100
  feature_mode= full
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=100, n_dof=6, feature_dim=24
X_train: (36119, 100, 24)  Y_train: (36119, 6)
X_test : (6505, 100, 24)  Y_test : (6505, 6)
feature_mode=full

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:15:03.686526: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:15:03.712613: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-9nsc9sm3 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 24
 dout = 6
  X_train = (36119, 100, 24), Y_train = (36119, 6)
  X_test  = (6505, 100, 24),  Y_test  = (6505, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:15:05.365179: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.370459: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.371371: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.373044: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.373943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.374796: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.471228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.472231: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.473116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:15:05.473901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9116 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:15:06.581404: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
508/508 - 4s - 7ms/step - loss: 0.1058 - val_loss: 0.1122
Epoch 2/120
508/508 - 2s - 4ms/step - loss: 0.0544 - val_loss: 0.1097
Epoch 3/120
508/508 - 2s - 4ms/step - loss: 0.0461 - val_loss: 0.0960
Epoch 4/120
508/508 - 2s - 4ms/step - loss: 0.0410 - val_loss: 0.0901
Epoch 5/120
508/508 - 2s - 4ms/step - loss: 0.0379 - val_loss: 0.0876
Epoch 6/120
508/508 - 2s - 4ms/step - loss: 0.0354 - val_loss: 0.0918
Epoch 7/120
508/508 - 2s - 4ms/step - loss: 0.0338 - val_loss: 0.0913
Epoch 8/120
508/508 - 2s - 4ms/step - loss: 0.0325 - val_loss: 0.0898
Epoch 9/120
508/508 - 2s - 4ms/step - loss: 0.0313 - val_loss: 0.0911
Epoch 10/120
508/508 - 2s - 4ms/step - loss: 0.0302 - val_loss: 0.0889
Epoch 11/120
508/508 - 2s - 4ms/step - loss: 0.0300 - val_loss: 0.0873
Epoch 12/120
508/508 - 2s - 4ms/step - loss: 0.0292 - val_loss: 0.0817
Epoch 13/120
508/508 - 2s - 4ms/step - loss: 0.0281 - val_loss: 0.0842
Epoch 14/120
508/508 - 2s - 4ms/step - loss: 0.0280 - val_loss: 0.0801
Epoch 15/120
508/508 - 2s - 4ms/step - loss: 0.0275 - val_loss: 0.0843
Epoch 16/120
508/508 - 2s - 4ms/step - loss: 0.0265 - val_loss: 0.0828
Epoch 17/120
508/508 - 2s - 4ms/step - loss: 0.0264 - val_loss: 0.0875
Epoch 18/120
508/508 - 2s - 4ms/step - loss: 0.0262 - val_loss: 0.0862
Epoch 19/120
508/508 - 2s - 4ms/step - loss: 0.0258 - val_loss: 0.0883
Epoch 20/120
508/508 - 2s - 4ms/step - loss: 0.0254 - val_loss: 0.0885
Epoch 21/120
508/508 - 2s - 4ms/step - loss: 0.0257 - val_loss: 0.0865
Epoch 22/120
508/508 - 2s - 4ms/step - loss: 0.0249 - val_loss: 0.0866
Epoch 23/120
508/508 - 2s - 4ms/step - loss: 0.0248 - val_loss: 0.0885
Epoch 24/120
508/508 - 2s - 4ms/step - loss: 0.0246 - val_loss: 0.0876
Epoch 25/120
508/508 - 2s - 4ms/step - loss: 0.0241 - val_loss: 0.0852
Epoch 26/120
508/508 - 2s - 4ms/step - loss: 0.0241 - val_loss: 0.0873
Epoch 27/120
508/508 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.0874
Epoch 28/120
508/508 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.0870
Epoch 29/120
508/508 - 2s - 4ms/step - loss: 0.0235 - val_loss: 0.0870
Epoch 30/120
508/508 - 2s - 4ms/step - loss: 0.0237 - val_loss: 0.0863
Epoch 31/120
508/508 - 2s - 4ms/step - loss: 0.0235 - val_loss: 0.0894
Epoch 32/120
508/508 - 2s - 4ms/step - loss: 0.0232 - val_loss: 0.0876
Epoch 33/120
508/508 - 2s - 4ms/step - loss: 0.0232 - val_loss: 0.0886
Epoch 34/120
508/508 - 2s - 4ms/step - loss: 0.0230 - val_loss: 0.0866
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0501
Per-joint RMSE: 0.0491 0.0511 0.0697 0.0378 0.0482 0.0381
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2 --H 100 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:16:24.449331: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:16:24.475478: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-l6k4qowi because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:16:25.473967: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.478728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.479520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.481178: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.481966: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.482778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.564899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.565735: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.566558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:25.567292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9097 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:16:25.872323: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294100e-01  RMSE=3.597360e-01
  per-joint RMSE: 0.4059 0.5436 0.3843 0.2447 0.2334 0.2326
Residual LSTM:  MSE=2.513944e-03      RMSE=5.013925e-02
  per-joint RMSE: 0.0491 0.0511 0.0697 0.0378 0.0482 0.0381
Combined torque MSE=2.513944e-03     RMSE=5.013925e-02
  per-joint RMSE: 0.0491 0.0511 0.0697 0.0378 0.0482 0.0381
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:16:27.792728: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:16:27.817822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-0ptknoo8 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_full__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 24
 dout = 6
  X_train = (36119, 100, 24), Y_train = (36119, 6)
  X_test  = (6505, 100, 24),  Y_test  = (6505, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (24,)/(24,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:16:29.455233: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.459991: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.461111: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.463009: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.463909: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.464903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.550501: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.551528: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.552336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:16:29.553123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        78,336 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 210,694 (823.02 KB)
 Trainable params: 210,694 (823.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:16:30.695923: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
508/508 - 4s - 7ms/step - loss: 0.1089 - val_loss: 0.1142
Epoch 2/120
508/508 - 2s - 4ms/step - loss: 0.0561 - val_loss: 0.1144
Epoch 3/120
508/508 - 2s - 4ms/step - loss: 0.0472 - val_loss: 0.0998
Epoch 4/120
508/508 - 2s - 4ms/step - loss: 0.0418 - val_loss: 0.0917
Epoch 5/120
508/508 - 2s - 4ms/step - loss: 0.0386 - val_loss: 0.0976
Epoch 6/120
508/508 - 2s - 4ms/step - loss: 0.0360 - val_loss: 0.0963
Epoch 7/120
508/508 - 2s - 4ms/step - loss: 0.0350 - val_loss: 0.0932
Epoch 8/120
508/508 - 2s - 4ms/step - loss: 0.0329 - val_loss: 0.0921
Epoch 9/120
508/508 - 2s - 4ms/step - loss: 0.0317 - val_loss: 0.0944
Epoch 10/120
508/508 - 2s - 4ms/step - loss: 0.0311 - val_loss: 0.0929
Epoch 11/120
508/508 - 2s - 4ms/step - loss: 0.0297 - val_loss: 0.0909
Epoch 12/120
508/508 - 2s - 4ms/step - loss: 0.0290 - val_loss: 0.1020
Epoch 13/120
508/508 - 2s - 4ms/step - loss: 0.0285 - val_loss: 0.0969
Epoch 14/120
508/508 - 2s - 4ms/step - loss: 0.0278 - val_loss: 0.0927
Epoch 15/120
508/508 - 2s - 4ms/step - loss: 0.0275 - val_loss: 0.0901
Epoch 16/120
508/508 - 2s - 4ms/step - loss: 0.0272 - val_loss: 0.0945
Epoch 17/120
508/508 - 2s - 4ms/step - loss: 0.0264 - val_loss: 0.0921
Epoch 18/120
508/508 - 2s - 4ms/step - loss: 0.0261 - val_loss: 0.0957
Epoch 19/120
508/508 - 2s - 4ms/step - loss: 0.0259 - val_loss: 0.0997
Epoch 20/120
508/508 - 2s - 4ms/step - loss: 0.0257 - val_loss: 0.0969
Epoch 21/120
508/508 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.0985
Epoch 22/120
508/508 - 2s - 4ms/step - loss: 0.0252 - val_loss: 0.0987
Epoch 23/120
508/508 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.0922
Epoch 24/120
508/508 - 2s - 4ms/step - loss: 0.0249 - val_loss: 0.0956
Epoch 25/120
508/508 - 2s - 4ms/step - loss: 0.0244 - val_loss: 0.0954
Epoch 26/120
508/508 - 2s - 4ms/step - loss: 0.0242 - val_loss: 0.0888
Epoch 27/120
508/508 - 2s - 4ms/step - loss: 0.0238 - val_loss: 0.0921
Epoch 28/120
508/508 - 2s - 4ms/step - loss: 0.0242 - val_loss: 0.0933
Epoch 29/120
508/508 - 2s - 4ms/step - loss: 0.0238 - val_loss: 0.0893
Epoch 30/120
508/508 - 2s - 4ms/step - loss: 0.0234 - val_loss: 0.0865
Epoch 31/120
508/508 - 2s - 4ms/step - loss: 0.0233 - val_loss: 0.0843
Epoch 32/120
508/508 - 2s - 4ms/step - loss: 0.0235 - val_loss: 0.0850
Epoch 33/120
508/508 - 2s - 4ms/step - loss: 0.0231 - val_loss: 0.0872
Epoch 34/120
508/508 - 2s - 4ms/step - loss: 0.0230 - val_loss: 0.0862
Epoch 35/120
508/508 - 2s - 4ms/step - loss: 0.0230 - val_loss: 0.0890
Epoch 36/120
508/508 - 2s - 4ms/step - loss: 0.0229 - val_loss: 0.0875
Epoch 37/120
508/508 - 2s - 4ms/step - loss: 0.0229 - val_loss: 0.0864
Epoch 38/120
508/508 - 2s - 4ms/step - loss: 0.0226 - val_loss: 0.0908
Epoch 39/120
508/508 - 2s - 4ms/step - loss: 0.0226 - val_loss: 0.0875
Epoch 40/120
508/508 - 2s - 4ms/step - loss: 0.0224 - val_loss: 0.0867
Epoch 41/120
508/508 - 2s - 4ms/step - loss: 0.0224 - val_loss: 0.0865
Epoch 42/120
508/508 - 2s - 4ms/step - loss: 0.0221 - val_loss: 0.0873
Epoch 43/120
508/508 - 2s - 4ms/step - loss: 0.0222 - val_loss: 0.0874
Epoch 44/120
508/508 - 2s - 4ms/step - loss: 0.0224 - val_loss: 0.0821
Epoch 45/120
508/508 - 2s - 4ms/step - loss: 0.0221 - val_loss: 0.0890
Epoch 46/120
508/508 - 2s - 4ms/step - loss: 0.0220 - val_loss: 0.0872
Epoch 47/120
508/508 - 2s - 4ms/step - loss: 0.0220 - val_loss: 0.0869
Epoch 48/120
508/508 - 2s - 4ms/step - loss: 0.0218 - val_loss: 0.0852
Epoch 49/120
508/508 - 2s - 4ms/step - loss: 0.0218 - val_loss: 0.0876
Epoch 50/120
508/508 - 2s - 4ms/step - loss: 0.0218 - val_loss: 0.0892
Epoch 51/120
508/508 - 2s - 4ms/step - loss: 0.0215 - val_loss: 0.0861
Epoch 52/120
508/508 - 2s - 4ms/step - loss: 0.0214 - val_loss: 0.0863
Epoch 53/120
508/508 - 2s - 4ms/step - loss: 0.0214 - val_loss: 0.0857
Epoch 54/120
508/508 - 2s - 4ms/step - loss: 0.0214 - val_loss: 0.0918
Epoch 55/120
508/508 - 2s - 4ms/step - loss: 0.0213 - val_loss: 0.0855
Epoch 56/120
508/508 - 2s - 4ms/step - loss: 0.0214 - val_loss: 0.0886
Epoch 57/120
508/508 - 2s - 4ms/step - loss: 0.0212 - val_loss: 0.0891
Epoch 58/120
508/508 - 2s - 4ms/step - loss: 0.0212 - val_loss: 0.0866
Epoch 59/120
508/508 - 2s - 4ms/step - loss: 0.0212 - val_loss: 0.0865
Epoch 60/120
508/508 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.0912
Epoch 61/120
508/508 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.0899
Epoch 62/120
508/508 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.0924
Epoch 63/120
508/508 - 2s - 4ms/step - loss: 0.0208 - val_loss: 0.0941
Epoch 64/120
508/508 - 2s - 4ms/step - loss: 0.0207 - val_loss: 0.0957
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0494
Per-joint RMSE: 0.0506 0.0470 0.0733 0.0377 0.0438 0.0337
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2 --H 100 --split test --features full --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:18:54.700258: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:18:54.726788: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-tx34yato because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:18:55.750913: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.755719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.756514: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.758132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.759012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.759835: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.838208: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.839101: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.839854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:18:55.840594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:18:56.150582: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294100e-01  RMSE=3.597360e-01
  per-joint RMSE: 0.4059 0.5436 0.3843 0.2447 0.2334 0.2326
Residual LSTM:  MSE=2.436186e-03      RMSE=4.935774e-02
  per-joint RMSE: 0.0506 0.0470 0.0733 0.0377 0.0438 0.0337
Combined torque MSE=2.436186e-03     RMSE=4.935774e-02
  per-joint RMSE: 0.0506 0.0470 0.0733 0.0377 0.0438 0.0337
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 50 --features state'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 50
  feature_mode= state
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=50, n_dof=6, feature_dim=18
X_train: (37069, 50, 18)  Y_train: (37069, 6)
X_test : (6755, 50, 18)  Y_test : (6755, 6)
feature_mode=state

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:18:58.689673: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:18:58.716325: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-33ylycn5 because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 18
 dout = 6
  X_train = (37069, 50, 18), Y_train = (37069, 6)
  X_test  = (6755, 50, 18),  Y_test  = (6755, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:19:00.069314: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.074516: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.075451: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.077281: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.078291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.079172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.163224: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.164132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.164944: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:19:00.165748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9025 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:19:01.196415: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
522/522 - 3s - 6ms/step - loss: 0.1107 - val_loss: 0.1368
Epoch 2/120
522/522 - 2s - 3ms/step - loss: 0.0588 - val_loss: 0.1442
Epoch 3/120
522/522 - 2s - 3ms/step - loss: 0.0493 - val_loss: 0.1461
Epoch 4/120
522/522 - 2s - 3ms/step - loss: 0.0432 - val_loss: 0.1409
Epoch 5/120
522/522 - 2s - 3ms/step - loss: 0.0401 - val_loss: 0.1353
Epoch 6/120
522/522 - 2s - 3ms/step - loss: 0.0375 - val_loss: 0.1465
Epoch 7/120
522/522 - 2s - 3ms/step - loss: 0.0363 - val_loss: 0.1475
Epoch 8/120
522/522 - 2s - 3ms/step - loss: 0.0348 - val_loss: 0.1443
Epoch 9/120
522/522 - 2s - 3ms/step - loss: 0.0334 - val_loss: 0.1404
Epoch 10/120
522/522 - 2s - 3ms/step - loss: 0.0322 - val_loss: 0.1428
Epoch 11/120
522/522 - 2s - 3ms/step - loss: 0.0314 - val_loss: 0.1348
Epoch 12/120
522/522 - 2s - 3ms/step - loss: 0.0311 - val_loss: 0.1371
Epoch 13/120
522/522 - 2s - 3ms/step - loss: 0.0295 - val_loss: 0.1348
Epoch 14/120
522/522 - 2s - 3ms/step - loss: 0.0295 - val_loss: 0.1376
Epoch 15/120
522/522 - 2s - 3ms/step - loss: 0.0288 - val_loss: 0.1373
Epoch 16/120
522/522 - 2s - 3ms/step - loss: 0.0282 - val_loss: 0.1340
Epoch 17/120
522/522 - 2s - 3ms/step - loss: 0.0277 - val_loss: 0.1377
Epoch 18/120
522/522 - 2s - 3ms/step - loss: 0.0277 - val_loss: 0.1338
Epoch 19/120
522/522 - 2s - 3ms/step - loss: 0.0272 - val_loss: 0.1341
Epoch 20/120
522/522 - 2s - 3ms/step - loss: 0.0272 - val_loss: 0.1349
Epoch 21/120
522/522 - 2s - 3ms/step - loss: 0.0263 - val_loss: 0.1378
Epoch 22/120
522/522 - 2s - 3ms/step - loss: 0.0260 - val_loss: 0.1390
Epoch 23/120
522/522 - 2s - 3ms/step - loss: 0.0260 - val_loss: 0.1440
Epoch 24/120
522/522 - 2s - 3ms/step - loss: 0.0257 - val_loss: 0.1490
Epoch 25/120
522/522 - 2s - 3ms/step - loss: 0.0255 - val_loss: 0.1327
Epoch 26/120
522/522 - 2s - 3ms/step - loss: 0.0254 - val_loss: 0.1363
Epoch 27/120
522/522 - 2s - 3ms/step - loss: 0.0249 - val_loss: 0.1393
Epoch 28/120
522/522 - 2s - 3ms/step - loss: 0.0250 - val_loss: 0.1375
Epoch 29/120
522/522 - 2s - 3ms/step - loss: 0.0247 - val_loss: 0.1403
Epoch 30/120
522/522 - 2s - 3ms/step - loss: 0.0246 - val_loss: 0.1355
Epoch 31/120
522/522 - 2s - 3ms/step - loss: 0.0246 - val_loss: 0.1397
Epoch 32/120
522/522 - 2s - 3ms/step - loss: 0.0242 - val_loss: 0.1356
Epoch 33/120
522/522 - 2s - 3ms/step - loss: 0.0240 - val_loss: 0.1369
Epoch 34/120
522/522 - 2s - 3ms/step - loss: 0.0242 - val_loss: 0.1362
Epoch 35/120
522/522 - 2s - 3ms/step - loss: 0.0240 - val_loss: 0.1394
Epoch 36/120
522/522 - 2s - 3ms/step - loss: 0.0239 - val_loss: 0.1362
Epoch 37/120
522/522 - 2s - 3ms/step - loss: 0.0237 - val_loss: 0.1324
Epoch 38/120
522/522 - 2s - 3ms/step - loss: 0.0234 - val_loss: 0.1362
Epoch 39/120
522/522 - 2s - 3ms/step - loss: 0.0238 - val_loss: 0.1399
Epoch 40/120
522/522 - 2s - 3ms/step - loss: 0.0234 - val_loss: 0.1367
Epoch 41/120
522/522 - 2s - 3ms/step - loss: 0.0231 - val_loss: 0.1386
Epoch 42/120
522/522 - 2s - 3ms/step - loss: 0.0231 - val_loss: 0.1467
Epoch 43/120
522/522 - 2s - 3ms/step - loss: 0.0232 - val_loss: 0.1426
Epoch 44/120
522/522 - 2s - 3ms/step - loss: 0.0228 - val_loss: 0.1432
Epoch 45/120
522/522 - 2s - 3ms/step - loss: 0.0229 - val_loss: 0.1456
Epoch 46/120
522/522 - 2s - 3ms/step - loss: 0.0226 - val_loss: 0.1442
Epoch 47/120
522/522 - 2s - 3ms/step - loss: 0.0228 - val_loss: 0.1370
Epoch 48/120
522/522 - 2s - 3ms/step - loss: 0.0229 - val_loss: 0.1460
Epoch 49/120
522/522 - 2s - 3ms/step - loss: 0.0225 - val_loss: 0.1378
Epoch 50/120
522/522 - 2s - 3ms/step - loss: 0.0223 - val_loss: 0.1423
Epoch 51/120
522/522 - 2s - 3ms/step - loss: 0.0224 - val_loss: 0.1395
Epoch 52/120
522/522 - 2s - 3ms/step - loss: 0.0223 - val_loss: 0.1447
Epoch 53/120
522/522 - 2s - 3ms/step - loss: 0.0225 - val_loss: 0.1431
Epoch 54/120
522/522 - 2s - 3ms/step - loss: 0.0222 - val_loss: 0.1400
Epoch 55/120
522/522 - 2s - 3ms/step - loss: 0.0222 - val_loss: 0.1407
Epoch 56/120
522/522 - 2s - 3ms/step - loss: 0.0223 - val_loss: 0.1424
Epoch 57/120
522/522 - 2s - 3ms/step - loss: 0.0220 - val_loss: 0.1386
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0561
Per-joint RMSE: 0.0598 0.0556 0.0743 0.0462 0.0454 0.0499
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2 --H 50 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:20:32.188423: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:20:32.214260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-lbb8sclb because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:20:33.223734: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.228433: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.229229: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.230950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.231740: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.232533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.310407: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.311404: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.312233: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:33.312963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9336 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:20:33.614406: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294841e-01  RMSE=3.598391e-01
  per-joint RMSE: 0.4098 0.5424 0.3822 0.2443 0.2329 0.2341
Residual LSTM:  MSE=3.144288e-03      RMSE=5.607395e-02
  per-joint RMSE: 0.0598 0.0556 0.0743 0.0462 0.0454 0.0499
Combined torque MSE=3.144288e-03     RMSE=5.607395e-02
  per-joint RMSE: 0.0598 0.0556 0.0743 0.0462 0.0454 0.0499
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:20:35.495927: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:20:35.521986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-7ayr563j because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H50__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 50
  din = 18
 dout = 6
  X_train = (37069, 50, 18), Y_train = (37069, 6)
  X_test  = (6755, 50, 18),  Y_test  = (6755, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:20:36.811757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.816444: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.817242: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.818925: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.819725: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.820528: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.893086: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.893925: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.894661: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:20:36.895628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 50, 128)        │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:20:37.889032: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
522/522 - 3s - 6ms/step - loss: 0.1119 - val_loss: 0.1432
Epoch 2/120
522/522 - 2s - 3ms/step - loss: 0.0584 - val_loss: 0.1382
Epoch 3/120
522/522 - 2s - 3ms/step - loss: 0.0491 - val_loss: 0.1308
Epoch 4/120
522/522 - 2s - 3ms/step - loss: 0.0434 - val_loss: 0.1439
Epoch 5/120
522/522 - 2s - 3ms/step - loss: 0.0403 - val_loss: 0.1367
Epoch 6/120
522/522 - 2s - 3ms/step - loss: 0.0377 - val_loss: 0.1423
Epoch 7/120
522/522 - 2s - 3ms/step - loss: 0.0361 - val_loss: 0.1484
Epoch 8/120
522/522 - 2s - 3ms/step - loss: 0.0344 - val_loss: 0.1524
Epoch 9/120
522/522 - 2s - 3ms/step - loss: 0.0340 - val_loss: 0.1338
Epoch 10/120
522/522 - 2s - 3ms/step - loss: 0.0323 - val_loss: 0.1463
Epoch 11/120
522/522 - 2s - 3ms/step - loss: 0.0317 - val_loss: 0.1403
Epoch 12/120
522/522 - 2s - 3ms/step - loss: 0.0305 - val_loss: 0.1346
Epoch 13/120
522/522 - 2s - 3ms/step - loss: 0.0302 - val_loss: 0.1341
Epoch 14/120
522/522 - 2s - 3ms/step - loss: 0.0298 - val_loss: 0.1322
Epoch 15/120
522/522 - 2s - 3ms/step - loss: 0.0290 - val_loss: 0.1392
Epoch 16/120
522/522 - 2s - 3ms/step - loss: 0.0285 - val_loss: 0.1409
Epoch 17/120
522/522 - 2s - 3ms/step - loss: 0.0278 - val_loss: 0.1367
Epoch 18/120
522/522 - 2s - 3ms/step - loss: 0.0277 - val_loss: 0.1380
Epoch 19/120
522/522 - 2s - 3ms/step - loss: 0.0272 - val_loss: 0.1376
Epoch 20/120
522/522 - 2s - 3ms/step - loss: 0.0269 - val_loss: 0.1431
Epoch 21/120
522/522 - 2s - 3ms/step - loss: 0.0267 - val_loss: 0.1374
Epoch 22/120
522/522 - 2s - 3ms/step - loss: 0.0265 - val_loss: 0.1379
Epoch 23/120
522/522 - 2s - 3ms/step - loss: 0.0263 - val_loss: 0.1345
Epoch 24/120
522/522 - 2s - 3ms/step - loss: 0.0260 - val_loss: 0.1408
Epoch 25/120
522/522 - 2s - 3ms/step - loss: 0.0256 - val_loss: 0.1381
Epoch 26/120
522/522 - 2s - 3ms/step - loss: 0.0254 - val_loss: 0.1467
Epoch 27/120
522/522 - 2s - 3ms/step - loss: 0.0255 - val_loss: 0.1435
Epoch 28/120
522/522 - 2s - 3ms/step - loss: 0.0253 - val_loss: 0.1368
Epoch 29/120
522/522 - 2s - 3ms/step - loss: 0.0248 - val_loss: 0.1461
Epoch 30/120
522/522 - 2s - 3ms/step - loss: 0.0247 - val_loss: 0.1351
Epoch 31/120
522/522 - 2s - 3ms/step - loss: 0.0244 - val_loss: 0.1468
Epoch 32/120
522/522 - 2s - 3ms/step - loss: 0.0242 - val_loss: 0.1395
Epoch 33/120
522/522 - 2s - 3ms/step - loss: 0.0242 - val_loss: 0.1413
Epoch 34/120
522/522 - 2s - 3ms/step - loss: 0.0241 - val_loss: 0.1402
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_train_test_H50.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0584
Per-joint RMSE: 0.0577 0.0656 0.0745 0.0467 0.0499 0.0509
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2 --H 50 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:21:32.602372: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:21:32.628546: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-z1r_tqlg because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:21:33.626651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.631451: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.632249: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.633949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.634816: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.635546: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.716633: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.717615: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.718423: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:33.719248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9174 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:21:34.023377: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294841e-01  RMSE=3.598391e-01
  per-joint RMSE: 0.4098 0.5424 0.3822 0.2443 0.2329 0.2341
Residual LSTM:  MSE=5.165862e-03      RMSE=7.187393e-02
  per-joint RMSE: 0.0777 0.0882 0.0853 0.0530 0.0582 0.0608
Combined torque MSE=5.165862e-03     RMSE=7.187393e-02
  per-joint RMSE: 0.0777 0.0882 0.0853 0.0530 0.0582 0.0608
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/metrics_test_H50.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H50_ep120_b64_u128_do0p2/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T preprocess bash -lc 'python3 scripts/build_lstm_windows.py --in_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --H 100 --features state'
Building LSTM windows
  in_npz      = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  out_npz     = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
  H           = 100
  feature_mode= state
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
Saved: /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.json
H=100, n_dof=6, feature_dim=18
X_train: (36119, 100, 18)  Y_train: (36119, 6)
X_test : (6505, 100, 18)  Y_test : (6505, 6)
feature_mode=state

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 0 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:21:36.481915: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:21:36.508521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-eddlyg9j because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 18
 dout = 6
  X_train = (36119, 100, 18), Y_train = (36119, 6)
  X_test  = (6505, 100, 18),  Y_test  = (6505, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:21:38.074262: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.079303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.080217: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.082056: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.082972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.083865: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.174838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.175762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.176704: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:21:38.177600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9159 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:21:39.266090: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
508/508 - 4s - 7ms/step - loss: 0.1124 - val_loss: 0.1364
Epoch 2/120
508/508 - 2s - 4ms/step - loss: 0.0592 - val_loss: 0.1347
Epoch 3/120
508/508 - 2s - 5ms/step - loss: 0.0496 - val_loss: 0.1303
Epoch 4/120
508/508 - 2s - 4ms/step - loss: 0.0443 - val_loss: 0.1285
Epoch 5/120
508/508 - 2s - 4ms/step - loss: 0.0412 - val_loss: 0.1229
Epoch 6/120
508/508 - 2s - 4ms/step - loss: 0.0376 - val_loss: 0.1221
Epoch 7/120
508/508 - 2s - 4ms/step - loss: 0.0361 - val_loss: 0.1205
Epoch 8/120
508/508 - 2s - 4ms/step - loss: 0.0344 - val_loss: 0.1181
Epoch 9/120
508/508 - 2s - 4ms/step - loss: 0.0334 - val_loss: 0.1224
Epoch 10/120
508/508 - 2s - 4ms/step - loss: 0.0322 - val_loss: 0.1275
Epoch 11/120
508/508 - 2s - 4ms/step - loss: 0.0315 - val_loss: 0.1280
Epoch 12/120
508/508 - 2s - 4ms/step - loss: 0.0310 - val_loss: 0.1253
Epoch 13/120
508/508 - 2s - 4ms/step - loss: 0.0296 - val_loss: 0.1224
Epoch 14/120
508/508 - 2s - 4ms/step - loss: 0.0293 - val_loss: 0.1259
Epoch 15/120
508/508 - 2s - 4ms/step - loss: 0.0287 - val_loss: 0.1326
Epoch 16/120
508/508 - 2s - 4ms/step - loss: 0.0284 - val_loss: 0.1299
Epoch 17/120
508/508 - 2s - 4ms/step - loss: 0.0279 - val_loss: 0.1278
Epoch 18/120
508/508 - 2s - 4ms/step - loss: 0.0276 - val_loss: 0.1243
Epoch 19/120
508/508 - 2s - 4ms/step - loss: 0.0271 - val_loss: 0.1266
Epoch 20/120
508/508 - 2s - 4ms/step - loss: 0.0266 - val_loss: 0.1260
Epoch 21/120
508/508 - 2s - 4ms/step - loss: 0.0270 - val_loss: 0.1265
Epoch 22/120
508/508 - 2s - 4ms/step - loss: 0.0261 - val_loss: 0.1320
Epoch 23/120
508/508 - 2s - 4ms/step - loss: 0.0258 - val_loss: 0.1341
Epoch 24/120
508/508 - 2s - 4ms/step - loss: 0.0258 - val_loss: 0.1361
Epoch 25/120
508/508 - 2s - 4ms/step - loss: 0.0253 - val_loss: 0.1359
Epoch 26/120
508/508 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.1334
Epoch 27/120
508/508 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.1360
Epoch 28/120
508/508 - 2s - 4ms/step - loss: 0.0249 - val_loss: 0.1366
Epoch 29/120
508/508 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.1364
Epoch 30/120
508/508 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.1393
Epoch 31/120
508/508 - 2s - 4ms/step - loss: 0.0240 - val_loss: 0.1361
Epoch 32/120
508/508 - 2s - 4ms/step - loss: 0.0244 - val_loss: 0.1365
Epoch 33/120
508/508 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.1382
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0568
Per-joint RMSE: 0.0538 0.0592 0.0776 0.0462 0.0508 0.0470
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_rmse_time.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2 --H 100 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 0 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:22:54.700317: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:22:54.726495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-4ynbobl9 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:22:55.714089: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.718897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.719727: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.721331: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.722125: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.722862: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.804247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.805118: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.805903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:55.806636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:22:56.113662: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294100e-01  RMSE=3.597360e-01
  per-joint RMSE: 0.4059 0.5436 0.3843 0.2447 0.2334 0.2326
Residual LSTM:  MSE=3.872515e-03      RMSE=6.222954e-02
  per-joint RMSE: 0.0572 0.0732 0.0825 0.0496 0.0517 0.0517
Combined torque MSE=3.872515e-03     RMSE=6.222954e-02
  per-joint RMSE: 0.0572 0.0732 0.0825 0.0496 0.0517 0.0517
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s0_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T lstm bash -lc 'python3 -c '"'"'import runpy
import keras.callbacks as cb
_Orig = cb.ModelCheckpoint

class PatchedModelCheckpoint(_Orig):
    def __init__(self, filepath, *args, **kwargs):
        if isinstance(filepath, str) and (not filepath.endswith('"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"')) and (not filepath.endswith('"'"'"'"'"'"'"'"'.h5'"'"'"'"'"'"'"'"')):
            filepath = filepath + '"'"'"'"'"'"'"'"'.keras'"'"'"'"'"'"'"'"'
        super().__init__(filepath, *args, **kwargs)

cb.ModelCheckpoint = PatchedModelCheckpoint
runpy.run_path('"'"'"'"'"'"'"'"'scripts/train_residual_lstm.py'"'"'"'"'"'"'"'"', run_name='"'"'"'"'"'"'"'"'__main__'"'"'"'"'"'"'"'"')
'"'"' --npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --out_dir /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2 --model_name residual_lstm.keras --epochs 120 --batch 64 --val_split 0.1 --seed 1 --units 128 --dropout 0.2 --eps 1e-08 --early_stop True --early_stop_patience 20 --early_stop_min_delta 0.0 --early_stop_warmup_evals 10 '
2026-01-30 16:22:58.066589: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:22:58.094333: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /.config/matplotlib: [Errno 13] Permission denied: '/.config'
Matplotlib created a temporary cache directory at /tmp/matplotlib-rglw2m0s because there was an issue with the default path (/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
LSTM Residual Dataset:
  npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__lstm_windows_H100__feat_state__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
   H  = 100
  din = 18
 dout = 6
  X_train = (36119, 100, 18), Y_train = (36119, 6)
  X_test  = (6505, 100, 18),  Y_test  = (6505, 6)
################################################

Saved scalers: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz
X mean/std shapes: (18,)/(18,)
Y mean/std shapes: (6,)/(6,)
2026-01-30 16:22:59.649476: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.654176: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.655106: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.656841: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.657623: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.658362: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.749627: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.750631: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.752504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:22:59.753542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9108 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ lstm (LSTM)                     │ (None, 100, 128)       │        75,264 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 100, 128)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 128)            │       131,584 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 128)            │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 6)              │           774 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 207,622 (811.02 KB)
 Trainable params: 207,622 (811.02 KB)
 Non-trainable params: 0 (0.00 B)


Epoch 1/120
2026-01-30 16:23:00.874442: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
508/508 - 4s - 7ms/step - loss: 0.1135 - val_loss: 0.1302
Epoch 2/120
508/508 - 2s - 4ms/step - loss: 0.0588 - val_loss: 0.1328
Epoch 3/120
508/508 - 2s - 4ms/step - loss: 0.0501 - val_loss: 0.1336
Epoch 4/120
508/508 - 2s - 4ms/step - loss: 0.0436 - val_loss: 0.1381
Epoch 5/120
508/508 - 2s - 4ms/step - loss: 0.0407 - val_loss: 0.1332
Epoch 6/120
508/508 - 2s - 4ms/step - loss: 0.0383 - val_loss: 0.1468
Epoch 7/120
508/508 - 2s - 4ms/step - loss: 0.0365 - val_loss: 0.1450
Epoch 8/120
508/508 - 2s - 4ms/step - loss: 0.0350 - val_loss: 0.1545
Epoch 9/120
508/508 - 2s - 4ms/step - loss: 0.0338 - val_loss: 0.1469
Epoch 10/120
508/508 - 2s - 4ms/step - loss: 0.0322 - val_loss: 0.1520
Epoch 11/120
508/508 - 2s - 4ms/step - loss: 0.0308 - val_loss: 0.1512
Epoch 12/120
508/508 - 2s - 4ms/step - loss: 0.0313 - val_loss: 0.1380
Epoch 13/120
508/508 - 2s - 4ms/step - loss: 0.0298 - val_loss: 0.1404
Epoch 14/120
508/508 - 2s - 4ms/step - loss: 0.0288 - val_loss: 0.1473
Epoch 15/120
508/508 - 2s - 4ms/step - loss: 0.0285 - val_loss: 0.1514
Epoch 16/120
508/508 - 2s - 4ms/step - loss: 0.0282 - val_loss: 0.1458
Epoch 17/120
508/508 - 2s - 5ms/step - loss: 0.0274 - val_loss: 0.1431
Epoch 18/120
508/508 - 2s - 4ms/step - loss: 0.0271 - val_loss: 0.1388
Epoch 19/120
508/508 - 2s - 4ms/step - loss: 0.0269 - val_loss: 0.1390
Epoch 20/120
508/508 - 2s - 4ms/step - loss: 0.0263 - val_loss: 0.1395
Epoch 21/120
508/508 - 2s - 4ms/step - loss: 0.0261 - val_loss: 0.1389
Epoch 22/120
508/508 - 2s - 4ms/step - loss: 0.0258 - val_loss: 0.1419
Epoch 23/120
508/508 - 2s - 4ms/step - loss: 0.0255 - val_loss: 0.1399
Epoch 24/120
508/508 - 2s - 4ms/step - loss: 0.0252 - val_loss: 0.1408
Epoch 25/120
508/508 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.1419
Epoch 26/120
508/508 - 2s - 4ms/step - loss: 0.0251 - val_loss: 0.1370
Epoch 27/120
508/508 - 2s - 4ms/step - loss: 0.0248 - val_loss: 0.1350
Epoch 28/120
508/508 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.1355
Epoch 29/120
508/508 - 2s - 4ms/step - loss: 0.0245 - val_loss: 0.1347
Epoch 30/120
508/508 - 2s - 4ms/step - loss: 0.0243 - val_loss: 0.1363
Epoch 31/120
508/508 - 2s - 4ms/step - loss: 0.0243 - val_loss: 0.1347
Epoch 32/120
508/508 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.1388
Epoch 33/120
508/508 - 2s - 4ms/step - loss: 0.0238 - val_loss: 0.1353
Epoch 34/120
508/508 - 2s - 4ms/step - loss: 0.0239 - val_loss: 0.1385
Epoch 35/120
508/508 - 2s - 4ms/step - loss: 0.0237 - val_loss: 0.1315
Epoch 36/120
508/508 - 2s - 4ms/step - loss: 0.0236 - val_loss: 0.1326
Epoch 37/120
508/508 - 2s - 4ms/step - loss: 0.0236 - val_loss: 0.1360
Epoch 38/120
508/508 - 2s - 4ms/step - loss: 0.0231 - val_loss: 0.1326
Epoch 39/120
508/508 - 2s - 4ms/step - loss: 0.0237 - val_loss: 0.1343
Epoch 40/120
508/508 - 2s - 4ms/step - loss: 0.0230 - val_loss: 0.1363
Epoch 41/120
508/508 - 2s - 5ms/step - loss: 0.0229 - val_loss: 0.1341
Epoch 42/120
508/508 - 2s - 4ms/step - loss: 0.0228 - val_loss: 0.1434
Epoch 43/120
508/508 - 2s - 4ms/step - loss: 0.0228 - val_loss: 0.1347
Epoch 44/120
508/508 - 2s - 4ms/step - loss: 0.0229 - val_loss: 0.1362
Epoch 45/120
508/508 - 2s - 4ms/step - loss: 0.0225 - val_loss: 0.1367
Epoch 46/120
508/508 - 2s - 4ms/step - loss: 0.0225 - val_loss: 0.1402
Epoch 47/120
508/508 - 2s - 4ms/step - loss: 0.0224 - val_loss: 0.1320
Epoch 48/120
508/508 - 2s - 4ms/step - loss: 0.0225 - val_loss: 0.1346
Epoch 49/120
508/508 - 2s - 4ms/step - loss: 0.0225 - val_loss: 0.1329
Epoch 50/120
508/508 - 2s - 4ms/step - loss: 0.0222 - val_loss: 0.1282
Epoch 51/120
508/508 - 2s - 4ms/step - loss: 0.0222 - val_loss: 0.1306
Epoch 52/120
508/508 - 2s - 4ms/step - loss: 0.0223 - val_loss: 0.1313
Epoch 53/120
508/508 - 2s - 4ms/step - loss: 0.0221 - val_loss: 0.1271
Epoch 54/120
508/508 - 2s - 4ms/step - loss: 0.0218 - val_loss: 0.1304
Epoch 55/120
508/508 - 2s - 4ms/step - loss: 0.0219 - val_loss: 0.1276
Epoch 56/120
508/508 - 2s - 5ms/step - loss: 0.0218 - val_loss: 0.1295
Epoch 57/120
508/508 - 2s - 5ms/step - loss: 0.0217 - val_loss: 0.1292
Epoch 58/120
508/508 - 2s - 5ms/step - loss: 0.0217 - val_loss: 0.1316
Epoch 59/120
508/508 - 2s - 4ms/step - loss: 0.0215 - val_loss: 0.1275
Epoch 60/120
508/508 - 2s - 5ms/step - loss: 0.0216 - val_loss: 0.1267
Epoch 61/120
508/508 - 2s - 5ms/step - loss: 0.0215 - val_loss: 0.1258
Epoch 62/120
508/508 - 2s - 5ms/step - loss: 0.0215 - val_loss: 0.1272
Epoch 63/120
508/508 - 2s - 5ms/step - loss: 0.0213 - val_loss: 0.1246
Epoch 64/120
508/508 - 2s - 5ms/step - loss: 0.0213 - val_loss: 0.1275
Epoch 65/120
508/508 - 2s - 5ms/step - loss: 0.0213 - val_loss: 0.1257
Epoch 66/120
508/508 - 2s - 4ms/step - loss: 0.0214 - val_loss: 0.1265
Epoch 67/120
508/508 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.1284
Epoch 68/120
508/508 - 2s - 4ms/step - loss: 0.0212 - val_loss: 0.1290
Epoch 69/120
508/508 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1296
Epoch 70/120
508/508 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1255
Epoch 71/120
508/508 - 2s - 4ms/step - loss: 0.0210 - val_loss: 0.1245
Epoch 72/120
508/508 - 2s - 5ms/step - loss: 0.0209 - val_loss: 0.1252
Epoch 73/120
508/508 - 2s - 4ms/step - loss: 0.0207 - val_loss: 0.1240
Epoch 74/120
508/508 - 2s - 4ms/step - loss: 0.0209 - val_loss: 0.1253
Epoch 75/120
508/508 - 2s - 4ms/step - loss: 0.0211 - val_loss: 0.1260
Epoch 76/120
508/508 - 2s - 5ms/step - loss: 0.0209 - val_loss: 0.1304
Epoch 77/120
508/508 - 2s - 4ms/step - loss: 0.0209 - val_loss: 0.1248
Epoch 78/120
508/508 - 2s - 4ms/step - loss: 0.0208 - val_loss: 0.1256
Epoch 79/120
508/508 - 2s - 4ms/step - loss: 0.0205 - val_loss: 0.1267
Epoch 80/120
508/508 - 2s - 4ms/step - loss: 0.0205 - val_loss: 0.1304
Epoch 81/120
508/508 - 2s - 4ms/step - loss: 0.0206 - val_loss: 0.1267
Epoch 82/120
508/508 - 2s - 4ms/step - loss: 0.0207 - val_loss: 0.1251
Epoch 83/120
508/508 - 2s - 4ms/step - loss: 0.0206 - val_loss: 0.1351
Epoch 84/120
508/508 - 2s - 4ms/step - loss: 0.0205 - val_loss: 0.1365
Epoch 85/120
508/508 - 2s - 4ms/step - loss: 0.0203 - val_loss: 0.1388
Epoch 86/120
508/508 - 2s - 4ms/step - loss: 0.0204 - val_loss: 0.1296
Epoch 87/120
508/508 - 2s - 4ms/step - loss: 0.0203 - val_loss: 0.1298
Epoch 88/120
508/508 - 2s - 4ms/step - loss: 0.0201 - val_loss: 0.1337
Epoch 89/120
508/508 - 2s - 4ms/step - loss: 0.0202 - val_loss: 0.1331
Epoch 90/120
508/508 - 2s - 4ms/step - loss: 0.0203 - val_loss: 0.1324
Epoch 91/120
508/508 - 2s - 4ms/step - loss: 0.0201 - val_loss: 0.1312
Epoch 92/120
508/508 - 2s - 4ms/step - loss: 0.0202 - val_loss: 0.1301
Epoch 93/120
508/508 - 2s - 4ms/step - loss: 0.0200 - val_loss: 0.1361
Saved metrics JSON: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_train_test_H100.json

################################################
LSTM Residual Evaluation (test, unscaled units):
Total RMSE: 0.0525
Per-joint RMSE: 0.0538 0.0499 0.0748 0.0409 0.0451 0.0432
################################################

Saved predictions: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/predictions_test.npz
Saved best model:  /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/loss_curve.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_per_joint.png
Saved: /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_rmse_time.png
/home/robat/.venv/ape_sweep/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:4596: RuntimeWarning: invalid value encountered in scalar subtract
  diff_b_a = b - a

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/scalers_H100.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2 --H 100 --split test --features state --save_pred_npz --metrics_csv /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv --metrics_json /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --K 84 --test_fraction 0.2 --seed 1 --dataset_seed 1 --delan_seed -1 --delan_epochs 200 --hp_preset lutter_like_256_wd1e4 --delan_rmse_val 0.5135230657472838 --delan_rmse_test 0.3582080470488492'
2026-01-30 16:26:32.521874: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:26:32.547962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-yqmv_0rh because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 100
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 18
################################################
2026-01-30 16:26:33.537972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.542787: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.543602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.545315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.546108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.546923: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.623460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.624289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.625036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:33.625764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9327 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:26:33.929797: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294100e-01  RMSE=3.597360e-01
  per-joint RMSE: 0.4059 0.5436 0.3843 0.2447 0.2334 0.2326
Residual LSTM:  MSE=2.758205e-03      RMSE=5.251862e-02
  per-joint RMSE: 0.0538 0.0499 0.0748 0.0409 0.0451 0.0432
Combined torque MSE=2.758205e-03     RMSE=5.251862e-02
  per-joint RMSE: 0.0538 0.0499 0.0748 0.0409 0.0451 0.0432
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/metrics_test_H100.json
Appended CSV: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.csv
Appended JSON: /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/combined_predictions_test_H100.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/residual_gt_vs_pred_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_gt_vs_delan_vs_combined_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_per_joint_grouped_test_H100.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_state__lstm_best_s1_H100_ep120_b64_u128_do0p2/torque_rmse_time_test_H100.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/combined_evaluation.py --residual_npz /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz --model /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras --scalers /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/scalers_H50.npz --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best --H 50 --split test --features full --save_pred_npz --K 84 --test_fraction 0.2 --seed 0'
2026-01-30 16:26:35.866100: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-30 16:26:35.892286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-yq32212w because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
################################################
Evaluate & Combine
 residual_npz = /workspace/shared/data/processed/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2/UR3_Load0_5x10^4_under__best5x10L0__K84__residual__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2.npz
 model        = /workspace/shared/models/lstm/best/UR3_Load0_5x10^4_under__best5x10L0__K84__d1__delan_jax_struct_s0_ep200_hp_lutter_like_256_wd1e4_actsoftplus_b1024_lr1e-4_wd1e-4_w256_d2__feat_full__lstm_best_s0_H50_ep120_b64_u128_do0p2/residual_lstm.keras
 split        = test
 H            = 50
 n_traj       = 5
 n_dof        = 6
 feature_dim  = 24
################################################
2026-01-30 16:26:36.896848: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.901692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.902750: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.904413: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.905200: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.905932: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.980739: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.981655: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.982411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2026-01-30 16:26:36.983143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9316 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9
2026-01-30 16:26:37.290216: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906
  done 5/5

################################################
Stage-2 Evaluation (test, valid k>=H-1):
DeLaN torque:   MSE=1.294841e-01  RMSE=3.598391e-01
  per-joint RMSE: 0.4098 0.5424 0.3822 0.2443 0.2329 0.2341
Residual LSTM:  MSE=2.676729e-03      RMSE=5.173711e-02
  per-joint RMSE: 0.0505 0.0528 0.0726 0.0419 0.0486 0.0365
Combined torque MSE=2.676729e-03     RMSE=5.173712e-02
  per-joint RMSE: 0.0505 0.0528 0.0726 0.0419 0.0486 0.0365
################################################

Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/metrics_test_H50.txt
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/metrics_test_H50.json
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/combined_predictions_test_H50.npz
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/residual_gt_vs_pred_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/torque_gt_vs_delan_vs_combined_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/torque_rmse_per_joint_grouped_test_H50.png
Saved: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/best/torque_rmse_time_test_H50.png

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/lstm_best_residual_rmse_aggregate.py --summary_jsonl /workspace/shared/evaluation/summary_lstm_best_runs_20260130_170200.jsonl --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/residual/full --bins 200 --feature full'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-xdc2vsp5 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/lstm_best_residual_rmse_aggregate.py --summary_jsonl /workspace/shared/evaluation/summary_lstm_best_runs_20260130_170200.jsonl --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/residual/state --bins 200 --feature state'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-4ijriwxr because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/lstm_best_combined_torque_rmse_aggregate.py --summary_jsonl /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/combined/full --bins 200 --split test --feature full'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-1yaz9xd9 because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/lstm_best_combined_torque_rmse_aggregate.py --summary_jsonl /workspace/shared/evaluation/summary_lstm_best_combined_20260130_170200.jsonl --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/combined/state --bins 200 --split test --feature state'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-h3r4a_xd because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

docker compose -p payload_estimation --project-directory /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation --env-file /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/.env -f /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/docker-compose.yml exec -T evaluation bash -lc 'python3 scripts/lstm_metrics_boxplots.py --lstm_root /workspace/shared/models/lstm/best --out_dir /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/boxplots'
/workspace/shared/.mplconfig is not a writable directory
Matplotlib created a temporary cache directory at /tmp/matplotlib-pax4uonp because there was an issue with the default path (/workspace/shared/.mplconfig); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:186: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax1.boxplot([groups[k] for k in top_lbl], labels=top_disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:193: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax2.boxplot([groups[k] for k in bot_lbl], labels=bot_disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:186: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax1.boxplot([groups[k] for k in top_lbl], labels=top_disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:193: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax2.boxplot([groups[k] for k in bot_lbl], labels=bot_disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:205: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  plt.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:246: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:246: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:246: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:246: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:246: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:246: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax.boxplot(data, labels=disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:186: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax1.boxplot([groups[k] for k in top_lbl], labels=top_disp, showmeans=True)
/workspace/evaluation/scripts/lstm_metrics_boxplots.py:193: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  ax2.boxplot([groups[k] for k in bot_lbl], labels=bot_disp, showmeans=True)
[lstm_metrics_boxplots] Saved plots to: /workspace/shared/evaluation/lstm_best/UR3_Load0_5x10^4_under__best5x10L0__20260130_170200/boxplots


MASTER LOG: /home/robat/.localgit/algorithmic_payload_estimation/payload_estimation/shared/logs/lstm_best_UR3_Load0_5x10^4_under_best5x10L0_20260130_170200/lstm_best_UR3_Load0_5x10^4_under_best5x10L0_20260130_170200.log
Done.

[2026-01-30 17:26:43] END best_lstm (5x10^4_under): exit_code=0
[2026-01-30 17:26:43] kBestModel^2 finished ok=True
